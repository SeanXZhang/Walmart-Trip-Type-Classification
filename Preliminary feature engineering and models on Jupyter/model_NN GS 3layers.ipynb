{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calendar\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "import re \n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import log_loss, accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"train.csv\").replace(\"MENS WEAR\",\"MENSWEAR\")\n",
    "data_train_orig = pd.read_csv(\"train.csv\").replace(\"MENS WEAR\",\"MENSWEAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dept_list = sorted(list(data_train.DepartmentDescription.dropna().unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekdays = list(calendar.day_name)\n",
    "dept_list_sum = dict.fromkeys(dept_list, np.sum)\n",
    "weekday_dict = dict.fromkeys(weekdays, np.max)\n",
    "feature_dict = {\"TripType\": np.max, 'NumItems': np.sum, 'Return': np.max}\n",
    "feature_dict = {**feature_dict, **weekday_dict, **dept_list_sum}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(data):\n",
    "    dummies = pd.get_dummies(data.Weekday)\n",
    "    data[dummies.columns] = dummies\n",
    "    \n",
    "    dummies = pd.get_dummies(data.DepartmentDescription)\n",
    "    dummies = dummies.apply(lambda x: x*data[\"ScanCount\"])\n",
    "    data[dummies.columns] = dummies \n",
    "\n",
    "    data.loc[data.ScanCount < 0, 'Return'] = 1\n",
    "    data.loc[data.Return != 1, 'Return'] = 0\n",
    "    \n",
    "    data = data.rename(columns={\"ScanCount\":\"NumItems\"})\n",
    "    \n",
    "    grouped = data.groupby(\"VisitNumber\")\n",
    "    grouped = grouped.aggregate(feature_dict)\n",
    "    data = grouped[[\"TripType\", \"NumItems\", \"Return\"] + weekdays + dept_list]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = transform_data(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_category_counts(data):\n",
    "    alist = []\n",
    "    for array in np.asarray(data.loc[:, dept_list[0]:]):\n",
    "        count = 0\n",
    "        count = sum(x > 0 for x in array)\n",
    "        alist.append(count)\n",
    "    cat_counts = pd.DataFrame(alist)\n",
    "    cat_counts = cat_counts.rename(columns={0:\"CategoryCount\"})\n",
    "    cat_counts = cat_counts.set_index(data.index)\n",
    "    data.insert(3, 'CategoryCounts', cat_counts)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new_cat = add_category_counts(data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new_cat.drop('TripType', axis=1)\n",
    "\n",
    "trip_types = sorted(data_new_cat.TripType.unique())\n",
    "trip_types_map = dict(zip(trip_types, np.arange(0, len(trip_types))))\n",
    "y = data_new_cat.TripType.map(trip_types_map)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_3hl(nodes_l1, nodes_l2, nodes_l3, dropout_l1, dropout_l2, dropout_l3):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(output_dim=nodes_l1, activation=\"relu\", input_dim=len(X.columns)))\n",
    "    model.add(Dropout(dropout_l1))\n",
    "    model.add(Dense(output_dim=nodes_l2, activation=\"relu\"))\n",
    "    model.add(Dropout(dropout_l2))\n",
    "    model.add(Dense(output_dim=nodes_l2, activation=\"relu\"))\n",
    "    model.add(Dropout(dropout_l3))\n",
    "            \n",
    "    model.add(Dense(output_dim=len(trip_types), activation=\"softmax\"))\n",
    "    \n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3hl = KerasClassifier(build_fn=create_model_3hl, epochs=70, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_l1 = np.arange(150, 200, 10)\n",
    "nodes_l2 = np.arange(90, 150, 10)\n",
    "nodes_l3 = np.arange(50, 90, 10)\n",
    "\n",
    "dropout_l1 = np.arange(0.1, 0.4, 0.1)\n",
    "dropout_l2 = np.arange(0.1, 0.4, 0.1)\n",
    "dropout_l3 = np.arange(0.1, 0.4, 0.1)\n",
    "batch_size = [500, 1000, 2000, 3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "params3 = dict(nodes_l1=nodes_l1, nodes_l2=nodes_l2, nodes_l3=nodes_l3, \n",
    "               dropout_l1=dropout_l1, dropout_l2=dropout_l2, dropout_l3=dropout_l3, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nodes_l1': array([150, 160, 170, 180, 190]),\n",
       " 'nodes_l2': array([ 90, 100, 110, 120, 130, 140]),\n",
       " 'nodes_l3': array([50, 60, 70, 80]),\n",
       " 'dropout_l1': array([0.1, 0.2, 0.3, 0.4]),\n",
       " 'dropout_l2': array([0.1, 0.2, 0.3, 0.4]),\n",
       " 'dropout_l3': array([0.1, 0.2, 0.3, 0.4]),\n",
       " 'batch_size': [500, 1000, 2000, 3000]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = ['neg_log_loss', 'accuracy']\n",
    "cv = StratifiedKFold(n_splits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "RS3 = RandomizedSearchCV(estimator=model_3hl, param_distributions=params3, cv=cv, n_iter = 30, \n",
    "                         scoring=scoring, refit='accuracy', random_state=42, n_jobs=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=4, random_state=None, shuffle=False),\n",
       "                   error_score='raise-deprecating',\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x0000029833AFA0B8>,\n",
       "                   iid='warn', n_iter=30, n_jobs=1,\n",
       "                   param_distributions={'batch_size': [500, 1000, 2000, 3000],\n",
       "                                        'dropout_l1': array([0.1, 0.2, 0.3, 0.4]),\n",
       "                                        'dropout_l2': array([0.1, 0.2, 0.3, 0.4]),\n",
       "                                        'dropout_l3': array([0.1, 0.2, 0.3, 0.4]),\n",
       "                                        'nodes_l1': array([150, 160, 170, 180, 190]),\n",
       "                                        'nodes_l2': array([ 90, 100, 110, 120, 130, 140]),\n",
       "                                        'nodes_l3': array([50, 60, 70, 80])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit='accuracy',\n",
       "                   return_train_score=False,\n",
       "                   scoring=['neg_log_loss', 'accuracy'], verbose=2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RS3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0905 01:53:35.492754 15156 deprecation_wrapper.py:119] From C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "[CV] nodes_l3=70, nodes_l2=120, nodes_l1=150, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.1, batch_size=3000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=150)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "W0905 01:53:35.529729 15156 deprecation_wrapper.py:119] From C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0905 01:53:35.532727 15156 deprecation_wrapper.py:119] From C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0905 01:53:35.557711 15156 deprecation_wrapper.py:119] From C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0905 01:53:35.568705 15156 deprecation.py:506] From C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "W0905 01:53:35.764356 15156 deprecation_wrapper.py:119] From C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0905 01:53:35.804333 15156 deprecation_wrapper.py:119] From C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0905 01:53:35.966230 15156 deprecation.py:323] From C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 3s - loss: 2.9129 - acc: 0.2682\n",
      "Epoch 2/70\n",
      " - 2s - loss: 2.0276 - acc: 0.4660\n",
      "Epoch 3/70\n",
      " - 2s - loss: 1.6533 - acc: 0.5562\n",
      "Epoch 4/70\n",
      " - 2s - loss: 1.4672 - acc: 0.5953\n",
      "Epoch 5/70\n",
      " - 2s - loss: 1.3614 - acc: 0.6144\n",
      "Epoch 6/70\n",
      " - 2s - loss: 1.2831 - acc: 0.6302\n",
      "Epoch 7/70\n",
      " - 2s - loss: 1.2350 - acc: 0.6359\n",
      "Epoch 8/70\n",
      " - 2s - loss: 1.1923 - acc: 0.6435\n",
      "Epoch 9/70\n",
      " - 2s - loss: 1.1642 - acc: 0.6502\n",
      "Epoch 10/70\n",
      " - 2s - loss: 1.1381 - acc: 0.6530\n",
      "Epoch 11/70\n",
      " - 2s - loss: 1.1224 - acc: 0.6558\n",
      "Epoch 12/70\n",
      " - 2s - loss: 1.1040 - acc: 0.6578\n",
      "Epoch 13/70\n",
      " - 2s - loss: 1.0921 - acc: 0.6602\n",
      "Epoch 14/70\n",
      " - 2s - loss: 1.0791 - acc: 0.6598\n",
      "Epoch 15/70\n",
      " - 2s - loss: 1.0711 - acc: 0.6640\n",
      "Epoch 16/70\n",
      " - 2s - loss: 1.0561 - acc: 0.6669\n",
      "Epoch 17/70\n",
      " - 2s - loss: 1.0420 - acc: 0.6691\n",
      "Epoch 18/70\n",
      " - 2s - loss: 1.0352 - acc: 0.6700\n",
      "Epoch 19/70\n",
      " - 2s - loss: 1.0235 - acc: 0.6727\n",
      "Epoch 20/70\n",
      " - 2s - loss: 1.0228 - acc: 0.6730\n",
      "Epoch 21/70\n",
      " - 2s - loss: 1.0126 - acc: 0.6754\n",
      "Epoch 22/70\n",
      " - 2s - loss: 1.0064 - acc: 0.6759\n",
      "Epoch 23/70\n",
      " - 2s - loss: 1.0045 - acc: 0.6769\n",
      "Epoch 24/70\n",
      " - 2s - loss: 0.9906 - acc: 0.6805\n",
      "Epoch 25/70\n",
      " - 2s - loss: 0.9855 - acc: 0.6821\n",
      "Epoch 26/70\n",
      " - 2s - loss: 0.9821 - acc: 0.6803\n",
      "Epoch 27/70\n",
      " - 2s - loss: 0.9818 - acc: 0.6791\n",
      "Epoch 28/70\n",
      " - 2s - loss: 0.9746 - acc: 0.6829\n",
      "Epoch 29/70\n",
      " - 2s - loss: 0.9681 - acc: 0.6824\n",
      "Epoch 30/70\n",
      " - 2s - loss: 0.9633 - acc: 0.6861\n",
      "Epoch 31/70\n",
      " - 2s - loss: 0.9591 - acc: 0.6850\n",
      "Epoch 32/70\n",
      " - 2s - loss: 0.9540 - acc: 0.6864\n",
      "Epoch 33/70\n",
      " - 2s - loss: 0.9484 - acc: 0.6872\n",
      "Epoch 34/70\n",
      " - 2s - loss: 0.9470 - acc: 0.6871\n",
      "Epoch 35/70\n",
      " - 2s - loss: 0.9462 - acc: 0.6863\n",
      "Epoch 36/70\n",
      " - 2s - loss: 0.9403 - acc: 0.6894\n",
      "Epoch 37/70\n",
      " - 2s - loss: 0.9376 - acc: 0.6900\n",
      "Epoch 38/70\n",
      " - 2s - loss: 0.9322 - acc: 0.6901\n",
      "Epoch 39/70\n",
      " - 2s - loss: 0.9286 - acc: 0.6922\n",
      "Epoch 40/70\n",
      " - 2s - loss: 0.9283 - acc: 0.6923\n",
      "Epoch 41/70\n",
      " - 2s - loss: 0.9227 - acc: 0.6926\n",
      "Epoch 42/70\n",
      " - 2s - loss: 0.9237 - acc: 0.6932\n",
      "Epoch 43/70\n",
      " - 2s - loss: 0.9181 - acc: 0.6936\n",
      "Epoch 44/70\n",
      " - 2s - loss: 0.9131 - acc: 0.6960\n",
      "Epoch 45/70\n",
      " - 2s - loss: 0.9122 - acc: 0.6937\n",
      "Epoch 46/70\n",
      " - 2s - loss: 0.9100 - acc: 0.6938\n",
      "Epoch 47/70\n",
      " - 2s - loss: 0.9075 - acc: 0.6963\n",
      "Epoch 48/70\n",
      " - 2s - loss: 0.9035 - acc: 0.6973\n",
      "Epoch 49/70\n",
      " - 2s - loss: 0.9016 - acc: 0.6976\n",
      "Epoch 50/70\n",
      " - 2s - loss: 0.9012 - acc: 0.6987\n",
      "Epoch 51/70\n",
      " - 2s - loss: 0.8934 - acc: 0.6978\n",
      "Epoch 52/70\n",
      " - 2s - loss: 0.8954 - acc: 0.6986\n",
      "Epoch 53/70\n",
      " - 2s - loss: 0.8909 - acc: 0.7006\n",
      "Epoch 54/70\n",
      " - 2s - loss: 0.8916 - acc: 0.6979\n",
      "Epoch 55/70\n",
      " - 2s - loss: 0.8864 - acc: 0.7002\n",
      "Epoch 56/70\n",
      " - 2s - loss: 0.8869 - acc: 0.7009\n",
      "Epoch 57/70\n",
      " - 2s - loss: 0.8824 - acc: 0.7036\n",
      "Epoch 58/70\n",
      " - 2s - loss: 0.8838 - acc: 0.7014\n",
      "Epoch 59/70\n",
      " - 2s - loss: 0.8793 - acc: 0.7029\n",
      "Epoch 60/70\n",
      " - 2s - loss: 0.8791 - acc: 0.7005\n",
      "Epoch 61/70\n",
      " - 2s - loss: 0.8802 - acc: 0.7014\n",
      "Epoch 62/70\n",
      " - 2s - loss: 0.8743 - acc: 0.7023\n",
      "Epoch 63/70\n",
      " - 2s - loss: 0.8750 - acc: 0.7030\n",
      "Epoch 64/70\n",
      " - 2s - loss: 0.8736 - acc: 0.7028\n",
      "Epoch 65/70\n",
      " - 2s - loss: 0.8699 - acc: 0.7032\n",
      "Epoch 66/70\n",
      " - 2s - loss: 0.8695 - acc: 0.7028\n",
      "Epoch 67/70\n",
      " - 2s - loss: 0.8680 - acc: 0.7041\n",
      "Epoch 68/70\n",
      " - 2s - loss: 0.8687 - acc: 0.7046\n",
      "Epoch 69/70\n",
      " - 2s - loss: 0.8664 - acc: 0.7030\n",
      "Epoch 70/70\n",
      " - 2s - loss: 0.8664 - acc: 0.7055\n",
      "[CV]  nodes_l3=70, nodes_l2=120, nodes_l1=150, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.1, batch_size=3000, total= 2.1min\n",
      "[CV] nodes_l3=70, nodes_l2=120, nodes_l1=150, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.1, batch_size=3000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.1min remaining:    0.0s\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=150)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 2s - loss: 2.9696 - acc: 0.2504\n",
      "Epoch 2/70\n",
      " - 2s - loss: 2.0755 - acc: 0.4514\n",
      "Epoch 3/70\n",
      " - 2s - loss: 1.6744 - acc: 0.5478\n",
      "Epoch 4/70\n",
      " - 2s - loss: 1.4706 - acc: 0.5933\n",
      "Epoch 5/70\n",
      " - 2s - loss: 1.3552 - acc: 0.6162\n",
      "Epoch 6/70\n",
      " - 2s - loss: 1.2798 - acc: 0.6302\n",
      "Epoch 7/70\n",
      " - 2s - loss: 1.2274 - acc: 0.6378\n",
      "Epoch 8/70\n",
      " - 2s - loss: 1.1932 - acc: 0.6441\n",
      "Epoch 9/70\n",
      " - 2s - loss: 1.1634 - acc: 0.6480\n",
      "Epoch 10/70\n",
      " - 2s - loss: 1.1407 - acc: 0.6520\n",
      "Epoch 11/70\n",
      " - 2s - loss: 1.1242 - acc: 0.6538\n",
      "Epoch 12/70\n",
      " - 2s - loss: 1.1101 - acc: 0.6568\n",
      "Epoch 13/70\n",
      " - 2s - loss: 1.0925 - acc: 0.6605\n",
      "Epoch 14/70\n",
      " - 2s - loss: 1.0788 - acc: 0.6642\n",
      "Epoch 15/70\n",
      " - 2s - loss: 1.0686 - acc: 0.6642\n",
      "Epoch 16/70\n",
      " - 2s - loss: 1.0535 - acc: 0.6666\n",
      "Epoch 17/70\n",
      " - 2s - loss: 1.0433 - acc: 0.6695\n",
      "Epoch 18/70\n",
      " - 2s - loss: 1.0410 - acc: 0.6690\n",
      "Epoch 19/70\n",
      " - 2s - loss: 1.0285 - acc: 0.6725\n",
      "Epoch 20/70\n",
      " - 2s - loss: 1.0192 - acc: 0.6760\n",
      "Epoch 21/70\n",
      " - 2s - loss: 1.0119 - acc: 0.6750\n",
      "Epoch 22/70\n",
      " - 2s - loss: 1.0028 - acc: 0.6774\n",
      "Epoch 23/70\n",
      " - 2s - loss: 1.0012 - acc: 0.6771\n",
      "Epoch 24/70\n",
      " - 2s - loss: 0.9952 - acc: 0.6796\n",
      "Epoch 25/70\n",
      " - 2s - loss: 0.9878 - acc: 0.6791\n",
      "Epoch 26/70\n",
      " - 2s - loss: 0.9806 - acc: 0.6818\n",
      "Epoch 27/70\n",
      " - 2s - loss: 0.9780 - acc: 0.6824\n",
      "Epoch 28/70\n",
      " - 2s - loss: 0.9720 - acc: 0.6835\n",
      "Epoch 29/70\n",
      " - 2s - loss: 0.9653 - acc: 0.6824\n",
      "Epoch 30/70\n",
      " - 2s - loss: 0.9600 - acc: 0.6841\n",
      "Epoch 31/70\n",
      " - 2s - loss: 0.9574 - acc: 0.6855\n",
      "Epoch 32/70\n",
      " - 2s - loss: 0.9521 - acc: 0.6869\n",
      "Epoch 33/70\n",
      " - 2s - loss: 0.9497 - acc: 0.6876\n",
      "Epoch 34/70\n",
      " - 2s - loss: 0.9445 - acc: 0.6885\n",
      "Epoch 35/70\n",
      " - 2s - loss: 0.9378 - acc: 0.6894\n",
      "Epoch 36/70\n",
      " - 2s - loss: 0.9398 - acc: 0.6900\n",
      "Epoch 37/70\n",
      " - 2s - loss: 0.9343 - acc: 0.6909\n",
      "Epoch 38/70\n",
      " - 2s - loss: 0.9293 - acc: 0.6929\n",
      "Epoch 39/70\n",
      " - 2s - loss: 0.9239 - acc: 0.6935\n",
      "Epoch 40/70\n",
      " - 2s - loss: 0.9266 - acc: 0.6935\n",
      "Epoch 41/70\n",
      " - 2s - loss: 0.9209 - acc: 0.6946\n",
      "Epoch 42/70\n",
      " - 2s - loss: 0.9174 - acc: 0.6936\n",
      "Epoch 43/70\n",
      " - 2s - loss: 0.9159 - acc: 0.6950\n",
      "Epoch 44/70\n",
      " - 2s - loss: 0.9124 - acc: 0.6955\n",
      "Epoch 45/70\n",
      " - 2s - loss: 0.9105 - acc: 0.6940\n",
      "Epoch 46/70\n",
      " - 2s - loss: 0.9086 - acc: 0.6962\n",
      "Epoch 47/70\n",
      " - 2s - loss: 0.9072 - acc: 0.6965\n",
      "Epoch 48/70\n",
      " - 2s - loss: 0.8992 - acc: 0.6982\n",
      "Epoch 49/70\n",
      " - 2s - loss: 0.9018 - acc: 0.6970\n",
      "Epoch 50/70\n",
      " - 2s - loss: 0.9017 - acc: 0.6973\n",
      "Epoch 51/70\n",
      " - 2s - loss: 0.8945 - acc: 0.6987\n",
      "Epoch 52/70\n",
      " - 2s - loss: 0.8921 - acc: 0.6987\n",
      "Epoch 53/70\n",
      " - 2s - loss: 0.8912 - acc: 0.7004\n",
      "Epoch 54/70\n",
      " - 2s - loss: 0.8919 - acc: 0.7016\n",
      "Epoch 55/70\n",
      " - 2s - loss: 0.8856 - acc: 0.7016\n",
      "Epoch 56/70\n",
      " - 2s - loss: 0.8871 - acc: 0.7018\n",
      "Epoch 57/70\n",
      " - 2s - loss: 0.8834 - acc: 0.7015\n",
      "Epoch 58/70\n",
      " - 2s - loss: 0.8791 - acc: 0.7020\n",
      "Epoch 59/70\n",
      " - 2s - loss: 0.8794 - acc: 0.7023\n",
      "Epoch 60/70\n",
      " - 2s - loss: 0.8797 - acc: 0.7013\n",
      "Epoch 61/70\n",
      " - 2s - loss: 0.8794 - acc: 0.7011\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.8747 - acc: 0.7035\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.8744 - acc: 0.7041\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.8724 - acc: 0.7017\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.8690 - acc: 0.7047\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.8683 - acc: 0.7039\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.8652 - acc: 0.7044\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.8628 - acc: 0.7057\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.8659 - acc: 0.7043\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.8609 - acc: 0.7083\n",
      "[CV]  nodes_l3=70, nodes_l2=120, nodes_l1=150, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.1, batch_size=3000, total= 2.3min\n",
      "[CV] nodes_l3=70, nodes_l2=120, nodes_l1=150, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.1, batch_size=3000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=150)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 3s - loss: 2.8948 - acc: 0.2568\n",
      "Epoch 2/70\n",
      " - 2s - loss: 2.0338 - acc: 0.4624\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.6437 - acc: 0.5595\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.4505 - acc: 0.5976\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.3411 - acc: 0.6174\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.2666 - acc: 0.6321\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.2129 - acc: 0.6417\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.1763 - acc: 0.6464\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.1481 - acc: 0.6516\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.1276 - acc: 0.6545\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.1095 - acc: 0.6583\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.0927 - acc: 0.6607\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.0787 - acc: 0.6639\n",
      "Epoch 14/70\n",
      " - 2s - loss: 1.0645 - acc: 0.6651\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.0523 - acc: 0.6696\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.0397 - acc: 0.6732\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.0311 - acc: 0.6724\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.0276 - acc: 0.6734\n",
      "Epoch 19/70\n",
      " - 2s - loss: 1.0164 - acc: 0.6745\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.0051 - acc: 0.6770\n",
      "Epoch 21/70\n",
      " - 3s - loss: 1.0026 - acc: 0.6772\n",
      "Epoch 22/70\n",
      " - 3s - loss: 0.9950 - acc: 0.6771\n",
      "Epoch 23/70\n",
      " - 3s - loss: 0.9877 - acc: 0.6798\n",
      "Epoch 24/70\n",
      " - 3s - loss: 0.9802 - acc: 0.6812\n",
      "Epoch 25/70\n",
      " - 3s - loss: 0.9728 - acc: 0.6846\n",
      "Epoch 26/70\n",
      " - 3s - loss: 0.9731 - acc: 0.6841\n",
      "Epoch 27/70\n",
      " - 3s - loss: 0.9635 - acc: 0.6829\n",
      "Epoch 28/70\n",
      " - 3s - loss: 0.9605 - acc: 0.6853\n",
      "Epoch 29/70\n",
      " - 3s - loss: 0.9553 - acc: 0.6870\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.9489 - acc: 0.6867\n",
      "Epoch 31/70\n",
      " - 3s - loss: 0.9475 - acc: 0.6881\n",
      "Epoch 32/70\n",
      " - 3s - loss: 0.9392 - acc: 0.6912\n",
      "Epoch 33/70\n",
      " - 3s - loss: 0.9361 - acc: 0.6895\n",
      "Epoch 34/70\n",
      " - 3s - loss: 0.9328 - acc: 0.6916\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9314 - acc: 0.6919\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9277 - acc: 0.6922\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9212 - acc: 0.6944\n",
      "Epoch 38/70\n",
      " - 3s - loss: 0.9220 - acc: 0.6943\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.9181 - acc: 0.6935\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.9136 - acc: 0.6974\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.9098 - acc: 0.6965\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.9086 - acc: 0.6966\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.9048 - acc: 0.6961\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.9007 - acc: 0.6969\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.8965 - acc: 0.7003\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.8969 - acc: 0.6989\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.8911 - acc: 0.6993\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.8905 - acc: 0.7001\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.8913 - acc: 0.6989\n",
      "Epoch 50/70\n",
      " - 3s - loss: 0.8864 - acc: 0.7021\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.8827 - acc: 0.7014\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.8802 - acc: 0.7030\n",
      "Epoch 53/70\n",
      " - 3s - loss: 0.8801 - acc: 0.7022\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.8804 - acc: 0.7015\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.8750 - acc: 0.7024\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.8744 - acc: 0.7037\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.8736 - acc: 0.7037\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.8705 - acc: 0.7038\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.8710 - acc: 0.7037\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.8673 - acc: 0.7050\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.8645 - acc: 0.7066\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.8632 - acc: 0.7049\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.8648 - acc: 0.7053\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.8590 - acc: 0.7073\n",
      "Epoch 65/70\n",
      " - 2s - loss: 0.8605 - acc: 0.7069\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.8593 - acc: 0.7064\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.8570 - acc: 0.7068\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.8566 - acc: 0.7068\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.8533 - acc: 0.7095\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.8528 - acc: 0.7060\n",
      "[CV]  nodes_l3=70, nodes_l2=120, nodes_l1=150, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.1, batch_size=3000, total= 3.3min\n",
      "[CV] nodes_l3=70, nodes_l2=120, nodes_l1=150, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.1, batch_size=3000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=150)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 3s - loss: 2.8746 - acc: 0.2705\n",
      "Epoch 2/70\n",
      " - 3s - loss: 2.0084 - acc: 0.4719\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.6407 - acc: 0.5563\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.4593 - acc: 0.5917\n",
      "Epoch 5/70\n",
      " - 2s - loss: 1.3476 - acc: 0.6170\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.2784 - acc: 0.6284\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.2270 - acc: 0.6365\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.1977 - acc: 0.6422\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.1637 - acc: 0.6476\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.1405 - acc: 0.6519\n",
      "Epoch 11/70\n",
      " - 2s - loss: 1.1227 - acc: 0.6541\n",
      "Epoch 12/70\n",
      " - 2s - loss: 1.1083 - acc: 0.6569\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.0933 - acc: 0.6590\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.0780 - acc: 0.6620\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.0685 - acc: 0.6621\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.0567 - acc: 0.6651\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.0474 - acc: 0.6676\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.0421 - acc: 0.6681\n",
      "Epoch 19/70\n",
      " - 3s - loss: 1.0315 - acc: 0.6715\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.0251 - acc: 0.6696\n",
      "Epoch 21/70\n",
      " - 3s - loss: 1.0141 - acc: 0.6743\n",
      "Epoch 22/70\n",
      " - 3s - loss: 1.0091 - acc: 0.6727\n",
      "Epoch 23/70\n",
      " - 2s - loss: 1.0037 - acc: 0.6754\n",
      "Epoch 24/70\n",
      " - 2s - loss: 0.9967 - acc: 0.6754\n",
      "Epoch 25/70\n",
      " - 3s - loss: 0.9924 - acc: 0.6769\n",
      "Epoch 26/70\n",
      " - 3s - loss: 0.9886 - acc: 0.6802\n",
      "Epoch 27/70\n",
      " - 3s - loss: 0.9817 - acc: 0.6804\n",
      "Epoch 28/70\n",
      " - 3s - loss: 0.9772 - acc: 0.6803\n",
      "Epoch 29/70\n",
      " - 3s - loss: 0.9710 - acc: 0.6822\n",
      "Epoch 30/70\n",
      " - 2s - loss: 0.9635 - acc: 0.6839\n",
      "Epoch 31/70\n",
      " - 3s - loss: 0.9641 - acc: 0.6825\n",
      "Epoch 32/70\n",
      " - 3s - loss: 0.9611 - acc: 0.6834\n",
      "Epoch 33/70\n",
      " - 3s - loss: 0.9551 - acc: 0.6860\n",
      "Epoch 34/70\n",
      " - 3s - loss: 0.9509 - acc: 0.6877\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9492 - acc: 0.6868\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9440 - acc: 0.6861\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9392 - acc: 0.6893\n",
      "Epoch 38/70\n",
      " - 3s - loss: 0.9391 - acc: 0.6874\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.9336 - acc: 0.6881\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.9314 - acc: 0.6899\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.9295 - acc: 0.6891\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.9250 - acc: 0.6918\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.9242 - acc: 0.6918\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.9180 - acc: 0.6936\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.9133 - acc: 0.6945\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.9140 - acc: 0.6929\n",
      "Epoch 47/70\n",
      " - 2s - loss: 0.9119 - acc: 0.6944\n",
      "Epoch 48/70\n",
      " - 2s - loss: 0.9123 - acc: 0.6945\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.9065 - acc: 0.6948\n",
      "Epoch 50/70\n",
      " - 3s - loss: 0.9026 - acc: 0.6968\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.9034 - acc: 0.6969\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.9022 - acc: 0.6956\n",
      "Epoch 53/70\n",
      " - 2s - loss: 0.8985 - acc: 0.6978\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.8967 - acc: 0.6960\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.8971 - acc: 0.6965\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.8895 - acc: 0.6998\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.8935 - acc: 0.6972\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.8881 - acc: 0.6990\n",
      "Epoch 59/70\n",
      " - 2s - loss: 0.8856 - acc: 0.7004\n",
      "Epoch 60/70\n",
      " - 2s - loss: 0.8845 - acc: 0.7004\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.8814 - acc: 0.7005\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.8787 - acc: 0.7021\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.8784 - acc: 0.7022\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.8771 - acc: 0.7020\n",
      "Epoch 65/70\n",
      " - 2s - loss: 0.8752 - acc: 0.7018\n",
      "Epoch 66/70\n",
      " - 2s - loss: 0.8740 - acc: 0.7020\n",
      "Epoch 67/70\n",
      " - 2s - loss: 0.8746 - acc: 0.7022\n",
      "Epoch 68/70\n",
      " - 2s - loss: 0.8706 - acc: 0.7044\n",
      "Epoch 69/70\n",
      " - 2s - loss: 0.8669 - acc: 0.7048\n",
      "Epoch 70/70\n",
      " - 2s - loss: 0.8676 - acc: 0.7051\n",
      "[CV]  nodes_l3=70, nodes_l2=120, nodes_l1=150, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.1, batch_size=3000, total= 3.1min\n",
      "[CV] nodes_l3=80, nodes_l2=90, nodes_l1=180, dropout_l3=0.4, dropout_l2=0.1, dropout_l1=0.1, batch_size=2000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=180)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 2s - loss: 2.8245 - acc: 0.2728\n",
      "Epoch 2/70\n",
      " - 2s - loss: 1.9459 - acc: 0.4811\n",
      "Epoch 3/70\n",
      " - 2s - loss: 1.6031 - acc: 0.5698\n",
      "Epoch 4/70\n",
      " - 2s - loss: 1.4370 - acc: 0.6044\n",
      "Epoch 5/70\n",
      " - 2s - loss: 1.3429 - acc: 0.6221\n",
      "Epoch 6/70\n",
      " - 2s - loss: 1.2767 - acc: 0.6322\n",
      "Epoch 7/70\n",
      " - 2s - loss: 1.2258 - acc: 0.6440\n",
      "Epoch 8/70\n",
      " - 2s - loss: 1.1921 - acc: 0.6464\n",
      "Epoch 9/70\n",
      " - 2s - loss: 1.1666 - acc: 0.6522\n",
      "Epoch 10/70\n",
      " - 2s - loss: 1.1431 - acc: 0.6558\n",
      "Epoch 11/70\n",
      " - 2s - loss: 1.1233 - acc: 0.6608\n",
      "Epoch 12/70\n",
      " - 2s - loss: 1.1075 - acc: 0.6622\n",
      "Epoch 13/70\n",
      " - 2s - loss: 1.0938 - acc: 0.6652\n",
      "Epoch 14/70\n",
      " - 2s - loss: 1.0814 - acc: 0.6654\n",
      "Epoch 15/70\n",
      " - 2s - loss: 1.0703 - acc: 0.6696\n",
      "Epoch 16/70\n",
      " - 2s - loss: 1.0635 - acc: 0.6717\n",
      "Epoch 17/70\n",
      " - 2s - loss: 1.0564 - acc: 0.6729\n",
      "Epoch 18/70\n",
      " - 2s - loss: 1.0425 - acc: 0.6752\n",
      "Epoch 19/70\n",
      " - 2s - loss: 1.0363 - acc: 0.6757\n",
      "Epoch 20/70\n",
      " - 2s - loss: 1.0285 - acc: 0.6767\n",
      "Epoch 21/70\n",
      " - 2s - loss: 1.0199 - acc: 0.6786\n",
      "Epoch 22/70\n",
      " - 2s - loss: 1.0139 - acc: 0.6814\n",
      "Epoch 23/70\n",
      " - 2s - loss: 1.0052 - acc: 0.6820\n",
      "Epoch 24/70\n",
      " - 2s - loss: 0.9997 - acc: 0.6846\n",
      "Epoch 25/70\n",
      " - 2s - loss: 0.9978 - acc: 0.6836\n",
      "Epoch 26/70\n",
      " - 2s - loss: 0.9904 - acc: 0.6850\n",
      "Epoch 27/70\n",
      " - 2s - loss: 0.9824 - acc: 0.6850\n",
      "Epoch 28/70\n",
      " - 2s - loss: 0.9787 - acc: 0.6860\n",
      "Epoch 29/70\n",
      " - 2s - loss: 0.9746 - acc: 0.6878\n",
      "Epoch 30/70\n",
      " - 2s - loss: 0.9711 - acc: 0.6879\n",
      "Epoch 31/70\n",
      " - 2s - loss: 0.9643 - acc: 0.6879\n",
      "Epoch 32/70\n",
      " - 2s - loss: 0.9617 - acc: 0.6904\n",
      "Epoch 33/70\n",
      " - 2s - loss: 0.9596 - acc: 0.6911\n",
      "Epoch 34/70\n",
      " - 2s - loss: 0.9576 - acc: 0.6917\n",
      "Epoch 35/70\n",
      " - 2s - loss: 0.9506 - acc: 0.6927\n",
      "Epoch 36/70\n",
      " - 2s - loss: 0.9502 - acc: 0.6926\n",
      "Epoch 37/70\n",
      " - 2s - loss: 0.9449 - acc: 0.6930\n",
      "Epoch 38/70\n",
      " - 2s - loss: 0.9406 - acc: 0.6966\n",
      "Epoch 39/70\n",
      " - 2s - loss: 0.9417 - acc: 0.6950\n",
      "Epoch 40/70\n",
      " - 2s - loss: 0.9361 - acc: 0.6946\n",
      "Epoch 41/70\n",
      " - 2s - loss: 0.9317 - acc: 0.6973\n",
      "Epoch 42/70\n",
      " - 2s - loss: 0.9315 - acc: 0.6963\n",
      "Epoch 43/70\n",
      " - 2s - loss: 0.9278 - acc: 0.6976\n",
      "Epoch 44/70\n",
      " - 2s - loss: 0.9262 - acc: 0.6987\n",
      "Epoch 45/70\n",
      " - 2s - loss: 0.9237 - acc: 0.6979\n",
      "Epoch 46/70\n",
      " - 2s - loss: 0.9212 - acc: 0.6986\n",
      "Epoch 47/70\n",
      " - 2s - loss: 0.9163 - acc: 0.6995\n",
      "Epoch 48/70\n",
      " - 2s - loss: 0.9182 - acc: 0.6987\n",
      "Epoch 49/70\n",
      " - 2s - loss: 0.9118 - acc: 0.7015\n",
      "Epoch 50/70\n",
      " - 2s - loss: 0.9139 - acc: 0.6978\n",
      "Epoch 51/70\n",
      " - 2s - loss: 0.9069 - acc: 0.7034\n",
      "Epoch 52/70\n",
      " - 2s - loss: 0.9039 - acc: 0.7009\n",
      "Epoch 53/70\n",
      " - 2s - loss: 0.9040 - acc: 0.7016\n",
      "Epoch 54/70\n",
      " - 2s - loss: 0.9029 - acc: 0.7022\n",
      "Epoch 55/70\n",
      " - 2s - loss: 0.9001 - acc: 0.7025\n",
      "Epoch 56/70\n",
      " - 2s - loss: 0.9006 - acc: 0.7041\n",
      "Epoch 57/70\n",
      " - 2s - loss: 0.8960 - acc: 0.7029\n",
      "Epoch 58/70\n",
      " - 2s - loss: 0.8965 - acc: 0.7028\n",
      "Epoch 59/70\n",
      " - 2s - loss: 0.8936 - acc: 0.7035\n",
      "Epoch 60/70\n",
      " - 2s - loss: 0.8913 - acc: 0.7027\n",
      "Epoch 61/70\n",
      " - 2s - loss: 0.8938 - acc: 0.7035\n",
      "Epoch 62/70\n",
      " - 2s - loss: 0.8925 - acc: 0.7034\n",
      "Epoch 63/70\n",
      " - 2s - loss: 0.8888 - acc: 0.7029\n",
      "Epoch 64/70\n",
      " - 2s - loss: 0.8848 - acc: 0.7044\n",
      "Epoch 65/70\n",
      " - 2s - loss: 0.8820 - acc: 0.7049\n",
      "Epoch 66/70\n",
      " - 2s - loss: 0.8844 - acc: 0.7043\n",
      "Epoch 67/70\n",
      " - 2s - loss: 0.8850 - acc: 0.7064\n",
      "Epoch 68/70\n",
      " - 2s - loss: 0.8810 - acc: 0.7060\n",
      "Epoch 69/70\n",
      " - 2s - loss: 0.8795 - acc: 0.7052\n",
      "Epoch 70/70\n",
      " - 2s - loss: 0.8764 - acc: 0.7071\n",
      "[CV]  nodes_l3=80, nodes_l2=90, nodes_l1=180, dropout_l3=0.4, dropout_l2=0.1, dropout_l1=0.1, batch_size=2000, total= 2.1min\n",
      "[CV] nodes_l3=80, nodes_l2=90, nodes_l1=180, dropout_l3=0.4, dropout_l2=0.1, dropout_l1=0.1, batch_size=2000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=180)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 2s - loss: 2.8714 - acc: 0.2679\n",
      "Epoch 2/70\n",
      " - 2s - loss: 1.9908 - acc: 0.4685\n",
      "Epoch 3/70\n",
      " - 2s - loss: 1.6197 - acc: 0.5655\n",
      "Epoch 4/70\n",
      " - 2s - loss: 1.4425 - acc: 0.6037\n",
      "Epoch 5/70\n",
      " - 2s - loss: 1.3397 - acc: 0.6229\n",
      "Epoch 6/70\n",
      " - 2s - loss: 1.2756 - acc: 0.6326\n",
      "Epoch 7/70\n",
      " - 2s - loss: 1.2255 - acc: 0.6446\n",
      "Epoch 8/70\n",
      " - 2s - loss: 1.1896 - acc: 0.6497\n",
      "Epoch 9/70\n",
      " - 2s - loss: 1.1656 - acc: 0.6544\n",
      "Epoch 10/70\n",
      " - 2s - loss: 1.1373 - acc: 0.6596\n",
      "Epoch 11/70\n",
      " - 2s - loss: 1.1248 - acc: 0.6618\n",
      "Epoch 12/70\n",
      " - 2s - loss: 1.1077 - acc: 0.6649\n",
      "Epoch 13/70\n",
      " - 2s - loss: 1.0966 - acc: 0.6661\n",
      "Epoch 14/70\n",
      " - 2s - loss: 1.0778 - acc: 0.6703\n",
      "Epoch 15/70\n",
      " - 2s - loss: 1.0706 - acc: 0.6708\n",
      "Epoch 16/70\n",
      " - 2s - loss: 1.0568 - acc: 0.6742\n",
      "Epoch 17/70\n",
      " - 2s - loss: 1.0480 - acc: 0.6758\n",
      "Epoch 18/70\n",
      " - 2s - loss: 1.0389 - acc: 0.6763\n",
      "Epoch 19/70\n",
      " - 2s - loss: 1.0311 - acc: 0.6783\n",
      "Epoch 20/70\n",
      " - 2s - loss: 1.0246 - acc: 0.6795\n",
      "Epoch 21/70\n",
      " - 2s - loss: 1.0194 - acc: 0.6825\n",
      "Epoch 22/70\n",
      " - 2s - loss: 1.0095 - acc: 0.6824\n",
      "Epoch 23/70\n",
      " - 2s - loss: 1.0023 - acc: 0.6841\n",
      "Epoch 24/70\n",
      " - 2s - loss: 0.9954 - acc: 0.6834\n",
      "Epoch 25/70\n",
      " - 2s - loss: 0.9907 - acc: 0.6856\n",
      "Epoch 26/70\n",
      " - 2s - loss: 0.9855 - acc: 0.6870\n",
      "Epoch 27/70\n",
      " - 2s - loss: 0.9783 - acc: 0.6876\n",
      "Epoch 28/70\n",
      " - 2s - loss: 0.9736 - acc: 0.6888\n",
      "Epoch 29/70\n",
      " - 2s - loss: 0.9697 - acc: 0.6907\n",
      "Epoch 30/70\n",
      " - 2s - loss: 0.9677 - acc: 0.6893\n",
      "Epoch 31/70\n",
      " - 2s - loss: 0.9641 - acc: 0.6904\n",
      "Epoch 32/70\n",
      " - 2s - loss: 0.9584 - acc: 0.6918\n",
      "Epoch 33/70\n",
      " - 2s - loss: 0.9522 - acc: 0.6932\n",
      "Epoch 34/70\n",
      " - 2s - loss: 0.9531 - acc: 0.6907\n",
      "Epoch 35/70\n",
      " - 2s - loss: 0.9471 - acc: 0.6921\n",
      "Epoch 36/70\n",
      " - 2s - loss: 0.9433 - acc: 0.6950\n",
      "Epoch 37/70\n",
      " - 2s - loss: 0.9434 - acc: 0.6943\n",
      "Epoch 38/70\n",
      " - 2s - loss: 0.9353 - acc: 0.6944\n",
      "Epoch 39/70\n",
      " - 2s - loss: 0.9306 - acc: 0.6964\n",
      "Epoch 40/70\n",
      " - 2s - loss: 0.9307 - acc: 0.6969\n",
      "Epoch 41/70\n",
      " - 2s - loss: 0.9288 - acc: 0.6959\n",
      "Epoch 42/70\n",
      " - 2s - loss: 0.9267 - acc: 0.6995\n",
      "Epoch 43/70\n",
      " - 2s - loss: 0.9244 - acc: 0.6974\n",
      "Epoch 44/70\n",
      " - 2s - loss: 0.9223 - acc: 0.6988\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.9188 - acc: 0.6982\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.9188 - acc: 0.6979\n",
      "Epoch 47/70\n",
      " - 2s - loss: 0.9132 - acc: 0.6997\n",
      "Epoch 48/70\n",
      " - 2s - loss: 0.9118 - acc: 0.6996\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.9097 - acc: 0.7016\n",
      "Epoch 50/70\n",
      " - 3s - loss: 0.9042 - acc: 0.7017\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.9036 - acc: 0.7014\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.9026 - acc: 0.7027\n",
      "Epoch 53/70\n",
      " - 3s - loss: 0.8989 - acc: 0.7025\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.8990 - acc: 0.7023\n",
      "Epoch 55/70\n",
      " - 4s - loss: 0.8969 - acc: 0.7028\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.8954 - acc: 0.7029\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.8918 - acc: 0.7042\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.8926 - acc: 0.7043\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.8903 - acc: 0.7035\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.8876 - acc: 0.7055\n",
      "Epoch 61/70\n",
      " - 4s - loss: 0.8890 - acc: 0.7032\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.8874 - acc: 0.7037\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.8825 - acc: 0.7053\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.8837 - acc: 0.7028\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.8815 - acc: 0.7074\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.8795 - acc: 0.7065\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.8753 - acc: 0.7072\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.8797 - acc: 0.7067\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.8770 - acc: 0.7070\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.8741 - acc: 0.7075\n",
      "[CV]  nodes_l3=80, nodes_l2=90, nodes_l1=180, dropout_l3=0.4, dropout_l2=0.1, dropout_l1=0.1, batch_size=2000, total= 2.6min\n",
      "[CV] nodes_l3=80, nodes_l2=90, nodes_l1=180, dropout_l3=0.4, dropout_l2=0.1, dropout_l1=0.1, batch_size=2000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=180)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 4s - loss: 2.8760 - acc: 0.2757\n",
      "Epoch 2/70\n",
      " - 3s - loss: 1.9530 - acc: 0.4801\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.5947 - acc: 0.5699\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.4217 - acc: 0.6053\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.3240 - acc: 0.6254\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.2575 - acc: 0.6379\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.2121 - acc: 0.6446\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.1807 - acc: 0.6500\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.1568 - acc: 0.6533\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.1328 - acc: 0.6591\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.1170 - acc: 0.6628\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.1028 - acc: 0.6620\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.0888 - acc: 0.6669\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.0758 - acc: 0.6673\n",
      "Epoch 15/70\n",
      " - 2s - loss: 1.0663 - acc: 0.6693\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.0523 - acc: 0.6726\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.0437 - acc: 0.6750\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.0339 - acc: 0.6770\n",
      "Epoch 19/70\n",
      " - 3s - loss: 1.0269 - acc: 0.6783\n",
      "Epoch 20/70\n",
      " - 2s - loss: 1.0190 - acc: 0.6790\n",
      "Epoch 21/70\n",
      " - 2s - loss: 1.0158 - acc: 0.6780\n",
      "Epoch 22/70\n",
      " - 3s - loss: 1.0065 - acc: 0.6820\n",
      "Epoch 23/70\n",
      " - 3s - loss: 1.0015 - acc: 0.6837\n",
      "Epoch 24/70\n",
      " - 3s - loss: 0.9934 - acc: 0.6832\n",
      "Epoch 25/70\n",
      " - 2s - loss: 0.9877 - acc: 0.6841\n",
      "Epoch 26/70\n",
      " - 2s - loss: 0.9810 - acc: 0.6851\n",
      "Epoch 27/70\n",
      " - 2s - loss: 0.9754 - acc: 0.6880\n",
      "Epoch 28/70\n",
      " - 2s - loss: 0.9721 - acc: 0.6886\n",
      "Epoch 29/70\n",
      " - 2s - loss: 0.9689 - acc: 0.6881\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.9657 - acc: 0.6884\n",
      "Epoch 31/70\n",
      " - 3s - loss: 0.9596 - acc: 0.6907\n",
      "Epoch 32/70\n",
      " - 3s - loss: 0.9537 - acc: 0.6913\n",
      "Epoch 33/70\n",
      " - 2s - loss: 0.9536 - acc: 0.6900\n",
      "Epoch 34/70\n",
      " - 2s - loss: 0.9464 - acc: 0.6935\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9394 - acc: 0.6940\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9363 - acc: 0.6953\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9367 - acc: 0.6957\n",
      "Epoch 38/70\n",
      " - 2s - loss: 0.9319 - acc: 0.6964\n",
      "Epoch 39/70\n",
      " - 2s - loss: 0.9298 - acc: 0.6956\n",
      "Epoch 40/70\n",
      " - 2s - loss: 0.9290 - acc: 0.6957\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.9262 - acc: 0.6976\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.9216 - acc: 0.6991\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.9195 - acc: 0.6994\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.9133 - acc: 0.6986\n",
      "Epoch 45/70\n",
      " - 2s - loss: 0.9146 - acc: 0.6993\n",
      "Epoch 46/70\n",
      " - 2s - loss: 0.9105 - acc: 0.6998\n",
      "Epoch 47/70\n",
      " - 2s - loss: 0.9079 - acc: 0.6997\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.9055 - acc: 0.7009\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.9030 - acc: 0.7017\n",
      "Epoch 50/70\n",
      " - 3s - loss: 0.9018 - acc: 0.7018\n",
      "Epoch 51/70\n",
      " - 2s - loss: 0.9001 - acc: 0.7005\n",
      "Epoch 52/70\n",
      " - 2s - loss: 0.8961 - acc: 0.7038\n",
      "Epoch 53/70\n",
      " - 3s - loss: 0.8940 - acc: 0.7040\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.8954 - acc: 0.7015\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.8932 - acc: 0.7030\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.8889 - acc: 0.7045\n",
      "Epoch 57/70\n",
      " - 2s - loss: 0.8879 - acc: 0.7030\n",
      "Epoch 58/70\n",
      " - 2s - loss: 0.8866 - acc: 0.7050\n",
      "Epoch 59/70\n",
      " - 2s - loss: 0.8844 - acc: 0.7059\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.8842 - acc: 0.7051\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.8796 - acc: 0.7059\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.8781 - acc: 0.7047\n",
      "Epoch 63/70\n",
      " - 2s - loss: 0.8759 - acc: 0.7060\n",
      "Epoch 64/70\n",
      " - 2s - loss: 0.8789 - acc: 0.7066\n",
      "Epoch 65/70\n",
      " - 2s - loss: 0.8712 - acc: 0.7069\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.8718 - acc: 0.7065\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.8716 - acc: 0.7060\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.8690 - acc: 0.7094\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.8700 - acc: 0.7088\n",
      "Epoch 70/70\n",
      " - 2s - loss: 0.8655 - acc: 0.7076\n",
      "[CV]  nodes_l3=80, nodes_l2=90, nodes_l1=180, dropout_l3=0.4, dropout_l2=0.1, dropout_l1=0.1, batch_size=2000, total= 3.1min\n",
      "[CV] nodes_l3=80, nodes_l2=90, nodes_l1=180, dropout_l3=0.4, dropout_l2=0.1, dropout_l1=0.1, batch_size=2000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=180)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 5s - loss: 2.8172 - acc: 0.2737\n",
      "Epoch 2/70\n",
      " - 3s - loss: 1.9449 - acc: 0.4832\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.6159 - acc: 0.5630\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.4522 - acc: 0.5971\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.3545 - acc: 0.6178\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.2849 - acc: 0.6304\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.2433 - acc: 0.6358\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.2050 - acc: 0.6432\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.1757 - acc: 0.6479\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.1555 - acc: 0.6524\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.1360 - acc: 0.6533\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.1190 - acc: 0.6567\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.1014 - acc: 0.6620\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.0884 - acc: 0.6636\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.0821 - acc: 0.6667\n",
      "Epoch 16/70\n",
      " - 2s - loss: 1.0697 - acc: 0.6686\n",
      "Epoch 17/70\n",
      " - 2s - loss: 1.0622 - acc: 0.6675\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.0520 - acc: 0.6703\n",
      "Epoch 19/70\n",
      " - 3s - loss: 1.0443 - acc: 0.6733\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.0323 - acc: 0.6749\n",
      "Epoch 21/70\n",
      " - 3s - loss: 1.0263 - acc: 0.6760\n",
      "Epoch 22/70\n",
      " - 3s - loss: 1.0234 - acc: 0.6777\n",
      "Epoch 23/70\n",
      " - 3s - loss: 1.0137 - acc: 0.6786\n",
      "Epoch 24/70\n",
      " - 3s - loss: 1.0058 - acc: 0.6804\n",
      "Epoch 25/70\n",
      " - 3s - loss: 1.0059 - acc: 0.6801\n",
      "Epoch 26/70\n",
      " - 3s - loss: 0.9988 - acc: 0.6807\n",
      "Epoch 27/70\n",
      " - 3s - loss: 0.9933 - acc: 0.6821\n",
      "Epoch 28/70\n",
      " - 3s - loss: 0.9879 - acc: 0.6848\n",
      "Epoch 29/70\n",
      " - 3s - loss: 0.9814 - acc: 0.6851\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.9813 - acc: 0.6850\n",
      "Epoch 31/70\n",
      " - 3s - loss: 0.9708 - acc: 0.6867\n",
      "Epoch 32/70\n",
      " - 3s - loss: 0.9712 - acc: 0.6869\n",
      "Epoch 33/70\n",
      " - 2s - loss: 0.9650 - acc: 0.6884\n",
      "Epoch 34/70\n",
      " - 2s - loss: 0.9608 - acc: 0.6883\n",
      "Epoch 35/70\n",
      " - 2s - loss: 0.9604 - acc: 0.6882\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9560 - acc: 0.6907\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9501 - acc: 0.6891\n",
      "Epoch 38/70\n",
      " - 3s - loss: 0.9489 - acc: 0.6907\n",
      "Epoch 39/70\n",
      " - 2s - loss: 0.9479 - acc: 0.6906\n",
      "Epoch 40/70\n",
      " - 2s - loss: 0.9457 - acc: 0.6912\n",
      "Epoch 41/70\n",
      " - 2s - loss: 0.9411 - acc: 0.6930\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.9375 - acc: 0.6945\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.9370 - acc: 0.6924\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.9353 - acc: 0.6946\n",
      "Epoch 45/70\n",
      " - 2s - loss: 0.9298 - acc: 0.6946\n",
      "Epoch 46/70\n",
      " - 2s - loss: 0.9248 - acc: 0.6951\n",
      "Epoch 47/70\n",
      " - 2s - loss: 0.9276 - acc: 0.6950\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.9214 - acc: 0.6964\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.9223 - acc: 0.6961\n",
      "Epoch 50/70\n",
      " - 3s - loss: 0.9205 - acc: 0.6975\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.9159 - acc: 0.6975\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.9158 - acc: 0.6976\n",
      "Epoch 53/70\n",
      " - 2s - loss: 0.9137 - acc: 0.6987\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.9102 - acc: 0.6978\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.9078 - acc: 0.7000\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.9077 - acc: 0.6999\n",
      "Epoch 57/70\n",
      " - 2s - loss: 0.9072 - acc: 0.6993\n",
      "Epoch 58/70\n",
      " - 2s - loss: 0.9050 - acc: 0.6993\n",
      "Epoch 59/70\n",
      " - 2s - loss: 0.9024 - acc: 0.7002\n",
      "Epoch 60/70\n",
      " - 2s - loss: 0.9000 - acc: 0.6987\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.8975 - acc: 0.7002\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.8990 - acc: 0.7010\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.8952 - acc: 0.7000\n",
      "Epoch 64/70\n",
      " - 2s - loss: 0.8948 - acc: 0.7012\n",
      "Epoch 65/70\n",
      " - 2s - loss: 0.8971 - acc: 0.7005\n",
      "Epoch 66/70\n",
      " - 2s - loss: 0.8886 - acc: 0.7027\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.8913 - acc: 0.7024\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.8884 - acc: 0.7016\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.8899 - acc: 0.7040\n",
      "Epoch 70/70\n",
      " - 2s - loss: 0.8876 - acc: 0.7021\n",
      "[CV]  nodes_l3=80, nodes_l2=90, nodes_l1=180, dropout_l3=0.4, dropout_l2=0.1, dropout_l1=0.1, batch_size=2000, total= 3.2min\n",
      "[CV] nodes_l3=50, nodes_l2=140, nodes_l1=150, dropout_l3=0.4, dropout_l2=0.2, dropout_l1=0.1, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=150)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=140)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=140)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 3s - loss: 2.0359 - acc: 0.4587\n",
      "Epoch 2/70\n",
      " - 2s - loss: 1.3364 - acc: 0.6222\n",
      "Epoch 3/70\n",
      " - 2s - loss: 1.1998 - acc: 0.6453\n",
      "Epoch 4/70\n",
      " - 2s - loss: 1.1342 - acc: 0.6553\n",
      "Epoch 5/70\n",
      " - 2s - loss: 1.0965 - acc: 0.6644\n",
      "Epoch 6/70\n",
      " - 2s - loss: 1.0675 - acc: 0.6690\n",
      "Epoch 7/70\n",
      " - 2s - loss: 1.0475 - acc: 0.6730\n",
      "Epoch 8/70\n",
      " - 2s - loss: 1.0224 - acc: 0.6769\n",
      "Epoch 9/70\n",
      " - 2s - loss: 1.0100 - acc: 0.6810\n",
      "Epoch 10/70\n",
      " - 2s - loss: 0.9973 - acc: 0.6814\n",
      "Epoch 11/70\n",
      " - 2s - loss: 0.9843 - acc: 0.6836\n",
      "Epoch 12/70\n",
      " - 2s - loss: 0.9766 - acc: 0.6861\n",
      "Epoch 13/70\n",
      " - 2s - loss: 0.9634 - acc: 0.6895\n",
      "Epoch 14/70\n",
      " - 2s - loss: 0.9539 - acc: 0.6913\n",
      "Epoch 15/70\n",
      " - 2s - loss: 0.9477 - acc: 0.6912\n",
      "Epoch 16/70\n",
      " - 2s - loss: 0.9453 - acc: 0.6930\n",
      "Epoch 17/70\n",
      " - 2s - loss: 0.9331 - acc: 0.6950\n",
      "Epoch 18/70\n",
      " - 2s - loss: 0.9290 - acc: 0.6948\n",
      "Epoch 19/70\n",
      " - 2s - loss: 0.9219 - acc: 0.6965\n",
      "Epoch 20/70\n",
      " - 2s - loss: 0.9179 - acc: 0.6979\n",
      "Epoch 21/70\n",
      " - 2s - loss: 0.9134 - acc: 0.6979\n",
      "Epoch 22/70\n",
      " - 2s - loss: 0.9065 - acc: 0.7011\n",
      "Epoch 23/70\n",
      " - 2s - loss: 0.9057 - acc: 0.7003\n",
      "Epoch 24/70\n",
      " - 2s - loss: 0.9008 - acc: 0.7010\n",
      "Epoch 25/70\n",
      " - 2s - loss: 0.8971 - acc: 0.7007\n",
      "Epoch 26/70\n",
      " - 2s - loss: 0.8907 - acc: 0.7031\n",
      "Epoch 27/70\n",
      " - 2s - loss: 0.8911 - acc: 0.7032\n",
      "Epoch 28/70\n",
      " - 2s - loss: 0.8867 - acc: 0.7033\n",
      "Epoch 29/70\n",
      " - 2s - loss: 0.8857 - acc: 0.7044\n",
      "Epoch 30/70\n",
      " - 2s - loss: 0.8820 - acc: 0.7046\n",
      "Epoch 31/70\n",
      " - 2s - loss: 0.8800 - acc: 0.7042\n",
      "Epoch 32/70\n",
      " - 2s - loss: 0.8794 - acc: 0.7043\n",
      "Epoch 33/70\n",
      " - 2s - loss: 0.8751 - acc: 0.7057\n",
      "Epoch 34/70\n",
      " - 2s - loss: 0.8765 - acc: 0.7048\n",
      "Epoch 35/70\n",
      " - 2s - loss: 0.8696 - acc: 0.7074\n",
      "Epoch 36/70\n",
      " - 2s - loss: 0.8697 - acc: 0.7075\n",
      "Epoch 37/70\n",
      " - 2s - loss: 0.8649 - acc: 0.7064\n",
      "Epoch 38/70\n",
      " - 2s - loss: 0.8641 - acc: 0.7083\n",
      "Epoch 39/70\n",
      " - 2s - loss: 0.8640 - acc: 0.7080\n",
      "Epoch 40/70\n",
      " - 2s - loss: 0.8632 - acc: 0.7076\n",
      "Epoch 41/70\n",
      " - 2s - loss: 0.8586 - acc: 0.7093\n",
      "Epoch 42/70\n",
      " - 2s - loss: 0.8561 - acc: 0.7098\n",
      "Epoch 43/70\n",
      " - 2s - loss: 0.8548 - acc: 0.7110\n",
      "Epoch 44/70\n",
      " - 2s - loss: 0.8563 - acc: 0.7108\n",
      "Epoch 45/70\n",
      " - 2s - loss: 0.8524 - acc: 0.7116\n",
      "Epoch 46/70\n",
      " - 2s - loss: 0.8498 - acc: 0.7123\n",
      "Epoch 47/70\n",
      " - 2s - loss: 0.8502 - acc: 0.7116\n",
      "Epoch 48/70\n",
      " - 2s - loss: 0.8501 - acc: 0.7108\n",
      "Epoch 49/70\n",
      " - 2s - loss: 0.8449 - acc: 0.7125\n",
      "Epoch 50/70\n",
      " - 2s - loss: 0.8471 - acc: 0.7127\n",
      "Epoch 51/70\n",
      " - 2s - loss: 0.8433 - acc: 0.7145\n",
      "Epoch 52/70\n",
      " - 2s - loss: 0.8440 - acc: 0.7137\n",
      "Epoch 53/70\n",
      " - 2s - loss: 0.8426 - acc: 0.7128\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.8424 - acc: 0.7127\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.8415 - acc: 0.7136\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.8411 - acc: 0.7129\n",
      "Epoch 57/70\n",
      " - 2s - loss: 0.8348 - acc: 0.7136\n",
      "Epoch 58/70\n",
      " - 2s - loss: 0.8351 - acc: 0.7146\n",
      "Epoch 59/70\n",
      " - 2s - loss: 0.8346 - acc: 0.7148\n",
      "Epoch 60/70\n",
      " - 2s - loss: 0.8325 - acc: 0.7153\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.8331 - acc: 0.7150\n",
      "Epoch 62/70\n",
      " - 2s - loss: 0.8316 - acc: 0.7154\n",
      "Epoch 63/70\n",
      " - 2s - loss: 0.8287 - acc: 0.7156\n",
      "Epoch 64/70\n",
      " - 2s - loss: 0.8320 - acc: 0.7177\n",
      "Epoch 65/70\n",
      " - 2s - loss: 0.8321 - acc: 0.7156\n",
      "Epoch 66/70\n",
      " - 2s - loss: 0.8312 - acc: 0.7163\n",
      "Epoch 67/70\n",
      " - 2s - loss: 0.8310 - acc: 0.7175\n",
      "Epoch 68/70\n",
      " - 2s - loss: 0.8273 - acc: 0.7164\n",
      "Epoch 69/70\n",
      " - 2s - loss: 0.8280 - acc: 0.7164\n",
      "Epoch 70/70\n",
      " - 2s - loss: 0.8234 - acc: 0.7167\n",
      "[CV]  nodes_l3=50, nodes_l2=140, nodes_l1=150, dropout_l3=0.4, dropout_l2=0.2, dropout_l1=0.1, batch_size=500, total= 2.6min\n",
      "[CV] nodes_l3=50, nodes_l2=140, nodes_l1=150, dropout_l3=0.4, dropout_l2=0.2, dropout_l1=0.1, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=150)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=140)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=140)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 3s - loss: 2.0448 - acc: 0.4549\n",
      "Epoch 2/70\n",
      " - 2s - loss: 1.3303 - acc: 0.6226\n",
      "Epoch 3/70\n",
      " - 2s - loss: 1.1919 - acc: 0.6464\n",
      "Epoch 4/70\n",
      " - 2s - loss: 1.1273 - acc: 0.6566\n",
      "Epoch 5/70\n",
      " - 2s - loss: 1.0927 - acc: 0.6616\n",
      "Epoch 6/70\n",
      " - 2s - loss: 1.0685 - acc: 0.6677\n",
      "Epoch 7/70\n",
      " - 2s - loss: 1.0423 - acc: 0.6727\n",
      "Epoch 8/70\n",
      " - 2s - loss: 1.0228 - acc: 0.6780\n",
      "Epoch 9/70\n",
      " - 2s - loss: 1.0078 - acc: 0.6802\n",
      "Epoch 10/70\n",
      " - 2s - loss: 0.9946 - acc: 0.6817\n",
      "Epoch 11/70\n",
      " - 2s - loss: 0.9797 - acc: 0.6858\n",
      "Epoch 12/70\n",
      " - 2s - loss: 0.9706 - acc: 0.6878\n",
      "Epoch 13/70\n",
      " - 2s - loss: 0.9614 - acc: 0.6894\n",
      "Epoch 14/70\n",
      " - 2s - loss: 0.9498 - acc: 0.6911\n",
      "Epoch 15/70\n",
      " - 2s - loss: 0.9420 - acc: 0.6921\n",
      "Epoch 16/70\n",
      " - 2s - loss: 0.9361 - acc: 0.6954\n",
      "Epoch 17/70\n",
      " - 2s - loss: 0.9307 - acc: 0.6963\n",
      "Epoch 18/70\n",
      " - 2s - loss: 0.9266 - acc: 0.6966\n",
      "Epoch 19/70\n",
      " - 3s - loss: 0.9196 - acc: 0.6967\n",
      "Epoch 20/70\n",
      " - 3s - loss: 0.9173 - acc: 0.6968\n",
      "Epoch 21/70\n",
      " - 3s - loss: 0.9155 - acc: 0.6986\n",
      "Epoch 22/70\n",
      " - 3s - loss: 0.9100 - acc: 0.6991\n",
      "Epoch 23/70\n",
      " - 3s - loss: 0.9063 - acc: 0.6993\n",
      "Epoch 24/70\n",
      " - 3s - loss: 0.9026 - acc: 0.7007\n",
      "Epoch 25/70\n",
      " - 4s - loss: 0.8970 - acc: 0.7026\n",
      "Epoch 26/70\n",
      " - 3s - loss: 0.8964 - acc: 0.7014\n",
      "Epoch 27/70\n",
      " - 3s - loss: 0.8931 - acc: 0.7007\n",
      "Epoch 28/70\n",
      " - 4s - loss: 0.8852 - acc: 0.7046\n",
      "Epoch 29/70\n",
      " - 4s - loss: 0.8838 - acc: 0.7039\n",
      "Epoch 30/70\n",
      " - 4s - loss: 0.8833 - acc: 0.7047\n",
      "Epoch 31/70\n",
      " - 4s - loss: 0.8819 - acc: 0.7035\n",
      "Epoch 32/70\n",
      " - 3s - loss: 0.8765 - acc: 0.7037\n",
      "Epoch 33/70\n",
      " - 4s - loss: 0.8763 - acc: 0.7064\n",
      "Epoch 34/70\n",
      " - 4s - loss: 0.8732 - acc: 0.7055\n",
      "Epoch 35/70\n",
      " - 4s - loss: 0.8698 - acc: 0.7070\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.8676 - acc: 0.7071\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.8672 - acc: 0.7066\n",
      "Epoch 38/70\n",
      " - 4s - loss: 0.8643 - acc: 0.7072\n",
      "Epoch 39/70\n",
      " - 4s - loss: 0.8647 - acc: 0.7084\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.8613 - acc: 0.7093\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.8613 - acc: 0.7086\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.8576 - acc: 0.7092\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.8580 - acc: 0.7089\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.8564 - acc: 0.7111\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.8532 - acc: 0.7118\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.8485 - acc: 0.7107\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.8491 - acc: 0.7111\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.8509 - acc: 0.7104\n",
      "Epoch 49/70\n",
      " - 4s - loss: 0.8480 - acc: 0.7133\n",
      "Epoch 50/70\n",
      " - 3s - loss: 0.8455 - acc: 0.7131\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.8449 - acc: 0.7112\n",
      "Epoch 52/70\n",
      " - 4s - loss: 0.8422 - acc: 0.7126\n",
      "Epoch 53/70\n",
      " - 4s - loss: 0.8438 - acc: 0.7115\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.8433 - acc: 0.7111\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.8408 - acc: 0.7129\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.8418 - acc: 0.7143\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.8408 - acc: 0.7123\n",
      "Epoch 58/70\n",
      " - 4s - loss: 0.8365 - acc: 0.7148\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.8398 - acc: 0.7131\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.8371 - acc: 0.7162\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.8384 - acc: 0.7137\n",
      "Epoch 62/70\n",
      " - 4s - loss: 0.8369 - acc: 0.7152\n",
      "Epoch 63/70\n",
      " - 4s - loss: 0.8359 - acc: 0.7145\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.8350 - acc: 0.7142\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.8322 - acc: 0.7147\n",
      "Epoch 66/70\n",
      " - 4s - loss: 0.8331 - acc: 0.7156\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.8316 - acc: 0.7167\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.8314 - acc: 0.7157\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.8294 - acc: 0.7153\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.8293 - acc: 0.7157\n",
      "[CV]  nodes_l3=50, nodes_l2=140, nodes_l1=150, dropout_l3=0.4, dropout_l2=0.2, dropout_l1=0.1, batch_size=500, total= 3.6min\n",
      "[CV] nodes_l3=50, nodes_l2=140, nodes_l1=150, dropout_l3=0.4, dropout_l2=0.2, dropout_l1=0.1, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=150)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=140)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=140)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 5s - loss: 2.0281 - acc: 0.4565\n",
      "Epoch 2/70\n",
      " - 3s - loss: 1.3348 - acc: 0.6206\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.1985 - acc: 0.6476\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.1308 - acc: 0.6559\n",
      "Epoch 5/70\n",
      " - 4s - loss: 1.0889 - acc: 0.6642\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.0592 - acc: 0.6706\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.0348 - acc: 0.6739\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.0179 - acc: 0.6796\n",
      "Epoch 9/70\n",
      " - 3s - loss: 0.9946 - acc: 0.6815\n",
      "Epoch 10/70\n",
      " - 3s - loss: 0.9830 - acc: 0.6861\n",
      "Epoch 11/70\n",
      " - 3s - loss: 0.9683 - acc: 0.6885\n",
      "Epoch 12/70\n",
      " - 3s - loss: 0.9611 - acc: 0.6883\n",
      "Epoch 13/70\n",
      " - 3s - loss: 0.9523 - acc: 0.6919\n",
      "Epoch 14/70\n",
      " - 3s - loss: 0.9442 - acc: 0.6940\n",
      "Epoch 15/70\n",
      " - 3s - loss: 0.9382 - acc: 0.6956\n",
      "Epoch 16/70\n",
      " - 3s - loss: 0.9282 - acc: 0.6964\n",
      "Epoch 17/70\n",
      " - 3s - loss: 0.9210 - acc: 0.6971\n",
      "Epoch 18/70\n",
      " - 3s - loss: 0.9186 - acc: 0.6969\n",
      "Epoch 19/70\n",
      " - 4s - loss: 0.9105 - acc: 0.6995\n",
      "Epoch 20/70\n",
      " - 4s - loss: 0.9068 - acc: 0.7010\n",
      "Epoch 21/70\n",
      " - 3s - loss: 0.9005 - acc: 0.7029\n",
      "Epoch 22/70\n",
      " - 3s - loss: 0.8988 - acc: 0.7020\n",
      "Epoch 23/70\n",
      " - 3s - loss: 0.8955 - acc: 0.7020\n",
      "Epoch 24/70\n",
      " - 3s - loss: 0.8898 - acc: 0.7024\n",
      "Epoch 25/70\n",
      " - 3s - loss: 0.8880 - acc: 0.7056\n",
      "Epoch 26/70\n",
      " - 3s - loss: 0.8805 - acc: 0.7058\n",
      "Epoch 27/70\n",
      " - 3s - loss: 0.8785 - acc: 0.7047\n",
      "Epoch 28/70\n",
      " - 3s - loss: 0.8750 - acc: 0.7066\n",
      "Epoch 29/70\n",
      " - 4s - loss: 0.8712 - acc: 0.7080\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.8684 - acc: 0.7084\n",
      "Epoch 31/70\n",
      " - 3s - loss: 0.8668 - acc: 0.7101\n",
      "Epoch 32/70\n",
      " - 3s - loss: 0.8663 - acc: 0.7087\n",
      "Epoch 33/70\n",
      " - 3s - loss: 0.8618 - acc: 0.7102\n",
      "Epoch 34/70\n",
      " - 4s - loss: 0.8624 - acc: 0.7085\n",
      "Epoch 35/70\n",
      " - 4s - loss: 0.8563 - acc: 0.7107\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.8565 - acc: 0.7114\n",
      "Epoch 37/70\n",
      " - 2s - loss: 0.8556 - acc: 0.7111\n",
      "Epoch 38/70\n",
      " - 2s - loss: 0.8539 - acc: 0.7117\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.8520 - acc: 0.7113\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.8505 - acc: 0.7121\n",
      "Epoch 41/70\n",
      " - 2s - loss: 0.8499 - acc: 0.7122\n",
      "Epoch 42/70\n",
      " - 2s - loss: 0.8469 - acc: 0.7123\n",
      "Epoch 43/70\n",
      " - 2s - loss: 0.8453 - acc: 0.7110\n",
      "Epoch 44/70\n",
      " - 2s - loss: 0.8411 - acc: 0.7143\n",
      "Epoch 45/70\n",
      " - 2s - loss: 0.8413 - acc: 0.7129\n",
      "Epoch 46/70\n",
      " - 2s - loss: 0.8395 - acc: 0.7139\n",
      "Epoch 47/70\n",
      " - 2s - loss: 0.8425 - acc: 0.7132\n",
      "Epoch 48/70\n",
      " - 2s - loss: 0.8400 - acc: 0.7125\n",
      "Epoch 49/70\n",
      " - 2s - loss: 0.8360 - acc: 0.7153\n",
      "Epoch 50/70\n",
      " - 2s - loss: 0.8355 - acc: 0.7147\n",
      "Epoch 51/70\n",
      " - 2s - loss: 0.8331 - acc: 0.7148\n",
      "Epoch 52/70\n",
      " - 2s - loss: 0.8335 - acc: 0.7157\n",
      "Epoch 53/70\n",
      " - 2s - loss: 0.8304 - acc: 0.7164\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.8291 - acc: 0.7159\n",
      "Epoch 55/70\n",
      " - 2s - loss: 0.8327 - acc: 0.7158\n",
      "Epoch 56/70\n",
      " - 2s - loss: 0.8284 - acc: 0.7153\n",
      "Epoch 57/70\n",
      " - 2s - loss: 0.8230 - acc: 0.7177\n",
      "Epoch 58/70\n",
      " - 2s - loss: 0.8238 - acc: 0.7181\n",
      "Epoch 59/70\n",
      " - 2s - loss: 0.8272 - acc: 0.7156\n",
      "Epoch 60/70\n",
      " - 2s - loss: 0.8281 - acc: 0.7153\n",
      "Epoch 61/70\n",
      " - 2s - loss: 0.8285 - acc: 0.7176\n",
      "Epoch 62/70\n",
      " - 2s - loss: 0.8209 - acc: 0.7180\n",
      "Epoch 63/70\n",
      " - 2s - loss: 0.8228 - acc: 0.7184\n",
      "Epoch 64/70\n",
      " - 2s - loss: 0.8234 - acc: 0.7169\n",
      "Epoch 65/70\n",
      " - 2s - loss: 0.8230 - acc: 0.7174\n",
      "Epoch 66/70\n",
      " - 2s - loss: 0.8205 - acc: 0.7179\n",
      "Epoch 67/70\n",
      " - 2s - loss: 0.8217 - acc: 0.7179\n",
      "Epoch 68/70\n",
      " - 2s - loss: 0.8184 - acc: 0.7191\n",
      "Epoch 69/70\n",
      " - 2s - loss: 0.8206 - acc: 0.7170\n",
      "Epoch 70/70\n",
      " - 2s - loss: 0.8186 - acc: 0.7199\n",
      "[CV]  nodes_l3=50, nodes_l2=140, nodes_l1=150, dropout_l3=0.4, dropout_l2=0.2, dropout_l1=0.1, batch_size=500, total= 3.3min\n",
      "[CV] nodes_l3=50, nodes_l2=140, nodes_l1=150, dropout_l3=0.4, dropout_l2=0.2, dropout_l1=0.1, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=150)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=140)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=140)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 3s - loss: 2.0428 - acc: 0.4596\n",
      "Epoch 2/70\n",
      " - 2s - loss: 1.3391 - acc: 0.6177\n",
      "Epoch 3/70\n",
      " - 2s - loss: 1.1968 - acc: 0.6443\n",
      "Epoch 4/70\n",
      " - 2s - loss: 1.1410 - acc: 0.6542\n",
      "Epoch 5/70\n",
      " - 2s - loss: 1.0952 - acc: 0.6632\n",
      "Epoch 6/70\n",
      " - 2s - loss: 1.0707 - acc: 0.6665\n",
      "Epoch 7/70\n",
      " - 2s - loss: 1.0458 - acc: 0.6710\n",
      "Epoch 8/70\n",
      " - 2s - loss: 1.0266 - acc: 0.6747\n",
      "Epoch 9/70\n",
      " - 2s - loss: 1.0068 - acc: 0.6777\n",
      "Epoch 10/70\n",
      " - 2s - loss: 0.9963 - acc: 0.6810\n",
      "Epoch 11/70\n",
      " - 2s - loss: 0.9849 - acc: 0.6832\n",
      "Epoch 12/70\n",
      " - 2s - loss: 0.9759 - acc: 0.6852\n",
      "Epoch 13/70\n",
      " - 2s - loss: 0.9629 - acc: 0.6876\n",
      "Epoch 14/70\n",
      " - 2s - loss: 0.9542 - acc: 0.6897\n",
      "Epoch 15/70\n",
      " - 2s - loss: 0.9485 - acc: 0.6897\n",
      "Epoch 16/70\n",
      " - 2s - loss: 0.9401 - acc: 0.6928\n",
      "Epoch 17/70\n",
      " - 2s - loss: 0.9353 - acc: 0.6929\n",
      "Epoch 18/70\n",
      " - 2s - loss: 0.9296 - acc: 0.6944\n",
      "Epoch 19/70\n",
      " - 2s - loss: 0.9248 - acc: 0.6951\n",
      "Epoch 20/70\n",
      " - 2s - loss: 0.9196 - acc: 0.6962\n",
      "Epoch 21/70\n",
      " - 2s - loss: 0.9154 - acc: 0.6974\n",
      "Epoch 22/70\n",
      " - 2s - loss: 0.9114 - acc: 0.6984\n",
      "Epoch 23/70\n",
      " - 2s - loss: 0.9080 - acc: 0.6980\n",
      "Epoch 24/70\n",
      " - 2s - loss: 0.9045 - acc: 0.6978\n",
      "Epoch 25/70\n",
      " - 2s - loss: 0.9031 - acc: 0.6999\n",
      "Epoch 26/70\n",
      " - 2s - loss: 0.8960 - acc: 0.6999\n",
      "Epoch 27/70\n",
      " - 2s - loss: 0.8933 - acc: 0.7025\n",
      "Epoch 28/70\n",
      " - 2s - loss: 0.8892 - acc: 0.7004\n",
      "Epoch 29/70\n",
      " - 2s - loss: 0.8903 - acc: 0.7011\n",
      "Epoch 30/70\n",
      " - 2s - loss: 0.8862 - acc: 0.7021\n",
      "Epoch 31/70\n",
      " - 2s - loss: 0.8849 - acc: 0.7016\n",
      "Epoch 32/70\n",
      " - 2s - loss: 0.8813 - acc: 0.7038\n",
      "Epoch 33/70\n",
      " - 3s - loss: 0.8772 - acc: 0.7043\n",
      "Epoch 34/70\n",
      " - 2s - loss: 0.8750 - acc: 0.7047\n",
      "Epoch 35/70\n",
      " - 2s - loss: 0.8737 - acc: 0.7058\n",
      "Epoch 36/70\n",
      " - 2s - loss: 0.8696 - acc: 0.7057\n",
      "Epoch 37/70\n",
      " - 2s - loss: 0.8725 - acc: 0.7058\n",
      "Epoch 38/70\n",
      " - 2s - loss: 0.8658 - acc: 0.7047\n",
      "Epoch 39/70\n",
      " - 2s - loss: 0.8687 - acc: 0.7057\n",
      "Epoch 40/70\n",
      " - 2s - loss: 0.8639 - acc: 0.7081\n",
      "Epoch 41/70\n",
      " - 2s - loss: 0.8632 - acc: 0.7083\n",
      "Epoch 42/70\n",
      " - 2s - loss: 0.8587 - acc: 0.7081\n",
      "Epoch 43/70\n",
      " - 2s - loss: 0.8617 - acc: 0.7073\n",
      "Epoch 44/70\n",
      " - 2s - loss: 0.8574 - acc: 0.7090\n",
      "Epoch 45/70\n",
      " - 2s - loss: 0.8555 - acc: 0.7078\n",
      "Epoch 46/70\n",
      " - 2s - loss: 0.8519 - acc: 0.7094\n",
      "Epoch 47/70\n",
      " - 2s - loss: 0.8544 - acc: 0.7087\n",
      "Epoch 48/70\n",
      " - 2s - loss: 0.8536 - acc: 0.7086\n",
      "Epoch 49/70\n",
      " - 2s - loss: 0.8527 - acc: 0.7109\n",
      "Epoch 50/70\n",
      " - 2s - loss: 0.8502 - acc: 0.7118\n",
      "Epoch 51/70\n",
      " - 2s - loss: 0.8465 - acc: 0.7118\n",
      "Epoch 52/70\n",
      " - 2s - loss: 0.8424 - acc: 0.7129\n",
      "Epoch 53/70\n",
      " - 2s - loss: 0.8470 - acc: 0.7102\n",
      "Epoch 54/70\n",
      " - 2s - loss: 0.8426 - acc: 0.7118\n",
      "Epoch 55/70\n",
      " - 2s - loss: 0.8440 - acc: 0.7124\n",
      "Epoch 56/70\n",
      " - 2s - loss: 0.8395 - acc: 0.7131\n",
      "Epoch 57/70\n",
      " - 2s - loss: 0.8427 - acc: 0.7123\n",
      "Epoch 58/70\n",
      " - 2s - loss: 0.8391 - acc: 0.7135\n",
      "Epoch 59/70\n",
      " - 2s - loss: 0.8394 - acc: 0.7128\n",
      "Epoch 60/70\n",
      " - 2s - loss: 0.8412 - acc: 0.7127\n",
      "Epoch 61/70\n",
      " - 2s - loss: 0.8363 - acc: 0.7133\n",
      "Epoch 62/70\n",
      " - 2s - loss: 0.8375 - acc: 0.7129\n",
      "Epoch 63/70\n",
      " - 2s - loss: 0.8364 - acc: 0.7133\n",
      "Epoch 64/70\n",
      " - 2s - loss: 0.8381 - acc: 0.7129\n",
      "Epoch 65/70\n",
      " - 2s - loss: 0.8337 - acc: 0.7137\n",
      "Epoch 66/70\n",
      " - 2s - loss: 0.8357 - acc: 0.7142\n",
      "Epoch 67/70\n",
      " - 2s - loss: 0.8337 - acc: 0.7135\n",
      "Epoch 68/70\n",
      " - 2s - loss: 0.8358 - acc: 0.7146\n",
      "Epoch 69/70\n",
      " - 2s - loss: 0.8326 - acc: 0.7142\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.8306 - acc: 0.7154\n",
      "[CV]  nodes_l3=50, nodes_l2=140, nodes_l1=150, dropout_l3=0.4, dropout_l2=0.2, dropout_l1=0.1, batch_size=500, total= 2.6min\n",
      "[CV] nodes_l3=70, nodes_l2=120, nodes_l1=190, dropout_l3=0.1, dropout_l2=0.4, dropout_l1=0.30000000000000004, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=190)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 3s - loss: 2.1677 - acc: 0.4197\n",
      "Epoch 2/70\n",
      " - 2s - loss: 1.4130 - acc: 0.6007\n",
      "Epoch 3/70\n",
      " - 2s - loss: 1.2596 - acc: 0.6314\n",
      "Epoch 4/70\n",
      " - 2s - loss: 1.1902 - acc: 0.6440\n",
      "Epoch 5/70\n",
      " - 2s - loss: 1.1505 - acc: 0.6514\n",
      "Epoch 6/70\n",
      " - 2s - loss: 1.1204 - acc: 0.6566\n",
      "Epoch 7/70\n",
      " - 2s - loss: 1.0988 - acc: 0.6612\n",
      "Epoch 8/70\n",
      " - 2s - loss: 1.0822 - acc: 0.6650\n",
      "Epoch 9/70\n",
      " - 2s - loss: 1.0608 - acc: 0.6692\n",
      "Epoch 10/70\n",
      " - 2s - loss: 1.0516 - acc: 0.6698\n",
      "Epoch 11/70\n",
      " - 2s - loss: 1.0379 - acc: 0.6732\n",
      "Epoch 12/70\n",
      " - 2s - loss: 1.0264 - acc: 0.6773\n",
      "Epoch 13/70\n",
      " - 2s - loss: 1.0152 - acc: 0.6783\n",
      "Epoch 14/70\n",
      " - 2s - loss: 1.0086 - acc: 0.6796\n",
      "Epoch 15/70\n",
      " - 2s - loss: 1.0020 - acc: 0.6793\n",
      "Epoch 16/70\n",
      " - 2s - loss: 0.9902 - acc: 0.6825\n",
      "Epoch 17/70\n",
      " - 2s - loss: 0.9831 - acc: 0.6840\n",
      "Epoch 18/70\n",
      " - 2s - loss: 0.9792 - acc: 0.6831\n",
      "Epoch 19/70\n",
      " - 4s - loss: 0.9737 - acc: 0.6860\n",
      "Epoch 20/70\n",
      " - 4s - loss: 0.9683 - acc: 0.6859\n",
      "Epoch 21/70\n",
      " - 3s - loss: 0.9666 - acc: 0.6878\n",
      "Epoch 22/70\n",
      " - 3s - loss: 0.9574 - acc: 0.6903\n",
      "Epoch 23/70\n",
      " - 3s - loss: 0.9581 - acc: 0.6905\n",
      "Epoch 24/70\n",
      " - 4s - loss: 0.9537 - acc: 0.6883\n",
      "Epoch 25/70\n",
      " - 3s - loss: 0.9516 - acc: 0.6917\n",
      "Epoch 26/70\n",
      " - 3s - loss: 0.9463 - acc: 0.6905\n",
      "Epoch 27/70\n",
      " - 3s - loss: 0.9453 - acc: 0.6927\n",
      "Epoch 28/70\n",
      " - 3s - loss: 0.9410 - acc: 0.6911\n",
      "Epoch 29/70\n",
      " - 3s - loss: 0.9383 - acc: 0.6927\n",
      "Epoch 30/70\n",
      " - 4s - loss: 0.9343 - acc: 0.6955\n",
      "Epoch 31/70\n",
      " - 3s - loss: 0.9359 - acc: 0.6933\n",
      "Epoch 32/70\n",
      " - 3s - loss: 0.9307 - acc: 0.6956\n",
      "Epoch 33/70\n",
      " - 3s - loss: 0.9286 - acc: 0.6956\n",
      "Epoch 34/70\n",
      " - 4s - loss: 0.9249 - acc: 0.6965\n",
      "Epoch 35/70\n",
      " - 4s - loss: 0.9235 - acc: 0.6967\n",
      "Epoch 36/70\n",
      " - 4s - loss: 0.9238 - acc: 0.6971\n",
      "Epoch 37/70\n",
      " - 4s - loss: 0.9217 - acc: 0.6969\n",
      "Epoch 38/70\n",
      " - 4s - loss: 0.9194 - acc: 0.6991\n",
      "Epoch 39/70\n",
      " - 4s - loss: 0.9173 - acc: 0.6977\n",
      "Epoch 40/70\n",
      " - 4s - loss: 0.9125 - acc: 0.6981\n",
      "Epoch 41/70\n",
      " - 4s - loss: 0.9102 - acc: 0.6994\n",
      "Epoch 42/70\n",
      " - 4s - loss: 0.9115 - acc: 0.6977\n",
      "Epoch 43/70\n",
      " - 4s - loss: 0.9112 - acc: 0.6993\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.9087 - acc: 0.6999\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.9081 - acc: 0.7009\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.9053 - acc: 0.7012\n",
      "Epoch 47/70\n",
      " - 4s - loss: 0.9071 - acc: 0.7008\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.9016 - acc: 0.7011\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.8982 - acc: 0.7020\n",
      "Epoch 50/70\n",
      " - 3s - loss: 0.9009 - acc: 0.7013\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.8974 - acc: 0.7033\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.8992 - acc: 0.7023\n",
      "Epoch 53/70\n",
      " - 4s - loss: 0.8969 - acc: 0.7035\n",
      "Epoch 54/70\n",
      " - 4s - loss: 0.8973 - acc: 0.7043\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.8965 - acc: 0.7028\n",
      "Epoch 56/70\n",
      " - 4s - loss: 0.8958 - acc: 0.7043\n",
      "Epoch 57/70\n",
      " - 4s - loss: 0.8923 - acc: 0.7055\n",
      "Epoch 58/70\n",
      " - 4s - loss: 0.8908 - acc: 0.7043\n",
      "Epoch 59/70\n",
      " - 4s - loss: 0.8908 - acc: 0.7031\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.8929 - acc: 0.7037\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.8885 - acc: 0.7046\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.8906 - acc: 0.7046\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.8887 - acc: 0.7052\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.8874 - acc: 0.7054\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.8855 - acc: 0.7074\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.8892 - acc: 0.7042\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.8855 - acc: 0.7073\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.8860 - acc: 0.7063\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.8847 - acc: 0.7053\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.8836 - acc: 0.7068\n",
      "[CV]  nodes_l3=70, nodes_l2=120, nodes_l1=190, dropout_l3=0.1, dropout_l2=0.4, dropout_l1=0.30000000000000004, batch_size=500, total= 3.7min\n",
      "[CV] nodes_l3=70, nodes_l2=120, nodes_l1=190, dropout_l3=0.1, dropout_l2=0.4, dropout_l1=0.30000000000000004, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=190)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 6s - loss: 2.1027 - acc: 0.4386\n",
      "Epoch 2/70\n",
      " - 2s - loss: 1.4057 - acc: 0.6011\n",
      "Epoch 3/70\n",
      " - 2s - loss: 1.2550 - acc: 0.6315\n",
      "Epoch 4/70\n",
      " - 2s - loss: 1.1938 - acc: 0.6425\n",
      "Epoch 5/70\n",
      " - 2s - loss: 1.1537 - acc: 0.6494\n",
      "Epoch 6/70\n",
      " - 2s - loss: 1.1152 - acc: 0.6580\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.1009 - acc: 0.6589\n",
      "Epoch 8/70\n",
      " - 2s - loss: 1.0795 - acc: 0.6649\n",
      "Epoch 9/70\n",
      " - 2s - loss: 1.0657 - acc: 0.6666\n",
      "Epoch 10/70\n",
      " - 2s - loss: 1.0526 - acc: 0.6706\n",
      "Epoch 11/70\n",
      " - 2s - loss: 1.0330 - acc: 0.6744\n",
      "Epoch 12/70\n",
      " - 2s - loss: 1.0256 - acc: 0.6727\n",
      "Epoch 13/70\n",
      " - 2s - loss: 1.0140 - acc: 0.6781\n",
      "Epoch 14/70\n",
      " - 2s - loss: 1.0110 - acc: 0.6772\n",
      "Epoch 15/70\n",
      " - 2s - loss: 1.0034 - acc: 0.6802\n",
      "Epoch 16/70\n",
      " - 2s - loss: 0.9961 - acc: 0.6822\n",
      "Epoch 17/70\n",
      " - 2s - loss: 0.9881 - acc: 0.6843\n",
      "Epoch 18/70\n",
      " - 2s - loss: 0.9811 - acc: 0.6851\n",
      "Epoch 19/70\n",
      " - 2s - loss: 0.9754 - acc: 0.6850\n",
      "Epoch 20/70\n",
      " - 2s - loss: 0.9722 - acc: 0.6872\n",
      "Epoch 21/70\n",
      " - 2s - loss: 0.9632 - acc: 0.6869\n",
      "Epoch 22/70\n",
      " - 2s - loss: 0.9626 - acc: 0.6877\n",
      "Epoch 23/70\n",
      " - 2s - loss: 0.9592 - acc: 0.6880\n",
      "Epoch 24/70\n",
      " - 2s - loss: 0.9581 - acc: 0.6890\n",
      "Epoch 25/70\n",
      " - 2s - loss: 0.9507 - acc: 0.6908\n",
      "Epoch 26/70\n",
      " - 2s - loss: 0.9481 - acc: 0.6905\n",
      "Epoch 27/70\n",
      " - 2s - loss: 0.9413 - acc: 0.6943\n",
      "Epoch 28/70\n",
      " - 2s - loss: 0.9440 - acc: 0.6929\n",
      "Epoch 29/70\n",
      " - 2s - loss: 0.9390 - acc: 0.6938\n",
      "Epoch 30/70\n",
      " - 2s - loss: 0.9377 - acc: 0.6963\n",
      "Epoch 31/70\n",
      " - 2s - loss: 0.9326 - acc: 0.6959\n",
      "Epoch 32/70\n",
      " - 2s - loss: 0.9282 - acc: 0.6955\n",
      "Epoch 33/70\n",
      " - 2s - loss: 0.9279 - acc: 0.6956\n",
      "Epoch 34/70\n",
      " - 2s - loss: 0.9287 - acc: 0.6959\n",
      "Epoch 35/70\n",
      " - 2s - loss: 0.9239 - acc: 0.6963\n",
      "Epoch 36/70\n",
      " - 2s - loss: 0.9219 - acc: 0.6971\n",
      "Epoch 37/70\n",
      " - 2s - loss: 0.9213 - acc: 0.6989\n",
      "Epoch 38/70\n",
      " - 2s - loss: 0.9193 - acc: 0.6994\n",
      "Epoch 39/70\n",
      " - 2s - loss: 0.9159 - acc: 0.6976\n",
      "Epoch 40/70\n",
      " - 2s - loss: 0.9157 - acc: 0.6990\n",
      "Epoch 41/70\n",
      " - 2s - loss: 0.9158 - acc: 0.6999\n",
      "Epoch 42/70\n",
      " - 2s - loss: 0.9088 - acc: 0.7002\n",
      "Epoch 43/70\n",
      " - 2s - loss: 0.9129 - acc: 0.7000\n",
      "Epoch 44/70\n",
      " - 2s - loss: 0.9091 - acc: 0.6989\n",
      "Epoch 45/70\n",
      " - 2s - loss: 0.9065 - acc: 0.7010\n",
      "Epoch 46/70\n",
      " - 2s - loss: 0.9030 - acc: 0.7025\n",
      "Epoch 47/70\n",
      " - 2s - loss: 0.9066 - acc: 0.7020\n",
      "Epoch 48/70\n",
      " - 2s - loss: 0.9016 - acc: 0.7025\n",
      "Epoch 49/70\n",
      " - 2s - loss: 0.8992 - acc: 0.7018\n",
      "Epoch 50/70\n",
      " - 2s - loss: 0.9025 - acc: 0.7017\n",
      "Epoch 51/70\n",
      " - 2s - loss: 0.8982 - acc: 0.7036\n",
      "Epoch 52/70\n",
      " - 2s - loss: 0.9015 - acc: 0.7040\n",
      "Epoch 53/70\n",
      " - 2s - loss: 0.9007 - acc: 0.7023\n",
      "Epoch 54/70\n",
      " - 2s - loss: 0.8964 - acc: 0.7042\n",
      "Epoch 55/70\n",
      " - 2s - loss: 0.8958 - acc: 0.7017\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.8970 - acc: 0.7037\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.8968 - acc: 0.7032\n",
      "Epoch 58/70\n",
      " - 2s - loss: 0.8909 - acc: 0.7049\n",
      "Epoch 59/70\n",
      " - 2s - loss: 0.8947 - acc: 0.7030\n",
      "Epoch 60/70\n",
      " - 2s - loss: 0.8969 - acc: 0.7037\n",
      "Epoch 61/70\n",
      " - 2s - loss: 0.8876 - acc: 0.7058\n",
      "Epoch 62/70\n",
      " - 2s - loss: 0.8907 - acc: 0.7059\n",
      "Epoch 63/70\n",
      " - 2s - loss: 0.8914 - acc: 0.7042\n",
      "Epoch 64/70\n",
      " - 2s - loss: 0.8851 - acc: 0.7056\n",
      "Epoch 65/70\n",
      " - 2s - loss: 0.8892 - acc: 0.7068\n",
      "Epoch 66/70\n",
      " - 2s - loss: 0.8861 - acc: 0.7068\n",
      "Epoch 67/70\n",
      " - 2s - loss: 0.8837 - acc: 0.7071\n",
      "Epoch 68/70\n",
      " - 2s - loss: 0.8845 - acc: 0.7067\n",
      "Epoch 69/70\n",
      " - 2s - loss: 0.8862 - acc: 0.7064\n",
      "Epoch 70/70\n",
      " - 2s - loss: 0.8854 - acc: 0.7060\n",
      "[CV]  nodes_l3=70, nodes_l2=120, nodes_l1=190, dropout_l3=0.1, dropout_l2=0.4, dropout_l1=0.30000000000000004, batch_size=500, total= 2.7min\n",
      "[CV] nodes_l3=70, nodes_l2=120, nodes_l1=190, dropout_l3=0.1, dropout_l2=0.4, dropout_l1=0.30000000000000004, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=190)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 3s - loss: 2.1755 - acc: 0.4184\n",
      "Epoch 2/70\n",
      " - 2s - loss: 1.4092 - acc: 0.6034\n",
      "Epoch 3/70\n",
      " - 2s - loss: 1.2570 - acc: 0.6336\n",
      "Epoch 4/70\n",
      " - 2s - loss: 1.1867 - acc: 0.6462\n",
      "Epoch 5/70\n",
      " - 2s - loss: 1.1400 - acc: 0.6553\n",
      "Epoch 6/70\n",
      " - 2s - loss: 1.1091 - acc: 0.6587\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.0874 - acc: 0.6630\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.0704 - acc: 0.6662\n",
      "Epoch 9/70\n",
      " - 2s - loss: 1.0531 - acc: 0.6707\n",
      "Epoch 10/70\n",
      " - 2s - loss: 1.0388 - acc: 0.6729\n",
      "Epoch 11/70\n",
      " - 2s - loss: 1.0270 - acc: 0.6758\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.0177 - acc: 0.6767\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.0034 - acc: 0.6815\n",
      "Epoch 14/70\n",
      " - 3s - loss: 0.9975 - acc: 0.6828\n",
      "Epoch 15/70\n",
      " - 2s - loss: 0.9875 - acc: 0.6824\n",
      "Epoch 16/70\n",
      " - 2s - loss: 0.9810 - acc: 0.6846\n",
      "Epoch 17/70\n",
      " - 2s - loss: 0.9750 - acc: 0.6873\n",
      "Epoch 18/70\n",
      " - 2s - loss: 0.9652 - acc: 0.6883\n",
      "Epoch 19/70\n",
      " - 3s - loss: 0.9635 - acc: 0.6895\n",
      "Epoch 20/70\n",
      " - 3s - loss: 0.9584 - acc: 0.6890\n",
      "Epoch 21/70\n",
      " - 3s - loss: 0.9504 - acc: 0.6926\n",
      "Epoch 22/70\n",
      " - 4s - loss: 0.9498 - acc: 0.6910\n",
      "Epoch 23/70\n",
      " - 4s - loss: 0.9433 - acc: 0.6927\n",
      "Epoch 24/70\n",
      " - 4s - loss: 0.9431 - acc: 0.6939\n",
      "Epoch 25/70\n",
      " - 21601s - loss: 0.9378 - acc: 0.6944\n",
      "Epoch 26/70\n",
      " - 3s - loss: 0.9340 - acc: 0.6951\n",
      "Epoch 27/70\n",
      " - 2s - loss: 0.9332 - acc: 0.6947\n",
      "Epoch 28/70\n",
      " - 3s - loss: 0.9288 - acc: 0.6975\n",
      "Epoch 29/70\n",
      " - 3s - loss: 0.9257 - acc: 0.6952\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.9197 - acc: 0.6975\n",
      "Epoch 31/70\n",
      " - 2s - loss: 0.9159 - acc: 0.7000\n",
      "Epoch 32/70\n",
      " - 2s - loss: 0.9199 - acc: 0.6975\n",
      "Epoch 33/70\n",
      " - 2s - loss: 0.9128 - acc: 0.6986\n",
      "Epoch 34/70\n",
      " - 2s - loss: 0.9133 - acc: 0.6988\n",
      "Epoch 35/70\n",
      " - 2s - loss: 0.9103 - acc: 0.7014\n",
      "Epoch 36/70\n",
      " - 2s - loss: 0.9065 - acc: 0.6991\n",
      "Epoch 37/70\n",
      " - 2s - loss: 0.9042 - acc: 0.7019\n",
      "Epoch 38/70\n",
      " - 2s - loss: 0.9057 - acc: 0.7020\n",
      "Epoch 39/70\n",
      " - 2s - loss: 0.8983 - acc: 0.7025\n",
      "Epoch 40/70\n",
      " - 2s - loss: 0.8979 - acc: 0.7015\n",
      "Epoch 41/70\n",
      " - 2s - loss: 0.8996 - acc: 0.7033\n",
      "Epoch 42/70\n",
      " - 2s - loss: 0.8993 - acc: 0.7036\n",
      "Epoch 43/70\n",
      " - 2s - loss: 0.8949 - acc: 0.7034\n",
      "Epoch 44/70\n",
      " - 2s - loss: 0.8960 - acc: 0.7043\n",
      "Epoch 45/70\n",
      " - 2s - loss: 0.8920 - acc: 0.7027\n",
      "Epoch 46/70\n",
      " - 2s - loss: 0.8920 - acc: 0.7052\n",
      "Epoch 47/70\n",
      " - 2s - loss: 0.8923 - acc: 0.7043\n",
      "Epoch 48/70\n",
      " - 2s - loss: 0.8901 - acc: 0.7041\n",
      "Epoch 49/70\n",
      " - 2s - loss: 0.8894 - acc: 0.7043\n",
      "Epoch 50/70\n",
      " - 2s - loss: 0.8904 - acc: 0.7053\n",
      "Epoch 51/70\n",
      " - 2s - loss: 0.8849 - acc: 0.7070\n",
      "Epoch 52/70\n",
      " - 2s - loss: 0.8845 - acc: 0.7051\n",
      "Epoch 53/70\n",
      " - 2s - loss: 0.8851 - acc: 0.7066\n",
      "Epoch 54/70\n",
      " - 2s - loss: 0.8812 - acc: 0.7064\n",
      "Epoch 55/70\n",
      " - 2s - loss: 0.8835 - acc: 0.7062\n",
      "Epoch 56/70\n",
      " - 2s - loss: 0.8791 - acc: 0.7080\n",
      "Epoch 57/70\n",
      " - 2s - loss: 0.8811 - acc: 0.7080\n",
      "Epoch 58/70\n",
      " - 2s - loss: 0.8821 - acc: 0.7076\n",
      "Epoch 59/70\n",
      " - 2s - loss: 0.8753 - acc: 0.7085\n",
      "Epoch 60/70\n",
      " - 2s - loss: 0.8814 - acc: 0.7076\n",
      "Epoch 61/70\n",
      " - 2s - loss: 0.8760 - acc: 0.7077\n",
      "Epoch 62/70\n",
      " - 2s - loss: 0.8779 - acc: 0.7083\n",
      "Epoch 63/70\n",
      " - 2s - loss: 0.8785 - acc: 0.7077\n",
      "Epoch 64/70\n",
      " - 2s - loss: 0.8784 - acc: 0.7066\n",
      "Epoch 65/70\n",
      " - 2s - loss: 0.8783 - acc: 0.7081\n",
      "Epoch 66/70\n",
      " - 2s - loss: 0.8752 - acc: 0.7080\n",
      "Epoch 67/70\n",
      " - 2s - loss: 0.8746 - acc: 0.7086\n",
      "Epoch 68/70\n",
      " - 2s - loss: 0.8705 - acc: 0.7082\n",
      "Epoch 69/70\n",
      " - 2s - loss: 0.8699 - acc: 0.7101\n",
      "Epoch 70/70\n",
      " - 2s - loss: 0.8716 - acc: 0.7103\n",
      "[CV]  nodes_l3=70, nodes_l2=120, nodes_l1=190, dropout_l3=0.1, dropout_l2=0.4, dropout_l1=0.30000000000000004, batch_size=500, total=433.7min\n",
      "[CV] nodes_l3=70, nodes_l2=120, nodes_l1=190, dropout_l3=0.1, dropout_l2=0.4, dropout_l1=0.30000000000000004, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=190)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 16s - loss: 2.1791 - acc: 0.4220\n",
      "Epoch 2/70\n",
      " - 3s - loss: 1.4274 - acc: 0.5961\n",
      "Epoch 3/70\n",
      " - 2s - loss: 1.2755 - acc: 0.6269\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.2048 - acc: 0.6394\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.1615 - acc: 0.6478\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.1318 - acc: 0.6515\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.1094 - acc: 0.6564\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.0905 - acc: 0.6606\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.0733 - acc: 0.6645\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.0576 - acc: 0.6675\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.0491 - acc: 0.6681\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.0377 - acc: 0.6708\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.0268 - acc: 0.6720\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.0185 - acc: 0.6744\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.0097 - acc: 0.6740\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.0046 - acc: 0.6762\n",
      "Epoch 17/70\n",
      " - 3s - loss: 0.9943 - acc: 0.6784\n",
      "Epoch 18/70\n",
      " - 3s - loss: 0.9954 - acc: 0.6775\n",
      "Epoch 19/70\n",
      " - 3s - loss: 0.9857 - acc: 0.6820\n",
      "Epoch 20/70\n",
      " - 3s - loss: 0.9803 - acc: 0.6834\n",
      "Epoch 21/70\n",
      " - 3s - loss: 0.9762 - acc: 0.6838\n",
      "Epoch 22/70\n",
      " - 3s - loss: 0.9701 - acc: 0.6847\n",
      "Epoch 23/70\n",
      " - 3s - loss: 0.9681 - acc: 0.6847\n",
      "Epoch 24/70\n",
      " - 3s - loss: 0.9624 - acc: 0.6867\n",
      "Epoch 25/70\n",
      " - 3s - loss: 0.9616 - acc: 0.6860\n",
      "Epoch 26/70\n",
      " - 2s - loss: 0.9579 - acc: 0.6870\n",
      "Epoch 27/70\n",
      " - 3s - loss: 0.9527 - acc: 0.6878\n",
      "Epoch 28/70\n",
      " - 3s - loss: 0.9490 - acc: 0.6876\n",
      "Epoch 29/70\n",
      " - 3s - loss: 0.9474 - acc: 0.6903\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.9416 - acc: 0.6902\n",
      "Epoch 31/70\n",
      " - 2s - loss: 0.9408 - acc: 0.6919\n",
      "Epoch 32/70\n",
      " - 2s - loss: 0.9389 - acc: 0.6912\n",
      "Epoch 33/70\n",
      " - 3s - loss: 0.9354 - acc: 0.6923\n",
      "Epoch 34/70\n",
      " - 3s - loss: 0.9294 - acc: 0.6935\n",
      "Epoch 35/70\n",
      " - 2s - loss: 0.9294 - acc: 0.6946\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9283 - acc: 0.6941\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9260 - acc: 0.6934\n",
      "Epoch 38/70\n",
      " - 2s - loss: 0.9241 - acc: 0.6957\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.9210 - acc: 0.6948\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.9236 - acc: 0.6948\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.9228 - acc: 0.6958\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.9163 - acc: 0.6954\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.9139 - acc: 0.6969\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.9154 - acc: 0.6981\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.9105 - acc: 0.6980\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.9110 - acc: 0.6978\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.9102 - acc: 0.6976\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.9083 - acc: 0.6987\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.9100 - acc: 0.6972\n",
      "Epoch 50/70\n",
      " - 3s - loss: 0.9058 - acc: 0.6978\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.9053 - acc: 0.7004\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.9070 - acc: 0.7005\n",
      "Epoch 53/70\n",
      " - 2s - loss: 0.9038 - acc: 0.6998\n",
      "Epoch 54/70\n",
      " - 2s - loss: 0.9034 - acc: 0.6998\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.9027 - acc: 0.7002\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.8988 - acc: 0.7014\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.9010 - acc: 0.7001\n",
      "Epoch 58/70\n",
      " - 2s - loss: 0.9010 - acc: 0.7009\n",
      "Epoch 59/70\n",
      " - 2s - loss: 0.8970 - acc: 0.7015\n",
      "Epoch 60/70\n",
      " - 2s - loss: 0.8982 - acc: 0.7013\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.8939 - acc: 0.7019\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.8943 - acc: 0.7040\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.8956 - acc: 0.7012\n",
      "Epoch 64/70\n",
      " - 2s - loss: 0.8930 - acc: 0.7017\n",
      "Epoch 65/70\n",
      " - 2s - loss: 0.8933 - acc: 0.7015\n",
      "Epoch 66/70\n",
      " - 2s - loss: 0.8967 - acc: 0.7013\n",
      "Epoch 67/70\n",
      " - 2s - loss: 0.8932 - acc: 0.7025\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.8909 - acc: 0.7030\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.8886 - acc: 0.7037\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.8926 - acc: 0.7034\n",
      "[CV]  nodes_l3=70, nodes_l2=120, nodes_l1=190, dropout_l3=0.1, dropout_l2=0.4, dropout_l1=0.30000000000000004, batch_size=500, total= 4.1min\n",
      "[CV] nodes_l3=70, nodes_l2=130, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=3000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=160)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=130)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=130)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 6s - loss: 3.0082 - acc: 0.2271\n",
      "Epoch 2/70\n",
      " - 2s - loss: 2.2307 - acc: 0.4104\n",
      "Epoch 3/70\n",
      " - 2s - loss: 1.8169 - acc: 0.5123\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.5950 - acc: 0.5600\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.4654 - acc: 0.5865\n",
      "Epoch 6/70\n",
      " - 2s - loss: 1.3809 - acc: 0.6040\n",
      "Epoch 7/70\n",
      " - 2s - loss: 1.3232 - acc: 0.6154\n",
      "Epoch 8/70\n",
      " - 2s - loss: 1.2805 - acc: 0.6239\n",
      "Epoch 9/70\n",
      " - 2s - loss: 1.2426 - acc: 0.6317\n",
      "Epoch 10/70\n",
      " - 2s - loss: 1.2145 - acc: 0.6374\n",
      "Epoch 11/70\n",
      " - 2s - loss: 1.1977 - acc: 0.6395\n",
      "Epoch 12/70\n",
      " - 2s - loss: 1.1761 - acc: 0.6437\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.1598 - acc: 0.6463\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.1454 - acc: 0.6500\n",
      "Epoch 15/70\n",
      " - 2s - loss: 1.1319 - acc: 0.6508\n",
      "Epoch 16/70\n",
      " - 2s - loss: 1.1253 - acc: 0.6534\n",
      "Epoch 17/70\n",
      " - 2s - loss: 1.1100 - acc: 0.6560\n",
      "Epoch 18/70\n",
      " - 2s - loss: 1.1007 - acc: 0.6565\n",
      "Epoch 19/70\n",
      " - 2s - loss: 1.0948 - acc: 0.6581\n",
      "Epoch 20/70\n",
      " - 2s - loss: 1.0892 - acc: 0.6590\n",
      "Epoch 21/70\n",
      " - 2s - loss: 1.0787 - acc: 0.6610\n",
      "Epoch 22/70\n",
      " - 2s - loss: 1.0698 - acc: 0.6634\n",
      "Epoch 23/70\n",
      " - 2s - loss: 1.0625 - acc: 0.6661\n",
      "Epoch 24/70\n",
      " - 2s - loss: 1.0610 - acc: 0.6657\n",
      "Epoch 25/70\n",
      " - 2s - loss: 1.0520 - acc: 0.6686\n",
      "Epoch 26/70\n",
      " - 2s - loss: 1.0442 - acc: 0.6665\n",
      "Epoch 27/70\n",
      " - 2s - loss: 1.0416 - acc: 0.6677\n",
      "Epoch 28/70\n",
      " - 3s - loss: 1.0363 - acc: 0.6706\n",
      "Epoch 29/70\n",
      " - 3s - loss: 1.0345 - acc: 0.6696\n",
      "Epoch 30/70\n",
      " - 2s - loss: 1.0253 - acc: 0.6726\n",
      "Epoch 31/70\n",
      " - 2s - loss: 1.0203 - acc: 0.6746\n",
      "Epoch 32/70\n",
      " - 2s - loss: 1.0223 - acc: 0.6710\n",
      "Epoch 33/70\n",
      " - 2s - loss: 1.0163 - acc: 0.6727\n",
      "Epoch 34/70\n",
      " - 2s - loss: 1.0097 - acc: 0.6755\n",
      "Epoch 35/70\n",
      " - 2s - loss: 1.0057 - acc: 0.6740\n",
      "Epoch 36/70\n",
      " - 2s - loss: 1.0032 - acc: 0.6762\n",
      "Epoch 37/70\n",
      " - 2s - loss: 0.9991 - acc: 0.6765\n",
      "Epoch 38/70\n",
      " - 2s - loss: 0.9944 - acc: 0.6777\n",
      "Epoch 39/70\n",
      " - 2s - loss: 0.9865 - acc: 0.6793\n",
      "Epoch 40/70\n",
      " - 2s - loss: 0.9885 - acc: 0.6806\n",
      "Epoch 41/70\n",
      " - 2s - loss: 0.9850 - acc: 0.6795\n",
      "Epoch 42/70\n",
      " - 2s - loss: 0.9803 - acc: 0.6824\n",
      "Epoch 43/70\n",
      " - 2s - loss: 0.9838 - acc: 0.6798\n",
      "Epoch 44/70\n",
      " - 2s - loss: 0.9772 - acc: 0.6810\n",
      "Epoch 45/70\n",
      " - 2s - loss: 0.9728 - acc: 0.6822\n",
      "Epoch 46/70\n",
      " - 2s - loss: 0.9722 - acc: 0.6831\n",
      "Epoch 47/70\n",
      " - 2s - loss: 0.9723 - acc: 0.6821\n",
      "Epoch 48/70\n",
      " - 2s - loss: 0.9661 - acc: 0.6851\n",
      "Epoch 49/70\n",
      " - 2s - loss: 0.9683 - acc: 0.6844\n",
      "Epoch 50/70\n",
      " - 2s - loss: 0.9637 - acc: 0.6839\n",
      "Epoch 51/70\n",
      " - 2s - loss: 0.9638 - acc: 0.6850\n",
      "Epoch 52/70\n",
      " - 2s - loss: 0.9591 - acc: 0.6854\n",
      "Epoch 53/70\n",
      " - 2s - loss: 0.9551 - acc: 0.6878\n",
      "Epoch 54/70\n",
      " - 2s - loss: 0.9522 - acc: 0.6878\n",
      "Epoch 55/70\n",
      " - 2s - loss: 0.9490 - acc: 0.6877\n",
      "Epoch 56/70\n",
      " - 2s - loss: 0.9524 - acc: 0.6878\n",
      "Epoch 57/70\n",
      " - 2s - loss: 0.9469 - acc: 0.6891\n",
      "Epoch 58/70\n",
      " - 2s - loss: 0.9480 - acc: 0.6873\n",
      "Epoch 59/70\n",
      " - 2s - loss: 0.9452 - acc: 0.6910\n",
      "Epoch 60/70\n",
      " - 2s - loss: 0.9417 - acc: 0.6898\n",
      "Epoch 61/70\n",
      " - 2s - loss: 0.9417 - acc: 0.6874\n",
      "Epoch 62/70\n",
      " - 2s - loss: 0.9387 - acc: 0.6906\n",
      "Epoch 63/70\n",
      " - 2s - loss: 0.9385 - acc: 0.6901\n",
      "Epoch 64/70\n",
      " - 2s - loss: 0.9360 - acc: 0.6907\n",
      "Epoch 65/70\n",
      " - 2s - loss: 0.9332 - acc: 0.6922\n",
      "Epoch 66/70\n",
      " - 2s - loss: 0.9318 - acc: 0.6917\n",
      "Epoch 67/70\n",
      " - 2s - loss: 0.9353 - acc: 0.6917\n",
      "Epoch 68/70\n",
      " - 2s - loss: 0.9306 - acc: 0.6915\n",
      "Epoch 69/70\n",
      " - 2s - loss: 0.9311 - acc: 0.6920\n",
      "Epoch 70/70\n",
      " - 2s - loss: 0.9287 - acc: 0.6913\n",
      "[CV]  nodes_l3=70, nodes_l2=130, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=3000, total= 2.8min\n",
      "[CV] nodes_l3=70, nodes_l2=130, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=3000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=160)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=130)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=130)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 5s - loss: 3.0684 - acc: 0.2055\n",
      "Epoch 2/70\n",
      " - 2s - loss: 2.2531 - acc: 0.3961\n",
      "Epoch 3/70\n",
      " - 2s - loss: 1.8396 - acc: 0.4968\n",
      "Epoch 4/70\n",
      " - 2s - loss: 1.6180 - acc: 0.5500\n",
      "Epoch 5/70\n",
      " - 2s - loss: 1.4879 - acc: 0.5819\n",
      "Epoch 6/70\n",
      " - 2s - loss: 1.4000 - acc: 0.5997\n",
      "Epoch 7/70\n",
      " - 2s - loss: 1.3377 - acc: 0.6155\n",
      "Epoch 8/70\n",
      " - 2s - loss: 1.2890 - acc: 0.6242\n",
      "Epoch 9/70\n",
      " - 2s - loss: 1.2563 - acc: 0.6291\n",
      "Epoch 10/70\n",
      " - 2s - loss: 1.2257 - acc: 0.6358\n",
      "Epoch 11/70\n",
      " - 2s - loss: 1.2014 - acc: 0.6401\n",
      "Epoch 12/70\n",
      " - 2s - loss: 1.1856 - acc: 0.6437\n",
      "Epoch 13/70\n",
      " - 2s - loss: 1.1712 - acc: 0.6438\n",
      "Epoch 14/70\n",
      " - 2s - loss: 1.1546 - acc: 0.6469\n",
      "Epoch 15/70\n",
      " - 2s - loss: 1.1425 - acc: 0.6490\n",
      "Epoch 16/70\n",
      " - 2s - loss: 1.1271 - acc: 0.6540\n",
      "Epoch 17/70\n",
      " - 2s - loss: 1.1216 - acc: 0.6538\n",
      "Epoch 18/70\n",
      " - 2s - loss: 1.1092 - acc: 0.6567\n",
      "Epoch 19/70\n",
      " - 2s - loss: 1.1017 - acc: 0.6579\n",
      "Epoch 20/70\n",
      " - 2s - loss: 1.0933 - acc: 0.6608\n",
      "Epoch 21/70\n",
      " - 2s - loss: 1.0847 - acc: 0.6595\n",
      "Epoch 22/70\n",
      " - 2s - loss: 1.0755 - acc: 0.6628\n",
      "Epoch 23/70\n",
      " - 2s - loss: 1.0678 - acc: 0.6629\n",
      "Epoch 24/70\n",
      " - 2s - loss: 1.0601 - acc: 0.6632\n",
      "Epoch 25/70\n",
      " - 2s - loss: 1.0584 - acc: 0.6635\n",
      "Epoch 26/70\n",
      " - 2s - loss: 1.0513 - acc: 0.6689\n",
      "Epoch 27/70\n",
      " - 2s - loss: 1.0486 - acc: 0.6672\n",
      "Epoch 28/70\n",
      " - 2s - loss: 1.0450 - acc: 0.6692\n",
      "Epoch 29/70\n",
      " - 2s - loss: 1.0342 - acc: 0.6689\n",
      "Epoch 30/70\n",
      " - 2s - loss: 1.0384 - acc: 0.6688\n",
      "Epoch 31/70\n",
      " - 2s - loss: 1.0281 - acc: 0.6711\n",
      "Epoch 32/70\n",
      " - 2s - loss: 1.0253 - acc: 0.6707\n",
      "Epoch 33/70\n",
      " - 2s - loss: 1.0216 - acc: 0.6725\n",
      "Epoch 34/70\n",
      " - 2s - loss: 1.0187 - acc: 0.6724\n",
      "Epoch 35/70\n",
      " - 3s - loss: 1.0136 - acc: 0.6736\n",
      "Epoch 36/70\n",
      " - 2s - loss: 1.0072 - acc: 0.6751\n",
      "Epoch 37/70\n",
      " - 2s - loss: 1.0083 - acc: 0.6763\n",
      "Epoch 38/70\n",
      " - 2s - loss: 0.9982 - acc: 0.6770\n",
      "Epoch 39/70\n",
      " - 2s - loss: 1.0005 - acc: 0.6768\n",
      "Epoch 40/70\n",
      " - 2s - loss: 1.0000 - acc: 0.6773\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.9904 - acc: 0.6797\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.9892 - acc: 0.6802\n",
      "Epoch 43/70\n",
      " - 2s - loss: 0.9868 - acc: 0.6806\n",
      "Epoch 44/70\n",
      " - 2s - loss: 0.9875 - acc: 0.6782\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.9814 - acc: 0.6811\n",
      "Epoch 46/70\n",
      " - 2s - loss: 0.9797 - acc: 0.6806\n",
      "Epoch 47/70\n",
      " - 2s - loss: 0.9799 - acc: 0.6815\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.9723 - acc: 0.6824\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.9741 - acc: 0.6826\n",
      "Epoch 50/70\n",
      " - 2s - loss: 0.9683 - acc: 0.6843\n",
      "Epoch 51/70\n",
      " - 2s - loss: 0.9670 - acc: 0.6839\n",
      "Epoch 52/70\n",
      " - 2s - loss: 0.9639 - acc: 0.6862\n",
      "Epoch 53/70\n",
      " - 2s - loss: 0.9616 - acc: 0.6856\n",
      "Epoch 54/70\n",
      " - 2s - loss: 0.9609 - acc: 0.6838\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.9568 - acc: 0.6860\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.9562 - acc: 0.6856\n",
      "Epoch 57/70\n",
      " - 2s - loss: 0.9540 - acc: 0.6879\n",
      "Epoch 58/70\n",
      " - 2s - loss: 0.9513 - acc: 0.6878\n",
      "Epoch 59/70\n",
      " - 2s - loss: 0.9504 - acc: 0.6874\n",
      "Epoch 60/70\n",
      " - 2s - loss: 0.9496 - acc: 0.6876\n",
      "Epoch 61/70\n",
      " - 2s - loss: 0.9463 - acc: 0.6886\n",
      "Epoch 62/70\n",
      " - 2s - loss: 0.9478 - acc: 0.6873\n",
      "Epoch 63/70\n",
      " - 2s - loss: 0.9398 - acc: 0.6909\n",
      "Epoch 64/70\n",
      " - 2s - loss: 0.9430 - acc: 0.6915\n",
      "Epoch 65/70\n",
      " - 2s - loss: 0.9399 - acc: 0.6894\n",
      "Epoch 66/70\n",
      " - 2s - loss: 0.9433 - acc: 0.6889\n",
      "Epoch 67/70\n",
      " - 2s - loss: 0.9395 - acc: 0.6909\n",
      "Epoch 68/70\n",
      " - 2s - loss: 0.9352 - acc: 0.6905\n",
      "Epoch 69/70\n",
      " - 2s - loss: 0.9333 - acc: 0.6922\n",
      "Epoch 70/70\n",
      " - 2s - loss: 0.9305 - acc: 0.6922\n",
      "[CV]  nodes_l3=70, nodes_l2=130, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=3000, total= 2.7min\n",
      "[CV] nodes_l3=70, nodes_l2=130, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=3000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=160)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=130)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=130)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 4s - loss: 3.0326 - acc: 0.2127\n",
      "Epoch 2/70\n",
      " - 2s - loss: 2.2164 - acc: 0.4086\n",
      "Epoch 3/70\n",
      " - 2s - loss: 1.8014 - acc: 0.5121\n",
      "Epoch 4/70\n",
      " - 2s - loss: 1.5841 - acc: 0.5633\n",
      "Epoch 5/70\n",
      " - 2s - loss: 1.4553 - acc: 0.5898\n",
      "Epoch 6/70\n",
      " - 2s - loss: 1.3715 - acc: 0.6074\n",
      "Epoch 7/70\n",
      " - 2s - loss: 1.3146 - acc: 0.6190\n",
      "Epoch 8/70\n",
      " - 2s - loss: 1.2649 - acc: 0.6309\n",
      "Epoch 9/70\n",
      " - 2s - loss: 1.2346 - acc: 0.6345\n",
      "Epoch 10/70\n",
      " - 2s - loss: 1.2076 - acc: 0.6406\n",
      "Epoch 11/70\n",
      " - 2s - loss: 1.1817 - acc: 0.6451\n",
      "Epoch 12/70\n",
      " - 2s - loss: 1.1662 - acc: 0.6459\n",
      "Epoch 13/70\n",
      " - 2s - loss: 1.1465 - acc: 0.6497\n",
      "Epoch 14/70\n",
      " - 2s - loss: 1.1352 - acc: 0.6515\n",
      "Epoch 15/70\n",
      " - 2s - loss: 1.1205 - acc: 0.6553\n",
      "Epoch 16/70\n",
      " - 2s - loss: 1.1102 - acc: 0.6558\n",
      "Epoch 17/70\n",
      " - 2s - loss: 1.1028 - acc: 0.6596\n",
      "Epoch 18/70\n",
      " - 2s - loss: 1.0852 - acc: 0.6624\n",
      "Epoch 19/70\n",
      " - 2s - loss: 1.0843 - acc: 0.6619\n",
      "Epoch 20/70\n",
      " - 2s - loss: 1.0720 - acc: 0.6654\n",
      "Epoch 21/70\n",
      " - 2s - loss: 1.0658 - acc: 0.6650\n",
      "Epoch 22/70\n",
      " - 2s - loss: 1.0568 - acc: 0.6675\n",
      "Epoch 23/70\n",
      " - 2s - loss: 1.0540 - acc: 0.6675\n",
      "Epoch 24/70\n",
      " - 2s - loss: 1.0458 - acc: 0.6697\n",
      "Epoch 25/70\n",
      " - 2s - loss: 1.0387 - acc: 0.6709\n",
      "Epoch 26/70\n",
      " - 2s - loss: 1.0341 - acc: 0.6720\n",
      "Epoch 27/70\n",
      " - 2s - loss: 1.0287 - acc: 0.6726\n",
      "Epoch 28/70\n",
      " - 2s - loss: 1.0236 - acc: 0.6729\n",
      "Epoch 29/70\n",
      " - 2s - loss: 1.0191 - acc: 0.6747\n",
      "Epoch 30/70\n",
      " - 2s - loss: 1.0127 - acc: 0.6770\n",
      "Epoch 31/70\n",
      " - 2s - loss: 1.0076 - acc: 0.6759\n",
      "Epoch 32/70\n",
      " - 2s - loss: 1.0022 - acc: 0.6783\n",
      "Epoch 33/70\n",
      " - 2s - loss: 0.9981 - acc: 0.6782\n",
      "Epoch 34/70\n",
      " - 2s - loss: 0.9943 - acc: 0.6777\n",
      "Epoch 35/70\n",
      " - 2s - loss: 0.9878 - acc: 0.6801\n",
      "Epoch 36/70\n",
      " - 2s - loss: 0.9910 - acc: 0.6788\n",
      "Epoch 37/70\n",
      " - 2s - loss: 0.9832 - acc: 0.6813\n",
      "Epoch 38/70\n",
      " - 2s - loss: 0.9821 - acc: 0.6824\n",
      "Epoch 39/70\n",
      " - 2s - loss: 0.9761 - acc: 0.6837\n",
      "Epoch 40/70\n",
      " - 2s - loss: 0.9751 - acc: 0.6824\n",
      "Epoch 41/70\n",
      " - 2s - loss: 0.9712 - acc: 0.6843\n",
      "Epoch 42/70\n",
      " - 2s - loss: 0.9688 - acc: 0.6849\n",
      "Epoch 43/70\n",
      " - 2s - loss: 0.9641 - acc: 0.6852\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.9643 - acc: 0.6851\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.9582 - acc: 0.6866\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.9572 - acc: 0.6867\n",
      "Epoch 47/70\n",
      " - 2s - loss: 0.9561 - acc: 0.6866\n",
      "Epoch 48/70\n",
      " - 2s - loss: 0.9494 - acc: 0.6883\n",
      "Epoch 49/70\n",
      " - 2s - loss: 0.9483 - acc: 0.6892\n",
      "Epoch 50/70\n",
      " - 2s - loss: 0.9465 - acc: 0.6900\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.9476 - acc: 0.6900\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.9481 - acc: 0.6869\n",
      "Epoch 53/70\n",
      " - 2s - loss: 0.9365 - acc: 0.6915\n",
      "Epoch 54/70\n",
      " - 2s - loss: 0.9404 - acc: 0.6908\n",
      "Epoch 55/70\n",
      " - 2s - loss: 0.9339 - acc: 0.6922\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.9343 - acc: 0.6928\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.9347 - acc: 0.6924\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.9298 - acc: 0.6930\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.9308 - acc: 0.6920\n",
      "Epoch 60/70\n",
      " - 2s - loss: 0.9304 - acc: 0.6914\n",
      "Epoch 61/70\n",
      " - 2s - loss: 0.9260 - acc: 0.6934\n",
      "Epoch 62/70\n",
      " - 2s - loss: 0.9225 - acc: 0.6931\n",
      "Epoch 63/70\n",
      " - 2s - loss: 0.9227 - acc: 0.6935\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.9229 - acc: 0.6939\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.9230 - acc: 0.6942\n",
      "Epoch 66/70\n",
      " - 2s - loss: 0.9192 - acc: 0.6948\n",
      "Epoch 67/70\n",
      " - 2s - loss: 0.9139 - acc: 0.6963\n",
      "Epoch 68/70\n",
      " - 2s - loss: 0.9173 - acc: 0.6957\n",
      "Epoch 69/70\n",
      " - 2s - loss: 0.9138 - acc: 0.6960\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.9118 - acc: 0.6956\n",
      "[CV]  nodes_l3=70, nodes_l2=130, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=3000, total= 2.9min\n",
      "[CV] nodes_l3=70, nodes_l2=130, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=3000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=160)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=130)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=130)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 4s - loss: 3.0256 - acc: 0.2083\n",
      "Epoch 2/70\n",
      " - 2s - loss: 2.1948 - acc: 0.4031\n",
      "Epoch 3/70\n",
      " - 2s - loss: 1.8089 - acc: 0.5102\n",
      "Epoch 4/70\n",
      " - 2s - loss: 1.5933 - acc: 0.5626\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.4701 - acc: 0.5870\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.3885 - acc: 0.6037\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.3299 - acc: 0.6150\n",
      "Epoch 8/70\n",
      " - 2s - loss: 1.2903 - acc: 0.6198\n",
      "Epoch 9/70\n",
      " - 2s - loss: 1.2543 - acc: 0.6289\n",
      "Epoch 10/70\n",
      " - 2s - loss: 1.2294 - acc: 0.6338\n",
      "Epoch 11/70\n",
      " - 2s - loss: 1.2070 - acc: 0.6355\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.1847 - acc: 0.6394\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.1681 - acc: 0.6442\n",
      "Epoch 14/70\n",
      " - 2s - loss: 1.1585 - acc: 0.6463\n",
      "Epoch 15/70\n",
      " - 2s - loss: 1.1438 - acc: 0.6485\n",
      "Epoch 16/70\n",
      " - 2s - loss: 1.1300 - acc: 0.6520\n",
      "Epoch 17/70\n",
      " - 2s - loss: 1.1191 - acc: 0.6521\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.1074 - acc: 0.6552\n",
      "Epoch 19/70\n",
      " - 3s - loss: 1.1009 - acc: 0.6565\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.0949 - acc: 0.6570\n",
      "Epoch 21/70\n",
      " - 2s - loss: 1.0886 - acc: 0.6605\n",
      "Epoch 22/70\n",
      " - 2s - loss: 1.0785 - acc: 0.6603\n",
      "Epoch 23/70\n",
      " - 2s - loss: 1.0729 - acc: 0.6617\n",
      "Epoch 24/70\n",
      " - 2s - loss: 1.0635 - acc: 0.6621\n",
      "Epoch 25/70\n",
      " - 3s - loss: 1.0606 - acc: 0.6628\n",
      "Epoch 26/70\n",
      " - 3s - loss: 1.0532 - acc: 0.6637\n",
      "Epoch 27/70\n",
      " - 2s - loss: 1.0532 - acc: 0.6665\n",
      "Epoch 28/70\n",
      " - 2s - loss: 1.0457 - acc: 0.6685\n",
      "Epoch 29/70\n",
      " - 2s - loss: 1.0419 - acc: 0.6670\n",
      "Epoch 30/70\n",
      " - 2s - loss: 1.0343 - acc: 0.6718\n",
      "Epoch 31/70\n",
      " - 3s - loss: 1.0298 - acc: 0.6691\n",
      "Epoch 32/70\n",
      " - 3s - loss: 1.0264 - acc: 0.6705\n",
      "Epoch 33/70\n",
      " - 3s - loss: 1.0242 - acc: 0.6709\n",
      "Epoch 34/70\n",
      " - 2s - loss: 1.0183 - acc: 0.6719\n",
      "Epoch 35/70\n",
      " - 2s - loss: 1.0153 - acc: 0.6746\n",
      "Epoch 36/70\n",
      " - 2s - loss: 1.0100 - acc: 0.6740\n",
      "Epoch 37/70\n",
      " - 2s - loss: 1.0088 - acc: 0.6745\n",
      "Epoch 38/70\n",
      " - 3s - loss: 1.0037 - acc: 0.6758\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.9984 - acc: 0.6749\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.9995 - acc: 0.6763\n",
      "Epoch 41/70\n",
      " - 2s - loss: 0.9932 - acc: 0.6770\n",
      "Epoch 42/70\n",
      " - 2s - loss: 0.9947 - acc: 0.6782\n",
      "Epoch 43/70\n",
      " - 2s - loss: 0.9907 - acc: 0.6771\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.9872 - acc: 0.6780\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.9837 - acc: 0.6792\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.9796 - acc: 0.6789\n",
      "Epoch 47/70\n",
      " - 2s - loss: 0.9801 - acc: 0.6802\n",
      "Epoch 48/70\n",
      " - 2s - loss: 0.9731 - acc: 0.6815\n",
      "Epoch 49/70\n",
      " - 2s - loss: 0.9731 - acc: 0.6826\n",
      "Epoch 50/70\n",
      " - 2s - loss: 0.9722 - acc: 0.6817\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.9701 - acc: 0.6816\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.9658 - acc: 0.6851\n",
      "Epoch 53/70\n",
      " - 3s - loss: 0.9637 - acc: 0.6843\n",
      "Epoch 54/70\n",
      " - 2s - loss: 0.9627 - acc: 0.6830\n",
      "Epoch 55/70\n",
      " - 2s - loss: 0.9593 - acc: 0.6843\n",
      "Epoch 56/70\n",
      " - 2s - loss: 0.9570 - acc: 0.6858\n",
      "Epoch 57/70\n",
      " - 2s - loss: 0.9562 - acc: 0.6848\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.9575 - acc: 0.6852\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.9540 - acc: 0.6846\n",
      "Epoch 60/70\n",
      " - 2s - loss: 0.9482 - acc: 0.6856\n",
      "Epoch 61/70\n",
      " - 2s - loss: 0.9480 - acc: 0.6867\n",
      "Epoch 62/70\n",
      " - 2s - loss: 0.9471 - acc: 0.6869\n",
      "Epoch 63/70\n",
      " - 2s - loss: 0.9459 - acc: 0.6874\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.9443 - acc: 0.6865\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.9402 - acc: 0.6898\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.9417 - acc: 0.6877\n",
      "Epoch 67/70\n",
      " - 2s - loss: 0.9382 - acc: 0.6896\n",
      "Epoch 68/70\n",
      " - 2s - loss: 0.9354 - acc: 0.6901\n",
      "Epoch 69/70\n",
      " - 2s - loss: 0.9395 - acc: 0.6896\n",
      "Epoch 70/70\n",
      " - 2s - loss: 0.9362 - acc: 0.6894\n",
      "[CV]  nodes_l3=70, nodes_l2=130, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=3000, total= 2.9min\n",
      "[CV] nodes_l3=80, nodes_l2=140, nodes_l1=180, dropout_l3=0.4, dropout_l2=0.1, dropout_l1=0.4, batch_size=2000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=180)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=140)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=140)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 5s - loss: 2.9449 - acc: 0.2409\n",
      "Epoch 2/70\n",
      " - 3s - loss: 1.9895 - acc: 0.4703\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.6286 - acc: 0.5598\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.4584 - acc: 0.5944\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.3551 - acc: 0.6153\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.2879 - acc: 0.6265\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.2418 - acc: 0.6352\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.2055 - acc: 0.6409\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.1826 - acc: 0.6446\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.1525 - acc: 0.6509\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.1404 - acc: 0.6531\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.1204 - acc: 0.6580\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.1066 - acc: 0.6593\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.0942 - acc: 0.6606\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.0842 - acc: 0.6640\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.0722 - acc: 0.6662\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.0634 - acc: 0.6655\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.0509 - acc: 0.6691\n",
      "Epoch 19/70\n",
      " - 3s - loss: 1.0427 - acc: 0.6704\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.0372 - acc: 0.6732\n",
      "Epoch 21/70\n",
      " - 3s - loss: 1.0300 - acc: 0.6736\n",
      "Epoch 22/70\n",
      " - 3s - loss: 1.0249 - acc: 0.6757\n",
      "Epoch 23/70\n",
      " - 3s - loss: 1.0169 - acc: 0.6769\n",
      "Epoch 24/70\n",
      " - 3s - loss: 1.0107 - acc: 0.6789\n",
      "Epoch 25/70\n",
      " - 3s - loss: 1.0014 - acc: 0.6806\n",
      "Epoch 26/70\n",
      " - 3s - loss: 0.9955 - acc: 0.6806\n",
      "Epoch 27/70\n",
      " - 3s - loss: 0.9934 - acc: 0.6822\n",
      "Epoch 28/70\n",
      " - 3s - loss: 0.9884 - acc: 0.6810\n",
      "Epoch 29/70\n",
      " - 3s - loss: 0.9835 - acc: 0.6833\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.9747 - acc: 0.6845\n",
      "Epoch 31/70\n",
      " - 3s - loss: 0.9733 - acc: 0.6843\n",
      "Epoch 32/70\n",
      " - 3s - loss: 0.9710 - acc: 0.6862\n",
      "Epoch 33/70\n",
      " - 3s - loss: 0.9659 - acc: 0.6862\n",
      "Epoch 34/70\n",
      " - 3s - loss: 0.9625 - acc: 0.6876\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9594 - acc: 0.6884\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9562 - acc: 0.6915\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9552 - acc: 0.6910\n",
      "Epoch 38/70\n",
      " - 3s - loss: 0.9494 - acc: 0.6898\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.9487 - acc: 0.6917\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.9428 - acc: 0.6926\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.9417 - acc: 0.6914\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.9406 - acc: 0.6921\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.9363 - acc: 0.6932\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.9319 - acc: 0.6932\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.9322 - acc: 0.6936\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.9284 - acc: 0.6949\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.9269 - acc: 0.6954\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.9245 - acc: 0.6954\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.9250 - acc: 0.6948\n",
      "Epoch 50/70\n",
      " - 3s - loss: 0.9199 - acc: 0.6978\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.9183 - acc: 0.6957\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.9189 - acc: 0.6972\n",
      "Epoch 53/70\n",
      " - 3s - loss: 0.9148 - acc: 0.6980\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.9134 - acc: 0.6984\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.9101 - acc: 0.6985\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.9097 - acc: 0.6992\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.9070 - acc: 0.6978\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.9043 - acc: 0.6997\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.9069 - acc: 0.6968\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.9035 - acc: 0.6999\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.9010 - acc: 0.6992\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.8991 - acc: 0.7011\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.8984 - acc: 0.6980\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.8996 - acc: 0.6998\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.8958 - acc: 0.7005\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.8946 - acc: 0.7008\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.8951 - acc: 0.7013\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.8936 - acc: 0.7021\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.8920 - acc: 0.7011\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.8913 - acc: 0.7005\n",
      "[CV]  nodes_l3=80, nodes_l2=140, nodes_l1=180, dropout_l3=0.4, dropout_l2=0.1, dropout_l1=0.4, batch_size=2000, total= 3.3min\n",
      "[CV] nodes_l3=80, nodes_l2=140, nodes_l1=180, dropout_l3=0.4, dropout_l2=0.1, dropout_l1=0.4, batch_size=2000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=180)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=140)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=140)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 5s - loss: 2.8023 - acc: 0.2764\n",
      "Epoch 2/70\n",
      " - 3s - loss: 1.9252 - acc: 0.4850\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.6014 - acc: 0.5643\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.4381 - acc: 0.5970\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.3438 - acc: 0.6166\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.2805 - acc: 0.6287\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.2335 - acc: 0.6370\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.2004 - acc: 0.6429\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.1814 - acc: 0.6455\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.1526 - acc: 0.6511\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.1393 - acc: 0.6535\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.1162 - acc: 0.6578\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.1083 - acc: 0.6598\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.0938 - acc: 0.6617\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.0833 - acc: 0.6627\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.0740 - acc: 0.6649\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.0642 - acc: 0.6680\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.0541 - acc: 0.6674\n",
      "Epoch 19/70\n",
      " - 3s - loss: 1.0498 - acc: 0.6703\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.0363 - acc: 0.6723\n",
      "Epoch 21/70\n",
      " - 3s - loss: 1.0322 - acc: 0.6738\n",
      "Epoch 22/70\n",
      " - 3s - loss: 1.0271 - acc: 0.6750\n",
      "Epoch 23/70\n",
      " - 3s - loss: 1.0209 - acc: 0.6753\n",
      "Epoch 24/70\n",
      " - 3s - loss: 1.0120 - acc: 0.6764\n",
      "Epoch 25/70\n",
      " - 3s - loss: 1.0053 - acc: 0.6806\n",
      "Epoch 26/70\n",
      " - 3s - loss: 0.9962 - acc: 0.6805\n",
      "Epoch 27/70\n",
      " - 3s - loss: 0.9939 - acc: 0.6814\n",
      "Epoch 28/70\n",
      " - 3s - loss: 0.9928 - acc: 0.6815\n",
      "Epoch 29/70\n",
      " - 3s - loss: 0.9895 - acc: 0.6820\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.9807 - acc: 0.6833\n",
      "Epoch 31/70\n",
      " - 3s - loss: 0.9767 - acc: 0.6844\n",
      "Epoch 32/70\n",
      " - 3s - loss: 0.9730 - acc: 0.6848\n",
      "Epoch 33/70\n",
      " - 3s - loss: 0.9695 - acc: 0.6869\n",
      "Epoch 34/70\n",
      " - 3s - loss: 0.9667 - acc: 0.6853\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9580 - acc: 0.6899\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9594 - acc: 0.6884\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9539 - acc: 0.6907\n",
      "Epoch 38/70\n",
      " - 3s - loss: 0.9554 - acc: 0.6890\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.9516 - acc: 0.6887\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.9486 - acc: 0.6899\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.9428 - acc: 0.6903\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.9378 - acc: 0.6945\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.9372 - acc: 0.6921\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.9372 - acc: 0.6921\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.9351 - acc: 0.6943\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.9318 - acc: 0.6938\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.9307 - acc: 0.6945\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.9253 - acc: 0.6956\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.9252 - acc: 0.6950\n",
      "Epoch 50/70\n",
      " - 3s - loss: 0.9264 - acc: 0.6953\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.9193 - acc: 0.6964\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.9183 - acc: 0.6963\n",
      "Epoch 53/70\n",
      " - 3s - loss: 0.9143 - acc: 0.6974\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.9176 - acc: 0.6962\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.9144 - acc: 0.6978\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.9154 - acc: 0.6979\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.9084 - acc: 0.6995\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.9099 - acc: 0.7001\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.9079 - acc: 0.6980\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.9051 - acc: 0.6969\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.9028 - acc: 0.6992\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.9046 - acc: 0.6997\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.9010 - acc: 0.7002\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.9009 - acc: 0.6999\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.8981 - acc: 0.7005\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.8982 - acc: 0.7005\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.8946 - acc: 0.7017\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.8941 - acc: 0.7003\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.8916 - acc: 0.7026\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.8932 - acc: 0.7014\n",
      "[CV]  nodes_l3=80, nodes_l2=140, nodes_l1=180, dropout_l3=0.4, dropout_l2=0.1, dropout_l1=0.4, batch_size=2000, total= 3.3min\n",
      "[CV] nodes_l3=80, nodes_l2=140, nodes_l1=180, dropout_l3=0.4, dropout_l2=0.1, dropout_l1=0.4, batch_size=2000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=180)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=140)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=140)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 6s - loss: 2.8506 - acc: 0.2595\n",
      "Epoch 2/70\n",
      " - 3s - loss: 1.9356 - acc: 0.4812\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.5934 - acc: 0.5623\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.4307 - acc: 0.5997\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.3380 - acc: 0.6158\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.2692 - acc: 0.6307\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.2285 - acc: 0.6365\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.1887 - acc: 0.6452\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.1629 - acc: 0.6496\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.1404 - acc: 0.6530\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.1214 - acc: 0.6570\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.1053 - acc: 0.6621\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.0923 - acc: 0.6627\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.0809 - acc: 0.6651\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.0651 - acc: 0.6669\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.0555 - acc: 0.6683\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.0448 - acc: 0.6710\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.0381 - acc: 0.6731\n",
      "Epoch 19/70\n",
      " - 3s - loss: 1.0289 - acc: 0.6733\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.0192 - acc: 0.6765\n",
      "Epoch 21/70\n",
      " - 3s - loss: 1.0155 - acc: 0.6764\n",
      "Epoch 22/70\n",
      " - 3s - loss: 1.0063 - acc: 0.6793\n",
      "Epoch 23/70\n",
      " - 3s - loss: 1.0001 - acc: 0.6804\n",
      "Epoch 24/70\n",
      " - 3s - loss: 0.9945 - acc: 0.6809\n",
      "Epoch 25/70\n",
      " - 3s - loss: 0.9928 - acc: 0.6814\n",
      "Epoch 26/70\n",
      " - 3s - loss: 0.9845 - acc: 0.6829\n",
      "Epoch 27/70\n",
      " - 3s - loss: 0.9791 - acc: 0.6839\n",
      "Epoch 28/70\n",
      " - 3s - loss: 0.9698 - acc: 0.6862\n",
      "Epoch 29/70\n",
      " - 3s - loss: 0.9653 - acc: 0.6864\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.9614 - acc: 0.6875\n",
      "Epoch 31/70\n",
      " - 3s - loss: 0.9583 - acc: 0.6883\n",
      "Epoch 32/70\n",
      " - 3s - loss: 0.9560 - acc: 0.6895\n",
      "Epoch 33/70\n",
      " - 3s - loss: 0.9525 - acc: 0.6904\n",
      "Epoch 34/70\n",
      " - 3s - loss: 0.9490 - acc: 0.6906\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9449 - acc: 0.6909\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9430 - acc: 0.6916\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9368 - acc: 0.6919\n",
      "Epoch 38/70\n",
      " - 3s - loss: 0.9326 - acc: 0.6924\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.9327 - acc: 0.6939\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.9296 - acc: 0.6949\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.9239 - acc: 0.6961\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.9260 - acc: 0.6938\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.9199 - acc: 0.6959\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.9182 - acc: 0.6963\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.9179 - acc: 0.6975\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.9132 - acc: 0.6977\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.9149 - acc: 0.6961\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.9116 - acc: 0.6981\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.9082 - acc: 0.6991\n",
      "Epoch 50/70\n",
      " - 3s - loss: 0.9063 - acc: 0.6992\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.9061 - acc: 0.6979\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.9029 - acc: 0.6986\n",
      "Epoch 53/70\n",
      " - 3s - loss: 0.9026 - acc: 0.6991\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.8996 - acc: 0.6986\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.8973 - acc: 0.7011\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.8940 - acc: 0.7002\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.8942 - acc: 0.7016\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.8913 - acc: 0.7020\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.8898 - acc: 0.7025\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.8894 - acc: 0.7020\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.8865 - acc: 0.7013\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.8878 - acc: 0.7013\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.8876 - acc: 0.7020\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.8842 - acc: 0.7027\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.8853 - acc: 0.7037\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.8840 - acc: 0.7023\n",
      "Epoch 67/70\n",
      " - 2s - loss: 0.8817 - acc: 0.7013\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.8781 - acc: 0.7050\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.8755 - acc: 0.7055\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.8752 - acc: 0.7045\n",
      "[CV]  nodes_l3=80, nodes_l2=140, nodes_l1=180, dropout_l3=0.4, dropout_l2=0.1, dropout_l1=0.4, batch_size=2000, total= 3.3min\n",
      "[CV] nodes_l3=80, nodes_l2=140, nodes_l1=180, dropout_l3=0.4, dropout_l2=0.1, dropout_l1=0.4, batch_size=2000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=180)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=140)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=140)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 5s - loss: 2.8162 - acc: 0.2693\n",
      "Epoch 2/70\n",
      " - 3s - loss: 1.9182 - acc: 0.4861\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.5991 - acc: 0.5643\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.4437 - acc: 0.5944\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.3456 - acc: 0.6152\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.2818 - acc: 0.6265\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.2364 - acc: 0.6383\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.2084 - acc: 0.6385\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.1778 - acc: 0.6449\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.1585 - acc: 0.6468\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.1396 - acc: 0.6515\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.1199 - acc: 0.6555\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.1036 - acc: 0.6584\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.0974 - acc: 0.6594\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.0843 - acc: 0.6617\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.0724 - acc: 0.6661\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.0645 - acc: 0.6669\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.0544 - acc: 0.6676\n",
      "Epoch 19/70\n",
      " - 3s - loss: 1.0449 - acc: 0.6695\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.0400 - acc: 0.6706\n",
      "Epoch 21/70\n",
      " - 3s - loss: 1.0315 - acc: 0.6706\n",
      "Epoch 22/70\n",
      " - 3s - loss: 1.0271 - acc: 0.6718\n",
      "Epoch 23/70\n",
      " - 3s - loss: 1.0181 - acc: 0.6750\n",
      "Epoch 24/70\n",
      " - 3s - loss: 1.0127 - acc: 0.6754\n",
      "Epoch 25/70\n",
      " - 3s - loss: 1.0043 - acc: 0.6770\n",
      "Epoch 26/70\n",
      " - 3s - loss: 1.0032 - acc: 0.6776\n",
      "Epoch 27/70\n",
      " - 2s - loss: 0.9971 - acc: 0.6785\n",
      "Epoch 28/70\n",
      " - 3s - loss: 0.9930 - acc: 0.6797\n",
      "Epoch 29/70\n",
      " - 2s - loss: 0.9855 - acc: 0.6821\n",
      "Epoch 30/70\n",
      " - 2s - loss: 0.9838 - acc: 0.6823\n",
      "Epoch 31/70\n",
      " - 3s - loss: 0.9742 - acc: 0.6831\n",
      "Epoch 32/70\n",
      " - 3s - loss: 0.9732 - acc: 0.6849\n",
      "Epoch 33/70\n",
      " - 3s - loss: 0.9723 - acc: 0.6854\n",
      "Epoch 34/70\n",
      " - 4s - loss: 0.9676 - acc: 0.6852\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9600 - acc: 0.6872\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9598 - acc: 0.6866\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9581 - acc: 0.6873\n",
      "Epoch 38/70\n",
      " - 3s - loss: 0.9539 - acc: 0.6873\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.9520 - acc: 0.6885\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.9505 - acc: 0.6890\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.9439 - acc: 0.6902\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.9432 - acc: 0.6914\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.9393 - acc: 0.6912\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.9369 - acc: 0.6903\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.9362 - acc: 0.6919\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.9348 - acc: 0.6917\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.9322 - acc: 0.6913\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.9276 - acc: 0.6927\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.9249 - acc: 0.6941\n",
      "Epoch 50/70\n",
      " - 3s - loss: 0.9239 - acc: 0.6940\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.9229 - acc: 0.6937\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.9193 - acc: 0.6944\n",
      "Epoch 53/70\n",
      " - 3s - loss: 0.9230 - acc: 0.6942\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.9200 - acc: 0.6961\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.9184 - acc: 0.6952\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.9117 - acc: 0.6962\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.9147 - acc: 0.6966\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.9134 - acc: 0.6965\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.9104 - acc: 0.6986\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.9091 - acc: 0.6977\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.9110 - acc: 0.6973\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.9061 - acc: 0.6965\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.9074 - acc: 0.6961\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.8995 - acc: 0.6973\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.9000 - acc: 0.6999\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.8991 - acc: 0.6981\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.8986 - acc: 0.6993\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.8982 - acc: 0.6994\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.8964 - acc: 0.6990\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.8944 - acc: 0.6985\n",
      "[CV]  nodes_l3=80, nodes_l2=140, nodes_l1=180, dropout_l3=0.4, dropout_l2=0.1, dropout_l1=0.4, batch_size=2000, total= 3.5min\n",
      "[CV] nodes_l3=50, nodes_l2=120, nodes_l1=180, dropout_l3=0.4, dropout_l2=0.1, dropout_l1=0.30000000000000004, batch_size=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=180)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 5s - loss: 2.4763 - acc: 0.3463\n",
      "Epoch 2/70\n",
      " - 2s - loss: 1.5966 - acc: 0.5650\n",
      "Epoch 3/70\n",
      " - 2s - loss: 1.3728 - acc: 0.6134\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.2685 - acc: 0.6344\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.2104 - acc: 0.6424\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.1734 - acc: 0.6493\n",
      "Epoch 7/70\n",
      " - 2s - loss: 1.1401 - acc: 0.6571\n",
      "Epoch 8/70\n",
      " - 2s - loss: 1.1132 - acc: 0.6602\n",
      "Epoch 9/70\n",
      " - 2s - loss: 1.0938 - acc: 0.6649\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.0805 - acc: 0.6672\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.0654 - acc: 0.6687\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.0505 - acc: 0.6712\n",
      "Epoch 13/70\n",
      " - 2s - loss: 1.0376 - acc: 0.6741\n",
      "Epoch 14/70\n",
      " - 2s - loss: 1.0278 - acc: 0.6746\n",
      "Epoch 15/70\n",
      " - 2s - loss: 1.0197 - acc: 0.6785\n",
      "Epoch 16/70\n",
      " - 2s - loss: 1.0097 - acc: 0.6799\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.0039 - acc: 0.6799\n",
      "Epoch 18/70\n",
      " - 3s - loss: 0.9941 - acc: 0.6820\n",
      "Epoch 19/70\n",
      " - 3s - loss: 0.9884 - acc: 0.6832\n",
      "Epoch 20/70\n",
      " - 2s - loss: 0.9815 - acc: 0.6871\n",
      "Epoch 21/70\n",
      " - 2s - loss: 0.9732 - acc: 0.6872\n",
      "Epoch 22/70\n",
      " - 2s - loss: 0.9675 - acc: 0.6890\n",
      "Epoch 23/70\n",
      " - 3s - loss: 0.9652 - acc: 0.6873\n",
      "Epoch 24/70\n",
      " - 3s - loss: 0.9603 - acc: 0.6884\n",
      "Epoch 25/70\n",
      " - 3s - loss: 0.9584 - acc: 0.6901\n",
      "Epoch 26/70\n",
      " - 2s - loss: 0.9490 - acc: 0.6908\n",
      "Epoch 27/70\n",
      " - 2s - loss: 0.9483 - acc: 0.6912\n",
      "Epoch 28/70\n",
      " - 3s - loss: 0.9397 - acc: 0.6941\n",
      "Epoch 29/70\n",
      " - 2s - loss: 0.9370 - acc: 0.6948\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.9337 - acc: 0.6949\n",
      "Epoch 31/70\n",
      " - 3s - loss: 0.9309 - acc: 0.6945\n",
      "Epoch 32/70\n",
      " - 2s - loss: 0.9295 - acc: 0.6962\n",
      "Epoch 33/70\n",
      " - 2s - loss: 0.9275 - acc: 0.6964\n",
      "Epoch 34/70\n",
      " - 4s - loss: 0.9207 - acc: 0.6976\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9152 - acc: 0.6995\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9168 - acc: 0.6972\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9146 - acc: 0.6990\n",
      "Epoch 38/70\n",
      " - 1115s - loss: 0.9122 - acc: 0.6977\n",
      "Epoch 39/70\n",
      " - 4s - loss: 0.9097 - acc: 0.6987\n",
      "Epoch 40/70\n",
      " - 4s - loss: 0.9083 - acc: 0.6995\n",
      "Epoch 41/70\n",
      " - 4s - loss: 0.9050 - acc: 0.7008\n",
      "Epoch 42/70\n",
      " - 4s - loss: 0.9020 - acc: 0.7016\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.9021 - acc: 0.7023\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.8994 - acc: 0.7014\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.8960 - acc: 0.7034\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.8956 - acc: 0.7024\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.8941 - acc: 0.7012\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.8907 - acc: 0.7032\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.8902 - acc: 0.7022\n",
      "Epoch 50/70\n",
      " - 3s - loss: 0.8880 - acc: 0.7031\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.8824 - acc: 0.7044\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.8840 - acc: 0.7052\n",
      "Epoch 53/70\n",
      " - 3s - loss: 0.8825 - acc: 0.7047\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.8817 - acc: 0.7041\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.8824 - acc: 0.7043\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.8785 - acc: 0.7057\n",
      "Epoch 57/70\n",
      " - 4s - loss: 0.8764 - acc: 0.7066\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.8731 - acc: 0.7065\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.8738 - acc: 0.7062\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.8755 - acc: 0.7057\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.8716 - acc: 0.7074\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.8706 - acc: 0.7074\n",
      "Epoch 63/70\n",
      " - 2s - loss: 0.8708 - acc: 0.7058\n",
      "Epoch 64/70\n",
      " - 2s - loss: 0.8688 - acc: 0.7072\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.8697 - acc: 0.7069\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.8686 - acc: 0.7064\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.8648 - acc: 0.7081\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.8643 - acc: 0.7087\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.8640 - acc: 0.7090\n",
      "Epoch 70/70\n",
      " - 2s - loss: 0.8607 - acc: 0.7083\n",
      "[CV]  nodes_l3=50, nodes_l2=120, nodes_l1=180, dropout_l3=0.4, dropout_l2=0.1, dropout_l1=0.30000000000000004, batch_size=1000, total=21.8min\n",
      "[CV] nodes_l3=50, nodes_l2=120, nodes_l1=180, dropout_l3=0.4, dropout_l2=0.1, dropout_l1=0.30000000000000004, batch_size=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=180)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 5s - loss: 2.4257 - acc: 0.3604\n",
      "Epoch 2/70\n",
      " - 3s - loss: 1.5865 - acc: 0.5664\n",
      "Epoch 3/70\n",
      " - 2s - loss: 1.3711 - acc: 0.6139\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.2652 - acc: 0.6331\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.2053 - acc: 0.6442\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.1630 - acc: 0.6534\n",
      "Epoch 7/70\n",
      " - 2s - loss: 1.1313 - acc: 0.6566\n",
      "Epoch 8/70\n",
      " - 2s - loss: 1.1103 - acc: 0.6604\n",
      "Epoch 9/70\n",
      " - 2s - loss: 1.0864 - acc: 0.6651\n",
      "Epoch 10/70\n",
      " - 2s - loss: 1.0748 - acc: 0.6654\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.0569 - acc: 0.6698\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.0467 - acc: 0.6725\n",
      "Epoch 13/70\n",
      " - 2s - loss: 1.0331 - acc: 0.6756\n",
      "Epoch 14/70\n",
      " - 2s - loss: 1.0181 - acc: 0.6776\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.0086 - acc: 0.6809\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.0028 - acc: 0.6803\n",
      "Epoch 17/70\n",
      " - 3s - loss: 0.9955 - acc: 0.6804\n",
      "Epoch 18/70\n",
      " - 3s - loss: 0.9909 - acc: 0.6844\n",
      "Epoch 19/70\n",
      " - 3s - loss: 0.9801 - acc: 0.6852\n",
      "Epoch 20/70\n",
      " - 3s - loss: 0.9727 - acc: 0.6877\n",
      "Epoch 21/70\n",
      " - 2s - loss: 0.9715 - acc: 0.6872\n",
      "Epoch 22/70\n",
      " - 2s - loss: 0.9647 - acc: 0.6897\n",
      "Epoch 23/70\n",
      " - 2s - loss: 0.9572 - acc: 0.6895\n",
      "Epoch 24/70\n",
      " - 2s - loss: 0.9538 - acc: 0.6905\n",
      "Epoch 25/70\n",
      " - 2s - loss: 0.9524 - acc: 0.6906\n",
      "Epoch 26/70\n",
      " - 2s - loss: 0.9470 - acc: 0.6941\n",
      "Epoch 27/70\n",
      " - 2s - loss: 0.9398 - acc: 0.6927\n",
      "Epoch 28/70\n",
      " - 2s - loss: 0.9395 - acc: 0.6945\n",
      "Epoch 29/70\n",
      " - 2s - loss: 0.9364 - acc: 0.6965\n",
      "Epoch 30/70\n",
      " - 2s - loss: 0.9312 - acc: 0.6954\n",
      "Epoch 31/70\n",
      " - 3s - loss: 0.9257 - acc: 0.6983\n",
      "Epoch 32/70\n",
      " - 3s - loss: 0.9241 - acc: 0.6974\n",
      "Epoch 33/70\n",
      " - 2s - loss: 0.9197 - acc: 0.6967\n",
      "Epoch 34/70\n",
      " - 2s - loss: 0.9188 - acc: 0.6984\n",
      "Epoch 35/70\n",
      " - 2s - loss: 0.9164 - acc: 0.6992\n",
      "Epoch 36/70\n",
      " - 2s - loss: 0.9111 - acc: 0.6991\n",
      "Epoch 37/70\n",
      " - 2s - loss: 0.9090 - acc: 0.6995\n",
      "Epoch 38/70\n",
      " - 2s - loss: 0.9097 - acc: 0.6984\n",
      "Epoch 39/70\n",
      " - 2s - loss: 0.9054 - acc: 0.6995\n",
      "Epoch 40/70\n",
      " - 2s - loss: 0.9036 - acc: 0.7003\n",
      "Epoch 41/70\n",
      " - 2s - loss: 0.9013 - acc: 0.7007\n",
      "Epoch 42/70\n",
      " - 2s - loss: 0.9006 - acc: 0.7006\n",
      "Epoch 43/70\n",
      " - 2s - loss: 0.8959 - acc: 0.7016\n",
      "Epoch 44/70\n",
      " - 2s - loss: 0.8967 - acc: 0.7025\n",
      "Epoch 45/70\n",
      " - 2s - loss: 0.8954 - acc: 0.7022\n",
      "Epoch 46/70\n",
      " - 2s - loss: 0.8904 - acc: 0.7040\n",
      "Epoch 47/70\n",
      " - 2s - loss: 0.8897 - acc: 0.7021\n",
      "Epoch 48/70\n",
      " - 2s - loss: 0.8907 - acc: 0.7057\n",
      "Epoch 49/70\n",
      " - 2s - loss: 0.8869 - acc: 0.7036\n",
      "Epoch 50/70\n",
      " - 2s - loss: 0.8868 - acc: 0.7027\n",
      "Epoch 51/70\n",
      " - 2s - loss: 0.8859 - acc: 0.7032\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.8835 - acc: 0.7030\n",
      "Epoch 53/70\n",
      " - 2s - loss: 0.8802 - acc: 0.7054\n",
      "Epoch 54/70\n",
      " - 2s - loss: 0.8796 - acc: 0.7047\n",
      "Epoch 55/70\n",
      " - 2s - loss: 0.8800 - acc: 0.7053\n",
      "Epoch 56/70\n",
      " - 2s - loss: 0.8768 - acc: 0.7061\n",
      "Epoch 57/70\n",
      " - 2s - loss: 0.8776 - acc: 0.7052\n",
      "Epoch 58/70\n",
      " - 2s - loss: 0.8761 - acc: 0.7041\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.8739 - acc: 0.7067\n",
      "Epoch 60/70\n",
      " - 2s - loss: 0.8772 - acc: 0.7064\n",
      "Epoch 61/70\n",
      " - 2s - loss: 0.8689 - acc: 0.7068\n",
      "Epoch 62/70\n",
      " - 2s - loss: 0.8716 - acc: 0.7081\n",
      "Epoch 63/70\n",
      " - 2s - loss: 0.8677 - acc: 0.7075\n",
      "Epoch 64/70\n",
      " - 2s - loss: 0.8627 - acc: 0.7070\n",
      "Epoch 65/70\n",
      " - 2s - loss: 0.8656 - acc: 0.7073\n",
      "Epoch 66/70\n",
      " - 2s - loss: 0.8669 - acc: 0.7081\n",
      "Epoch 67/70\n",
      " - 2s - loss: 0.8629 - acc: 0.7074\n",
      "Epoch 68/70\n",
      " - 2s - loss: 0.8652 - acc: 0.7084\n",
      "Epoch 69/70\n",
      " - 2s - loss: 0.8635 - acc: 0.7087\n",
      "Epoch 70/70\n",
      " - 2s - loss: 0.8592 - acc: 0.7084\n",
      "[CV]  nodes_l3=50, nodes_l2=120, nodes_l1=180, dropout_l3=0.4, dropout_l2=0.1, dropout_l1=0.30000000000000004, batch_size=1000, total= 2.8min\n",
      "[CV] nodes_l3=50, nodes_l2=120, nodes_l1=180, dropout_l3=0.4, dropout_l2=0.1, dropout_l1=0.30000000000000004, batch_size=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=180)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 5s - loss: 2.4874 - acc: 0.3429\n",
      "Epoch 2/70\n",
      " - 2s - loss: 1.5901 - acc: 0.5666\n",
      "Epoch 3/70\n",
      " - 2s - loss: 1.3539 - acc: 0.6162\n",
      "Epoch 4/70\n",
      " - 2s - loss: 1.2580 - acc: 0.6355\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.1959 - acc: 0.6449\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.1572 - acc: 0.6531\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.1260 - acc: 0.6577\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.0999 - acc: 0.6621\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.0820 - acc: 0.6656\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.0619 - acc: 0.6700\n",
      "Epoch 11/70\n",
      " - 2s - loss: 1.0493 - acc: 0.6713\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.0342 - acc: 0.6748\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.0231 - acc: 0.6775\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.0083 - acc: 0.6798\n",
      "Epoch 15/70\n",
      " - 2s - loss: 1.0010 - acc: 0.6816\n",
      "Epoch 16/70\n",
      " - 2s - loss: 0.9927 - acc: 0.6834\n",
      "Epoch 17/70\n",
      " - 3s - loss: 0.9844 - acc: 0.6849\n",
      "Epoch 18/70\n",
      " - 3s - loss: 0.9753 - acc: 0.6869\n",
      "Epoch 19/70\n",
      " - 2s - loss: 0.9684 - acc: 0.6897\n",
      "Epoch 20/70\n",
      " - 2s - loss: 0.9613 - acc: 0.6891\n",
      "Epoch 21/70\n",
      " - 3s - loss: 0.9537 - acc: 0.6912\n",
      "Epoch 22/70\n",
      " - 2s - loss: 0.9522 - acc: 0.6902\n",
      "Epoch 23/70\n",
      " - 2s - loss: 0.9471 - acc: 0.6915\n",
      "Epoch 24/70\n",
      " - 3s - loss: 0.9387 - acc: 0.6947\n",
      "Epoch 25/70\n",
      " - 3s - loss: 0.9398 - acc: 0.6933\n",
      "Epoch 26/70\n",
      " - 2s - loss: 0.9329 - acc: 0.6947\n",
      "Epoch 27/70\n",
      " - 2s - loss: 0.9299 - acc: 0.6960\n",
      "Epoch 28/70\n",
      " - 2s - loss: 0.9253 - acc: 0.6971\n",
      "Epoch 29/70\n",
      " - 2s - loss: 0.9228 - acc: 0.6964\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.9197 - acc: 0.6967\n",
      "Epoch 31/70\n",
      " - 3s - loss: 0.9176 - acc: 0.6965\n",
      "Epoch 32/70\n",
      " - 3s - loss: 0.9088 - acc: 0.6991\n",
      "Epoch 33/70\n",
      " - 3s - loss: 0.9060 - acc: 0.7010\n",
      "Epoch 34/70\n",
      " - 2s - loss: 0.9046 - acc: 0.7010\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9037 - acc: 0.6999\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.8996 - acc: 0.7011\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.8973 - acc: 0.7026\n",
      "Epoch 38/70\n",
      " - 3s - loss: 0.8938 - acc: 0.7026\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.8946 - acc: 0.7026\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.8877 - acc: 0.7044\n",
      "Epoch 41/70\n",
      " - 2s - loss: 0.8881 - acc: 0.7019\n",
      "Epoch 42/70\n",
      " - 2s - loss: 0.8876 - acc: 0.7045\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.8826 - acc: 0.7063\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.8824 - acc: 0.7039\n",
      "Epoch 45/70\n",
      " - 2s - loss: 0.8784 - acc: 0.7062\n",
      "Epoch 46/70\n",
      " - 2s - loss: 0.8804 - acc: 0.7054\n",
      "Epoch 47/70\n",
      " - 2s - loss: 0.8776 - acc: 0.7052\n",
      "Epoch 48/70\n",
      " - 2s - loss: 0.8724 - acc: 0.7053\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.8732 - acc: 0.7063\n",
      "Epoch 50/70\n",
      " - 3s - loss: 0.8711 - acc: 0.7065\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.8681 - acc: 0.7072\n",
      "Epoch 52/70\n",
      " - 2s - loss: 0.8686 - acc: 0.7080\n",
      "Epoch 53/70\n",
      " - 2s - loss: 0.8690 - acc: 0.7081\n",
      "Epoch 54/70\n",
      " - 2s - loss: 0.8654 - acc: 0.7094\n",
      "Epoch 55/70\n",
      " - 2s - loss: 0.8664 - acc: 0.7082\n",
      "Epoch 56/70\n",
      " - 2s - loss: 0.8647 - acc: 0.7078\n",
      "Epoch 57/70\n",
      " - 2s - loss: 0.8617 - acc: 0.7082\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.8603 - acc: 0.7096\n",
      "Epoch 59/70\n",
      " - 2s - loss: 0.8594 - acc: 0.7079\n",
      "Epoch 60/70\n",
      " - 2s - loss: 0.8571 - acc: 0.7105\n",
      "Epoch 61/70\n",
      " - 2s - loss: 0.8546 - acc: 0.7104\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.8533 - acc: 0.7091\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.8527 - acc: 0.7101\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.8527 - acc: 0.7109\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.8515 - acc: 0.7112\n",
      "Epoch 66/70\n",
      " - 2s - loss: 0.8488 - acc: 0.7116\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.8512 - acc: 0.7100\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.8503 - acc: 0.7111\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.8488 - acc: 0.7111\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.8466 - acc: 0.7135\n",
      "[CV]  nodes_l3=50, nodes_l2=120, nodes_l1=180, dropout_l3=0.4, dropout_l2=0.1, dropout_l1=0.30000000000000004, batch_size=1000, total= 3.2min\n",
      "[CV] nodes_l3=50, nodes_l2=120, nodes_l1=180, dropout_l3=0.4, dropout_l2=0.1, dropout_l1=0.30000000000000004, batch_size=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=180)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 6s - loss: 2.5587 - acc: 0.3336\n",
      "Epoch 2/70\n",
      " - 3s - loss: 1.6419 - acc: 0.5569\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.3998 - acc: 0.6068\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.2873 - acc: 0.6282\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.2226 - acc: 0.6407\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.1726 - acc: 0.6488\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.1442 - acc: 0.6515\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.1209 - acc: 0.6563\n",
      "Epoch 9/70\n",
      " - 4s - loss: 1.0974 - acc: 0.6612\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.0862 - acc: 0.6638\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.0665 - acc: 0.6675\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.0544 - acc: 0.6690\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.0415 - acc: 0.6717\n",
      "Epoch 14/70\n",
      " - 2s - loss: 1.0292 - acc: 0.6743\n",
      "Epoch 15/70\n",
      " - 2s - loss: 1.0221 - acc: 0.6766\n",
      "Epoch 16/70\n",
      " - 2s - loss: 1.0141 - acc: 0.6759\n",
      "Epoch 17/70\n",
      " - 2s - loss: 1.0039 - acc: 0.6800\n",
      "Epoch 18/70\n",
      " - 3s - loss: 0.9984 - acc: 0.6795\n",
      "Epoch 19/70\n",
      " - 3s - loss: 0.9932 - acc: 0.6822\n",
      "Epoch 20/70\n",
      " - 2s - loss: 0.9875 - acc: 0.6809\n",
      "Epoch 21/70\n",
      " - 3s - loss: 0.9800 - acc: 0.6838\n",
      "Epoch 22/70\n",
      " - 3s - loss: 0.9742 - acc: 0.6859\n",
      "Epoch 23/70\n",
      " - 3s - loss: 0.9683 - acc: 0.6866\n",
      "Epoch 24/70\n",
      " - 3s - loss: 0.9628 - acc: 0.6855\n",
      "Epoch 25/70\n",
      " - 3s - loss: 0.9597 - acc: 0.6882\n",
      "Epoch 26/70\n",
      " - 2s - loss: 0.9522 - acc: 0.6891\n",
      "Epoch 27/70\n",
      " - 3s - loss: 0.9472 - acc: 0.6898\n",
      "Epoch 28/70\n",
      " - 3s - loss: 0.9460 - acc: 0.6908\n",
      "Epoch 29/70\n",
      " - 3s - loss: 0.9435 - acc: 0.6905\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.9386 - acc: 0.6933\n",
      "Epoch 31/70\n",
      " - 3s - loss: 0.9339 - acc: 0.6937\n",
      "Epoch 32/70\n",
      " - 3s - loss: 0.9295 - acc: 0.6963\n",
      "Epoch 33/70\n",
      " - 2s - loss: 0.9313 - acc: 0.6948\n",
      "Epoch 34/70\n",
      " - 2s - loss: 0.9256 - acc: 0.6952\n",
      "Epoch 35/70\n",
      " - 2s - loss: 0.9233 - acc: 0.6949\n",
      "Epoch 36/70\n",
      " - 4s - loss: 0.9198 - acc: 0.6957\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9144 - acc: 0.6961\n",
      "Epoch 38/70\n",
      " - 2s - loss: 0.9180 - acc: 0.6971\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.9120 - acc: 0.6966\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.9144 - acc: 0.6968\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.9100 - acc: 0.6980\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.9056 - acc: 0.6988\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.9059 - acc: 0.6983\n",
      "Epoch 44/70\n",
      " - 2s - loss: 0.9062 - acc: 0.6977\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.9017 - acc: 0.6984\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.9018 - acc: 0.6996\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.8968 - acc: 0.7005\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.8943 - acc: 0.7017\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.8947 - acc: 0.7008\n",
      "Epoch 50/70\n",
      " - 2s - loss: 0.8925 - acc: 0.7022\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.8947 - acc: 0.6995\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.8900 - acc: 0.7034\n",
      "Epoch 53/70\n",
      " - 3s - loss: 0.8875 - acc: 0.7033\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.8856 - acc: 0.7021\n",
      "Epoch 55/70\n",
      " - 2s - loss: 0.8851 - acc: 0.7035\n",
      "Epoch 56/70\n",
      " - 2s - loss: 0.8829 - acc: 0.7027\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.8812 - acc: 0.7037\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.8805 - acc: 0.7025\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.8802 - acc: 0.7044\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.8782 - acc: 0.7047\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.8805 - acc: 0.7034\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.8769 - acc: 0.7056\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.8755 - acc: 0.7052\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.8733 - acc: 0.7045\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.8727 - acc: 0.7054\n",
      "Epoch 66/70\n",
      " - 2s - loss: 0.8719 - acc: 0.7058\n",
      "Epoch 67/70\n",
      " - 2s - loss: 0.8696 - acc: 0.7048\n",
      "Epoch 68/70\n",
      " - 2s - loss: 0.8697 - acc: 0.7067\n",
      "Epoch 69/70\n",
      " - 2s - loss: 0.8665 - acc: 0.7065\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.8709 - acc: 0.7053\n",
      "[CV]  nodes_l3=50, nodes_l2=120, nodes_l1=180, dropout_l3=0.4, dropout_l2=0.1, dropout_l1=0.30000000000000004, batch_size=1000, total= 3.4min\n",
      "[CV] nodes_l3=50, nodes_l2=100, nodes_l1=150, dropout_l3=0.30000000000000004, dropout_l2=0.4, dropout_l1=0.2, batch_size=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=150)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 4s - loss: 2.6591 - acc: 0.3026\n",
      "Epoch 2/70\n",
      " - 2s - loss: 1.7759 - acc: 0.5190\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.5098 - acc: 0.5839\n",
      "Epoch 4/70\n",
      " - 2s - loss: 1.3913 - acc: 0.6109\n",
      "Epoch 5/70\n",
      " - 2s - loss: 1.3164 - acc: 0.6244\n",
      "Epoch 6/70\n",
      " - 2s - loss: 1.2642 - acc: 0.6351\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.2310 - acc: 0.6408\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.2053 - acc: 0.6462\n",
      "Epoch 9/70\n",
      " - 2s - loss: 1.1769 - acc: 0.6507\n",
      "Epoch 10/70\n",
      " - 2s - loss: 1.1670 - acc: 0.6531\n",
      "Epoch 11/70\n",
      " - 2s - loss: 1.1516 - acc: 0.6538\n",
      "Epoch 12/70\n",
      " - 2s - loss: 1.1358 - acc: 0.6601\n",
      "Epoch 13/70\n",
      " - 2s - loss: 1.1256 - acc: 0.6604\n",
      "Epoch 14/70\n",
      " - 2s - loss: 1.1103 - acc: 0.6616\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.1062 - acc: 0.6633\n",
      "Epoch 16/70\n",
      " - 2s - loss: 1.0920 - acc: 0.6666\n",
      "Epoch 17/70\n",
      " - 2s - loss: 1.0858 - acc: 0.6661\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.0762 - acc: 0.6683\n",
      "Epoch 19/70\n",
      " - 3s - loss: 1.0731 - acc: 0.6701\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.0617 - acc: 0.6730\n",
      "Epoch 21/70\n",
      " - 3s - loss: 1.0539 - acc: 0.6749\n",
      "Epoch 22/70\n",
      " - 2s - loss: 1.0486 - acc: 0.6768\n",
      "Epoch 23/70\n",
      " - 2s - loss: 1.0431 - acc: 0.6742\n",
      "Epoch 24/70\n",
      " - 2s - loss: 1.0404 - acc: 0.6773\n",
      "Epoch 25/70\n",
      " - 2s - loss: 1.0323 - acc: 0.6793\n",
      "Epoch 26/70\n",
      " - 2s - loss: 1.0331 - acc: 0.6793\n",
      "Epoch 27/70\n",
      " - 2s - loss: 1.0264 - acc: 0.6799\n",
      "Epoch 28/70\n",
      " - 2s - loss: 1.0239 - acc: 0.6799\n",
      "Epoch 29/70\n",
      " - 2s - loss: 1.0163 - acc: 0.6806\n",
      "Epoch 30/70\n",
      " - 2s - loss: 1.0147 - acc: 0.6826\n",
      "Epoch 31/70\n",
      " - 2s - loss: 1.0127 - acc: 0.6795\n",
      "Epoch 32/70\n",
      " - 2s - loss: 1.0072 - acc: 0.6824\n",
      "Epoch 33/70\n",
      " - 2s - loss: 1.0036 - acc: 0.6835\n",
      "Epoch 34/70\n",
      " - 2s - loss: 1.0001 - acc: 0.6835\n",
      "Epoch 35/70\n",
      " - 2s - loss: 0.9994 - acc: 0.6849\n",
      "Epoch 36/70\n",
      " - 2s - loss: 0.9984 - acc: 0.6827\n",
      "Epoch 37/70\n",
      " - 2s - loss: 0.9947 - acc: 0.6872\n",
      "Epoch 38/70\n",
      " - 2s - loss: 0.9926 - acc: 0.6869\n",
      "Epoch 39/70\n",
      " - 2s - loss: 0.9924 - acc: 0.6866\n",
      "Epoch 40/70\n",
      " - 2s - loss: 0.9856 - acc: 0.6865\n",
      "Epoch 41/70\n",
      " - 2s - loss: 0.9835 - acc: 0.6877\n",
      "Epoch 42/70\n",
      " - 2s - loss: 0.9824 - acc: 0.6867\n",
      "Epoch 43/70\n",
      " - 2s - loss: 0.9838 - acc: 0.6877\n",
      "Epoch 44/70\n",
      " - 2s - loss: 0.9812 - acc: 0.6882\n",
      "Epoch 45/70\n",
      " - 2s - loss: 0.9771 - acc: 0.6893\n",
      "Epoch 46/70\n",
      " - 2s - loss: 0.9785 - acc: 0.6892\n",
      "Epoch 47/70\n",
      " - 2s - loss: 0.9762 - acc: 0.6896\n",
      "Epoch 48/70\n",
      " - 2s - loss: 0.9718 - acc: 0.6908\n",
      "Epoch 49/70\n",
      " - 2s - loss: 0.9698 - acc: 0.6904\n",
      "Epoch 50/70\n",
      " - 2s - loss: 0.9687 - acc: 0.6895\n",
      "Epoch 51/70\n",
      " - 2s - loss: 0.9699 - acc: 0.6890\n",
      "Epoch 52/70\n",
      " - 2s - loss: 0.9662 - acc: 0.6918\n",
      "Epoch 53/70\n",
      " - 2s - loss: 0.9651 - acc: 0.6901\n",
      "Epoch 54/70\n",
      " - 2s - loss: 0.9620 - acc: 0.6917\n",
      "Epoch 55/70\n",
      " - 2s - loss: 0.9584 - acc: 0.6932\n",
      "Epoch 56/70\n",
      " - 2s - loss: 0.9601 - acc: 0.6924\n",
      "Epoch 57/70\n",
      " - 2s - loss: 0.9579 - acc: 0.6931\n",
      "Epoch 58/70\n",
      " - 2s - loss: 0.9560 - acc: 0.6913\n",
      "Epoch 59/70\n",
      " - 2s - loss: 0.9557 - acc: 0.6925\n",
      "Epoch 60/70\n",
      " - 2s - loss: 0.9545 - acc: 0.6929\n",
      "Epoch 61/70\n",
      " - 2s - loss: 0.9520 - acc: 0.6932\n",
      "Epoch 62/70\n",
      " - 2s - loss: 0.9515 - acc: 0.6948\n",
      "Epoch 63/70\n",
      " - 2s - loss: 0.9526 - acc: 0.6944\n",
      "Epoch 64/70\n",
      " - 2s - loss: 0.9492 - acc: 0.6963\n",
      "Epoch 65/70\n",
      " - 2s - loss: 0.9489 - acc: 0.6955\n",
      "Epoch 66/70\n",
      " - 2s - loss: 0.9483 - acc: 0.6961\n",
      "Epoch 67/70\n",
      " - 2s - loss: 0.9499 - acc: 0.6958\n",
      "Epoch 68/70\n",
      " - 2s - loss: 0.9498 - acc: 0.6949\n",
      "Epoch 69/70\n",
      " - 2s - loss: 0.9433 - acc: 0.6965\n",
      "Epoch 70/70\n",
      " - 2s - loss: 0.9438 - acc: 0.6972\n",
      "[CV]  nodes_l3=50, nodes_l2=100, nodes_l1=150, dropout_l3=0.30000000000000004, dropout_l2=0.4, dropout_l1=0.2, batch_size=1000, total= 2.6min\n",
      "[CV] nodes_l3=50, nodes_l2=100, nodes_l1=150, dropout_l3=0.30000000000000004, dropout_l2=0.4, dropout_l1=0.2, batch_size=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=150)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 6s - loss: 2.6608 - acc: 0.2928\n",
      "Epoch 2/70\n",
      " - 2s - loss: 1.7574 - acc: 0.5228\n",
      "Epoch 3/70\n",
      " - 2s - loss: 1.5034 - acc: 0.5863\n",
      "Epoch 4/70\n",
      " - 2s - loss: 1.3870 - acc: 0.6103\n",
      "Epoch 5/70\n",
      " - 2s - loss: 1.3170 - acc: 0.6248\n",
      "Epoch 6/70\n",
      " - 2s - loss: 1.2656 - acc: 0.6343\n",
      "Epoch 7/70\n",
      " - 2s - loss: 1.2364 - acc: 0.6380\n",
      "Epoch 8/70\n",
      " - 2s - loss: 1.2085 - acc: 0.6446\n",
      "Epoch 9/70\n",
      " - 2s - loss: 1.1826 - acc: 0.6485\n",
      "Epoch 10/70\n",
      " - 2s - loss: 1.1650 - acc: 0.6528\n",
      "Epoch 11/70\n",
      " - 2s - loss: 1.1507 - acc: 0.6539\n",
      "Epoch 12/70\n",
      " - 2s - loss: 1.1353 - acc: 0.6585\n",
      "Epoch 13/70\n",
      " - 2s - loss: 1.1264 - acc: 0.6597\n",
      "Epoch 14/70\n",
      " - 2s - loss: 1.1103 - acc: 0.6624\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.0999 - acc: 0.6630\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.0907 - acc: 0.6657\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.0820 - acc: 0.6690\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.0750 - acc: 0.6689\n",
      "Epoch 19/70\n",
      " - 3s - loss: 1.0745 - acc: 0.6691\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.0565 - acc: 0.6746\n",
      "Epoch 21/70\n",
      " - 3s - loss: 1.0543 - acc: 0.6724\n",
      "Epoch 22/70\n",
      " - 3s - loss: 1.0524 - acc: 0.6740\n",
      "Epoch 23/70\n",
      " - 3s - loss: 1.0443 - acc: 0.6758\n",
      "Epoch 24/70\n",
      " - 3s - loss: 1.0390 - acc: 0.6769\n",
      "Epoch 25/70\n",
      " - 3s - loss: 1.0364 - acc: 0.6766\n",
      "Epoch 26/70\n",
      " - 3s - loss: 1.0289 - acc: 0.6779\n",
      "Epoch 27/70\n",
      " - 3s - loss: 1.0246 - acc: 0.6801\n",
      "Epoch 28/70\n",
      " - 3s - loss: 1.0217 - acc: 0.6802\n",
      "Epoch 29/70\n",
      " - 3s - loss: 1.0182 - acc: 0.6794\n",
      "Epoch 30/70\n",
      " - 3s - loss: 1.0140 - acc: 0.6817\n",
      "Epoch 31/70\n",
      " - 3s - loss: 1.0089 - acc: 0.6837\n",
      "Epoch 32/70\n",
      " - 3s - loss: 1.0073 - acc: 0.6831\n",
      "Epoch 33/70\n",
      " - 3s - loss: 1.0051 - acc: 0.6839\n",
      "Epoch 34/70\n",
      " - 3s - loss: 0.9973 - acc: 0.6846\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9948 - acc: 0.6877\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9953 - acc: 0.6855\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9906 - acc: 0.6873\n",
      "Epoch 38/70\n",
      " - 3s - loss: 0.9925 - acc: 0.6854\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.9866 - acc: 0.6867\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.9847 - acc: 0.6888\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.9803 - acc: 0.6903\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.9803 - acc: 0.6889\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.9744 - acc: 0.6906\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.9752 - acc: 0.6902\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.9730 - acc: 0.6903\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.9699 - acc: 0.6905\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.9694 - acc: 0.6906\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.9685 - acc: 0.6928\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.9672 - acc: 0.6920\n",
      "Epoch 50/70\n",
      " - 3s - loss: 0.9656 - acc: 0.6921\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.9626 - acc: 0.6931\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.9609 - acc: 0.6927\n",
      "Epoch 53/70\n",
      " - 3s - loss: 0.9597 - acc: 0.6949\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.9580 - acc: 0.6946\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.9551 - acc: 0.6944\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.9557 - acc: 0.6958\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.9530 - acc: 0.6939\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.9514 - acc: 0.6970\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.9512 - acc: 0.6954\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.9496 - acc: 0.6956\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.9441 - acc: 0.6956\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.9460 - acc: 0.6961\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.9481 - acc: 0.6968\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.9460 - acc: 0.6960\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.9469 - acc: 0.6972\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.9411 - acc: 0.6974\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.9456 - acc: 0.6971\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.9414 - acc: 0.6984\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.9380 - acc: 0.6993\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.9410 - acc: 0.6987\n",
      "[CV]  nodes_l3=50, nodes_l2=100, nodes_l1=150, dropout_l3=0.30000000000000004, dropout_l2=0.4, dropout_l1=0.2, batch_size=1000, total= 3.4min\n",
      "[CV] nodes_l3=50, nodes_l2=100, nodes_l1=150, dropout_l3=0.30000000000000004, dropout_l2=0.4, dropout_l1=0.2, batch_size=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=150)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 6s - loss: 2.6608 - acc: 0.2962\n",
      "Epoch 2/70\n",
      " - 3s - loss: 1.7951 - acc: 0.5124\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.5103 - acc: 0.5804\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.3791 - acc: 0.6104\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.3035 - acc: 0.6253\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.2554 - acc: 0.6354\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.2199 - acc: 0.6444\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.1894 - acc: 0.6486\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.1673 - acc: 0.6534\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.1483 - acc: 0.6571\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.1342 - acc: 0.6591\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.1234 - acc: 0.6640\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.1070 - acc: 0.6663\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.0965 - acc: 0.6662\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.0853 - acc: 0.6673\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.0799 - acc: 0.6695\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.0682 - acc: 0.6731\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.0662 - acc: 0.6726\n",
      "Epoch 19/70\n",
      " - 3s - loss: 1.0532 - acc: 0.6754\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.0451 - acc: 0.6780\n",
      "Epoch 21/70\n",
      " - 3s - loss: 1.0446 - acc: 0.6771\n",
      "Epoch 22/70\n",
      " - 3s - loss: 1.0399 - acc: 0.6784\n",
      "Epoch 23/70\n",
      " - 4s - loss: 1.0309 - acc: 0.6792\n",
      "Epoch 24/70\n",
      " - 3s - loss: 1.0272 - acc: 0.6808\n",
      "Epoch 25/70\n",
      " - 3s - loss: 1.0219 - acc: 0.6815\n",
      "Epoch 26/70\n",
      " - 3s - loss: 1.0154 - acc: 0.6828\n",
      "Epoch 27/70\n",
      " - 3s - loss: 1.0118 - acc: 0.6842\n",
      "Epoch 28/70\n",
      " - 3s - loss: 1.0084 - acc: 0.6842\n",
      "Epoch 29/70\n",
      " - 4s - loss: 1.0081 - acc: 0.6833\n",
      "Epoch 30/70\n",
      " - 3s - loss: 1.0015 - acc: 0.6852\n",
      "Epoch 31/70\n",
      " - 3s - loss: 0.9952 - acc: 0.6867\n",
      "Epoch 32/70\n",
      " - 3s - loss: 0.9949 - acc: 0.6863\n",
      "Epoch 33/70\n",
      " - 3s - loss: 0.9944 - acc: 0.6868\n",
      "Epoch 34/70\n",
      " - 3s - loss: 0.9878 - acc: 0.6881\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9854 - acc: 0.6887\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9793 - acc: 0.6924\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9825 - acc: 0.6864\n",
      "Epoch 38/70\n",
      " - 2s - loss: 0.9789 - acc: 0.6892\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.9766 - acc: 0.6909\n",
      "Epoch 40/70\n",
      " - 2s - loss: 0.9729 - acc: 0.6918\n",
      "Epoch 41/70\n",
      " - 2s - loss: 0.9690 - acc: 0.6912\n",
      "Epoch 42/70\n",
      " - 2s - loss: 0.9671 - acc: 0.6937\n",
      "Epoch 43/70\n",
      " - 2s - loss: 0.9664 - acc: 0.6927\n",
      "Epoch 44/70\n",
      " - 2s - loss: 0.9645 - acc: 0.6932\n",
      "Epoch 45/70\n",
      " - 2s - loss: 0.9689 - acc: 0.6909\n",
      "Epoch 46/70\n",
      " - 2s - loss: 0.9601 - acc: 0.6942\n",
      "Epoch 47/70\n",
      " - 2s - loss: 0.9602 - acc: 0.6949\n",
      "Epoch 48/70\n",
      " - 2s - loss: 0.9575 - acc: 0.6944\n",
      "Epoch 49/70\n",
      " - 2s - loss: 0.9560 - acc: 0.6953\n",
      "Epoch 50/70\n",
      " - 2s - loss: 0.9565 - acc: 0.6950\n",
      "Epoch 51/70\n",
      " - 2s - loss: 0.9507 - acc: 0.6960\n",
      "Epoch 52/70\n",
      " - 2s - loss: 0.9525 - acc: 0.6962\n",
      "Epoch 53/70\n",
      " - 2s - loss: 0.9524 - acc: 0.6946\n",
      "Epoch 54/70\n",
      " - 2s - loss: 0.9458 - acc: 0.6971\n",
      "Epoch 55/70\n",
      " - 2s - loss: 0.9484 - acc: 0.6967\n",
      "Epoch 56/70\n",
      " - 2s - loss: 0.9467 - acc: 0.6980\n",
      "Epoch 57/70\n",
      " - 2s - loss: 0.9421 - acc: 0.6988\n",
      "Epoch 58/70\n",
      " - 2s - loss: 0.9464 - acc: 0.6960\n",
      "Epoch 59/70\n",
      " - 2s - loss: 0.9444 - acc: 0.6983\n",
      "Epoch 60/70\n",
      " - 2s - loss: 0.9417 - acc: 0.6992\n",
      "Epoch 61/70\n",
      " - 2s - loss: 0.9390 - acc: 0.6977\n",
      "Epoch 62/70\n",
      " - 2s - loss: 0.9362 - acc: 0.6993\n",
      "Epoch 63/70\n",
      " - 2s - loss: 0.9383 - acc: 0.6988\n",
      "Epoch 64/70\n",
      " - 2s - loss: 0.9323 - acc: 0.6997\n",
      "Epoch 65/70\n",
      " - 2s - loss: 0.9375 - acc: 0.6995\n",
      "Epoch 66/70\n",
      " - 2s - loss: 0.9309 - acc: 0.6991\n",
      "Epoch 67/70\n",
      " - 2s - loss: 0.9316 - acc: 0.7006\n",
      "Epoch 68/70\n",
      " - 2s - loss: 0.9309 - acc: 0.7015\n",
      "Epoch 69/70\n",
      " - 2s - loss: 0.9289 - acc: 0.7010\n",
      "Epoch 70/70\n",
      " - 2s - loss: 0.9285 - acc: 0.7019\n",
      "[CV]  nodes_l3=50, nodes_l2=100, nodes_l1=150, dropout_l3=0.30000000000000004, dropout_l2=0.4, dropout_l1=0.2, batch_size=1000, total= 3.1min\n",
      "[CV] nodes_l3=50, nodes_l2=100, nodes_l1=150, dropout_l3=0.30000000000000004, dropout_l2=0.4, dropout_l1=0.2, batch_size=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=150)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 5s - loss: 2.6397 - acc: 0.3024\n",
      "Epoch 2/70\n",
      " - 2s - loss: 1.7587 - acc: 0.5263\n",
      "Epoch 3/70\n",
      " - 2s - loss: 1.5257 - acc: 0.5800\n",
      "Epoch 4/70\n",
      " - 2s - loss: 1.4053 - acc: 0.6076\n",
      "Epoch 5/70\n",
      " - 2s - loss: 1.3313 - acc: 0.6222\n",
      "Epoch 6/70\n",
      " - 2s - loss: 1.2798 - acc: 0.6309\n",
      "Epoch 7/70\n",
      " - 2s - loss: 1.2411 - acc: 0.6367\n",
      "Epoch 8/70\n",
      " - 2s - loss: 1.2144 - acc: 0.6431\n",
      "Epoch 9/70\n",
      " - 2s - loss: 1.1904 - acc: 0.6451\n",
      "Epoch 10/70\n",
      " - 2s - loss: 1.1700 - acc: 0.6498\n",
      "Epoch 11/70\n",
      " - 2s - loss: 1.1562 - acc: 0.6511\n",
      "Epoch 12/70\n",
      " - 2s - loss: 1.1371 - acc: 0.6558\n",
      "Epoch 13/70\n",
      " - 2s - loss: 1.1237 - acc: 0.6596\n",
      "Epoch 14/70\n",
      " - 2s - loss: 1.1159 - acc: 0.6608\n",
      "Epoch 15/70\n",
      " - 2s - loss: 1.1014 - acc: 0.6642\n",
      "Epoch 16/70\n",
      " - 2s - loss: 1.0942 - acc: 0.6644\n",
      "Epoch 17/70\n",
      " - 2s - loss: 1.0850 - acc: 0.6672\n",
      "Epoch 18/70\n",
      " - 2s - loss: 1.0798 - acc: 0.6665\n",
      "Epoch 19/70\n",
      " - 3s - loss: 1.0705 - acc: 0.6686\n",
      "Epoch 20/70\n",
      " - 2s - loss: 1.0637 - acc: 0.6719\n",
      "Epoch 21/70\n",
      " - 2s - loss: 1.0562 - acc: 0.6737\n",
      "Epoch 22/70\n",
      " - 2s - loss: 1.0503 - acc: 0.6749\n",
      "Epoch 23/70\n",
      " - 2s - loss: 1.0426 - acc: 0.6750\n",
      "Epoch 24/70\n",
      " - 2s - loss: 1.0394 - acc: 0.6759\n",
      "Epoch 25/70\n",
      " - 2s - loss: 1.0370 - acc: 0.6761\n",
      "Epoch 26/70\n",
      " - 2s - loss: 1.0297 - acc: 0.6781\n",
      "Epoch 27/70\n",
      " - 2s - loss: 1.0290 - acc: 0.6781\n",
      "Epoch 28/70\n",
      " - 2s - loss: 1.0257 - acc: 0.6775\n",
      "Epoch 29/70\n",
      " - 2s - loss: 1.0180 - acc: 0.6821\n",
      "Epoch 30/70\n",
      " - 2s - loss: 1.0116 - acc: 0.6825\n",
      "Epoch 31/70\n",
      " - 2s - loss: 1.0110 - acc: 0.6823\n",
      "Epoch 32/70\n",
      " - 2s - loss: 1.0090 - acc: 0.6819\n",
      "Epoch 33/70\n",
      " - 2s - loss: 1.0041 - acc: 0.6835\n",
      "Epoch 34/70\n",
      " - 2s - loss: 1.0038 - acc: 0.6854\n",
      "Epoch 35/70\n",
      " - 2s - loss: 1.0002 - acc: 0.6853\n",
      "Epoch 36/70\n",
      " - 2s - loss: 0.9972 - acc: 0.6852\n",
      "Epoch 37/70\n",
      " - 2s - loss: 0.9934 - acc: 0.6856\n",
      "Epoch 38/70\n",
      " - 2s - loss: 0.9915 - acc: 0.6882\n",
      "Epoch 39/70\n",
      " - 2s - loss: 0.9896 - acc: 0.6875\n",
      "Epoch 40/70\n",
      " - 2s - loss: 0.9884 - acc: 0.6868\n",
      "Epoch 41/70\n",
      " - 2s - loss: 0.9894 - acc: 0.6875\n",
      "Epoch 42/70\n",
      " - 2s - loss: 0.9839 - acc: 0.6881\n",
      "Epoch 43/70\n",
      " - 2s - loss: 0.9831 - acc: 0.6898\n",
      "Epoch 44/70\n",
      " - 2s - loss: 0.9794 - acc: 0.6876\n",
      "Epoch 45/70\n",
      " - 2s - loss: 0.9765 - acc: 0.6890\n",
      "Epoch 46/70\n",
      " - 2s - loss: 0.9703 - acc: 0.6899\n",
      "Epoch 47/70\n",
      " - 2s - loss: 0.9737 - acc: 0.6903\n",
      "Epoch 48/70\n",
      " - 2s - loss: 0.9718 - acc: 0.6903\n",
      "Epoch 49/70\n",
      " - 2s - loss: 0.9718 - acc: 0.6913\n",
      "Epoch 50/70\n",
      " - 2s - loss: 0.9699 - acc: 0.6917\n",
      "Epoch 51/70\n",
      " - 2s - loss: 0.9671 - acc: 0.6921\n",
      "Epoch 52/70\n",
      " - 2s - loss: 0.9652 - acc: 0.6909\n",
      "Epoch 53/70\n",
      " - 2s - loss: 0.9636 - acc: 0.6913\n",
      "Epoch 54/70\n",
      " - 2s - loss: 0.9622 - acc: 0.6938\n",
      "Epoch 55/70\n",
      " - 2s - loss: 0.9635 - acc: 0.6930\n",
      "Epoch 56/70\n",
      " - 2s - loss: 0.9598 - acc: 0.6928\n",
      "Epoch 57/70\n",
      " - 2s - loss: 0.9587 - acc: 0.6939\n",
      "Epoch 58/70\n",
      " - 2s - loss: 0.9556 - acc: 0.6931\n",
      "Epoch 59/70\n",
      " - 2s - loss: 0.9565 - acc: 0.6929\n",
      "Epoch 60/70\n",
      " - 2s - loss: 0.9562 - acc: 0.6932\n",
      "Epoch 61/70\n",
      " - 2s - loss: 0.9515 - acc: 0.6928\n",
      "Epoch 62/70\n",
      " - 2s - loss: 0.9554 - acc: 0.6933\n",
      "Epoch 63/70\n",
      " - 2s - loss: 0.9541 - acc: 0.6940\n",
      "Epoch 64/70\n",
      " - 2s - loss: 0.9536 - acc: 0.6946\n",
      "Epoch 65/70\n",
      " - 2s - loss: 0.9538 - acc: 0.6946\n",
      "Epoch 66/70\n",
      " - 2s - loss: 0.9484 - acc: 0.6947\n",
      "Epoch 67/70\n",
      " - 2s - loss: 0.9499 - acc: 0.6937\n",
      "Epoch 68/70\n",
      " - 2s - loss: 0.9469 - acc: 0.6950\n",
      "Epoch 69/70\n",
      " - 2s - loss: 0.9438 - acc: 0.6960\n",
      "Epoch 70/70\n",
      " - 2s - loss: 0.9406 - acc: 0.6970\n",
      "[CV]  nodes_l3=50, nodes_l2=100, nodes_l1=150, dropout_l3=0.30000000000000004, dropout_l2=0.4, dropout_l1=0.2, batch_size=1000, total= 2.6min\n",
      "[CV] nodes_l3=70, nodes_l2=120, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=2000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=160)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 4s - loss: 2.8773 - acc: 0.2494\n",
      "Epoch 2/70\n",
      " - 2s - loss: 2.0091 - acc: 0.4581\n",
      "Epoch 3/70\n",
      " - 2s - loss: 1.6472 - acc: 0.5488\n",
      "Epoch 4/70\n",
      " - 2s - loss: 1.4729 - acc: 0.5886\n",
      "Epoch 5/70\n",
      " - 2s - loss: 1.3688 - acc: 0.6079\n",
      "Epoch 6/70\n",
      " - 2s - loss: 1.3016 - acc: 0.6200\n",
      "Epoch 7/70\n",
      " - 2s - loss: 1.2565 - acc: 0.6292\n",
      "Epoch 8/70\n",
      " - 2s - loss: 1.2225 - acc: 0.6360\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.1929 - acc: 0.6415\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.1732 - acc: 0.6466\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.1580 - acc: 0.6483\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.1416 - acc: 0.6512\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.1237 - acc: 0.6531\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.1135 - acc: 0.6559\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.1027 - acc: 0.6575\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.0931 - acc: 0.6603\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.0838 - acc: 0.6602\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.0752 - acc: 0.6640\n",
      "Epoch 19/70\n",
      " - 3s - loss: 1.0654 - acc: 0.6655\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.0632 - acc: 0.6655\n",
      "Epoch 21/70\n",
      " - 3s - loss: 1.0566 - acc: 0.6673\n",
      "Epoch 22/70\n",
      " - 3s - loss: 1.0458 - acc: 0.6700\n",
      "Epoch 23/70\n",
      " - 3s - loss: 1.0431 - acc: 0.6693\n",
      "Epoch 24/70\n",
      " - 3s - loss: 1.0356 - acc: 0.6709\n",
      "Epoch 25/70\n",
      " - 3s - loss: 1.0314 - acc: 0.6733\n",
      "Epoch 26/70\n",
      " - 3s - loss: 1.0207 - acc: 0.6740\n",
      "Epoch 27/70\n",
      " - 3s - loss: 1.0204 - acc: 0.6752\n",
      "Epoch 28/70\n",
      " - 3s - loss: 1.0171 - acc: 0.6749\n",
      "Epoch 29/70\n",
      " - 3s - loss: 1.0115 - acc: 0.6761\n",
      "Epoch 30/70\n",
      " - 3s - loss: 1.0073 - acc: 0.6776\n",
      "Epoch 31/70\n",
      " - 3s - loss: 0.9982 - acc: 0.6793\n",
      "Epoch 32/70\n",
      " - 3s - loss: 0.9982 - acc: 0.6794\n",
      "Epoch 33/70\n",
      " - 3s - loss: 0.9966 - acc: 0.6787\n",
      "Epoch 34/70\n",
      " - 3s - loss: 0.9894 - acc: 0.6808\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9865 - acc: 0.6819\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9856 - acc: 0.6818\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9779 - acc: 0.6829\n",
      "Epoch 38/70\n",
      " - 3s - loss: 0.9794 - acc: 0.6825\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.9773 - acc: 0.6826\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.9712 - acc: 0.6825\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.9731 - acc: 0.6831\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.9678 - acc: 0.6867\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.9611 - acc: 0.6862\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.9616 - acc: 0.6872\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.9573 - acc: 0.6883\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.9556 - acc: 0.6900\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.9586 - acc: 0.6875\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.9513 - acc: 0.6881\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.9523 - acc: 0.6882\n",
      "Epoch 50/70\n",
      " - 3s - loss: 0.9506 - acc: 0.6887\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.9459 - acc: 0.6893\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.9482 - acc: 0.6903\n",
      "Epoch 53/70\n",
      " - 3s - loss: 0.9442 - acc: 0.6910\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.9388 - acc: 0.6912\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.9391 - acc: 0.6915\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.9381 - acc: 0.6918\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.9355 - acc: 0.6909\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.9383 - acc: 0.6922\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.9335 - acc: 0.6930\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.9330 - acc: 0.6933\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.9318 - acc: 0.6921\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.9296 - acc: 0.6928\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.9259 - acc: 0.6957\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.9276 - acc: 0.6934\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.9225 - acc: 0.6958\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.9236 - acc: 0.6934\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.9244 - acc: 0.6950\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.9213 - acc: 0.6950\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.9196 - acc: 0.6961\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.9159 - acc: 0.6955\n",
      "[CV]  nodes_l3=70, nodes_l2=120, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=2000, total= 3.3min\n",
      "[CV] nodes_l3=70, nodes_l2=120, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=2000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=160)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 6s - loss: 2.8765 - acc: 0.2525\n",
      "Epoch 2/70\n",
      " - 3s - loss: 1.9989 - acc: 0.4573\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.6497 - acc: 0.5449\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.4804 - acc: 0.5833\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.3768 - acc: 0.6064\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.3092 - acc: 0.6210\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.2606 - acc: 0.6294\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.2171 - acc: 0.6374\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.1937 - acc: 0.6407\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.1720 - acc: 0.6464\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.1530 - acc: 0.6500\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.1392 - acc: 0.6493\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.1239 - acc: 0.6538\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.1159 - acc: 0.6542\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.1015 - acc: 0.6589\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.0887 - acc: 0.6612\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.0786 - acc: 0.6627\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.0758 - acc: 0.6617\n",
      "Epoch 19/70\n",
      " - 3s - loss: 1.0654 - acc: 0.6643\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.0573 - acc: 0.6652\n",
      "Epoch 21/70\n",
      " - 3s - loss: 1.0515 - acc: 0.6669\n",
      "Epoch 22/70\n",
      " - 3s - loss: 1.0418 - acc: 0.6680\n",
      "Epoch 23/70\n",
      " - 4s - loss: 1.0369 - acc: 0.6708\n",
      "Epoch 24/70\n",
      " - 4s - loss: 1.0324 - acc: 0.6721\n",
      "Epoch 25/70\n",
      " - 3s - loss: 1.0256 - acc: 0.6733\n",
      "Epoch 26/70\n",
      " - 3s - loss: 1.0256 - acc: 0.6733\n",
      "Epoch 27/70\n",
      " - 4s - loss: 1.0125 - acc: 0.6746\n",
      "Epoch 28/70\n",
      " - 3s - loss: 1.0097 - acc: 0.6763\n",
      "Epoch 29/70\n",
      " - 3s - loss: 1.0060 - acc: 0.6760\n",
      "Epoch 30/70\n",
      " - 3s - loss: 1.0016 - acc: 0.6781\n",
      "Epoch 31/70\n",
      " - 3s - loss: 1.0019 - acc: 0.6794\n",
      "Epoch 32/70\n",
      " - 3s - loss: 0.9949 - acc: 0.6790\n",
      "Epoch 33/70\n",
      " - 3s - loss: 0.9938 - acc: 0.6807\n",
      "Epoch 34/70\n",
      " - 3s - loss: 0.9918 - acc: 0.6807\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9856 - acc: 0.6810\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9840 - acc: 0.6826\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9777 - acc: 0.6810\n",
      "Epoch 38/70\n",
      " - 3s - loss: 0.9783 - acc: 0.6831\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.9700 - acc: 0.6839\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.9720 - acc: 0.6836\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.9627 - acc: 0.6879\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.9665 - acc: 0.6861\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.9621 - acc: 0.6867\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.9595 - acc: 0.6868\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.9588 - acc: 0.6868\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.9570 - acc: 0.6866\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.9557 - acc: 0.6873\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.9506 - acc: 0.6885\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.9491 - acc: 0.6885\n",
      "Epoch 50/70\n",
      " - 3s - loss: 0.9464 - acc: 0.6900\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.9455 - acc: 0.6894\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.9458 - acc: 0.6890\n",
      "Epoch 53/70\n",
      " - 3s - loss: 0.9420 - acc: 0.6906\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.9381 - acc: 0.6895\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.9396 - acc: 0.6911\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.9380 - acc: 0.6898\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.9348 - acc: 0.6935\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.9361 - acc: 0.6911\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.9329 - acc: 0.6927\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.9307 - acc: 0.6919\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.9312 - acc: 0.6916\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.9290 - acc: 0.6934\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.9282 - acc: 0.6919\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.9237 - acc: 0.6944\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.9200 - acc: 0.6962\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.9240 - acc: 0.6938\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.9201 - acc: 0.6968\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.9186 - acc: 0.6956\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.9164 - acc: 0.6965\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.9175 - acc: 0.6973\n",
      "[CV]  nodes_l3=70, nodes_l2=120, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=2000, total= 3.6min\n",
      "[CV] nodes_l3=70, nodes_l2=120, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=2000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=160)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 5s - loss: 2.8901 - acc: 0.2560\n",
      "Epoch 2/70\n",
      " - 2s - loss: 1.9867 - acc: 0.4713\n",
      "Epoch 3/70\n",
      " - 2s - loss: 1.6196 - acc: 0.5570\n",
      "Epoch 4/70\n",
      " - 2s - loss: 1.4620 - acc: 0.5915\n",
      "Epoch 5/70\n",
      " - 2s - loss: 1.3623 - acc: 0.6119\n",
      "Epoch 6/70\n",
      " - 2s - loss: 1.2957 - acc: 0.6247\n",
      "Epoch 7/70\n",
      " - 2s - loss: 1.2455 - acc: 0.6333\n",
      "Epoch 8/70\n",
      " - 2s - loss: 1.2069 - acc: 0.6399\n",
      "Epoch 9/70\n",
      " - 2s - loss: 1.1813 - acc: 0.6441\n",
      "Epoch 10/70\n",
      " - 2s - loss: 1.1650 - acc: 0.6470\n",
      "Epoch 11/70\n",
      " - 2s - loss: 1.1410 - acc: 0.6517\n",
      "Epoch 12/70\n",
      " - 2s - loss: 1.1264 - acc: 0.6539\n",
      "Epoch 13/70\n",
      " - 2s - loss: 1.1140 - acc: 0.6564\n",
      "Epoch 14/70\n",
      " - 2s - loss: 1.0982 - acc: 0.6578\n",
      "Epoch 15/70\n",
      " - 2s - loss: 1.0924 - acc: 0.6598\n",
      "Epoch 16/70\n",
      " - 2s - loss: 1.0775 - acc: 0.6625\n",
      "Epoch 17/70\n",
      " - 2s - loss: 1.0717 - acc: 0.6646\n",
      "Epoch 18/70\n",
      " - 2s - loss: 1.0609 - acc: 0.6667\n",
      "Epoch 19/70\n",
      " - 2s - loss: 1.0499 - acc: 0.6695\n",
      "Epoch 20/70\n",
      " - 2s - loss: 1.0463 - acc: 0.6682\n",
      "Epoch 21/70\n",
      " - 2s - loss: 1.0372 - acc: 0.6708\n",
      "Epoch 22/70\n",
      " - 2s - loss: 1.0307 - acc: 0.6712\n",
      "Epoch 23/70\n",
      " - 2s - loss: 1.0270 - acc: 0.6712\n",
      "Epoch 24/70\n",
      " - 2s - loss: 1.0183 - acc: 0.6760\n",
      "Epoch 25/70\n",
      " - 2s - loss: 1.0116 - acc: 0.6753\n",
      "Epoch 26/70\n",
      " - 2s - loss: 1.0096 - acc: 0.6769\n",
      "Epoch 27/70\n",
      " - 2s - loss: 1.0057 - acc: 0.6767\n",
      "Epoch 28/70\n",
      " - 2s - loss: 0.9992 - acc: 0.6794\n",
      "Epoch 29/70\n",
      " - 2s - loss: 0.9950 - acc: 0.6797\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.9935 - acc: 0.6789\n",
      "Epoch 31/70\n",
      " - 2s - loss: 0.9850 - acc: 0.6819\n",
      "Epoch 32/70\n",
      " - 2s - loss: 0.9812 - acc: 0.6824\n",
      "Epoch 33/70\n",
      " - 2s - loss: 0.9829 - acc: 0.6817\n",
      "Epoch 34/70\n",
      " - 2s - loss: 0.9756 - acc: 0.6836\n",
      "Epoch 35/70\n",
      " - 2s - loss: 0.9731 - acc: 0.6829\n",
      "Epoch 36/70\n",
      " - 2s - loss: 0.9682 - acc: 0.6861\n",
      "Epoch 37/70\n",
      " - 2s - loss: 0.9680 - acc: 0.6861\n",
      "Epoch 38/70\n",
      " - 2s - loss: 0.9625 - acc: 0.6869\n",
      "Epoch 39/70\n",
      " - 2s - loss: 0.9637 - acc: 0.6872\n",
      "Epoch 40/70\n",
      " - 2s - loss: 0.9566 - acc: 0.6878\n",
      "Epoch 41/70\n",
      " - 2s - loss: 0.9556 - acc: 0.6865\n",
      "Epoch 42/70\n",
      " - 2s - loss: 0.9495 - acc: 0.6904\n",
      "Epoch 43/70\n",
      " - 2s - loss: 0.9473 - acc: 0.6889\n",
      "Epoch 44/70\n",
      " - 2s - loss: 0.9449 - acc: 0.6901\n",
      "Epoch 45/70\n",
      " - 2s - loss: 0.9414 - acc: 0.6895\n",
      "Epoch 46/70\n",
      " - 2s - loss: 0.9423 - acc: 0.6904\n",
      "Epoch 47/70\n",
      " - 2s - loss: 0.9423 - acc: 0.6906\n",
      "Epoch 48/70\n",
      " - 2s - loss: 0.9381 - acc: 0.6918\n",
      "Epoch 49/70\n",
      " - 2s - loss: 0.9378 - acc: 0.6936\n",
      "Epoch 50/70\n",
      " - 2s - loss: 0.9321 - acc: 0.6914\n",
      "Epoch 51/70\n",
      " - 2s - loss: 0.9299 - acc: 0.6926\n",
      "Epoch 52/70\n",
      " - 2s - loss: 0.9333 - acc: 0.6935\n",
      "Epoch 53/70\n",
      " - 2s - loss: 0.9287 - acc: 0.6920\n",
      "Epoch 54/70\n",
      " - 2s - loss: 0.9269 - acc: 0.6933\n",
      "Epoch 55/70\n",
      " - 2s - loss: 0.9250 - acc: 0.6944\n",
      "Epoch 56/70\n",
      " - 2s - loss: 0.9263 - acc: 0.6937\n",
      "Epoch 57/70\n",
      " - 2s - loss: 0.9196 - acc: 0.6963\n",
      "Epoch 58/70\n",
      " - 2s - loss: 0.9181 - acc: 0.6968\n",
      "Epoch 59/70\n",
      " - 2s - loss: 0.9157 - acc: 0.6965\n",
      "Epoch 60/70\n",
      " - 2s - loss: 0.9155 - acc: 0.6975\n",
      "Epoch 61/70\n",
      " - 2s - loss: 0.9142 - acc: 0.6969\n",
      "Epoch 62/70\n",
      " - 2s - loss: 0.9139 - acc: 0.6967\n",
      "Epoch 63/70\n",
      " - 2s - loss: 0.9142 - acc: 0.6971\n",
      "Epoch 64/70\n",
      " - 2s - loss: 0.9093 - acc: 0.6973\n",
      "Epoch 65/70\n",
      " - 2s - loss: 0.9120 - acc: 0.6959\n",
      "Epoch 66/70\n",
      " - 2s - loss: 0.9088 - acc: 0.6987\n",
      "Epoch 67/70\n",
      " - 2s - loss: 0.9099 - acc: 0.6973\n",
      "Epoch 68/70\n",
      " - 2s - loss: 0.9080 - acc: 0.6965\n",
      "Epoch 69/70\n",
      " - 2s - loss: 0.9040 - acc: 0.6991\n",
      "Epoch 70/70\n",
      " - 2s - loss: 0.9014 - acc: 0.6982\n",
      "[CV]  nodes_l3=70, nodes_l2=120, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=2000, total= 2.5min\n",
      "[CV] nodes_l3=70, nodes_l2=120, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=2000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=160)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 4s - loss: 2.8904 - acc: 0.2539\n",
      "Epoch 2/70\n",
      " - 2s - loss: 2.0036 - acc: 0.4587\n",
      "Epoch 3/70\n",
      " - 2s - loss: 1.6491 - acc: 0.5457\n",
      "Epoch 4/70\n",
      " - 2s - loss: 1.4746 - acc: 0.5852\n",
      "Epoch 5/70\n",
      " - 2s - loss: 1.3714 - acc: 0.6051\n",
      "Epoch 6/70\n",
      " - 2s - loss: 1.3060 - acc: 0.6210\n",
      "Epoch 7/70\n",
      " - 2s - loss: 1.2629 - acc: 0.6288\n",
      "Epoch 8/70\n",
      " - 2s - loss: 1.2277 - acc: 0.6356\n",
      "Epoch 9/70\n",
      " - 2s - loss: 1.2009 - acc: 0.6384\n",
      "Epoch 10/70\n",
      " - 2s - loss: 1.1779 - acc: 0.6421\n",
      "Epoch 11/70\n",
      " - 2s - loss: 1.1604 - acc: 0.6479\n",
      "Epoch 12/70\n",
      " - 2s - loss: 1.1429 - acc: 0.6502\n",
      "Epoch 13/70\n",
      " - 2s - loss: 1.1315 - acc: 0.6504\n",
      "Epoch 14/70\n",
      " - 2s - loss: 1.1190 - acc: 0.6536\n",
      "Epoch 15/70\n",
      " - 2s - loss: 1.1098 - acc: 0.6560\n",
      "Epoch 16/70\n",
      " - 2s - loss: 1.1021 - acc: 0.6561\n",
      "Epoch 17/70\n",
      " - 2s - loss: 1.0948 - acc: 0.6575\n",
      "Epoch 18/70\n",
      " - 2s - loss: 1.0816 - acc: 0.6586\n",
      "Epoch 19/70\n",
      " - 2s - loss: 1.0781 - acc: 0.6615\n",
      "Epoch 20/70\n",
      " - 2s - loss: 1.0676 - acc: 0.6645\n",
      "Epoch 21/70\n",
      " - 2s - loss: 1.0608 - acc: 0.6651\n",
      "Epoch 22/70\n",
      " - 2s - loss: 1.0563 - acc: 0.6646\n",
      "Epoch 23/70\n",
      " - 2s - loss: 1.0480 - acc: 0.6685\n",
      "Epoch 24/70\n",
      " - 2s - loss: 1.0453 - acc: 0.6662\n",
      "Epoch 25/70\n",
      " - 2s - loss: 1.0386 - acc: 0.6685\n",
      "Epoch 26/70\n",
      " - 2s - loss: 1.0352 - acc: 0.6679\n",
      "Epoch 27/70\n",
      " - 2s - loss: 1.0257 - acc: 0.6705\n",
      "Epoch 28/70\n",
      " - 2s - loss: 1.0211 - acc: 0.6714\n",
      "Epoch 29/70\n",
      " - 2s - loss: 1.0201 - acc: 0.6718\n",
      "Epoch 30/70\n",
      " - 2s - loss: 1.0161 - acc: 0.6728\n",
      "Epoch 31/70\n",
      " - 2s - loss: 1.0076 - acc: 0.6742\n",
      "Epoch 32/70\n",
      " - 2s - loss: 1.0069 - acc: 0.6741\n",
      "Epoch 33/70\n",
      " - 2s - loss: 0.9998 - acc: 0.6757\n",
      "Epoch 34/70\n",
      " - 2s - loss: 0.9993 - acc: 0.6774\n",
      "Epoch 35/70\n",
      " - 2s - loss: 0.9967 - acc: 0.6760\n",
      "Epoch 36/70\n",
      " - 2s - loss: 0.9932 - acc: 0.6772\n",
      "Epoch 37/70\n",
      " - 2s - loss: 0.9925 - acc: 0.6773\n",
      "Epoch 38/70\n",
      " - 2s - loss: 0.9860 - acc: 0.6771\n",
      "Epoch 39/70\n",
      " - 2s - loss: 0.9837 - acc: 0.6785\n",
      "Epoch 40/70\n",
      " - 2s - loss: 0.9813 - acc: 0.6781\n",
      "Epoch 41/70\n",
      " - 2s - loss: 0.9775 - acc: 0.6796\n",
      "Epoch 42/70\n",
      " - 2s - loss: 0.9793 - acc: 0.6822\n",
      "Epoch 43/70\n",
      " - 2s - loss: 0.9737 - acc: 0.6806\n",
      "Epoch 44/70\n",
      " - 2s - loss: 0.9699 - acc: 0.6822\n",
      "Epoch 45/70\n",
      " - 2s - loss: 0.9657 - acc: 0.6831\n",
      "Epoch 46/70\n",
      " - 2s - loss: 0.9662 - acc: 0.6821\n",
      "Epoch 47/70\n",
      " - 2s - loss: 0.9621 - acc: 0.6842\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.9621 - acc: 0.6832\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.9615 - acc: 0.6855\n",
      "Epoch 50/70\n",
      " - 3s - loss: 0.9565 - acc: 0.6852\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.9572 - acc: 0.6852\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.9513 - acc: 0.6876\n",
      "Epoch 53/70\n",
      " - 3s - loss: 0.9548 - acc: 0.6846\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.9471 - acc: 0.6880\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.9508 - acc: 0.6876\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.9448 - acc: 0.6854\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.9411 - acc: 0.6886\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.9451 - acc: 0.6896\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.9410 - acc: 0.6876\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.9407 - acc: 0.6900\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.9386 - acc: 0.6883\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.9371 - acc: 0.6901\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.9382 - acc: 0.6896\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.9359 - acc: 0.6910\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.9327 - acc: 0.6891\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.9320 - acc: 0.6911\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.9293 - acc: 0.6899\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.9293 - acc: 0.6928\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.9292 - acc: 0.6916\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.9266 - acc: 0.6910\n",
      "[CV]  nodes_l3=70, nodes_l2=120, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=2000, total= 2.8min\n",
      "[CV] nodes_l3=60, nodes_l2=90, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.2, dropout_l1=0.4, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=160)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 8s - loss: 2.2458 - acc: 0.4061\n",
      "Epoch 2/70\n",
      " - 4s - loss: 1.4592 - acc: 0.5899\n",
      "Epoch 3/70\n",
      " - 4s - loss: 1.2916 - acc: 0.6245\n",
      "Epoch 4/70\n",
      " - 4s - loss: 1.2164 - acc: 0.6376\n",
      "Epoch 5/70\n",
      " - 4s - loss: 1.1695 - acc: 0.6469\n",
      "Epoch 6/70\n",
      " - 4s - loss: 1.1393 - acc: 0.6505\n",
      "Epoch 7/70\n",
      " - 4s - loss: 1.1206 - acc: 0.6554\n",
      "Epoch 8/70\n",
      " - 4s - loss: 1.1020 - acc: 0.6570\n",
      "Epoch 9/70\n",
      " - 4s - loss: 1.0810 - acc: 0.6619\n",
      "Epoch 10/70\n",
      " - 4s - loss: 1.0675 - acc: 0.6666\n",
      "Epoch 11/70\n",
      " - 4s - loss: 1.0608 - acc: 0.6671\n",
      "Epoch 12/70\n",
      " - 4s - loss: 1.0413 - acc: 0.6710\n",
      "Epoch 13/70\n",
      " - 5s - loss: 1.0344 - acc: 0.6705\n",
      "Epoch 14/70\n",
      " - 4s - loss: 1.0303 - acc: 0.6741\n",
      "Epoch 15/70\n",
      " - 4s - loss: 1.0195 - acc: 0.6757\n",
      "Epoch 16/70\n",
      " - 4s - loss: 1.0138 - acc: 0.6761\n",
      "Epoch 17/70\n",
      " - 4s - loss: 1.0051 - acc: 0.6779\n",
      "Epoch 18/70\n",
      " - 4s - loss: 1.0015 - acc: 0.6771\n",
      "Epoch 19/70\n",
      " - 4s - loss: 0.9937 - acc: 0.6817\n",
      "Epoch 20/70\n",
      " - 4s - loss: 0.9881 - acc: 0.6819\n",
      "Epoch 21/70\n",
      " - 4s - loss: 0.9854 - acc: 0.6815\n",
      "Epoch 22/70\n",
      " - 4s - loss: 0.9792 - acc: 0.6840\n",
      "Epoch 23/70\n",
      " - 3s - loss: 0.9769 - acc: 0.6837\n",
      "Epoch 24/70\n",
      " - 3s - loss: 0.9716 - acc: 0.6843\n",
      "Epoch 25/70\n",
      " - 3s - loss: 0.9668 - acc: 0.6847\n",
      "Epoch 26/70\n",
      " - 3s - loss: 0.9623 - acc: 0.6872\n",
      "Epoch 27/70\n",
      " - 3s - loss: 0.9615 - acc: 0.6866\n",
      "Epoch 28/70\n",
      " - 3s - loss: 0.9613 - acc: 0.6887\n",
      "Epoch 29/70\n",
      " - 3s - loss: 0.9531 - acc: 0.6896\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.9533 - acc: 0.6898\n",
      "Epoch 31/70\n",
      " - 3s - loss: 0.9467 - acc: 0.6905\n",
      "Epoch 32/70\n",
      " - 3s - loss: 0.9509 - acc: 0.6881\n",
      "Epoch 33/70\n",
      " - 3s - loss: 0.9462 - acc: 0.6906\n",
      "Epoch 34/70\n",
      " - 3s - loss: 0.9435 - acc: 0.6914\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9405 - acc: 0.6919\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9444 - acc: 0.6907\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9334 - acc: 0.6933\n",
      "Epoch 38/70\n",
      " - 3s - loss: 0.9367 - acc: 0.6935\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.9316 - acc: 0.6936\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.9317 - acc: 0.6948\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.9287 - acc: 0.6957\n",
      "Epoch 42/70\n",
      " - 4s - loss: 0.9286 - acc: 0.6947\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.9276 - acc: 0.6960\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.9277 - acc: 0.6954\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.9240 - acc: 0.6952\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.9228 - acc: 0.6958\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.9192 - acc: 0.6963\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.9244 - acc: 0.6960\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.9201 - acc: 0.6964\n",
      "Epoch 50/70\n",
      " - 3s - loss: 0.9192 - acc: 0.6973\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.9181 - acc: 0.6966\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.9174 - acc: 0.6968\n",
      "Epoch 53/70\n",
      " - 3s - loss: 0.9174 - acc: 0.6976\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.9135 - acc: 0.6998\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.9134 - acc: 0.6981\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.9122 - acc: 0.6997\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.9085 - acc: 0.6993\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.9126 - acc: 0.6982\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.9088 - acc: 0.6984\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.9095 - acc: 0.6994\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.9110 - acc: 0.6987\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.9095 - acc: 0.6971\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.9060 - acc: 0.6996\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.9051 - acc: 0.7006\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.9053 - acc: 0.6987\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.9028 - acc: 0.7014\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.9031 - acc: 0.7014\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.9045 - acc: 0.7008\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.9047 - acc: 0.7008\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.9000 - acc: 0.7018\n",
      "[CV]  nodes_l3=60, nodes_l2=90, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.2, dropout_l1=0.4, batch_size=500, total= 3.8min\n",
      "[CV] nodes_l3=60, nodes_l2=90, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.2, dropout_l1=0.4, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=160)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 6s - loss: 2.2602 - acc: 0.3970\n",
      "Epoch 2/70\n",
      " - 3s - loss: 1.4641 - acc: 0.5907\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.2945 - acc: 0.6238\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.2171 - acc: 0.6367\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.1800 - acc: 0.6469\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.1417 - acc: 0.6516\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.1147 - acc: 0.6565\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.0954 - acc: 0.6601\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.0814 - acc: 0.6637\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.0686 - acc: 0.6656\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.0552 - acc: 0.6696\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.0481 - acc: 0.6690\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.0391 - acc: 0.6707\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.0284 - acc: 0.6720\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.0235 - acc: 0.6735\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.0138 - acc: 0.6775\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.0082 - acc: 0.6780\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.0015 - acc: 0.6780\n",
      "Epoch 19/70\n",
      " - 3s - loss: 0.9949 - acc: 0.6801\n",
      "Epoch 20/70\n",
      " - 3s - loss: 0.9906 - acc: 0.6814\n",
      "Epoch 21/70\n",
      " - 3s - loss: 0.9842 - acc: 0.6813\n",
      "Epoch 22/70\n",
      " - 3s - loss: 0.9746 - acc: 0.6846\n",
      "Epoch 23/70\n",
      " - 3s - loss: 0.9757 - acc: 0.6832\n",
      "Epoch 24/70\n",
      " - 3s - loss: 0.9728 - acc: 0.6856\n",
      "Epoch 25/70\n",
      " - 3s - loss: 0.9687 - acc: 0.6862\n",
      "Epoch 26/70\n",
      " - 3s - loss: 0.9643 - acc: 0.6871\n",
      "Epoch 27/70\n",
      " - 3s - loss: 0.9626 - acc: 0.6862\n",
      "Epoch 28/70\n",
      " - 3s - loss: 0.9590 - acc: 0.6867\n",
      "Epoch 29/70\n",
      " - 3s - loss: 0.9573 - acc: 0.6877\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.9544 - acc: 0.6886\n",
      "Epoch 31/70\n",
      " - 4s - loss: 0.9519 - acc: 0.6900\n",
      "Epoch 32/70\n",
      " - 4s - loss: 0.9487 - acc: 0.6911\n",
      "Epoch 33/70\n",
      " - 3s - loss: 0.9466 - acc: 0.6892\n",
      "Epoch 34/70\n",
      " - 3s - loss: 0.9429 - acc: 0.6922\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9416 - acc: 0.6934\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9359 - acc: 0.6943\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9367 - acc: 0.6926\n",
      "Epoch 38/70\n",
      " - 3s - loss: 0.9352 - acc: 0.6910\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.9327 - acc: 0.6918\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.9290 - acc: 0.6941\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.9343 - acc: 0.6918\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.9279 - acc: 0.6942\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.9251 - acc: 0.6958\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.9229 - acc: 0.6957\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.9249 - acc: 0.6947\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.9206 - acc: 0.6964\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.9196 - acc: 0.6971\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.9191 - acc: 0.6975\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.9158 - acc: 0.6983\n",
      "Epoch 50/70\n",
      " - 3s - loss: 0.9148 - acc: 0.6977\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.9148 - acc: 0.6975\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.9131 - acc: 0.6976\n",
      "Epoch 53/70\n",
      " - 3s - loss: 0.9113 - acc: 0.6972\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.9164 - acc: 0.6971\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.9116 - acc: 0.6977\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.9090 - acc: 0.6985\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.9076 - acc: 0.6991\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.9091 - acc: 0.6983\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.9061 - acc: 0.6998\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.9093 - acc: 0.6999\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.9058 - acc: 0.6992\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.9066 - acc: 0.7002\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.9036 - acc: 0.6999\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.9015 - acc: 0.6994\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.9037 - acc: 0.7011\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.9027 - acc: 0.7004\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.9027 - acc: 0.7011\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.9039 - acc: 0.7017\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.8987 - acc: 0.7006\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.9010 - acc: 0.7006\n",
      "[CV]  nodes_l3=60, nodes_l2=90, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.2, dropout_l1=0.4, batch_size=500, total= 3.4min\n",
      "[CV] nodes_l3=60, nodes_l2=90, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.2, dropout_l1=0.4, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=160)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 6s - loss: 2.2327 - acc: 0.4041\n",
      "Epoch 2/70\n",
      " - 3s - loss: 1.4452 - acc: 0.5926\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.2778 - acc: 0.6277\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.2088 - acc: 0.6401\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.1556 - acc: 0.6479\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.1280 - acc: 0.6539\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.0988 - acc: 0.6598\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.0817 - acc: 0.6621\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.0662 - acc: 0.6647\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.0480 - acc: 0.6678\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.0388 - acc: 0.6703\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.0272 - acc: 0.6752\n",
      "Epoch 13/70\n",
      " - 5s - loss: 1.0146 - acc: 0.6772\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.0082 - acc: 0.6771\n",
      "Epoch 15/70\n",
      " - 2372s - loss: 1.0018 - acc: 0.6796\n",
      "Epoch 16/70\n",
      " - 6s - loss: 0.9926 - acc: 0.6800\n",
      "Epoch 17/70\n",
      " - 5s - loss: 0.9853 - acc: 0.6810\n",
      "Epoch 18/70\n",
      " - 5s - loss: 0.9783 - acc: 0.6836\n",
      "Epoch 19/70\n",
      " - 5s - loss: 0.9711 - acc: 0.6862\n",
      "Epoch 20/70\n",
      " - 5s - loss: 0.9681 - acc: 0.6845\n",
      "Epoch 21/70\n",
      " - 4s - loss: 0.9607 - acc: 0.6880\n",
      "Epoch 22/70\n",
      " - 4s - loss: 0.9599 - acc: 0.6869\n",
      "Epoch 23/70\n",
      " - 4s - loss: 0.9528 - acc: 0.6904\n",
      "Epoch 24/70\n",
      " - 4s - loss: 0.9501 - acc: 0.6907\n",
      "Epoch 25/70\n",
      " - 4s - loss: 0.9440 - acc: 0.6913\n",
      "Epoch 26/70\n",
      " - 4s - loss: 0.9436 - acc: 0.6920\n",
      "Epoch 27/70\n",
      " - 4s - loss: 0.9375 - acc: 0.6934\n",
      "Epoch 28/70\n",
      " - 3s - loss: 0.9348 - acc: 0.6953\n",
      "Epoch 29/70\n",
      " - 3s - loss: 0.9346 - acc: 0.6946\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.9296 - acc: 0.6958\n",
      "Epoch 31/70\n",
      " - 4s - loss: 0.9314 - acc: 0.6946\n",
      "Epoch 32/70\n",
      " - 3s - loss: 0.9290 - acc: 0.6951\n",
      "Epoch 33/70\n",
      " - 3s - loss: 0.9209 - acc: 0.6963\n",
      "Epoch 34/70\n",
      " - 3s - loss: 0.9189 - acc: 0.6957\n",
      "Epoch 35/70\n",
      " - 4s - loss: 0.9197 - acc: 0.6966\n",
      "Epoch 36/70\n",
      " - 4s - loss: 0.9178 - acc: 0.6970\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9162 - acc: 0.6971\n",
      "Epoch 38/70\n",
      " - 3s - loss: 0.9154 - acc: 0.6976\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.9116 - acc: 0.6987\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.9095 - acc: 0.6994\n",
      "Epoch 41/70\n",
      " - 4s - loss: 0.9098 - acc: 0.6995\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.9042 - acc: 0.7011\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.9024 - acc: 0.7022\n",
      "Epoch 44/70\n",
      " - 4s - loss: 0.9068 - acc: 0.6999\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.9004 - acc: 0.7004\n",
      "Epoch 46/70\n",
      " - 4s - loss: 0.8987 - acc: 0.7014\n",
      "Epoch 47/70\n",
      " - 4s - loss: 0.8995 - acc: 0.6999\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.9014 - acc: 0.7001\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.8974 - acc: 0.7011\n",
      "Epoch 50/70\n",
      " - 3s - loss: 0.8994 - acc: 0.7017\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.8958 - acc: 0.7026\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.8926 - acc: 0.7022\n",
      "Epoch 53/70\n",
      " - 3s - loss: 0.8905 - acc: 0.7028\n",
      "Epoch 54/70\n",
      " - 4s - loss: 0.8902 - acc: 0.7043\n",
      "Epoch 55/70\n",
      " - 4s - loss: 0.8925 - acc: 0.7049\n",
      "Epoch 56/70\n",
      " - 4s - loss: 0.8914 - acc: 0.7032\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.8890 - acc: 0.7034\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.8887 - acc: 0.7038\n",
      "Epoch 59/70\n",
      " - 4s - loss: 0.8851 - acc: 0.7045\n",
      "Epoch 60/70\n",
      " - 4s - loss: 0.8846 - acc: 0.7059\n",
      "Epoch 61/70\n",
      " - 4s - loss: 0.8853 - acc: 0.7029\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.8868 - acc: 0.7045\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.8859 - acc: 0.7054\n",
      "Epoch 64/70\n",
      " - 4s - loss: 0.8838 - acc: 0.7055\n",
      "Epoch 65/70\n",
      " - 5s - loss: 0.8844 - acc: 0.7043\n",
      "Epoch 66/70\n",
      " - 4s - loss: 0.8849 - acc: 0.7059\n",
      "Epoch 67/70\n",
      " - 4s - loss: 0.8826 - acc: 0.7073\n",
      "Epoch 68/70\n",
      " - 5s - loss: 0.8810 - acc: 0.7053\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.8794 - acc: 0.7060\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.8805 - acc: 0.7083\n",
      "[CV]  nodes_l3=60, nodes_l2=90, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.2, dropout_l1=0.4, batch_size=500, total=43.7min\n",
      "[CV] nodes_l3=60, nodes_l2=90, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.2, dropout_l1=0.4, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=160)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 7s - loss: 2.3166 - acc: 0.3865\n",
      "Epoch 2/70\n",
      " - 3s - loss: 1.4780 - acc: 0.5863\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.3032 - acc: 0.6220\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.2263 - acc: 0.6343\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.1743 - acc: 0.6442\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.1420 - acc: 0.6497\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.1170 - acc: 0.6561\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.0985 - acc: 0.6592\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.0750 - acc: 0.6653\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.0635 - acc: 0.6662\n",
      "Epoch 11/70\n",
      " - 4s - loss: 1.0495 - acc: 0.6688\n",
      "Epoch 12/70\n",
      " - 4s - loss: 1.0389 - acc: 0.6714\n",
      "Epoch 13/70\n",
      " - 4s - loss: 1.0318 - acc: 0.6735\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.0217 - acc: 0.6750\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.0125 - acc: 0.6754\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.0046 - acc: 0.6783\n",
      "Epoch 17/70\n",
      " - 3s - loss: 0.9984 - acc: 0.6796\n",
      "Epoch 18/70\n",
      " - 3s - loss: 0.9946 - acc: 0.6783\n",
      "Epoch 19/70\n",
      " - 3s - loss: 0.9899 - acc: 0.6813\n",
      "Epoch 20/70\n",
      " - 3s - loss: 0.9834 - acc: 0.6820\n",
      "Epoch 21/70\n",
      " - 3s - loss: 0.9808 - acc: 0.6814\n",
      "Epoch 22/70\n",
      " - 3s - loss: 0.9750 - acc: 0.6827\n",
      "Epoch 23/70\n",
      " - 3s - loss: 0.9686 - acc: 0.6849\n",
      "Epoch 24/70\n",
      " - 3s - loss: 0.9659 - acc: 0.6850\n",
      "Epoch 25/70\n",
      " - 4s - loss: 0.9671 - acc: 0.6854\n",
      "Epoch 26/70\n",
      " - 3s - loss: 0.9605 - acc: 0.6863\n",
      "Epoch 27/70\n",
      " - 4s - loss: 0.9555 - acc: 0.6885\n",
      "Epoch 28/70\n",
      " - 3s - loss: 0.9546 - acc: 0.6872\n",
      "Epoch 29/70\n",
      " - 3s - loss: 0.9494 - acc: 0.6890\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.9468 - acc: 0.6898\n",
      "Epoch 31/70\n",
      " - 4s - loss: 0.9469 - acc: 0.6888\n",
      "Epoch 32/70\n",
      " - 4s - loss: 0.9474 - acc: 0.6895\n",
      "Epoch 33/70\n",
      " - 4s - loss: 0.9397 - acc: 0.6917\n",
      "Epoch 34/70\n",
      " - 3s - loss: 0.9394 - acc: 0.6902\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9365 - acc: 0.6922\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9362 - acc: 0.6929\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9375 - acc: 0.6925\n",
      "Epoch 38/70\n",
      " - 3s - loss: 0.9346 - acc: 0.6925\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.9352 - acc: 0.6918\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.9303 - acc: 0.6920\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.9271 - acc: 0.6943\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.9294 - acc: 0.6919\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.9271 - acc: 0.6933\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.9226 - acc: 0.6938\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.9213 - acc: 0.6946\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.9235 - acc: 0.6942\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.9228 - acc: 0.6947\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.9194 - acc: 0.6948\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.9175 - acc: 0.6959\n",
      "Epoch 50/70\n",
      " - 3s - loss: 0.9168 - acc: 0.6968\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.9167 - acc: 0.6969\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.9142 - acc: 0.6961\n",
      "Epoch 53/70\n",
      " - 3s - loss: 0.9140 - acc: 0.6961\n",
      "Epoch 54/70\n",
      " - 4s - loss: 0.9127 - acc: 0.6949\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.9126 - acc: 0.6974\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.9123 - acc: 0.6969\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.9110 - acc: 0.6979\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.9091 - acc: 0.6979\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.9117 - acc: 0.6968\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.9079 - acc: 0.6977\n",
      "Epoch 61/70\n",
      " - 4s - loss: 0.9075 - acc: 0.6961\n",
      "Epoch 62/70\n",
      " - 4s - loss: 0.9068 - acc: 0.6979\n",
      "Epoch 63/70\n",
      " - 4s - loss: 0.9046 - acc: 0.6990\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.9030 - acc: 0.6997\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.9042 - acc: 0.6979\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.9045 - acc: 0.6981\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.9015 - acc: 0.6979\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.9018 - acc: 0.6996\n",
      "Epoch 69/70\n",
      " - 4s - loss: 0.9006 - acc: 0.7007\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.9029 - acc: 0.6978\n",
      "[CV]  nodes_l3=60, nodes_l2=90, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.2, dropout_l1=0.4, batch_size=500, total= 3.8min\n",
      "[CV] nodes_l3=70, nodes_l2=90, nodes_l1=170, dropout_l3=0.1, dropout_l2=0.4, dropout_l1=0.1, batch_size=2000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=170)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 5s - loss: 2.8291 - acc: 0.2670\n",
      "Epoch 2/70\n",
      " - 2s - loss: 1.9387 - acc: 0.4801\n",
      "Epoch 3/70\n",
      " - 2s - loss: 1.5878 - acc: 0.5675\n",
      "Epoch 4/70\n",
      " - 2s - loss: 1.4247 - acc: 0.5989\n",
      "Epoch 5/70\n",
      " - 2s - loss: 1.3359 - acc: 0.6169\n",
      "Epoch 6/70\n",
      " - 2s - loss: 1.2819 - acc: 0.6282\n",
      "Epoch 7/70\n",
      " - 2s - loss: 1.2355 - acc: 0.6367\n",
      "Epoch 8/70\n",
      " - 2s - loss: 1.2082 - acc: 0.6422\n",
      "Epoch 9/70\n",
      " - 2s - loss: 1.1832 - acc: 0.6460\n",
      "Epoch 10/70\n",
      " - 2s - loss: 1.1604 - acc: 0.6504\n",
      "Epoch 11/70\n",
      " - 2s - loss: 1.1452 - acc: 0.6524\n",
      "Epoch 12/70\n",
      " - 2s - loss: 1.1292 - acc: 0.6553\n",
      "Epoch 13/70\n",
      " - 2s - loss: 1.1174 - acc: 0.6586\n",
      "Epoch 14/70\n",
      " - 2s - loss: 1.1027 - acc: 0.6601\n",
      "Epoch 15/70\n",
      " - 2s - loss: 1.0957 - acc: 0.6623\n",
      "Epoch 16/70\n",
      " - 2s - loss: 1.0877 - acc: 0.6629\n",
      "Epoch 17/70\n",
      " - 2s - loss: 1.0778 - acc: 0.6655\n",
      "Epoch 18/70\n",
      " - 2s - loss: 1.0660 - acc: 0.6679\n",
      "Epoch 19/70\n",
      " - 2s - loss: 1.0607 - acc: 0.6684\n",
      "Epoch 20/70\n",
      " - 2s - loss: 1.0561 - acc: 0.6699\n",
      "Epoch 21/70\n",
      " - 2s - loss: 1.0465 - acc: 0.6715\n",
      "Epoch 22/70\n",
      " - 2s - loss: 1.0483 - acc: 0.6704\n",
      "Epoch 23/70\n",
      " - 2s - loss: 1.0369 - acc: 0.6717\n",
      "Epoch 24/70\n",
      " - 3s - loss: 1.0324 - acc: 0.6745\n",
      "Epoch 25/70\n",
      " - 3s - loss: 1.0287 - acc: 0.6744\n",
      "Epoch 26/70\n",
      " - 3s - loss: 1.0222 - acc: 0.6739\n",
      "Epoch 27/70\n",
      " - 2s - loss: 1.0175 - acc: 0.6756\n",
      "Epoch 28/70\n",
      " - 2s - loss: 1.0113 - acc: 0.6783\n",
      "Epoch 29/70\n",
      " - 2s - loss: 1.0071 - acc: 0.6792\n",
      "Epoch 30/70\n",
      " - 3s - loss: 1.0068 - acc: 0.6783\n",
      "Epoch 31/70\n",
      " - 2s - loss: 1.0014 - acc: 0.6792\n",
      "Epoch 32/70\n",
      " - 2s - loss: 0.9950 - acc: 0.6798\n",
      "Epoch 33/70\n",
      " - 2s - loss: 0.9942 - acc: 0.6814\n",
      "Epoch 34/70\n",
      " - 2s - loss: 0.9909 - acc: 0.6810\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9853 - acc: 0.6835\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9825 - acc: 0.6839\n",
      "Epoch 37/70\n",
      " - 2s - loss: 0.9797 - acc: 0.6837\n",
      "Epoch 38/70\n",
      " - 3s - loss: 0.9756 - acc: 0.6830\n",
      "Epoch 39/70\n",
      " - 2s - loss: 0.9742 - acc: 0.6853\n",
      "Epoch 40/70\n",
      " - 2s - loss: 0.9715 - acc: 0.6849\n",
      "Epoch 41/70\n",
      " - 2s - loss: 0.9661 - acc: 0.6849\n",
      "Epoch 42/70\n",
      " - 2s - loss: 0.9635 - acc: 0.6874\n",
      "Epoch 43/70\n",
      " - 2s - loss: 0.9586 - acc: 0.6893\n",
      "Epoch 44/70\n",
      " - 2s - loss: 0.9581 - acc: 0.6889\n",
      "Epoch 45/70\n",
      " - 2s - loss: 0.9595 - acc: 0.6879\n",
      "Epoch 46/70\n",
      " - 2s - loss: 0.9567 - acc: 0.6887\n",
      "Epoch 47/70\n",
      " - 2s - loss: 0.9563 - acc: 0.6893\n",
      "Epoch 48/70\n",
      " - 2s - loss: 0.9490 - acc: 0.6907\n",
      "Epoch 49/70\n",
      " - 2s - loss: 0.9476 - acc: 0.6907\n",
      "Epoch 50/70\n",
      " - 2s - loss: 0.9472 - acc: 0.6900\n",
      "Epoch 51/70\n",
      " - 2s - loss: 0.9437 - acc: 0.6910\n",
      "Epoch 52/70\n",
      " - 2s - loss: 0.9438 - acc: 0.6910\n",
      "Epoch 53/70\n",
      " - 2s - loss: 0.9397 - acc: 0.6907\n",
      "Epoch 54/70\n",
      " - 2s - loss: 0.9374 - acc: 0.6921\n",
      "Epoch 55/70\n",
      " - 2s - loss: 0.9390 - acc: 0.6924\n",
      "Epoch 56/70\n",
      " - 2s - loss: 0.9367 - acc: 0.6916\n",
      "Epoch 57/70\n",
      " - 2s - loss: 0.9314 - acc: 0.6944\n",
      "Epoch 58/70\n",
      " - 2s - loss: 0.9301 - acc: 0.6936\n",
      "Epoch 59/70\n",
      " - 2s - loss: 0.9281 - acc: 0.6940\n",
      "Epoch 60/70\n",
      " - 2s - loss: 0.9259 - acc: 0.6930\n",
      "Epoch 61/70\n",
      " - 2s - loss: 0.9243 - acc: 0.6952\n",
      "Epoch 62/70\n",
      " - 2s - loss: 0.9262 - acc: 0.6963\n",
      "Epoch 63/70\n",
      " - 2s - loss: 0.9189 - acc: 0.6964\n",
      "Epoch 64/70\n",
      " - 2s - loss: 0.9197 - acc: 0.6969\n",
      "Epoch 65/70\n",
      " - 2s - loss: 0.9183 - acc: 0.6960\n",
      "Epoch 66/70\n",
      " - 2s - loss: 0.9193 - acc: 0.6966\n",
      "Epoch 67/70\n",
      " - 2s - loss: 0.9154 - acc: 0.6976\n",
      "Epoch 68/70\n",
      " - 2s - loss: 0.9172 - acc: 0.6965\n",
      "Epoch 69/70\n",
      " - 2s - loss: 0.9159 - acc: 0.6983\n",
      "Epoch 70/70\n",
      " - 2s - loss: 0.9131 - acc: 0.6953\n",
      "[CV]  nodes_l3=70, nodes_l2=90, nodes_l1=170, dropout_l3=0.1, dropout_l2=0.4, dropout_l1=0.1, batch_size=2000, total= 2.5min\n",
      "[CV] nodes_l3=70, nodes_l2=90, nodes_l1=170, dropout_l3=0.1, dropout_l2=0.4, dropout_l1=0.1, batch_size=2000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=170)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 5s - loss: 2.8148 - acc: 0.2706\n",
      "Epoch 2/70\n",
      " - 2s - loss: 1.9187 - acc: 0.4859\n",
      "Epoch 3/70\n",
      " - 2s - loss: 1.5900 - acc: 0.5641\n",
      "Epoch 4/70\n",
      " - 2s - loss: 1.4342 - acc: 0.5946\n",
      "Epoch 5/70\n",
      " - 2s - loss: 1.3437 - acc: 0.6154\n",
      "Epoch 6/70\n",
      " - 2s - loss: 1.2863 - acc: 0.6286\n",
      "Epoch 7/70\n",
      " - 2s - loss: 1.2404 - acc: 0.6372\n",
      "Epoch 8/70\n",
      " - 2s - loss: 1.2105 - acc: 0.6406\n",
      "Epoch 9/70\n",
      " - 2s - loss: 1.1892 - acc: 0.6450\n",
      "Epoch 10/70\n",
      " - 2s - loss: 1.1642 - acc: 0.6501\n",
      "Epoch 11/70\n",
      " - 2s - loss: 1.1511 - acc: 0.6500\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.1395 - acc: 0.6527\n",
      "Epoch 13/70\n",
      " - 2s - loss: 1.1195 - acc: 0.6577\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.1095 - acc: 0.6597\n",
      "Epoch 15/70\n",
      " - 2s - loss: 1.0972 - acc: 0.6636\n",
      "Epoch 16/70\n",
      " - 2s - loss: 1.0912 - acc: 0.6626\n",
      "Epoch 17/70\n",
      " - 2s - loss: 1.0809 - acc: 0.6640\n",
      "Epoch 18/70\n",
      " - 2s - loss: 1.0719 - acc: 0.6681\n",
      "Epoch 19/70\n",
      " - 3s - loss: 1.0634 - acc: 0.6690\n",
      "Epoch 20/70\n",
      " - 2s - loss: 1.0543 - acc: 0.6706\n",
      "Epoch 21/70\n",
      " - 2s - loss: 1.0488 - acc: 0.6702\n",
      "Epoch 22/70\n",
      " - 2s - loss: 1.0410 - acc: 0.6741\n",
      "Epoch 23/70\n",
      " - 2s - loss: 1.0414 - acc: 0.6720\n",
      "Epoch 24/70\n",
      " - 2s - loss: 1.0289 - acc: 0.6747\n",
      "Epoch 25/70\n",
      " - 2s - loss: 1.0219 - acc: 0.6758\n",
      "Epoch 26/70\n",
      " - 2s - loss: 1.0199 - acc: 0.6768\n",
      "Epoch 27/70\n",
      " - 2s - loss: 1.0161 - acc: 0.6780\n",
      "Epoch 28/70\n",
      " - 2s - loss: 1.0107 - acc: 0.6789\n",
      "Epoch 29/70\n",
      " - 2s - loss: 1.0066 - acc: 0.6786\n",
      "Epoch 30/70\n",
      " - 2s - loss: 1.0022 - acc: 0.6800\n",
      "Epoch 31/70\n",
      " - 2s - loss: 0.9962 - acc: 0.6813\n",
      "Epoch 32/70\n",
      " - 2s - loss: 0.9935 - acc: 0.6823\n",
      "Epoch 33/70\n",
      " - 2s - loss: 0.9901 - acc: 0.6836\n",
      "Epoch 34/70\n",
      " - 2s - loss: 0.9827 - acc: 0.6841\n",
      "Epoch 35/70\n",
      " - 2s - loss: 0.9799 - acc: 0.6850\n",
      "Epoch 36/70\n",
      " - 2s - loss: 0.9830 - acc: 0.6830\n",
      "Epoch 37/70\n",
      " - 2s - loss: 0.9739 - acc: 0.6865\n",
      "Epoch 38/70\n",
      " - 2s - loss: 0.9724 - acc: 0.6862\n",
      "Epoch 39/70\n",
      " - 2s - loss: 0.9688 - acc: 0.6875\n",
      "Epoch 40/70\n",
      " - 2s - loss: 0.9699 - acc: 0.6870\n",
      "Epoch 41/70\n",
      " - 2s - loss: 0.9649 - acc: 0.6884\n",
      "Epoch 42/70\n",
      " - 2s - loss: 0.9607 - acc: 0.6887\n",
      "Epoch 43/70\n",
      " - 2s - loss: 0.9593 - acc: 0.6887\n",
      "Epoch 44/70\n",
      " - 2s - loss: 0.9574 - acc: 0.6894\n",
      "Epoch 45/70\n",
      " - 2s - loss: 0.9547 - acc: 0.6914\n",
      "Epoch 46/70\n",
      " - 2s - loss: 0.9532 - acc: 0.6916\n",
      "Epoch 47/70\n",
      " - 2s - loss: 0.9507 - acc: 0.6905\n",
      "Epoch 48/70\n",
      " - 2s - loss: 0.9461 - acc: 0.6907\n",
      "Epoch 49/70\n",
      " - 2s - loss: 0.9412 - acc: 0.6921\n",
      "Epoch 50/70\n",
      " - 2s - loss: 0.9407 - acc: 0.6955\n",
      "Epoch 51/70\n",
      " - 2s - loss: 0.9391 - acc: 0.6944\n",
      "Epoch 52/70\n",
      " - 2s - loss: 0.9410 - acc: 0.6926\n",
      "Epoch 53/70\n",
      " - 2s - loss: 0.9346 - acc: 0.6939\n",
      "Epoch 54/70\n",
      " - 2s - loss: 0.9354 - acc: 0.6937\n",
      "Epoch 55/70\n",
      " - 2s - loss: 0.9352 - acc: 0.6934\n",
      "Epoch 56/70\n",
      " - 2s - loss: 0.9361 - acc: 0.6936\n",
      "Epoch 57/70\n",
      " - 2s - loss: 0.9314 - acc: 0.6944\n",
      "Epoch 58/70\n",
      " - 2s - loss: 0.9291 - acc: 0.6953\n",
      "Epoch 59/70\n",
      " - 2s - loss: 0.9285 - acc: 0.6962\n",
      "Epoch 60/70\n",
      " - 2s - loss: 0.9234 - acc: 0.6969\n",
      "Epoch 61/70\n",
      " - 2s - loss: 0.9257 - acc: 0.6943\n",
      "Epoch 62/70\n",
      " - 2s - loss: 0.9260 - acc: 0.6963\n",
      "Epoch 63/70\n",
      " - 2s - loss: 0.9195 - acc: 0.6969\n",
      "Epoch 64/70\n",
      " - 2s - loss: 0.9229 - acc: 0.6983\n",
      "Epoch 65/70\n",
      " - 2s - loss: 0.9194 - acc: 0.6979\n",
      "Epoch 66/70\n",
      " - 2s - loss: 0.9192 - acc: 0.6968\n",
      "Epoch 67/70\n",
      " - 2s - loss: 0.9123 - acc: 0.6974\n",
      "Epoch 68/70\n",
      " - 2s - loss: 0.9171 - acc: 0.6986\n",
      "Epoch 69/70\n",
      " - 2s - loss: 0.9152 - acc: 0.6984\n",
      "Epoch 70/70\n",
      " - 2s - loss: 0.9104 - acc: 0.7005\n",
      "[CV]  nodes_l3=70, nodes_l2=90, nodes_l1=170, dropout_l3=0.1, dropout_l2=0.4, dropout_l1=0.1, batch_size=2000, total= 2.6min\n",
      "[CV] nodes_l3=70, nodes_l2=90, nodes_l1=170, dropout_l3=0.1, dropout_l2=0.4, dropout_l1=0.1, batch_size=2000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=170)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 5s - loss: 2.8358 - acc: 0.2781\n",
      "Epoch 2/70\n",
      " - 2s - loss: 1.9287 - acc: 0.4804\n",
      "Epoch 3/70\n",
      " - 2s - loss: 1.5767 - acc: 0.5690\n",
      "Epoch 4/70\n",
      " - 2s - loss: 1.4238 - acc: 0.5996\n",
      "Epoch 5/70\n",
      " - 2s - loss: 1.3348 - acc: 0.6176\n",
      "Epoch 6/70\n",
      " - 2s - loss: 1.2763 - acc: 0.6285\n",
      "Epoch 7/70\n",
      " - 2s - loss: 1.2350 - acc: 0.6383\n",
      "Epoch 8/70\n",
      " - 2s - loss: 1.1980 - acc: 0.6433\n",
      "Epoch 9/70\n",
      " - 2s - loss: 1.1744 - acc: 0.6479\n",
      "Epoch 10/70\n",
      " - 2s - loss: 1.1580 - acc: 0.6510\n",
      "Epoch 11/70\n",
      " - 2s - loss: 1.1367 - acc: 0.6548\n",
      "Epoch 12/70\n",
      " - 2s - loss: 1.1176 - acc: 0.6577\n",
      "Epoch 13/70\n",
      " - 2s - loss: 1.1054 - acc: 0.6603\n",
      "Epoch 14/70\n",
      " - 2s - loss: 1.0961 - acc: 0.6613\n",
      "Epoch 15/70\n",
      " - 2s - loss: 1.0856 - acc: 0.6622\n",
      "Epoch 16/70\n",
      " - 2s - loss: 1.0760 - acc: 0.6664\n",
      "Epoch 17/70\n",
      " - 2s - loss: 1.0654 - acc: 0.6684\n",
      "Epoch 18/70\n",
      " - 2s - loss: 1.0581 - acc: 0.6683\n",
      "Epoch 19/70\n",
      " - 2s - loss: 1.0468 - acc: 0.6709\n",
      "Epoch 20/70\n",
      " - 2s - loss: 1.0427 - acc: 0.6714\n",
      "Epoch 21/70\n",
      " - 2s - loss: 1.0353 - acc: 0.6745\n",
      "Epoch 22/70\n",
      " - 2s - loss: 1.0303 - acc: 0.6739\n",
      "Epoch 23/70\n",
      " - 2s - loss: 1.0209 - acc: 0.6763\n",
      "Epoch 24/70\n",
      " - 3s - loss: 1.0145 - acc: 0.6793\n",
      "Epoch 25/70\n",
      " - 2s - loss: 1.0130 - acc: 0.6781\n",
      "Epoch 26/70\n",
      " - 2s - loss: 1.0092 - acc: 0.6784\n",
      "Epoch 27/70\n",
      " - 3s - loss: 1.0006 - acc: 0.6800\n",
      "Epoch 28/70\n",
      " - 3s - loss: 0.9969 - acc: 0.6821\n",
      "Epoch 29/70\n",
      " - 2s - loss: 0.9899 - acc: 0.6833\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.9869 - acc: 0.6844\n",
      "Epoch 31/70\n",
      " - 3s - loss: 0.9815 - acc: 0.6836\n",
      "Epoch 32/70\n",
      " - 3s - loss: 0.9793 - acc: 0.6843\n",
      "Epoch 33/70\n",
      " - 3s - loss: 0.9760 - acc: 0.6859\n",
      "Epoch 34/70\n",
      " - 3s - loss: 0.9726 - acc: 0.6857\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9700 - acc: 0.6870\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9642 - acc: 0.6897\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9604 - acc: 0.6886\n",
      "Epoch 38/70\n",
      " - 2s - loss: 0.9571 - acc: 0.6889\n",
      "Epoch 39/70\n",
      " - 2s - loss: 0.9581 - acc: 0.6879\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.9509 - acc: 0.6910\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.9490 - acc: 0.6913\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.9486 - acc: 0.6916\n",
      "Epoch 43/70\n",
      " - 2s - loss: 0.9453 - acc: 0.6931\n",
      "Epoch 44/70\n",
      " - 2s - loss: 0.9419 - acc: 0.6936\n",
      "Epoch 45/70\n",
      " - 2s - loss: 0.9400 - acc: 0.6934\n",
      "Epoch 46/70\n",
      " - 2s - loss: 0.9357 - acc: 0.6927\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.9347 - acc: 0.6943\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.9335 - acc: 0.6939\n",
      "Epoch 49/70\n",
      " - 2s - loss: 0.9294 - acc: 0.6952\n",
      "Epoch 50/70\n",
      " - 2s - loss: 0.9304 - acc: 0.6937\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.9277 - acc: 0.6948\n",
      "Epoch 52/70\n",
      " - 2s - loss: 0.9205 - acc: 0.6968\n",
      "Epoch 53/70\n",
      " - 3s - loss: 0.9205 - acc: 0.6959\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.9222 - acc: 0.6963\n",
      "Epoch 55/70\n",
      " - 2s - loss: 0.9147 - acc: 0.6974\n",
      "Epoch 56/70\n",
      " - 2s - loss: 0.9198 - acc: 0.6960\n",
      "Epoch 57/70\n",
      " - 2s - loss: 0.9144 - acc: 0.6975\n",
      "Epoch 58/70\n",
      " - 2s - loss: 0.9164 - acc: 0.6972\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.9122 - acc: 0.6990\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.9127 - acc: 0.6982\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.9092 - acc: 0.6977\n",
      "Epoch 62/70\n",
      " - 2s - loss: 0.9088 - acc: 0.6991\n",
      "Epoch 63/70\n",
      " - 2s - loss: 0.9059 - acc: 0.6999\n",
      "Epoch 64/70\n",
      " - 2s - loss: 0.9050 - acc: 0.7000\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.9020 - acc: 0.7011\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.8979 - acc: 0.7006\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.8998 - acc: 0.7010\n",
      "Epoch 68/70\n",
      " - 2s - loss: 0.8984 - acc: 0.7015\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.8977 - acc: 0.7020\n",
      "Epoch 70/70\n",
      " - 2s - loss: 0.8989 - acc: 0.7020\n",
      "[CV]  nodes_l3=70, nodes_l2=90, nodes_l1=170, dropout_l3=0.1, dropout_l2=0.4, dropout_l1=0.1, batch_size=2000, total= 2.9min\n",
      "[CV] nodes_l3=70, nodes_l2=90, nodes_l1=170, dropout_l3=0.1, dropout_l2=0.4, dropout_l1=0.1, batch_size=2000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=170)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 5s - loss: 2.8640 - acc: 0.2663\n",
      "Epoch 2/70\n",
      " - 2s - loss: 1.9161 - acc: 0.4848\n",
      "Epoch 3/70\n",
      " - 2s - loss: 1.5737 - acc: 0.5681\n",
      "Epoch 4/70\n",
      " - 2s - loss: 1.4242 - acc: 0.5998\n",
      "Epoch 5/70\n",
      " - 2s - loss: 1.3398 - acc: 0.6179\n",
      "Epoch 6/70\n",
      " - 2s - loss: 1.2813 - acc: 0.6273\n",
      "Epoch 7/70\n",
      " - 2s - loss: 1.2436 - acc: 0.6348\n",
      "Epoch 8/70\n",
      " - 2s - loss: 1.2113 - acc: 0.6407\n",
      "Epoch 9/70\n",
      " - 2s - loss: 1.1862 - acc: 0.6449\n",
      "Epoch 10/70\n",
      " - 2s - loss: 1.1716 - acc: 0.6478\n",
      "Epoch 11/70\n",
      " - 2s - loss: 1.1521 - acc: 0.6517\n",
      "Epoch 12/70\n",
      " - 2s - loss: 1.1370 - acc: 0.6545\n",
      "Epoch 13/70\n",
      " - 2s - loss: 1.1194 - acc: 0.6578\n",
      "Epoch 14/70\n",
      " - 2s - loss: 1.1059 - acc: 0.6597\n",
      "Epoch 15/70\n",
      " - 2s - loss: 1.1019 - acc: 0.6595\n",
      "Epoch 16/70\n",
      " - 2s - loss: 1.0922 - acc: 0.6631\n",
      "Epoch 17/70\n",
      " - 2s - loss: 1.0797 - acc: 0.6625\n",
      "Epoch 18/70\n",
      " - 2s - loss: 1.0723 - acc: 0.6654\n",
      "Epoch 19/70\n",
      " - 2s - loss: 1.0644 - acc: 0.6665\n",
      "Epoch 20/70\n",
      " - 2s - loss: 1.0629 - acc: 0.6647\n",
      "Epoch 21/70\n",
      " - 3s - loss: 1.0541 - acc: 0.6682\n",
      "Epoch 22/70\n",
      " - 2s - loss: 1.0466 - acc: 0.6708\n",
      "Epoch 23/70\n",
      " - 2s - loss: 1.0416 - acc: 0.6701\n",
      "Epoch 24/70\n",
      " - 2s - loss: 1.0361 - acc: 0.6720\n",
      "Epoch 25/70\n",
      " - 2s - loss: 1.0321 - acc: 0.6710\n",
      "Epoch 26/70\n",
      " - 2s - loss: 1.0271 - acc: 0.6731\n",
      "Epoch 27/70\n",
      " - 2s - loss: 1.0198 - acc: 0.6748\n",
      "Epoch 28/70\n",
      " - 3s - loss: 1.0152 - acc: 0.6765\n",
      "Epoch 29/70\n",
      " - 3s - loss: 1.0136 - acc: 0.6751\n",
      "Epoch 30/70\n",
      " - 2s - loss: 1.0070 - acc: 0.6787\n",
      "Epoch 31/70\n",
      " - 2s - loss: 1.0064 - acc: 0.6770\n",
      "Epoch 32/70\n",
      " - 2s - loss: 1.0003 - acc: 0.6788\n",
      "Epoch 33/70\n",
      " - 2s - loss: 0.9938 - acc: 0.6790\n",
      "Epoch 34/70\n",
      " - 2s - loss: 0.9945 - acc: 0.6795\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9892 - acc: 0.6809\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9874 - acc: 0.6810\n",
      "Epoch 37/70\n",
      " - 2s - loss: 0.9856 - acc: 0.6826\n",
      "Epoch 38/70\n",
      " - 2s - loss: 0.9785 - acc: 0.6825\n",
      "Epoch 39/70\n",
      " - 2s - loss: 0.9780 - acc: 0.6836\n",
      "Epoch 40/70\n",
      " - 2s - loss: 0.9741 - acc: 0.6841\n",
      "Epoch 41/70\n",
      " - 2s - loss: 0.9725 - acc: 0.6841\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.9681 - acc: 0.6862\n",
      "Epoch 43/70\n",
      " - 2s - loss: 0.9663 - acc: 0.6869\n",
      "Epoch 44/70\n",
      " - 2s - loss: 0.9662 - acc: 0.6843\n",
      "Epoch 45/70\n",
      " - 2s - loss: 0.9595 - acc: 0.6874\n",
      "Epoch 46/70\n",
      " - 2s - loss: 0.9598 - acc: 0.6871\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.9562 - acc: 0.6881\n",
      "Epoch 48/70\n",
      " - 2s - loss: 0.9559 - acc: 0.6869\n",
      "Epoch 49/70\n",
      " - 2s - loss: 0.9492 - acc: 0.6885\n",
      "Epoch 50/70\n",
      " - 2s - loss: 0.9518 - acc: 0.6894\n",
      "Epoch 51/70\n",
      " - 2s - loss: 0.9503 - acc: 0.6902\n",
      "Epoch 52/70\n",
      " - 2s - loss: 0.9476 - acc: 0.6879\n",
      "Epoch 53/70\n",
      " - 2s - loss: 0.9434 - acc: 0.6909\n",
      "Epoch 54/70\n",
      " - 2s - loss: 0.9425 - acc: 0.6899\n",
      "Epoch 55/70\n",
      " - 2s - loss: 0.9410 - acc: 0.6917\n",
      "Epoch 56/70\n",
      " - 2s - loss: 0.9432 - acc: 0.6885\n",
      "Epoch 57/70\n",
      " - 2s - loss: 0.9345 - acc: 0.6928\n",
      "Epoch 58/70\n",
      " - 2s - loss: 0.9381 - acc: 0.6911\n",
      "Epoch 59/70\n",
      " - 2s - loss: 0.9349 - acc: 0.6915\n",
      "Epoch 60/70\n",
      " - 2s - loss: 0.9321 - acc: 0.6918\n",
      "Epoch 61/70\n",
      " - 2s - loss: 0.9285 - acc: 0.6912\n",
      "Epoch 62/70\n",
      " - 2s - loss: 0.9300 - acc: 0.6932\n",
      "Epoch 63/70\n",
      " - 2s - loss: 0.9269 - acc: 0.6937\n",
      "Epoch 64/70\n",
      " - 2s - loss: 0.9278 - acc: 0.6943\n",
      "Epoch 65/70\n",
      " - 2s - loss: 0.9248 - acc: 0.6922\n",
      "Epoch 66/70\n",
      " - 2s - loss: 0.9212 - acc: 0.6946\n",
      "Epoch 67/70\n",
      " - 2s - loss: 0.9229 - acc: 0.6928\n",
      "Epoch 68/70\n",
      " - 2s - loss: 0.9231 - acc: 0.6975\n",
      "Epoch 69/70\n",
      " - 2s - loss: 0.9215 - acc: 0.6947\n",
      "Epoch 70/70\n",
      " - 2s - loss: 0.9188 - acc: 0.6940\n",
      "[CV]  nodes_l3=70, nodes_l2=90, nodes_l1=170, dropout_l3=0.1, dropout_l2=0.4, dropout_l1=0.1, batch_size=2000, total= 2.7min\n",
      "[CV] nodes_l3=70, nodes_l2=100, nodes_l1=160, dropout_l3=0.2, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=3000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=160)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 6s - loss: 3.1633 - acc: 0.1921\n",
      "Epoch 2/70\n",
      " - 2s - loss: 2.3835 - acc: 0.3588\n",
      "Epoch 3/70\n",
      " - 2s - loss: 1.9642 - acc: 0.4698\n",
      "Epoch 4/70\n",
      " - 2s - loss: 1.7267 - acc: 0.5315\n",
      "Epoch 5/70\n",
      " - 2s - loss: 1.5900 - acc: 0.5664\n",
      "Epoch 6/70\n",
      " - 2s - loss: 1.4853 - acc: 0.5880\n",
      "Epoch 7/70\n",
      " - 2s - loss: 1.4241 - acc: 0.6002\n",
      "Epoch 8/70\n",
      " - 2s - loss: 1.3658 - acc: 0.6121\n",
      "Epoch 9/70\n",
      " - 2s - loss: 1.3277 - acc: 0.6196\n",
      "Epoch 10/70\n",
      " - 2s - loss: 1.2935 - acc: 0.6256\n",
      "Epoch 11/70\n",
      " - 2s - loss: 1.2691 - acc: 0.6293\n",
      "Epoch 12/70\n",
      " - 2s - loss: 1.2498 - acc: 0.6333\n",
      "Epoch 13/70\n",
      " - 2s - loss: 1.2270 - acc: 0.6400\n",
      "Epoch 14/70\n",
      " - 2s - loss: 1.2140 - acc: 0.6412\n",
      "Epoch 15/70\n",
      " - 2s - loss: 1.2016 - acc: 0.6396\n",
      "Epoch 16/70\n",
      " - 2s - loss: 1.1842 - acc: 0.6449\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.1781 - acc: 0.6461\n",
      "Epoch 18/70\n",
      " - 4s - loss: 1.1595 - acc: 0.6504\n",
      "Epoch 19/70\n",
      " - 4s - loss: 1.1543 - acc: 0.6513\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.1455 - acc: 0.6520\n",
      "Epoch 21/70\n",
      " - 3s - loss: 1.1353 - acc: 0.6543\n",
      "Epoch 22/70\n",
      " - 4s - loss: 1.1314 - acc: 0.6548\n",
      "Epoch 23/70\n",
      " - 4s - loss: 1.1175 - acc: 0.6581\n",
      "Epoch 24/70\n",
      " - 4s - loss: 1.1173 - acc: 0.6556\n",
      "Epoch 25/70\n",
      " - 4s - loss: 1.1082 - acc: 0.6607\n",
      "Epoch 26/70\n",
      " - 3s - loss: 1.0988 - acc: 0.6606\n",
      "Epoch 27/70\n",
      " - 3s - loss: 1.0967 - acc: 0.6612\n",
      "Epoch 28/70\n",
      " - 4s - loss: 1.0914 - acc: 0.6621\n",
      "Epoch 29/70\n",
      " - 4s - loss: 1.0832 - acc: 0.6635\n",
      "Epoch 30/70\n",
      " - 3s - loss: 1.0805 - acc: 0.6648\n",
      "Epoch 31/70\n",
      " - 3s - loss: 1.0761 - acc: 0.6649\n",
      "Epoch 32/70\n",
      " - 3s - loss: 1.0681 - acc: 0.6684\n",
      "Epoch 33/70\n",
      " - 3s - loss: 1.0680 - acc: 0.6681\n",
      "Epoch 34/70\n",
      " - 3s - loss: 1.0613 - acc: 0.6699\n",
      "Epoch 35/70\n",
      " - 3s - loss: 1.0612 - acc: 0.6677\n",
      "Epoch 36/70\n",
      " - 3s - loss: 1.0508 - acc: 0.6717\n",
      "Epoch 37/70\n",
      " - 3s - loss: 1.0509 - acc: 0.6702\n",
      "Epoch 38/70\n",
      " - 3s - loss: 1.0455 - acc: 0.6722\n",
      "Epoch 39/70\n",
      " - 3s - loss: 1.0430 - acc: 0.6731\n",
      "Epoch 40/70\n",
      " - 3s - loss: 1.0424 - acc: 0.6727\n",
      "Epoch 41/70\n",
      " - 3s - loss: 1.0320 - acc: 0.6763\n",
      "Epoch 42/70\n",
      " - 3s - loss: 1.0339 - acc: 0.6753\n",
      "Epoch 43/70\n",
      " - 3s - loss: 1.0276 - acc: 0.6754\n",
      "Epoch 44/70\n",
      " - 4s - loss: 1.0296 - acc: 0.6749\n",
      "Epoch 45/70\n",
      " - 3s - loss: 1.0235 - acc: 0.6764\n",
      "Epoch 46/70\n",
      " - 3s - loss: 1.0224 - acc: 0.6774\n",
      "Epoch 47/70\n",
      " - 3s - loss: 1.0153 - acc: 0.6800\n",
      "Epoch 48/70\n",
      " - 4s - loss: 1.0136 - acc: 0.6780\n",
      "Epoch 49/70\n",
      " - 3s - loss: 1.0132 - acc: 0.6811\n",
      "Epoch 50/70\n",
      " - 3s - loss: 1.0087 - acc: 0.6808\n",
      "Epoch 51/70\n",
      " - 4s - loss: 1.0084 - acc: 0.6790\n",
      "Epoch 52/70\n",
      " - 4s - loss: 1.0024 - acc: 0.6819\n",
      "Epoch 53/70\n",
      " - 3s - loss: 1.0031 - acc: 0.6818\n",
      "Epoch 54/70\n",
      " - 3s - loss: 1.0018 - acc: 0.6817\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.9984 - acc: 0.6823\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.9978 - acc: 0.6827\n",
      "Epoch 57/70\n",
      " - 4s - loss: 0.9994 - acc: 0.6800\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.9929 - acc: 0.6832\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.9916 - acc: 0.6838\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.9926 - acc: 0.6827\n",
      "Epoch 61/70\n",
      " - 5s - loss: 0.9895 - acc: 0.6853\n",
      "Epoch 62/70\n",
      " - 5s - loss: 0.9855 - acc: 0.6833\n",
      "Epoch 63/70\n",
      " - 4s - loss: 0.9865 - acc: 0.6836\n",
      "Epoch 64/70\n",
      " - 5s - loss: 0.9833 - acc: 0.6849\n",
      "Epoch 65/70\n",
      " - 4s - loss: 0.9815 - acc: 0.6857\n",
      "Epoch 66/70\n",
      " - 4s - loss: 0.9807 - acc: 0.6853\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.9779 - acc: 0.6869\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.9770 - acc: 0.6836\n",
      "Epoch 69/70\n",
      " - 4s - loss: 0.9767 - acc: 0.6848\n",
      "Epoch 70/70\n",
      " - 4s - loss: 0.9721 - acc: 0.6861\n",
      "[CV]  nodes_l3=70, nodes_l2=100, nodes_l1=160, dropout_l3=0.2, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=3000, total= 3.9min\n",
      "[CV] nodes_l3=70, nodes_l2=100, nodes_l1=160, dropout_l3=0.2, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=3000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=160)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 8s - loss: 3.1649 - acc: 0.1885\n",
      "Epoch 2/70\n",
      " - 3s - loss: 2.4329 - acc: 0.3427\n",
      "Epoch 3/70\n",
      " - 3s - loss: 2.0058 - acc: 0.4567\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.7583 - acc: 0.5197\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.6011 - acc: 0.5582\n",
      "Epoch 6/70\n",
      " - 4s - loss: 1.4953 - acc: 0.5827\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.4236 - acc: 0.5995\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.3725 - acc: 0.6067\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.3243 - acc: 0.6181\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.2938 - acc: 0.6251\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.2656 - acc: 0.6298\n",
      "Epoch 12/70\n",
      " - 4s - loss: 1.2447 - acc: 0.6337\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.2271 - acc: 0.6370\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.2056 - acc: 0.6409\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.1982 - acc: 0.6437\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.1808 - acc: 0.6449\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.1704 - acc: 0.6477\n",
      "Epoch 18/70\n",
      " - 4s - loss: 1.1607 - acc: 0.6500\n",
      "Epoch 19/70\n",
      " - 3s - loss: 1.1512 - acc: 0.6515\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.1362 - acc: 0.6551\n",
      "Epoch 21/70\n",
      " - 3s - loss: 1.1325 - acc: 0.6545\n",
      "Epoch 22/70\n",
      " - 4s - loss: 1.1237 - acc: 0.6556\n",
      "Epoch 23/70\n",
      " - 4s - loss: 1.1144 - acc: 0.6577\n",
      "Epoch 24/70\n",
      " - 3s - loss: 1.1130 - acc: 0.6598\n",
      "Epoch 25/70\n",
      " - 3s - loss: 1.0999 - acc: 0.6612\n",
      "Epoch 26/70\n",
      " - 3s - loss: 1.0982 - acc: 0.6610\n",
      "Epoch 27/70\n",
      " - 4s - loss: 1.0935 - acc: 0.6636\n",
      "Epoch 28/70\n",
      " - 4s - loss: 1.0854 - acc: 0.6637\n",
      "Epoch 29/70\n",
      " - 3s - loss: 1.0801 - acc: 0.6664\n",
      "Epoch 30/70\n",
      " - 3s - loss: 1.0737 - acc: 0.6676\n",
      "Epoch 31/70\n",
      " - 3s - loss: 1.0696 - acc: 0.6662\n",
      "Epoch 32/70\n",
      " - 3s - loss: 1.0668 - acc: 0.6668\n",
      "Epoch 33/70\n",
      " - 3s - loss: 1.0640 - acc: 0.6688\n",
      "Epoch 34/70\n",
      " - 3s - loss: 1.0574 - acc: 0.6718\n",
      "Epoch 35/70\n",
      " - 3s - loss: 1.0564 - acc: 0.6709\n",
      "Epoch 36/70\n",
      " - 3s - loss: 1.0514 - acc: 0.6714\n",
      "Epoch 37/70\n",
      " - 3s - loss: 1.0454 - acc: 0.6726\n",
      "Epoch 38/70\n",
      " - 3s - loss: 1.0397 - acc: 0.6734\n",
      "Epoch 39/70\n",
      " - 3s - loss: 1.0413 - acc: 0.6748\n",
      "Epoch 40/70\n",
      " - 4s - loss: 1.0324 - acc: 0.6758\n",
      "Epoch 41/70\n",
      " - 4s - loss: 1.0352 - acc: 0.6730\n",
      "Epoch 42/70\n",
      " - 3s - loss: 1.0329 - acc: 0.6750\n",
      "Epoch 43/70\n",
      " - 4s - loss: 1.0284 - acc: 0.6759\n",
      "Epoch 44/70\n",
      " - 3s - loss: 1.0238 - acc: 0.6772\n",
      "Epoch 45/70\n",
      " - 4s - loss: 1.0219 - acc: 0.6776\n",
      "Epoch 46/70\n",
      " - 4s - loss: 1.0190 - acc: 0.6787\n",
      "Epoch 47/70\n",
      " - 4s - loss: 1.0156 - acc: 0.6792\n",
      "Epoch 48/70\n",
      " - 3s - loss: 1.0166 - acc: 0.6787\n",
      "Epoch 49/70\n",
      " - 3s - loss: 1.0118 - acc: 0.6795\n",
      "Epoch 50/70\n",
      " - 4s - loss: 1.0082 - acc: 0.6797\n",
      "Epoch 51/70\n",
      " - 4s - loss: 1.0063 - acc: 0.6812\n",
      "Epoch 52/70\n",
      " - 4s - loss: 1.0038 - acc: 0.6824\n",
      "Epoch 53/70\n",
      " - 5s - loss: 1.0020 - acc: 0.6815\n",
      "Epoch 54/70\n",
      " - 3s - loss: 1.0019 - acc: 0.6809\n",
      "Epoch 55/70\n",
      " - 4s - loss: 0.9975 - acc: 0.6840\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.9974 - acc: 0.6839\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.9958 - acc: 0.6831\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.9941 - acc: 0.6830\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.9886 - acc: 0.6846\n",
      "Epoch 60/70\n",
      " - 4s - loss: 0.9909 - acc: 0.6827\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.9864 - acc: 0.6842\n",
      "Epoch 62/70\n",
      " - 4s - loss: 0.9844 - acc: 0.6851\n",
      "Epoch 63/70\n",
      " - 4s - loss: 0.9844 - acc: 0.6851\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.9848 - acc: 0.6848\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.9815 - acc: 0.6865\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.9777 - acc: 0.6872\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.9783 - acc: 0.6879\n",
      "Epoch 68/70\n",
      " - 4s - loss: 0.9775 - acc: 0.6863\n",
      "Epoch 69/70\n",
      " - 4s - loss: 0.9724 - acc: 0.6888\n",
      "Epoch 70/70\n",
      " - 4s - loss: 0.9698 - acc: 0.6884\n",
      "[CV]  nodes_l3=70, nodes_l2=100, nodes_l1=160, dropout_l3=0.2, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=3000, total= 4.1min\n",
      "[CV] nodes_l3=70, nodes_l2=100, nodes_l1=160, dropout_l3=0.2, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=3000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=160)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 6s - loss: 3.2004 - acc: 0.1866\n",
      "Epoch 2/70\n",
      " - 2s - loss: 2.4351 - acc: 0.3346\n",
      "Epoch 3/70\n",
      " - 2s - loss: 1.9997 - acc: 0.4503\n",
      "Epoch 4/70\n",
      " - 2s - loss: 1.7433 - acc: 0.5237\n",
      "Epoch 5/70\n",
      " - 2s - loss: 1.5811 - acc: 0.5606\n",
      "Epoch 6/70\n",
      " - 2s - loss: 1.4788 - acc: 0.5829\n",
      "Epoch 7/70\n",
      " - 2s - loss: 1.4062 - acc: 0.6032\n",
      "Epoch 8/70\n",
      " - 2s - loss: 1.3552 - acc: 0.6133\n",
      "Epoch 9/70\n",
      " - 2s - loss: 1.3099 - acc: 0.6204\n",
      "Epoch 10/70\n",
      " - 2s - loss: 1.2760 - acc: 0.6275\n",
      "Epoch 11/70\n",
      " - 2s - loss: 1.2503 - acc: 0.6327\n",
      "Epoch 12/70\n",
      " - 2s - loss: 1.2288 - acc: 0.6365\n",
      "Epoch 13/70\n",
      " - 2s - loss: 1.2135 - acc: 0.6395\n",
      "Epoch 14/70\n",
      " - 2s - loss: 1.1964 - acc: 0.6404\n",
      "Epoch 15/70\n",
      " - 2s - loss: 1.1750 - acc: 0.6461\n",
      "Epoch 16/70\n",
      " - 2s - loss: 1.1684 - acc: 0.6501\n",
      "Epoch 17/70\n",
      " - 2s - loss: 1.1555 - acc: 0.6495\n",
      "Epoch 18/70\n",
      " - 2s - loss: 1.1437 - acc: 0.6515\n",
      "Epoch 19/70\n",
      " - 2s - loss: 1.1304 - acc: 0.6553\n",
      "Epoch 20/70\n",
      " - 2s - loss: 1.1254 - acc: 0.6565\n",
      "Epoch 21/70\n",
      " - 2s - loss: 1.1155 - acc: 0.6576\n",
      "Epoch 22/70\n",
      " - 2s - loss: 1.1064 - acc: 0.6600\n",
      "Epoch 23/70\n",
      " - 2s - loss: 1.1010 - acc: 0.6619\n",
      "Epoch 24/70\n",
      " - 2s - loss: 1.0901 - acc: 0.6622\n",
      "Epoch 25/70\n",
      " - 2s - loss: 1.0856 - acc: 0.6652\n",
      "Epoch 26/70\n",
      " - 2s - loss: 1.0806 - acc: 0.6655\n",
      "Epoch 27/70\n",
      " - 2s - loss: 1.0734 - acc: 0.6660\n",
      "Epoch 28/70\n",
      " - 2s - loss: 1.0672 - acc: 0.6680\n",
      "Epoch 29/70\n",
      " - 2s - loss: 1.0668 - acc: 0.6681\n",
      "Epoch 30/70\n",
      " - 2s - loss: 1.0572 - acc: 0.6716\n",
      "Epoch 31/70\n",
      " - 2s - loss: 1.0541 - acc: 0.6715\n",
      "Epoch 32/70\n",
      " - 2s - loss: 1.0453 - acc: 0.6724\n",
      "Epoch 33/70\n",
      " - 2s - loss: 1.0426 - acc: 0.6727\n",
      "Epoch 34/70\n",
      " - 2s - loss: 1.0369 - acc: 0.6754\n",
      "Epoch 35/70\n",
      " - 2s - loss: 1.0357 - acc: 0.6744\n",
      "Epoch 36/70\n",
      " - 2s - loss: 1.0316 - acc: 0.6760\n",
      "Epoch 37/70\n",
      " - 2s - loss: 1.0313 - acc: 0.6756\n",
      "Epoch 38/70\n",
      " - 2s - loss: 1.0249 - acc: 0.6797\n",
      "Epoch 39/70\n",
      " - 2s - loss: 1.0201 - acc: 0.6780\n",
      "Epoch 40/70\n",
      " - 2s - loss: 1.0194 - acc: 0.6791\n",
      "Epoch 41/70\n",
      " - 2s - loss: 1.0140 - acc: 0.6813\n",
      "Epoch 42/70\n",
      " - 2s - loss: 1.0114 - acc: 0.6796\n",
      "Epoch 43/70\n",
      " - 2s - loss: 1.0069 - acc: 0.6809\n",
      "Epoch 44/70\n",
      " - 2s - loss: 1.0070 - acc: 0.6807\n",
      "Epoch 45/70\n",
      " - 2s - loss: 1.0045 - acc: 0.6802\n",
      "Epoch 46/70\n",
      " - 2s - loss: 1.0027 - acc: 0.6809\n",
      "Epoch 47/70\n",
      " - 2s - loss: 0.9977 - acc: 0.6824\n",
      "Epoch 48/70\n",
      " - 2s - loss: 0.9990 - acc: 0.6831\n",
      "Epoch 49/70\n",
      " - 2s - loss: 0.9928 - acc: 0.6847\n",
      "Epoch 50/70\n",
      " - 2s - loss: 0.9896 - acc: 0.6824\n",
      "Epoch 51/70\n",
      " - 2s - loss: 0.9879 - acc: 0.6834\n",
      "Epoch 52/70\n",
      " - 2s - loss: 0.9873 - acc: 0.6857\n",
      "Epoch 53/70\n",
      " - 2s - loss: 0.9841 - acc: 0.6842\n",
      "Epoch 54/70\n",
      " - 2s - loss: 0.9779 - acc: 0.6852\n",
      "Epoch 55/70\n",
      " - 2s - loss: 0.9789 - acc: 0.6865\n",
      "Epoch 56/70\n",
      " - 2s - loss: 0.9774 - acc: 0.6877\n",
      "Epoch 57/70\n",
      " - 2s - loss: 0.9751 - acc: 0.6877\n",
      "Epoch 58/70\n",
      " - 2s - loss: 0.9758 - acc: 0.6876\n",
      "Epoch 59/70\n",
      " - 2s - loss: 0.9734 - acc: 0.6888\n",
      "Epoch 60/70\n",
      " - 2s - loss: 0.9663 - acc: 0.6899\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.9675 - acc: 0.6888\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.9673 - acc: 0.6884\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.9653 - acc: 0.6901\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.9651 - acc: 0.6889\n",
      "Epoch 65/70\n",
      " - 4s - loss: 0.9606 - acc: 0.6906\n",
      "Epoch 66/70\n",
      " - 4s - loss: 0.9613 - acc: 0.6908\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.9610 - acc: 0.6911\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.9583 - acc: 0.6914\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.9554 - acc: 0.6934\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.9588 - acc: 0.6900\n",
      "[CV]  nodes_l3=70, nodes_l2=100, nodes_l1=160, dropout_l3=0.2, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=3000, total= 2.8min\n",
      "[CV] nodes_l3=70, nodes_l2=100, nodes_l1=160, dropout_l3=0.2, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=3000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=160)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 8s - loss: 3.1857 - acc: 0.1792\n",
      "Epoch 2/70\n",
      " - 3s - loss: 2.4567 - acc: 0.3318\n",
      "Epoch 3/70\n",
      " - 3s - loss: 2.0209 - acc: 0.4459\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.7639 - acc: 0.5182\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.6004 - acc: 0.5574\n",
      "Epoch 6/70\n",
      " - 4s - loss: 1.5036 - acc: 0.5806\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.4280 - acc: 0.5973\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.3744 - acc: 0.6069\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.3303 - acc: 0.6158\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.3011 - acc: 0.6219\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.2777 - acc: 0.6285\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.2547 - acc: 0.6314\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.2307 - acc: 0.6379\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.2125 - acc: 0.6394\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.2003 - acc: 0.6416\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.1867 - acc: 0.6441\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.1714 - acc: 0.6458\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.1585 - acc: 0.6490\n",
      "Epoch 19/70\n",
      " - 3s - loss: 1.1498 - acc: 0.6501\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.1419 - acc: 0.6492\n",
      "Epoch 21/70\n",
      " - 3s - loss: 1.1317 - acc: 0.6549\n",
      "Epoch 22/70\n",
      " - 3s - loss: 1.1288 - acc: 0.6532\n",
      "Epoch 23/70\n",
      " - 3s - loss: 1.1169 - acc: 0.6569\n",
      "Epoch 24/70\n",
      " - 3s - loss: 1.1140 - acc: 0.6586\n",
      "Epoch 25/70\n",
      " - 4s - loss: 1.1058 - acc: 0.6589\n",
      "Epoch 26/70\n",
      " - 3s - loss: 1.0978 - acc: 0.6622\n",
      "Epoch 27/70\n",
      " - 3s - loss: 1.0921 - acc: 0.6619\n",
      "Epoch 28/70\n",
      " - 3s - loss: 1.0872 - acc: 0.6617\n",
      "Epoch 29/70\n",
      " - 3s - loss: 1.0791 - acc: 0.6660\n",
      "Epoch 30/70\n",
      " - 4s - loss: 1.0734 - acc: 0.6659\n",
      "Epoch 31/70\n",
      " - 4s - loss: 1.0715 - acc: 0.6675\n",
      "Epoch 32/70\n",
      " - 3s - loss: 1.0693 - acc: 0.6659\n",
      "Epoch 33/70\n",
      " - 3s - loss: 1.0596 - acc: 0.6694\n",
      "Epoch 34/70\n",
      " - 3s - loss: 1.0588 - acc: 0.6698\n",
      "Epoch 35/70\n",
      " - 3s - loss: 1.0514 - acc: 0.6699\n",
      "Epoch 36/70\n",
      " - 3s - loss: 1.0502 - acc: 0.6709\n",
      "Epoch 37/70\n",
      " - 3s - loss: 1.0415 - acc: 0.6721\n",
      "Epoch 38/70\n",
      " - 3s - loss: 1.0414 - acc: 0.6728\n",
      "Epoch 39/70\n",
      " - 3s - loss: 1.0373 - acc: 0.6732\n",
      "Epoch 40/70\n",
      " - 3s - loss: 1.0313 - acc: 0.6741\n",
      "Epoch 41/70\n",
      " - 3s - loss: 1.0313 - acc: 0.6734\n",
      "Epoch 42/70\n",
      " - 3s - loss: 1.0289 - acc: 0.6751\n",
      "Epoch 43/70\n",
      " - 3s - loss: 1.0233 - acc: 0.6769\n",
      "Epoch 44/70\n",
      " - 3s - loss: 1.0237 - acc: 0.6746\n",
      "Epoch 45/70\n",
      " - 4s - loss: 1.0230 - acc: 0.6766\n",
      "Epoch 46/70\n",
      " - 4s - loss: 1.0179 - acc: 0.6785\n",
      "Epoch 47/70\n",
      " - 3s - loss: 1.0138 - acc: 0.6784\n",
      "Epoch 48/70\n",
      " - 3s - loss: 1.0133 - acc: 0.6770\n",
      "Epoch 49/70\n",
      " - 3s - loss: 1.0065 - acc: 0.6799\n",
      "Epoch 50/70\n",
      " - 3s - loss: 1.0097 - acc: 0.6787\n",
      "Epoch 51/70\n",
      " - 3s - loss: 1.0066 - acc: 0.6792\n",
      "Epoch 52/70\n",
      " - 3s - loss: 1.0069 - acc: 0.6794\n",
      "Epoch 53/70\n",
      " - 3s - loss: 1.0015 - acc: 0.6808\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.9981 - acc: 0.6818\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.9972 - acc: 0.6817\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.9928 - acc: 0.6818\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.9913 - acc: 0.6817\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.9904 - acc: 0.6847\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.9890 - acc: 0.6831\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.9871 - acc: 0.6826\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.9860 - acc: 0.6843\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.9824 - acc: 0.6844\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.9829 - acc: 0.6854\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.9825 - acc: 0.6823\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.9812 - acc: 0.6862\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.9822 - acc: 0.6827\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.9783 - acc: 0.6858\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.9779 - acc: 0.6868\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.9728 - acc: 0.6861\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.9747 - acc: 0.6858\n",
      "[CV]  nodes_l3=70, nodes_l2=100, nodes_l1=160, dropout_l3=0.2, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=3000, total= 3.7min\n",
      "[CV] nodes_l3=70, nodes_l2=110, nodes_l1=190, dropout_l3=0.1, dropout_l2=0.2, dropout_l1=0.30000000000000004, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=190)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=110)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=110)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 7s - loss: 2.0733 - acc: 0.4432\n",
      "Epoch 2/70\n",
      " - 4s - loss: 1.3393 - acc: 0.6194\n",
      "Epoch 3/70\n",
      " - 4s - loss: 1.1968 - acc: 0.6424\n",
      "Epoch 4/70\n",
      " - 4s - loss: 1.1348 - acc: 0.6545\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.0948 - acc: 0.6602\n",
      "Epoch 6/70\n",
      " - 4s - loss: 1.0691 - acc: 0.6658\n",
      "Epoch 7/70\n",
      " - 4s - loss: 1.0410 - acc: 0.6699\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.0240 - acc: 0.6723\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.0105 - acc: 0.6750\n",
      "Epoch 10/70\n",
      " - 4s - loss: 0.9949 - acc: 0.6786\n",
      "Epoch 11/70\n",
      " - 4s - loss: 0.9822 - acc: 0.6815\n",
      "Epoch 12/70\n",
      " - 4s - loss: 0.9726 - acc: 0.6833\n",
      "Epoch 13/70\n",
      " - 3s - loss: 0.9660 - acc: 0.6835\n",
      "Epoch 14/70\n",
      " - 4s - loss: 0.9598 - acc: 0.6874\n",
      "Epoch 15/70\n",
      " - 4s - loss: 0.9474 - acc: 0.6892\n",
      "Epoch 16/70\n",
      " - 4s - loss: 0.9400 - acc: 0.6896\n",
      "Epoch 17/70\n",
      " - 4s - loss: 0.9358 - acc: 0.6923\n",
      "Epoch 18/70\n",
      " - 3s - loss: 0.9307 - acc: 0.6920\n",
      "Epoch 19/70\n",
      " - 3s - loss: 0.9249 - acc: 0.6945\n",
      "Epoch 20/70\n",
      " - 4s - loss: 0.9229 - acc: 0.6936\n",
      "Epoch 21/70\n",
      " - 4s - loss: 0.9145 - acc: 0.6965\n",
      "Epoch 22/70\n",
      " - 3s - loss: 0.9138 - acc: 0.6957\n",
      "Epoch 23/70\n",
      " - 3s - loss: 0.9093 - acc: 0.6962\n",
      "Epoch 24/70\n",
      " - 4s - loss: 0.9035 - acc: 0.6988\n",
      "Epoch 25/70\n",
      " - 4s - loss: 0.8985 - acc: 0.6990\n",
      "Epoch 26/70\n",
      " - 4s - loss: 0.8965 - acc: 0.6991\n",
      "Epoch 27/70\n",
      " - 3s - loss: 0.8945 - acc: 0.6997\n",
      "Epoch 28/70\n",
      " - 4s - loss: 0.8929 - acc: 0.6998\n",
      "Epoch 29/70\n",
      " - 4s - loss: 0.8896 - acc: 0.7010\n",
      "Epoch 30/70\n",
      " - 4s - loss: 0.8855 - acc: 0.7012\n",
      "Epoch 31/70\n",
      " - 4s - loss: 0.8828 - acc: 0.7025\n",
      "Epoch 32/70\n",
      " - 4s - loss: 0.8828 - acc: 0.7023\n",
      "Epoch 33/70\n",
      " - 4s - loss: 0.8791 - acc: 0.7030\n",
      "Epoch 34/70\n",
      " - 4s - loss: 0.8749 - acc: 0.7033\n",
      "Epoch 35/70\n",
      " - 4s - loss: 0.8749 - acc: 0.7038\n",
      "Epoch 36/70\n",
      " - 4s - loss: 0.8712 - acc: 0.7051\n",
      "Epoch 37/70\n",
      " - 4s - loss: 0.8713 - acc: 0.7058\n",
      "Epoch 38/70\n",
      " - 4s - loss: 0.8699 - acc: 0.7048\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.8703 - acc: 0.7058\n",
      "Epoch 40/70\n",
      " - 4s - loss: 0.8682 - acc: 0.7056\n",
      "Epoch 41/70\n",
      " - 4s - loss: 0.8660 - acc: 0.7072\n",
      "Epoch 42/70\n",
      " - 4s - loss: 0.8632 - acc: 0.7053\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.8610 - acc: 0.7071\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.8604 - acc: 0.7062\n",
      "Epoch 45/70\n",
      " - 4s - loss: 0.8593 - acc: 0.7062\n",
      "Epoch 46/70\n",
      " - 4s - loss: 0.8572 - acc: 0.7086\n",
      "Epoch 47/70\n",
      " - 4s - loss: 0.8555 - acc: 0.7092\n",
      "Epoch 48/70\n",
      " - 4s - loss: 0.8550 - acc: 0.7084\n",
      "Epoch 49/70\n",
      " - 4s - loss: 0.8526 - acc: 0.7098\n",
      "Epoch 50/70\n",
      " - 4s - loss: 0.8514 - acc: 0.7103\n",
      "Epoch 51/70\n",
      " - 4s - loss: 0.8516 - acc: 0.7103\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.8507 - acc: 0.7110\n",
      "Epoch 53/70\n",
      " - 4s - loss: 0.8478 - acc: 0.7092\n",
      "Epoch 54/70\n",
      " - 4s - loss: 0.8468 - acc: 0.7108\n",
      "Epoch 55/70\n",
      " - 4s - loss: 0.8464 - acc: 0.7103\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.8456 - acc: 0.7104\n",
      "Epoch 57/70\n",
      " - 4s - loss: 0.8461 - acc: 0.7126\n",
      "Epoch 58/70\n",
      " - 4s - loss: 0.8464 - acc: 0.7116\n",
      "Epoch 59/70\n",
      " - 4s - loss: 0.8438 - acc: 0.7113\n",
      "Epoch 60/70\n",
      " - 4s - loss: 0.8453 - acc: 0.7114\n",
      "Epoch 61/70\n",
      " - 4s - loss: 0.8399 - acc: 0.7126\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.8418 - acc: 0.7103\n",
      "Epoch 63/70\n",
      " - 4s - loss: 0.8410 - acc: 0.7125\n",
      "Epoch 64/70\n",
      " - 4s - loss: 0.8383 - acc: 0.7124\n",
      "Epoch 65/70\n",
      " - 4s - loss: 0.8397 - acc: 0.7127\n",
      "Epoch 66/70\n",
      " - 4s - loss: 0.8377 - acc: 0.7116\n",
      "Epoch 67/70\n",
      " - 4s - loss: 0.8378 - acc: 0.7120\n",
      "Epoch 68/70\n",
      " - 4s - loss: 0.8378 - acc: 0.7130\n",
      "Epoch 69/70\n",
      " - 4s - loss: 0.8369 - acc: 0.7126\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.8351 - acc: 0.7138\n",
      "[CV]  nodes_l3=70, nodes_l2=110, nodes_l1=190, dropout_l3=0.1, dropout_l2=0.2, dropout_l1=0.30000000000000004, batch_size=500, total= 4.4min\n",
      "[CV] nodes_l3=70, nodes_l2=110, nodes_l1=190, dropout_l3=0.1, dropout_l2=0.2, dropout_l1=0.30000000000000004, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=190)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=110)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=110)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 8s - loss: 2.0757 - acc: 0.4421\n",
      "Epoch 2/70\n",
      " - 4s - loss: 1.3339 - acc: 0.6176\n",
      "Epoch 3/70\n",
      " - 4s - loss: 1.1964 - acc: 0.6416\n",
      "Epoch 4/70\n",
      " - 4s - loss: 1.1319 - acc: 0.6540\n",
      "Epoch 5/70\n",
      " - 4s - loss: 1.0952 - acc: 0.6620\n",
      "Epoch 6/70\n",
      " - 4s - loss: 1.0672 - acc: 0.6664\n",
      "Epoch 7/70\n",
      " - 4s - loss: 1.0431 - acc: 0.6699\n",
      "Epoch 8/70\n",
      " - 4s - loss: 1.0223 - acc: 0.6747\n",
      "Epoch 9/70\n",
      " - 4s - loss: 1.0131 - acc: 0.6761\n",
      "Epoch 10/70\n",
      " - 4s - loss: 0.9951 - acc: 0.6784\n",
      "Epoch 11/70\n",
      " - 4s - loss: 0.9829 - acc: 0.6812\n",
      "Epoch 12/70\n",
      " - 4s - loss: 0.9716 - acc: 0.6834\n",
      "Epoch 13/70\n",
      " - 4s - loss: 0.9639 - acc: 0.6852\n",
      "Epoch 14/70\n",
      " - 4s - loss: 0.9552 - acc: 0.6875\n",
      "Epoch 15/70\n",
      " - 4s - loss: 0.9481 - acc: 0.6881\n",
      "Epoch 16/70\n",
      " - 4s - loss: 0.9401 - acc: 0.6919\n",
      "Epoch 17/70\n",
      " - 4s - loss: 0.9324 - acc: 0.6903\n",
      "Epoch 18/70\n",
      " - 4s - loss: 0.9287 - acc: 0.6925\n",
      "Epoch 19/70\n",
      " - 4s - loss: 0.9204 - acc: 0.6948\n",
      "Epoch 20/70\n",
      " - 4s - loss: 0.9212 - acc: 0.6954\n",
      "Epoch 21/70\n",
      " - 4s - loss: 0.9132 - acc: 0.6948\n",
      "Epoch 22/70\n",
      " - 4s - loss: 0.9082 - acc: 0.6974\n",
      "Epoch 23/70\n",
      " - 4s - loss: 0.9093 - acc: 0.6957\n",
      "Epoch 24/70\n",
      " - 4s - loss: 0.9018 - acc: 0.6980\n",
      "Epoch 25/70\n",
      " - 5s - loss: 0.9019 - acc: 0.6988\n",
      "Epoch 26/70\n",
      " - 5s - loss: 0.8939 - acc: 0.7005\n",
      "Epoch 27/70\n",
      " - 4s - loss: 0.8949 - acc: 0.6995\n",
      "Epoch 28/70\n",
      " - 4s - loss: 0.8893 - acc: 0.7021\n",
      "Epoch 29/70\n",
      " - 5s - loss: 0.8873 - acc: 0.7026\n",
      "Epoch 30/70\n",
      " - 5s - loss: 0.8855 - acc: 0.7024\n",
      "Epoch 31/70\n",
      " - 5s - loss: 0.8807 - acc: 0.7045\n",
      "Epoch 32/70\n",
      " - 5s - loss: 0.8777 - acc: 0.7023\n",
      "Epoch 33/70\n",
      " - 5s - loss: 0.8774 - acc: 0.7036\n",
      "Epoch 34/70\n",
      " - 4s - loss: 0.8766 - acc: 0.7042\n",
      "Epoch 35/70\n",
      " - 4s - loss: 0.8757 - acc: 0.7042\n",
      "Epoch 36/70\n",
      " - 5s - loss: 0.8732 - acc: 0.7041\n",
      "Epoch 37/70\n",
      " - 4s - loss: 0.8710 - acc: 0.7057\n",
      "Epoch 38/70\n",
      " - 4s - loss: 0.8677 - acc: 0.7059\n",
      "Epoch 39/70\n",
      " - 4s - loss: 0.8648 - acc: 0.7085\n",
      "Epoch 40/70\n",
      " - 4s - loss: 0.8668 - acc: 0.7077\n",
      "Epoch 41/70\n",
      " - 4s - loss: 0.8650 - acc: 0.7065\n",
      "Epoch 42/70\n",
      " - 5s - loss: 0.8584 - acc: 0.7097\n",
      "Epoch 43/70\n",
      " - 5s - loss: 0.8625 - acc: 0.7068\n",
      "Epoch 44/70\n",
      " - 5s - loss: 0.8570 - acc: 0.7077\n",
      "Epoch 45/70\n",
      " - 5s - loss: 0.8582 - acc: 0.7090\n",
      "Epoch 46/70\n",
      " - 5s - loss: 0.8572 - acc: 0.7089\n",
      "Epoch 47/70\n",
      " - 6s - loss: 0.8546 - acc: 0.7100\n",
      "Epoch 48/70\n",
      " - 5s - loss: 0.8562 - acc: 0.7099\n",
      "Epoch 49/70\n",
      " - 6s - loss: 0.8548 - acc: 0.7074\n",
      "Epoch 50/70\n",
      " - 6s - loss: 0.8518 - acc: 0.7113\n",
      "Epoch 51/70\n",
      " - 6s - loss: 0.8527 - acc: 0.7098\n",
      "Epoch 52/70\n",
      " - 6s - loss: 0.8500 - acc: 0.7095\n",
      "Epoch 53/70\n",
      " - 6s - loss: 0.8456 - acc: 0.7105\n",
      "Epoch 54/70\n",
      " - 5s - loss: 0.8468 - acc: 0.7116\n",
      "Epoch 55/70\n",
      " - 6s - loss: 0.8459 - acc: 0.7122\n",
      "Epoch 56/70\n",
      " - 5s - loss: 0.8493 - acc: 0.7113\n",
      "Epoch 57/70\n",
      " - 5s - loss: 0.8429 - acc: 0.7120\n",
      "Epoch 58/70\n",
      " - 6s - loss: 0.8447 - acc: 0.7128\n",
      "Epoch 59/70\n",
      " - 5s - loss: 0.8420 - acc: 0.7129\n",
      "Epoch 60/70\n",
      " - 5s - loss: 0.8422 - acc: 0.7132\n",
      "Epoch 61/70\n",
      " - 6s - loss: 0.8438 - acc: 0.7130\n",
      "Epoch 62/70\n",
      " - 5s - loss: 0.8421 - acc: 0.7125\n",
      "Epoch 63/70\n",
      " - 5s - loss: 0.8410 - acc: 0.7120\n",
      "Epoch 64/70\n",
      " - 6s - loss: 0.8389 - acc: 0.7123\n",
      "Epoch 65/70\n",
      " - 5s - loss: 0.8388 - acc: 0.7133\n",
      "Epoch 66/70\n",
      " - 5s - loss: 0.8372 - acc: 0.7134\n",
      "Epoch 67/70\n",
      " - 6s - loss: 0.8336 - acc: 0.7148\n",
      "Epoch 68/70\n",
      " - 6s - loss: 0.8358 - acc: 0.7139\n",
      "Epoch 69/70\n",
      " - 5s - loss: 0.8331 - acc: 0.7146\n",
      "Epoch 70/70\n",
      " - 6s - loss: 0.8320 - acc: 0.7136\n",
      "[CV]  nodes_l3=70, nodes_l2=110, nodes_l1=190, dropout_l3=0.1, dropout_l2=0.2, dropout_l1=0.30000000000000004, batch_size=500, total= 5.5min\n",
      "[CV] nodes_l3=70, nodes_l2=110, nodes_l1=190, dropout_l3=0.1, dropout_l2=0.2, dropout_l1=0.30000000000000004, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=190)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=110)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=110)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 11s - loss: 2.0385 - acc: 0.4532\n",
      "Epoch 2/70\n",
      " - 5s - loss: 1.3067 - acc: 0.6239\n",
      "Epoch 3/70\n",
      " - 5s - loss: 1.1767 - acc: 0.6469\n",
      "Epoch 4/70\n",
      " - 6s - loss: 1.1139 - acc: 0.6577\n",
      "Epoch 5/70\n",
      " - 5s - loss: 1.0738 - acc: 0.6639\n",
      "Epoch 6/70\n",
      " - 5s - loss: 1.0543 - acc: 0.6663\n",
      "Epoch 7/70\n",
      " - 6s - loss: 1.0275 - acc: 0.6724\n",
      "Epoch 8/70\n",
      " - 5s - loss: 1.0096 - acc: 0.6752\n",
      "Epoch 9/70\n",
      " - 5s - loss: 0.9953 - acc: 0.6769\n",
      "Epoch 10/70\n",
      " - 6s - loss: 0.9831 - acc: 0.6815\n",
      "Epoch 11/70\n",
      " - 5s - loss: 0.9750 - acc: 0.6828\n",
      "Epoch 12/70\n",
      " - 5s - loss: 0.9587 - acc: 0.6876\n",
      "Epoch 13/70\n",
      " - 6s - loss: 0.9528 - acc: 0.6881\n",
      "Epoch 14/70\n",
      " - 6s - loss: 0.9457 - acc: 0.6884\n",
      "Epoch 15/70\n",
      " - 5s - loss: 0.9377 - acc: 0.6902\n",
      "Epoch 16/70\n",
      " - 6s - loss: 0.9310 - acc: 0.6919\n",
      "Epoch 17/70\n",
      " - 5s - loss: 0.9235 - acc: 0.6934\n",
      "Epoch 18/70\n",
      " - 5s - loss: 0.9207 - acc: 0.6946\n",
      "Epoch 19/70\n",
      " - 4s - loss: 0.9134 - acc: 0.6967\n",
      "Epoch 20/70\n",
      " - 4s - loss: 0.9090 - acc: 0.6967\n",
      "Epoch 21/70\n",
      " - 4s - loss: 0.9039 - acc: 0.6979\n",
      "Epoch 22/70\n",
      " - 4s - loss: 0.8998 - acc: 0.6984\n",
      "Epoch 23/70\n",
      " - 5s - loss: 0.8920 - acc: 0.7005\n",
      "Epoch 24/70\n",
      " - 4s - loss: 0.8904 - acc: 0.7005\n",
      "Epoch 25/70\n",
      " - 4s - loss: 0.8880 - acc: 0.7012\n",
      "Epoch 26/70\n",
      " - 4s - loss: 0.8885 - acc: 0.7014\n",
      "Epoch 27/70\n",
      " - 5s - loss: 0.8834 - acc: 0.7027\n",
      "Epoch 28/70\n",
      " - 4s - loss: 0.8767 - acc: 0.7040\n",
      "Epoch 29/70\n",
      " - 4s - loss: 0.8758 - acc: 0.7032\n",
      "Epoch 30/70\n",
      " - 4s - loss: 0.8730 - acc: 0.7046\n",
      "Epoch 31/70\n",
      " - 4s - loss: 0.8714 - acc: 0.7049\n",
      "Epoch 32/70\n",
      " - 4s - loss: 0.8687 - acc: 0.7053\n",
      "Epoch 33/70\n",
      " - 4s - loss: 0.8664 - acc: 0.7065\n",
      "Epoch 34/70\n",
      " - 4s - loss: 0.8673 - acc: 0.7068\n",
      "Epoch 35/70\n",
      " - 4s - loss: 0.8612 - acc: 0.7077\n",
      "Epoch 36/70\n",
      " - 4s - loss: 0.8582 - acc: 0.7077\n",
      "Epoch 37/70\n",
      " - 4s - loss: 0.8547 - acc: 0.7089\n",
      "Epoch 38/70\n",
      " - 4s - loss: 0.8566 - acc: 0.7085\n",
      "Epoch 39/70\n",
      " - 4s - loss: 0.8522 - acc: 0.7095\n",
      "Epoch 40/70\n",
      " - 4s - loss: 0.8513 - acc: 0.7094\n",
      "Epoch 41/70\n",
      " - 4s - loss: 0.8485 - acc: 0.7110\n",
      "Epoch 42/70\n",
      " - 4s - loss: 0.8464 - acc: 0.7113\n",
      "Epoch 43/70\n",
      " - 4s - loss: 0.8453 - acc: 0.7111\n",
      "Epoch 44/70\n",
      " - 4s - loss: 0.8431 - acc: 0.7113\n",
      "Epoch 45/70\n",
      " - 4s - loss: 0.8424 - acc: 0.7110\n",
      "Epoch 46/70\n",
      " - 4s - loss: 0.8408 - acc: 0.7124\n",
      "Epoch 47/70\n",
      " - 4s - loss: 0.8443 - acc: 0.7105\n",
      "Epoch 48/70\n",
      " - 4s - loss: 0.8376 - acc: 0.7125\n",
      "Epoch 49/70\n",
      " - 4s - loss: 0.8403 - acc: 0.7111\n",
      "Epoch 50/70\n",
      " - 4s - loss: 0.8374 - acc: 0.7138\n",
      "Epoch 51/70\n",
      " - 4s - loss: 0.8377 - acc: 0.7113\n",
      "Epoch 52/70\n",
      " - 4s - loss: 0.8343 - acc: 0.7142\n",
      "Epoch 53/70\n",
      " - 4s - loss: 0.8339 - acc: 0.7134\n",
      "Epoch 54/70\n",
      " - 4s - loss: 0.8315 - acc: 0.7141\n",
      "Epoch 55/70\n",
      " - 4s - loss: 0.8326 - acc: 0.7133\n",
      "Epoch 56/70\n",
      " - 4s - loss: 0.8314 - acc: 0.7142\n",
      "Epoch 57/70\n",
      " - 4s - loss: 0.8305 - acc: 0.7141\n",
      "Epoch 58/70\n",
      " - 4s - loss: 0.8314 - acc: 0.7142\n",
      "Epoch 59/70\n",
      " - 4s - loss: 0.8284 - acc: 0.7152\n",
      "Epoch 60/70\n",
      " - 4s - loss: 0.8248 - acc: 0.7176\n",
      "Epoch 61/70\n",
      " - 4s - loss: 0.8253 - acc: 0.7164\n",
      "Epoch 62/70\n",
      " - 4s - loss: 0.8284 - acc: 0.7154\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.8263 - acc: 0.7145\n",
      "Epoch 64/70\n",
      " - 4s - loss: 0.8270 - acc: 0.7155\n",
      "Epoch 65/70\n",
      " - 4s - loss: 0.8210 - acc: 0.7166\n",
      "Epoch 66/70\n",
      " - 4s - loss: 0.8260 - acc: 0.7157\n",
      "Epoch 67/70\n",
      " - 4s - loss: 0.8230 - acc: 0.7176\n",
      "Epoch 68/70\n",
      " - 4s - loss: 0.8238 - acc: 0.7170\n",
      "Epoch 69/70\n",
      " - 4s - loss: 0.8202 - acc: 0.7179\n",
      "Epoch 70/70\n",
      " - 4s - loss: 0.8196 - acc: 0.7185\n",
      "[CV]  nodes_l3=70, nodes_l2=110, nodes_l1=190, dropout_l3=0.1, dropout_l2=0.2, dropout_l1=0.30000000000000004, batch_size=500, total= 5.1min\n",
      "[CV] nodes_l3=70, nodes_l2=110, nodes_l1=190, dropout_l3=0.1, dropout_l2=0.2, dropout_l1=0.30000000000000004, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=190)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=110)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=110)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 9s - loss: 2.0406 - acc: 0.4594\n",
      "Epoch 2/70\n",
      " - 4s - loss: 1.3292 - acc: 0.6173\n",
      "Epoch 3/70\n",
      " - 4s - loss: 1.1967 - acc: 0.6420\n",
      "Epoch 4/70\n",
      " - 4s - loss: 1.1364 - acc: 0.6516\n",
      "Epoch 5/70\n",
      " - 4s - loss: 1.0957 - acc: 0.6605\n",
      "Epoch 6/70\n",
      " - 4s - loss: 1.0699 - acc: 0.6630\n",
      "Epoch 7/70\n",
      " - 4s - loss: 1.0481 - acc: 0.6666\n",
      "Epoch 8/70\n",
      " - 4s - loss: 1.0288 - acc: 0.6728\n",
      "Epoch 9/70\n",
      " - 4s - loss: 1.0114 - acc: 0.6745\n",
      "Epoch 10/70\n",
      " - 4s - loss: 0.9994 - acc: 0.6759\n",
      "Epoch 11/70\n",
      " - 4s - loss: 0.9835 - acc: 0.6809\n",
      "Epoch 12/70\n",
      " - 4s - loss: 0.9737 - acc: 0.6837\n",
      "Epoch 13/70\n",
      " - 4s - loss: 0.9655 - acc: 0.6839\n",
      "Epoch 14/70\n",
      " - 4s - loss: 0.9587 - acc: 0.6845\n",
      "Epoch 15/70\n",
      " - 4s - loss: 0.9498 - acc: 0.6854\n",
      "Epoch 16/70\n",
      " - 4s - loss: 0.9413 - acc: 0.6888\n",
      "Epoch 17/70\n",
      " - 4s - loss: 0.9392 - acc: 0.6891\n",
      "Epoch 18/70\n",
      " - 4s - loss: 0.9310 - acc: 0.6904\n",
      "Epoch 19/70\n",
      " - 4s - loss: 0.9248 - acc: 0.6924\n",
      "Epoch 20/70\n",
      " - 4s - loss: 0.9187 - acc: 0.6947\n",
      "Epoch 21/70\n",
      " - 4s - loss: 0.9177 - acc: 0.6954\n",
      "Epoch 22/70\n",
      " - 4s - loss: 0.9114 - acc: 0.6950\n",
      "Epoch 23/70\n",
      " - 4s - loss: 0.9107 - acc: 0.6964\n",
      "Epoch 24/70\n",
      " - 4s - loss: 0.9056 - acc: 0.6964\n",
      "Epoch 25/70\n",
      " - 4s - loss: 0.9031 - acc: 0.6982\n",
      "Epoch 26/70\n",
      " - 4s - loss: 0.9011 - acc: 0.6972\n",
      "Epoch 27/70\n",
      " - 4s - loss: 0.8971 - acc: 0.6978\n",
      "Epoch 28/70\n",
      " - 4s - loss: 0.8959 - acc: 0.6974\n",
      "Epoch 29/70\n",
      " - 4s - loss: 0.8908 - acc: 0.6980\n",
      "Epoch 30/70\n",
      " - 4s - loss: 0.8867 - acc: 0.6994\n",
      "Epoch 31/70\n",
      " - 4s - loss: 0.8894 - acc: 0.7001\n",
      "Epoch 32/70\n",
      " - 4s - loss: 0.8855 - acc: 0.7016\n",
      "Epoch 33/70\n",
      " - 4s - loss: 0.8826 - acc: 0.7022\n",
      "Epoch 34/70\n",
      " - 4s - loss: 0.8797 - acc: 0.7025\n",
      "Epoch 35/70\n",
      " - 4s - loss: 0.8789 - acc: 0.7024\n",
      "Epoch 36/70\n",
      " - 4s - loss: 0.8752 - acc: 0.7026\n",
      "Epoch 37/70\n",
      " - 4s - loss: 0.8747 - acc: 0.7036\n",
      "Epoch 38/70\n",
      " - 4s - loss: 0.8749 - acc: 0.7028\n",
      "Epoch 39/70\n",
      " - 4s - loss: 0.8744 - acc: 0.7019\n",
      "Epoch 40/70\n",
      " - 4s - loss: 0.8683 - acc: 0.7048\n",
      "Epoch 41/70\n",
      " - 4s - loss: 0.8715 - acc: 0.7034\n",
      "Epoch 42/70\n",
      " - 4s - loss: 0.8663 - acc: 0.7043\n",
      "Epoch 43/70\n",
      " - 4s - loss: 0.8645 - acc: 0.7057\n",
      "Epoch 44/70\n",
      " - 4s - loss: 0.8643 - acc: 0.7055\n",
      "Epoch 45/70\n",
      " - 4s - loss: 0.8619 - acc: 0.7060\n",
      "Epoch 46/70\n",
      " - 4s - loss: 0.8594 - acc: 0.7060\n",
      "Epoch 47/70\n",
      " - 4s - loss: 0.8574 - acc: 0.7064\n",
      "Epoch 48/70\n",
      " - 4s - loss: 0.8578 - acc: 0.7063\n",
      "Epoch 49/70\n",
      " - 4s - loss: 0.8578 - acc: 0.7067\n",
      "Epoch 50/70\n",
      " - 4s - loss: 0.8570 - acc: 0.7084\n",
      "Epoch 51/70\n",
      " - 4s - loss: 0.8546 - acc: 0.7078\n",
      "Epoch 52/70\n",
      " - 4s - loss: 0.8540 - acc: 0.7070\n",
      "Epoch 53/70\n",
      " - 4s - loss: 0.8533 - acc: 0.7076\n",
      "Epoch 54/70\n",
      " - 4s - loss: 0.8512 - acc: 0.7095\n",
      "Epoch 55/70\n",
      " - 5s - loss: 0.8524 - acc: 0.7080\n",
      "Epoch 56/70\n",
      " - 4s - loss: 0.8538 - acc: 0.7084\n",
      "Epoch 57/70\n",
      " - 4s - loss: 0.8465 - acc: 0.7099\n",
      "Epoch 58/70\n",
      " - 4s - loss: 0.8515 - acc: 0.7082\n",
      "Epoch 59/70\n",
      " - 4s - loss: 0.8482 - acc: 0.7098\n",
      "Epoch 60/70\n",
      " - 4s - loss: 0.8452 - acc: 0.7117\n",
      "Epoch 61/70\n",
      " - 4s - loss: 0.8447 - acc: 0.7110\n",
      "Epoch 62/70\n",
      " - 4s - loss: 0.8457 - acc: 0.7098\n",
      "Epoch 63/70\n",
      " - 4s - loss: 0.8455 - acc: 0.7089\n",
      "Epoch 64/70\n",
      " - 4s - loss: 0.8448 - acc: 0.7100\n",
      "Epoch 65/70\n",
      " - 4s - loss: 0.8417 - acc: 0.7104\n",
      "Epoch 66/70\n",
      " - 4s - loss: 0.8384 - acc: 0.7117\n",
      "Epoch 67/70\n",
      " - 4s - loss: 0.8417 - acc: 0.7107\n",
      "Epoch 68/70\n",
      " - 4s - loss: 0.8378 - acc: 0.7109\n",
      "Epoch 69/70\n",
      " - 4s - loss: 0.8405 - acc: 0.7121\n",
      "Epoch 70/70\n",
      " - 4s - loss: 0.8391 - acc: 0.7114\n",
      "[CV]  nodes_l3=70, nodes_l2=110, nodes_l1=190, dropout_l3=0.1, dropout_l2=0.2, dropout_l1=0.30000000000000004, batch_size=500, total= 4.6min\n",
      "[CV] nodes_l3=70, nodes_l2=90, nodes_l1=150, dropout_l3=0.4, dropout_l2=0.2, dropout_l1=0.4, batch_size=2000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=150)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 6s - loss: 3.1554 - acc: 0.1769\n",
      "Epoch 2/70\n",
      " - 2s - loss: 2.3360 - acc: 0.3673\n",
      "Epoch 3/70\n",
      " - 2s - loss: 1.9198 - acc: 0.4850\n",
      "Epoch 4/70\n",
      " - 2s - loss: 1.6976 - acc: 0.5395\n",
      "Epoch 5/70\n",
      " - 2s - loss: 1.5604 - acc: 0.5720\n",
      "Epoch 6/70\n",
      " - 2s - loss: 1.4752 - acc: 0.5925\n",
      "Epoch 7/70\n",
      " - 2s - loss: 1.4054 - acc: 0.6069\n",
      "Epoch 8/70\n",
      " - 2s - loss: 1.3578 - acc: 0.6159\n",
      "Epoch 9/70\n",
      " - 2s - loss: 1.3205 - acc: 0.6262\n",
      "Epoch 10/70\n",
      " - 2s - loss: 1.2914 - acc: 0.6304\n",
      "Epoch 11/70\n",
      " - 2s - loss: 1.2673 - acc: 0.6358\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.2528 - acc: 0.6356\n",
      "Epoch 13/70\n",
      " - 4s - loss: 1.2311 - acc: 0.6412\n",
      "Epoch 14/70\n",
      " - 5s - loss: 1.2109 - acc: 0.6447\n",
      "Epoch 15/70\n",
      " - 4s - loss: 1.2021 - acc: 0.6478\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.1876 - acc: 0.6488\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.1795 - acc: 0.6493\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.1667 - acc: 0.6512\n",
      "Epoch 19/70\n",
      " - 3s - loss: 1.1591 - acc: 0.6536\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.1479 - acc: 0.6566\n",
      "Epoch 21/70\n",
      " - 3s - loss: 1.1443 - acc: 0.6553\n",
      "Epoch 22/70\n",
      " - 3s - loss: 1.1329 - acc: 0.6589\n",
      "Epoch 23/70\n",
      " - 4s - loss: 1.1267 - acc: 0.6585\n",
      "Epoch 24/70\n",
      " - 4s - loss: 1.1273 - acc: 0.6590\n",
      "Epoch 25/70\n",
      " - 3s - loss: 1.1178 - acc: 0.6611\n",
      "Epoch 26/70\n",
      " - 4s - loss: 1.1054 - acc: 0.6636\n",
      "Epoch 27/70\n",
      " - 5s - loss: 1.1058 - acc: 0.6652\n",
      "Epoch 28/70\n",
      " - 4s - loss: 1.0961 - acc: 0.6649\n",
      "Epoch 29/70\n",
      " - 6s - loss: 1.0940 - acc: 0.6673\n",
      "Epoch 30/70\n",
      " - 6s - loss: 1.0846 - acc: 0.6688\n",
      "Epoch 31/70\n",
      " - 4s - loss: 1.0850 - acc: 0.6701\n",
      "Epoch 32/70\n",
      " - 4s - loss: 1.0801 - acc: 0.6696\n",
      "Epoch 33/70\n",
      " - 4s - loss: 1.0794 - acc: 0.6677\n",
      "Epoch 34/70\n",
      " - 4s - loss: 1.0795 - acc: 0.6710\n",
      "Epoch 35/70\n",
      " - 4s - loss: 1.0658 - acc: 0.6727\n",
      "Epoch 36/70\n",
      " - 3s - loss: 1.0658 - acc: 0.6740\n",
      "Epoch 37/70\n",
      " - 3s - loss: 1.0559 - acc: 0.6739\n",
      "Epoch 38/70\n",
      " - 3s - loss: 1.0603 - acc: 0.6743\n",
      "Epoch 39/70\n",
      " - 4s - loss: 1.0549 - acc: 0.6735\n",
      "Epoch 40/70\n",
      " - 4s - loss: 1.0542 - acc: 0.6763\n",
      "Epoch 41/70\n",
      " - 3s - loss: 1.0523 - acc: 0.6744\n",
      "Epoch 42/70\n",
      " - 3s - loss: 1.0454 - acc: 0.6771\n",
      "Epoch 43/70\n",
      " - 3s - loss: 1.0421 - acc: 0.6769\n",
      "Epoch 44/70\n",
      " - 3s - loss: 1.0399 - acc: 0.6792\n",
      "Epoch 45/70\n",
      " - 3s - loss: 1.0401 - acc: 0.6777\n",
      "Epoch 46/70\n",
      " - 3s - loss: 1.0351 - acc: 0.6795\n",
      "Epoch 47/70\n",
      " - 5s - loss: 1.0310 - acc: 0.6806\n",
      "Epoch 48/70\n",
      " - 4s - loss: 1.0345 - acc: 0.6784\n",
      "Epoch 49/70\n",
      " - 4s - loss: 1.0318 - acc: 0.6793\n",
      "Epoch 50/70\n",
      " - 3s - loss: 1.0301 - acc: 0.6805\n",
      "Epoch 51/70\n",
      " - 4s - loss: 1.0239 - acc: 0.6795\n",
      "Epoch 52/70\n",
      " - 4s - loss: 1.0257 - acc: 0.6797\n",
      "Epoch 53/70\n",
      " - 4s - loss: 1.0186 - acc: 0.6819\n",
      "Epoch 54/70\n",
      " - 3s - loss: 1.0194 - acc: 0.6839\n",
      "Epoch 55/70\n",
      " - 4s - loss: 1.0169 - acc: 0.6823\n",
      "Epoch 56/70\n",
      " - 5s - loss: 1.0118 - acc: 0.6831\n",
      "Epoch 57/70\n",
      " - 4s - loss: 1.0115 - acc: 0.6829\n",
      "Epoch 58/70\n",
      " - 3s - loss: 1.0130 - acc: 0.6829\n",
      "Epoch 59/70\n",
      " - 4s - loss: 1.0121 - acc: 0.6811\n",
      "Epoch 60/70\n",
      " - 4s - loss: 1.0095 - acc: 0.6823\n",
      "Epoch 61/70\n",
      " - 5s - loss: 1.0073 - acc: 0.6836\n",
      "Epoch 62/70\n",
      " - 4s - loss: 1.0089 - acc: 0.6837\n",
      "Epoch 63/70\n",
      " - 4s - loss: 1.0084 - acc: 0.6833\n",
      "Epoch 64/70\n",
      " - 4s - loss: 1.0044 - acc: 0.6835\n",
      "Epoch 65/70\n",
      " - 4s - loss: 1.0011 - acc: 0.6843\n",
      "Epoch 66/70\n",
      " - 4s - loss: 1.0025 - acc: 0.6852\n",
      "Epoch 67/70\n",
      " - 4s - loss: 1.0013 - acc: 0.6850\n",
      "Epoch 68/70\n",
      " - 4s - loss: 1.0011 - acc: 0.6859\n",
      "Epoch 69/70\n",
      " - 4s - loss: 0.9984 - acc: 0.6850\n",
      "Epoch 70/70\n",
      " - 4s - loss: 0.9962 - acc: 0.6855\n",
      "[CV]  nodes_l3=70, nodes_l2=90, nodes_l1=150, dropout_l3=0.4, dropout_l2=0.2, dropout_l1=0.4, batch_size=2000, total= 4.4min\n",
      "[CV] nodes_l3=70, nodes_l2=90, nodes_l1=150, dropout_l3=0.4, dropout_l2=0.2, dropout_l1=0.4, batch_size=2000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=150)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 13s - loss: 3.0978 - acc: 0.2009\n",
      "Epoch 2/70\n",
      " - 5s - loss: 2.2905 - acc: 0.3820\n",
      "Epoch 3/70\n",
      " - 4s - loss: 1.8669 - acc: 0.4948\n",
      "Epoch 4/70\n",
      " - 4s - loss: 1.6629 - acc: 0.5491\n",
      "Epoch 5/70\n",
      " - 4s - loss: 1.5426 - acc: 0.5757\n",
      "Epoch 6/70\n",
      " - 4s - loss: 1.4551 - acc: 0.5970\n",
      "Epoch 7/70\n",
      " - 4s - loss: 1.3906 - acc: 0.6103\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.3513 - acc: 0.6181\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.3189 - acc: 0.6245\n",
      "Epoch 10/70\n",
      " - 4s - loss: 1.2865 - acc: 0.6291\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.2615 - acc: 0.6334\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.2420 - acc: 0.6370\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.2249 - acc: 0.6398\n",
      "Epoch 14/70\n",
      " - 4s - loss: 1.2076 - acc: 0.6448\n",
      "Epoch 15/70\n",
      " - 4s - loss: 1.1979 - acc: 0.6452\n",
      "Epoch 16/70\n",
      " - 4s - loss: 1.1807 - acc: 0.6494\n",
      "Epoch 17/70\n",
      " - 4s - loss: 1.1742 - acc: 0.6518\n",
      "Epoch 18/70\n",
      " - 4s - loss: 1.1643 - acc: 0.6526\n",
      "Epoch 19/70\n",
      " - 5s - loss: 1.1537 - acc: 0.6562\n",
      "Epoch 20/70\n",
      " - 4s - loss: 1.1482 - acc: 0.6565\n",
      "Epoch 21/70\n",
      " - 4s - loss: 1.1396 - acc: 0.6560\n",
      "Epoch 22/70\n",
      " - 4s - loss: 1.1239 - acc: 0.6623\n",
      "Epoch 23/70\n",
      " - 4s - loss: 1.1209 - acc: 0.6617\n",
      "Epoch 24/70\n",
      " - 4s - loss: 1.1210 - acc: 0.6595\n",
      "Epoch 25/70\n",
      " - 4s - loss: 1.1154 - acc: 0.6626\n",
      "Epoch 26/70\n",
      " - 5s - loss: 1.1036 - acc: 0.6654\n",
      "Epoch 27/70\n",
      " - 5s - loss: 1.0991 - acc: 0.6648\n",
      "Epoch 28/70\n",
      " - 4s - loss: 1.0931 - acc: 0.6668\n",
      "Epoch 29/70\n",
      " - 5s - loss: 1.0915 - acc: 0.6682\n",
      "Epoch 30/70\n",
      " - 5s - loss: 1.0861 - acc: 0.6682\n",
      "Epoch 31/70\n",
      " - 5s - loss: 1.0777 - acc: 0.6690\n",
      "Epoch 32/70\n",
      " - 4s - loss: 1.0811 - acc: 0.6688\n",
      "Epoch 33/70\n",
      " - 4s - loss: 1.0700 - acc: 0.6699\n",
      "Epoch 34/70\n",
      " - 4s - loss: 1.0723 - acc: 0.6716\n",
      "Epoch 35/70\n",
      " - 3s - loss: 1.0637 - acc: 0.6740\n",
      "Epoch 36/70\n",
      " - 3s - loss: 1.0602 - acc: 0.6730\n",
      "Epoch 37/70\n",
      " - 4s - loss: 1.0606 - acc: 0.6731\n",
      "Epoch 38/70\n",
      " - 3s - loss: 1.0563 - acc: 0.6734\n",
      "Epoch 39/70\n",
      " - 3s - loss: 1.0517 - acc: 0.6748\n",
      "Epoch 40/70\n",
      " - 3s - loss: 1.0539 - acc: 0.6753\n",
      "Epoch 41/70\n",
      " - 3s - loss: 1.0493 - acc: 0.6724\n",
      "Epoch 42/70\n",
      " - 4s - loss: 1.0449 - acc: 0.6763\n",
      "Epoch 43/70\n",
      " - 3s - loss: 1.0404 - acc: 0.6768\n",
      "Epoch 44/70\n",
      " - 3s - loss: 1.0393 - acc: 0.6769\n",
      "Epoch 45/70\n",
      " - 3s - loss: 1.0389 - acc: 0.6785\n",
      "Epoch 46/70\n",
      " - 3s - loss: 1.0318 - acc: 0.6783\n",
      "Epoch 47/70\n",
      " - 3s - loss: 1.0293 - acc: 0.6788\n",
      "Epoch 48/70\n",
      " - 3s - loss: 1.0314 - acc: 0.6801\n",
      "Epoch 49/70\n",
      " - 3s - loss: 1.0241 - acc: 0.6782\n",
      "Epoch 50/70\n",
      " - 3s - loss: 1.0255 - acc: 0.6797\n",
      "Epoch 51/70\n",
      " - 3s - loss: 1.0244 - acc: 0.6806\n",
      "Epoch 52/70\n",
      " - 4s - loss: 1.0221 - acc: 0.6797\n",
      "Epoch 53/70\n",
      " - 3s - loss: 1.0214 - acc: 0.6812\n",
      "Epoch 54/70\n",
      " - 3s - loss: 1.0206 - acc: 0.6813\n",
      "Epoch 55/70\n",
      " - 3s - loss: 1.0156 - acc: 0.6827\n",
      "Epoch 56/70\n",
      " - 3s - loss: 1.0160 - acc: 0.6813\n",
      "Epoch 57/70\n",
      " - 4s - loss: 1.0113 - acc: 0.6835\n",
      "Epoch 58/70\n",
      " - 4s - loss: 1.0109 - acc: 0.6824\n",
      "Epoch 59/70\n",
      " - 3s - loss: 1.0080 - acc: 0.6842\n",
      "Epoch 60/70\n",
      " - 4s - loss: 1.0053 - acc: 0.6833\n",
      "Epoch 61/70\n",
      " - 6s - loss: 1.0036 - acc: 0.6843\n",
      "Epoch 62/70\n",
      " - 5s - loss: 1.0007 - acc: 0.6839\n",
      "Epoch 63/70\n",
      " - 4s - loss: 0.9975 - acc: 0.6855\n",
      "Epoch 64/70\n",
      " - 4s - loss: 1.0017 - acc: 0.6841\n",
      "Epoch 65/70\n",
      " - 4s - loss: 0.9993 - acc: 0.6837\n",
      "Epoch 66/70\n",
      " - 4s - loss: 0.9968 - acc: 0.6846\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.9981 - acc: 0.6848\n",
      "Epoch 68/70\n",
      " - 4s - loss: 0.9961 - acc: 0.6865\n",
      "Epoch 69/70\n",
      " - 4s - loss: 0.9945 - acc: 0.6849\n",
      "Epoch 70/70\n",
      " - 4s - loss: 0.9956 - acc: 0.6861\n",
      "[CV]  nodes_l3=70, nodes_l2=90, nodes_l1=150, dropout_l3=0.4, dropout_l2=0.2, dropout_l1=0.4, batch_size=2000, total= 4.7min\n",
      "[CV] nodes_l3=70, nodes_l2=90, nodes_l1=150, dropout_l3=0.4, dropout_l2=0.2, dropout_l1=0.4, batch_size=2000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=150)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 11s - loss: 3.1253 - acc: 0.1900\n",
      "Epoch 2/70\n",
      " - 3s - loss: 2.2909 - acc: 0.3810\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.8754 - acc: 0.4942\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.6631 - acc: 0.5491\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.5334 - acc: 0.5800\n",
      "Epoch 6/70\n",
      " - 4s - loss: 1.4512 - acc: 0.5969\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.3891 - acc: 0.6119\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.3477 - acc: 0.6201\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.3102 - acc: 0.6278\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.2796 - acc: 0.6332\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.2517 - acc: 0.6383\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.2269 - acc: 0.6415\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.2131 - acc: 0.6454\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.1992 - acc: 0.6474\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.1835 - acc: 0.6494\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.1740 - acc: 0.6505\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.1641 - acc: 0.6529\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.1474 - acc: 0.6563\n",
      "Epoch 19/70\n",
      " - 3s - loss: 1.1434 - acc: 0.6568\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.1323 - acc: 0.6593\n",
      "Epoch 21/70\n",
      " - 3s - loss: 1.1274 - acc: 0.6610\n",
      "Epoch 22/70\n",
      " - 3s - loss: 1.1196 - acc: 0.6612\n",
      "Epoch 23/70\n",
      " - 3s - loss: 1.1137 - acc: 0.6622\n",
      "Epoch 24/70\n",
      " - 3s - loss: 1.1040 - acc: 0.6618\n",
      "Epoch 25/70\n",
      " - 3s - loss: 1.1002 - acc: 0.6656\n",
      "Epoch 26/70\n",
      " - 3s - loss: 1.0966 - acc: 0.6657\n",
      "Epoch 27/70\n",
      " - 3s - loss: 1.0884 - acc: 0.6694\n",
      "Epoch 28/70\n",
      " - 3s - loss: 1.0829 - acc: 0.6683\n",
      "Epoch 29/70\n",
      " - 4s - loss: 1.0767 - acc: 0.6713\n",
      "Epoch 30/70\n",
      " - 4s - loss: 1.0749 - acc: 0.6720\n",
      "Epoch 31/70\n",
      " - 3s - loss: 1.0669 - acc: 0.6724\n",
      "Epoch 32/70\n",
      " - 3s - loss: 1.0652 - acc: 0.6735\n",
      "Epoch 33/70\n",
      " - 3s - loss: 1.0632 - acc: 0.6737\n",
      "Epoch 34/70\n",
      " - 3s - loss: 1.0548 - acc: 0.6752\n",
      "Epoch 35/70\n",
      " - 5s - loss: 1.0526 - acc: 0.6746\n",
      "Epoch 36/70\n",
      " - 3s - loss: 1.0512 - acc: 0.6768\n",
      "Epoch 37/70\n",
      " - 3s - loss: 1.0460 - acc: 0.6773\n",
      "Epoch 38/70\n",
      " - 3s - loss: 1.0426 - acc: 0.6773\n",
      "Epoch 39/70\n",
      " - 3s - loss: 1.0395 - acc: 0.6767\n",
      "Epoch 40/70\n",
      " - 3s - loss: 1.0374 - acc: 0.6777\n",
      "Epoch 41/70\n",
      " - 3s - loss: 1.0371 - acc: 0.6767\n",
      "Epoch 42/70\n",
      " - 3s - loss: 1.0293 - acc: 0.6803\n",
      "Epoch 43/70\n",
      " - 3s - loss: 1.0280 - acc: 0.6799\n",
      "Epoch 44/70\n",
      " - 3s - loss: 1.0308 - acc: 0.6784\n",
      "Epoch 45/70\n",
      " - 4s - loss: 1.0208 - acc: 0.6816\n",
      "Epoch 46/70\n",
      " - 4s - loss: 1.0200 - acc: 0.6823\n",
      "Epoch 47/70\n",
      " - 3s - loss: 1.0202 - acc: 0.6823\n",
      "Epoch 48/70\n",
      " - 3s - loss: 1.0173 - acc: 0.6824\n",
      "Epoch 49/70\n",
      " - 3s - loss: 1.0141 - acc: 0.6819\n",
      "Epoch 50/70\n",
      " - 3s - loss: 1.0146 - acc: 0.6853\n",
      "Epoch 51/70\n",
      " - 2s - loss: 1.0068 - acc: 0.6861\n",
      "Epoch 52/70\n",
      " - 2s - loss: 1.0071 - acc: 0.6850\n",
      "Epoch 53/70\n",
      " - 3s - loss: 1.0073 - acc: 0.6841\n",
      "Epoch 54/70\n",
      " - 3s - loss: 1.0039 - acc: 0.6862\n",
      "Epoch 55/70\n",
      " - 3s - loss: 1.0032 - acc: 0.6850\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.9990 - acc: 0.6859\n",
      "Epoch 57/70\n",
      " - 2s - loss: 0.9955 - acc: 0.6876\n",
      "Epoch 58/70\n",
      " - 2s - loss: 1.0004 - acc: 0.6836\n",
      "Epoch 59/70\n",
      " - 2s - loss: 0.9983 - acc: 0.6853\n",
      "Epoch 60/70\n",
      " - 2s - loss: 0.9955 - acc: 0.6867\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.9911 - acc: 0.6874\n",
      "Epoch 62/70\n",
      " - 2s - loss: 0.9965 - acc: 0.6875\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.9871 - acc: 0.6881\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.9864 - acc: 0.6880\n",
      "Epoch 65/70\n",
      " - 2s - loss: 0.9878 - acc: 0.6884\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.9856 - acc: 0.6873\n",
      "Epoch 67/70\n",
      " - 2s - loss: 0.9820 - acc: 0.6911\n",
      "Epoch 68/70\n",
      " - 2s - loss: 0.9838 - acc: 0.6889\n",
      "Epoch 69/70\n",
      " - 2s - loss: 0.9802 - acc: 0.6902\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.9790 - acc: 0.6908\n",
      "[CV]  nodes_l3=70, nodes_l2=90, nodes_l1=150, dropout_l3=0.4, dropout_l2=0.2, dropout_l1=0.4, batch_size=2000, total= 3.7min\n",
      "[CV] nodes_l3=70, nodes_l2=90, nodes_l1=150, dropout_l3=0.4, dropout_l2=0.2, dropout_l1=0.4, batch_size=2000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=150)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 6s - loss: 3.1592 - acc: 0.1829\n",
      "Epoch 2/70\n",
      " - 2s - loss: 2.3916 - acc: 0.3482\n",
      "Epoch 3/70\n",
      " - 2s - loss: 1.9539 - acc: 0.4682\n",
      "Epoch 4/70\n",
      " - 2s - loss: 1.7245 - acc: 0.5329\n",
      "Epoch 5/70\n",
      " - 2s - loss: 1.5888 - acc: 0.5657\n",
      "Epoch 6/70\n",
      " - 2s - loss: 1.4946 - acc: 0.5847\n",
      "Epoch 7/70\n",
      " - 2s - loss: 1.4241 - acc: 0.6013\n",
      "Epoch 8/70\n",
      " - 2s - loss: 1.3768 - acc: 0.6094\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.3496 - acc: 0.6169\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.3132 - acc: 0.6234\n",
      "Epoch 11/70\n",
      " - 2s - loss: 1.2816 - acc: 0.6271\n",
      "Epoch 12/70\n",
      " - 2s - loss: 1.2645 - acc: 0.6303\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.2492 - acc: 0.6343\n",
      "Epoch 14/70\n",
      " - 2s - loss: 1.2307 - acc: 0.6386\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.2120 - acc: 0.6430\n",
      "Epoch 16/70\n",
      " - 2s - loss: 1.2001 - acc: 0.6437\n",
      "Epoch 17/70\n",
      " - 2s - loss: 1.1926 - acc: 0.6455\n",
      "Epoch 18/70\n",
      " - 2s - loss: 1.1820 - acc: 0.6477\n",
      "Epoch 19/70\n",
      " - 2s - loss: 1.1726 - acc: 0.6490\n",
      "Epoch 20/70\n",
      " - 2s - loss: 1.1605 - acc: 0.6523\n",
      "Epoch 21/70\n",
      " - 2s - loss: 1.1581 - acc: 0.6512\n",
      "Epoch 22/70\n",
      " - 2s - loss: 1.1550 - acc: 0.6517\n",
      "Epoch 23/70\n",
      " - 2s - loss: 1.1386 - acc: 0.6547\n",
      "Epoch 24/70\n",
      " - 2s - loss: 1.1341 - acc: 0.6577\n",
      "Epoch 25/70\n",
      " - 2s - loss: 1.1312 - acc: 0.6575\n",
      "Epoch 26/70\n",
      " - 2s - loss: 1.1250 - acc: 0.6595\n",
      "Epoch 27/70\n",
      " - 2s - loss: 1.1228 - acc: 0.6590\n",
      "Epoch 28/70\n",
      " - 2s - loss: 1.1109 - acc: 0.6600\n",
      "Epoch 29/70\n",
      " - 2s - loss: 1.1092 - acc: 0.6632\n",
      "Epoch 30/70\n",
      " - 2s - loss: 1.1038 - acc: 0.6618\n",
      "Epoch 31/70\n",
      " - 2s - loss: 1.0965 - acc: 0.6618\n",
      "Epoch 32/70\n",
      " - 2s - loss: 1.0958 - acc: 0.6653\n",
      "Epoch 33/70\n",
      " - 2s - loss: 1.0908 - acc: 0.6646\n",
      "Epoch 34/70\n",
      " - 2s - loss: 1.0885 - acc: 0.6677\n",
      "Epoch 35/70\n",
      " - 2s - loss: 1.0791 - acc: 0.6658\n",
      "Epoch 36/70\n",
      " - 2s - loss: 1.0763 - acc: 0.6689\n",
      "Epoch 37/70\n",
      " - 2s - loss: 1.0751 - acc: 0.6687\n",
      "Epoch 38/70\n",
      " - 2s - loss: 1.0668 - acc: 0.6697\n",
      "Epoch 39/70\n",
      " - 2s - loss: 1.0674 - acc: 0.6709\n",
      "Epoch 40/70\n",
      " - 3s - loss: 1.0665 - acc: 0.6694\n",
      "Epoch 41/70\n",
      " - 3s - loss: 1.0642 - acc: 0.6691\n",
      "Epoch 42/70\n",
      " - 3s - loss: 1.0524 - acc: 0.6733\n",
      "Epoch 43/70\n",
      " - 3s - loss: 1.0591 - acc: 0.6712\n",
      "Epoch 44/70\n",
      " - 3s - loss: 1.0542 - acc: 0.6729\n",
      "Epoch 45/70\n",
      " - 3s - loss: 1.0538 - acc: 0.6728\n",
      "Epoch 46/70\n",
      " - 3s - loss: 1.0477 - acc: 0.6739\n",
      "Epoch 47/70\n",
      " - 3s - loss: 1.0484 - acc: 0.6739\n",
      "Epoch 48/70\n",
      " - 3s - loss: 1.0407 - acc: 0.6734\n",
      "Epoch 49/70\n",
      " - 3s - loss: 1.0394 - acc: 0.6754\n",
      "Epoch 50/70\n",
      " - 3s - loss: 1.0430 - acc: 0.6766\n",
      "Epoch 51/70\n",
      " - 3s - loss: 1.0337 - acc: 0.6769\n",
      "Epoch 52/70\n",
      " - 3s - loss: 1.0329 - acc: 0.6770\n",
      "Epoch 53/70\n",
      " - 3s - loss: 1.0305 - acc: 0.6768\n",
      "Epoch 54/70\n",
      " - 4s - loss: 1.0332 - acc: 0.6772\n",
      "Epoch 55/70\n",
      " - 3s - loss: 1.0288 - acc: 0.6776\n",
      "Epoch 56/70\n",
      " - 3s - loss: 1.0249 - acc: 0.6785\n",
      "Epoch 57/70\n",
      " - 3s - loss: 1.0219 - acc: 0.6788\n",
      "Epoch 58/70\n",
      " - 3s - loss: 1.0212 - acc: 0.6794\n",
      "Epoch 59/70\n",
      " - 3s - loss: 1.0182 - acc: 0.6810\n",
      "Epoch 60/70\n",
      " - 3s - loss: 1.0189 - acc: 0.6811\n",
      "Epoch 61/70\n",
      " - 3s - loss: 1.0162 - acc: 0.6799\n",
      "Epoch 62/70\n",
      " - 3s - loss: 1.0171 - acc: 0.6793\n",
      "Epoch 63/70\n",
      " - 3s - loss: 1.0130 - acc: 0.6821\n",
      "Epoch 64/70\n",
      " - 4s - loss: 1.0124 - acc: 0.6816\n",
      "Epoch 65/70\n",
      " - 3s - loss: 1.0085 - acc: 0.6813\n",
      "Epoch 66/70\n",
      " - 3s - loss: 1.0099 - acc: 0.6819\n",
      "Epoch 67/70\n",
      " - 3s - loss: 1.0062 - acc: 0.6823\n",
      "Epoch 68/70\n",
      " - 3s - loss: 1.0110 - acc: 0.6822\n",
      "Epoch 69/70\n",
      " - 3s - loss: 1.0052 - acc: 0.6829\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.9996 - acc: 0.6832\n",
      "[CV]  nodes_l3=70, nodes_l2=90, nodes_l1=150, dropout_l3=0.4, dropout_l2=0.2, dropout_l1=0.4, batch_size=2000, total= 3.2min\n",
      "[CV] nodes_l3=80, nodes_l2=140, nodes_l1=150, dropout_l3=0.1, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=150)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=140)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=140)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 11s - loss: 2.5051 - acc: 0.3431\n",
      "Epoch 2/70\n",
      " - 5s - loss: 1.6279 - acc: 0.5518\n",
      "Epoch 3/70\n",
      " - 6s - loss: 1.3936 - acc: 0.6034\n",
      "Epoch 4/70\n",
      " - 5s - loss: 1.2805 - acc: 0.6275\n",
      "Epoch 5/70\n",
      " - 5s - loss: 1.2190 - acc: 0.6389\n",
      "Epoch 6/70\n",
      " - 4s - loss: 1.1843 - acc: 0.6449\n",
      "Epoch 7/70\n",
      " - 5s - loss: 1.1563 - acc: 0.6483\n",
      "Epoch 8/70\n",
      " - 6s - loss: 1.1308 - acc: 0.6542\n",
      "Epoch 9/70\n",
      " - 5s - loss: 1.1087 - acc: 0.6593\n",
      "Epoch 10/70\n",
      " - 5s - loss: 1.0915 - acc: 0.6610\n",
      "Epoch 11/70\n",
      " - 5s - loss: 1.0806 - acc: 0.6618\n",
      "Epoch 12/70\n",
      " - 5s - loss: 1.0661 - acc: 0.6634\n",
      "Epoch 13/70\n",
      " - 5s - loss: 1.0577 - acc: 0.6672\n",
      "Epoch 14/70\n",
      " - 5s - loss: 1.0467 - acc: 0.6697\n",
      "Epoch 15/70\n",
      " - 4s - loss: 1.0364 - acc: 0.6710\n",
      "Epoch 16/70\n",
      " - 5s - loss: 1.0283 - acc: 0.6736\n",
      "Epoch 17/70\n",
      " - 5s - loss: 1.0228 - acc: 0.6733\n",
      "Epoch 18/70\n",
      " - 5s - loss: 1.0130 - acc: 0.6761\n",
      "Epoch 19/70\n",
      " - 5s - loss: 1.0070 - acc: 0.6771\n",
      "Epoch 20/70\n",
      " - 5s - loss: 1.0036 - acc: 0.6777\n",
      "Epoch 21/70\n",
      " - 5s - loss: 0.9933 - acc: 0.6799\n",
      "Epoch 22/70\n",
      " - 4s - loss: 0.9909 - acc: 0.6808\n",
      "Epoch 23/70\n",
      " - 4s - loss: 0.9846 - acc: 0.6807\n",
      "Epoch 24/70\n",
      " - 5s - loss: 0.9812 - acc: 0.6818\n",
      "Epoch 25/70\n",
      " - 5s - loss: 0.9806 - acc: 0.6813\n",
      "Epoch 26/70\n",
      " - 5s - loss: 0.9737 - acc: 0.6827\n",
      "Epoch 27/70\n",
      " - 5s - loss: 0.9648 - acc: 0.6863\n",
      "Epoch 28/70\n",
      " - 5s - loss: 0.9637 - acc: 0.6850\n",
      "Epoch 29/70\n",
      " - 5s - loss: 0.9593 - acc: 0.6872\n",
      "Epoch 30/70\n",
      " - 5s - loss: 0.9593 - acc: 0.6869\n",
      "Epoch 31/70\n",
      " - 5s - loss: 0.9558 - acc: 0.6873\n",
      "Epoch 32/70\n",
      " - 5s - loss: 0.9508 - acc: 0.6885\n",
      "Epoch 33/70\n",
      " - 6s - loss: 0.9510 - acc: 0.6879\n",
      "Epoch 34/70\n",
      " - 5s - loss: 0.9462 - acc: 0.6903\n",
      "Epoch 35/70\n",
      " - 5s - loss: 0.9467 - acc: 0.6914\n",
      "Epoch 36/70\n",
      " - 5s - loss: 0.9420 - acc: 0.6897\n",
      "Epoch 37/70\n",
      " - 5s - loss: 0.9368 - acc: 0.6921\n",
      "Epoch 38/70\n",
      " - 5s - loss: 0.9364 - acc: 0.6913\n",
      "Epoch 39/70\n",
      " - 4s - loss: 0.9379 - acc: 0.6922\n",
      "Epoch 40/70\n",
      " - 5s - loss: 0.9307 - acc: 0.6929\n",
      "Epoch 41/70\n",
      " - 5s - loss: 0.9305 - acc: 0.6920\n",
      "Epoch 42/70\n",
      " - 4s - loss: 0.9267 - acc: 0.6931\n",
      "Epoch 43/70\n",
      " - 4s - loss: 0.9251 - acc: 0.6943\n",
      "Epoch 44/70\n",
      " - 5s - loss: 0.9249 - acc: 0.6940\n",
      "Epoch 45/70\n",
      " - 5s - loss: 0.9228 - acc: 0.6944\n",
      "Epoch 46/70\n",
      " - 5s - loss: 0.9234 - acc: 0.6930\n",
      "Epoch 47/70\n",
      " - 5s - loss: 0.9216 - acc: 0.6952\n",
      "Epoch 48/70\n",
      " - 5s - loss: 0.9184 - acc: 0.6961\n",
      "Epoch 49/70\n",
      " - 4s - loss: 0.9166 - acc: 0.6947\n",
      "Epoch 50/70\n",
      " - 4s - loss: 0.9178 - acc: 0.6947\n",
      "Epoch 51/70\n",
      " - 5s - loss: 0.9131 - acc: 0.6970\n",
      "Epoch 52/70\n",
      " - 5s - loss: 0.9117 - acc: 0.6971\n",
      "Epoch 53/70\n",
      " - 4s - loss: 0.9105 - acc: 0.6977\n",
      "Epoch 54/70\n",
      " - 5s - loss: 0.9100 - acc: 0.6967\n",
      "Epoch 55/70\n",
      " - 5s - loss: 0.9074 - acc: 0.6996\n",
      "Epoch 56/70\n",
      " - 4s - loss: 0.9062 - acc: 0.6988\n",
      "Epoch 57/70\n",
      " - 4s - loss: 0.9071 - acc: 0.6980\n",
      "Epoch 58/70\n",
      " - 5s - loss: 0.9023 - acc: 0.6975\n",
      "Epoch 59/70\n",
      " - 5s - loss: 0.9041 - acc: 0.7005\n",
      "Epoch 60/70\n",
      " - 4s - loss: 0.9012 - acc: 0.6992\n",
      "Epoch 61/70\n",
      " - 4s - loss: 0.8982 - acc: 0.7005\n",
      "Epoch 62/70\n",
      " - 5s - loss: 0.9013 - acc: 0.6982\n",
      "Epoch 63/70\n",
      " - 4s - loss: 0.8987 - acc: 0.6996\n",
      "Epoch 64/70\n",
      " - 4s - loss: 0.8979 - acc: 0.7000\n",
      "Epoch 65/70\n",
      " - 5s - loss: 0.8963 - acc: 0.7017\n",
      "Epoch 66/70\n",
      " - 5s - loss: 0.8925 - acc: 0.7010\n",
      "Epoch 67/70\n",
      " - 4s - loss: 0.8957 - acc: 0.7006\n",
      "Epoch 68/70\n",
      " - 5s - loss: 0.8968 - acc: 0.6992\n",
      "Epoch 69/70\n",
      " - 5s - loss: 0.8911 - acc: 0.7014\n",
      "Epoch 70/70\n",
      " - 5s - loss: 0.8929 - acc: 0.7020\n",
      "[CV]  nodes_l3=80, nodes_l2=140, nodes_l1=150, dropout_l3=0.1, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=1000, total= 5.7min\n",
      "[CV] nodes_l3=80, nodes_l2=140, nodes_l1=150, dropout_l3=0.1, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=150)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=140)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=140)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 8s - loss: 2.5384 - acc: 0.3255\n",
      "Epoch 2/70\n",
      " - 3s - loss: 1.6513 - acc: 0.5407\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.4076 - acc: 0.5976\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.2935 - acc: 0.6218\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.2243 - acc: 0.6341\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.1852 - acc: 0.6415\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.1555 - acc: 0.6473\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.1318 - acc: 0.6521\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.1125 - acc: 0.6556\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.0979 - acc: 0.6581\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.0800 - acc: 0.6628\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.0683 - acc: 0.6641\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.0561 - acc: 0.6654\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.0470 - acc: 0.6670\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.0411 - acc: 0.6686\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.0271 - acc: 0.6709\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.0240 - acc: 0.6711\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.0147 - acc: 0.6740\n",
      "Epoch 19/70\n",
      " - 3s - loss: 1.0068 - acc: 0.6751\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.0007 - acc: 0.6759\n",
      "Epoch 21/70\n",
      " - 3s - loss: 0.9988 - acc: 0.6769\n",
      "Epoch 22/70\n",
      " - 3s - loss: 0.9923 - acc: 0.6794\n",
      "Epoch 23/70\n",
      " - 3s - loss: 0.9837 - acc: 0.6804\n",
      "Epoch 24/70\n",
      " - 4s - loss: 0.9743 - acc: 0.6814\n",
      "Epoch 25/70\n",
      " - 3s - loss: 0.9790 - acc: 0.6814\n",
      "Epoch 26/70\n",
      " - 3s - loss: 0.9686 - acc: 0.6855\n",
      "Epoch 27/70\n",
      " - 3s - loss: 0.9708 - acc: 0.6831\n",
      "Epoch 28/70\n",
      " - 3s - loss: 0.9640 - acc: 0.6835\n",
      "Epoch 29/70\n",
      " - 3s - loss: 0.9605 - acc: 0.6846\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.9583 - acc: 0.6858\n",
      "Epoch 31/70\n",
      " - 3s - loss: 0.9574 - acc: 0.6848\n",
      "Epoch 32/70\n",
      " - 3s - loss: 0.9547 - acc: 0.6870\n",
      "Epoch 33/70\n",
      " - 3s - loss: 0.9505 - acc: 0.6895\n",
      "Epoch 34/70\n",
      " - 3s - loss: 0.9471 - acc: 0.6886\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9478 - acc: 0.6890\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9410 - acc: 0.6897\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9395 - acc: 0.6897\n",
      "Epoch 38/70\n",
      " - 3s - loss: 0.9332 - acc: 0.6913\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.9369 - acc: 0.6900\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.9317 - acc: 0.6912\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.9307 - acc: 0.6922\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.9301 - acc: 0.6925\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.9258 - acc: 0.6937\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.9267 - acc: 0.6932\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.9211 - acc: 0.6929\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.9203 - acc: 0.6945\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.9217 - acc: 0.6939\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.9155 - acc: 0.6950\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.9187 - acc: 0.6947\n",
      "Epoch 50/70\n",
      " - 3s - loss: 0.9136 - acc: 0.6959\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.9137 - acc: 0.6979\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.9107 - acc: 0.6959\n",
      "Epoch 53/70\n",
      " - 3s - loss: 0.9095 - acc: 0.6966\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.9084 - acc: 0.6962\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.9081 - acc: 0.6964\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.9099 - acc: 0.6966\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.9060 - acc: 0.6969\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.9058 - acc: 0.6965\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.9086 - acc: 0.6964\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.9035 - acc: 0.6979\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.9026 - acc: 0.6986\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.8999 - acc: 0.6995\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.8988 - acc: 0.6989\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.8975 - acc: 0.6992\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.8974 - acc: 0.6995\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.8957 - acc: 0.6997\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.8979 - acc: 0.7009\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.8962 - acc: 0.6996\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.8949 - acc: 0.7005\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.8951 - acc: 0.7007\n",
      "[CV]  nodes_l3=80, nodes_l2=140, nodes_l1=150, dropout_l3=0.1, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=1000, total= 3.9min\n",
      "[CV] nodes_l3=80, nodes_l2=140, nodes_l1=150, dropout_l3=0.1, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=150)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=140)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=140)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 8s - loss: 2.5347 - acc: 0.3308\n",
      "Epoch 2/70\n",
      " - 4s - loss: 1.6104 - acc: 0.5563\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.3785 - acc: 0.6068\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.2718 - acc: 0.6275\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.2137 - acc: 0.6398\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.1723 - acc: 0.6466\n",
      "Epoch 7/70\n",
      " - 4s - loss: 1.1400 - acc: 0.6514\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.1211 - acc: 0.6550\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.1012 - acc: 0.6592\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.0821 - acc: 0.6632\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.0674 - acc: 0.6641\n",
      "Epoch 12/70\n",
      " - 4s - loss: 1.0531 - acc: 0.6685\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.0471 - acc: 0.6689\n",
      "Epoch 14/70\n",
      " - 4s - loss: 1.0381 - acc: 0.6705\n",
      "Epoch 15/70\n",
      " - 4s - loss: 1.0207 - acc: 0.6732\n",
      "Epoch 16/70\n",
      " - 4s - loss: 1.0144 - acc: 0.6758\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.0053 - acc: 0.6776\n",
      "Epoch 18/70\n",
      " - 3s - loss: 0.9972 - acc: 0.6795\n",
      "Epoch 19/70\n",
      " - 3s - loss: 0.9935 - acc: 0.6802\n",
      "Epoch 20/70\n",
      " - 3s - loss: 0.9900 - acc: 0.6800\n",
      "Epoch 21/70\n",
      " - 3s - loss: 0.9798 - acc: 0.6824\n",
      "Epoch 22/70\n",
      " - 3s - loss: 0.9735 - acc: 0.6818\n",
      "Epoch 23/70\n",
      " - 3s - loss: 0.9717 - acc: 0.6840\n",
      "Epoch 24/70\n",
      " - 3s - loss: 0.9690 - acc: 0.6841\n",
      "Epoch 25/70\n",
      " - 3s - loss: 0.9622 - acc: 0.6872\n",
      "Epoch 26/70\n",
      " - 3s - loss: 0.9552 - acc: 0.6889\n",
      "Epoch 27/70\n",
      " - 3s - loss: 0.9519 - acc: 0.6887\n",
      "Epoch 28/70\n",
      " - 3s - loss: 0.9462 - acc: 0.6889\n",
      "Epoch 29/70\n",
      " - 3s - loss: 0.9455 - acc: 0.6878\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.9405 - acc: 0.6896\n",
      "Epoch 31/70\n",
      " - 3s - loss: 0.9373 - acc: 0.6916\n",
      "Epoch 32/70\n",
      " - 3s - loss: 0.9356 - acc: 0.6904\n",
      "Epoch 33/70\n",
      " - 3s - loss: 0.9337 - acc: 0.6923\n",
      "Epoch 34/70\n",
      " - 3s - loss: 0.9333 - acc: 0.6921\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9279 - acc: 0.6919\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9255 - acc: 0.6933\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9226 - acc: 0.6925\n",
      "Epoch 38/70\n",
      " - 3s - loss: 0.9208 - acc: 0.6932\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.9205 - acc: 0.6945\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.9168 - acc: 0.6943\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.9162 - acc: 0.6953\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.9094 - acc: 0.6982\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.9114 - acc: 0.6982\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.9078 - acc: 0.6983\n",
      "Epoch 45/70\n",
      " - 4s - loss: 0.9074 - acc: 0.6972\n",
      "Epoch 46/70\n",
      " - 4s - loss: 0.9052 - acc: 0.6964\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.9023 - acc: 0.6999\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.9011 - acc: 0.6986\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.8965 - acc: 0.6989\n",
      "Epoch 50/70\n",
      " - 4s - loss: 0.8954 - acc: 0.7002\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.8990 - acc: 0.6995\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.8969 - acc: 0.7007\n",
      "Epoch 53/70\n",
      " - 3s - loss: 0.8960 - acc: 0.6993\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.8934 - acc: 0.6998\n",
      "Epoch 55/70\n",
      " - 4s - loss: 0.8905 - acc: 0.7021\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.8878 - acc: 0.7022\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.8880 - acc: 0.7017\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.8878 - acc: 0.7017\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.8879 - acc: 0.7007\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.8896 - acc: 0.7013\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.8860 - acc: 0.7015\n",
      "Epoch 62/70\n",
      " - 4s - loss: 0.8834 - acc: 0.7031\n",
      "Epoch 63/70\n",
      " - 4s - loss: 0.8841 - acc: 0.7023\n",
      "Epoch 64/70\n",
      " - 5s - loss: 0.8813 - acc: 0.7026\n",
      "Epoch 65/70\n",
      " - 5s - loss: 0.8795 - acc: 0.7044\n",
      "Epoch 66/70\n",
      " - 5s - loss: 0.8804 - acc: 0.7018\n",
      "Epoch 67/70\n",
      " - 5s - loss: 0.8771 - acc: 0.7029\n",
      "Epoch 68/70\n",
      " - 5s - loss: 0.8777 - acc: 0.7050\n",
      "Epoch 69/70\n",
      " - 4s - loss: 0.8754 - acc: 0.7039\n",
      "Epoch 70/70\n",
      " - 4s - loss: 0.8766 - acc: 0.7054\n",
      "[CV]  nodes_l3=80, nodes_l2=140, nodes_l1=150, dropout_l3=0.1, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=1000, total= 4.2min\n",
      "[CV] nodes_l3=80, nodes_l2=140, nodes_l1=150, dropout_l3=0.1, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=150)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=140)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=140)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 10s - loss: 2.5307 - acc: 0.3317\n",
      "Epoch 2/70\n",
      " - 5s - loss: 1.6287 - acc: 0.5505\n",
      "Epoch 3/70\n",
      " - 5s - loss: 1.4029 - acc: 0.6007\n",
      "Epoch 4/70\n",
      " - 4s - loss: 1.2892 - acc: 0.6231\n",
      "Epoch 5/70\n",
      " - 5s - loss: 1.2317 - acc: 0.6341\n",
      "Epoch 6/70\n",
      " - 5s - loss: 1.1869 - acc: 0.6414\n",
      "Epoch 7/70\n",
      " - 4s - loss: 1.1607 - acc: 0.6445\n",
      "Epoch 8/70\n",
      " - 4s - loss: 1.1361 - acc: 0.6510\n",
      "Epoch 9/70\n",
      " - 5s - loss: 1.1184 - acc: 0.6523\n",
      "Epoch 10/70\n",
      " - 5s - loss: 1.0973 - acc: 0.6569\n",
      "Epoch 11/70\n",
      " - 4s - loss: 1.0919 - acc: 0.6578\n",
      "Epoch 12/70\n",
      " - 5s - loss: 1.0741 - acc: 0.6625\n",
      "Epoch 13/70\n",
      " - 5s - loss: 1.0681 - acc: 0.6620\n",
      "Epoch 14/70\n",
      " - 4s - loss: 1.0549 - acc: 0.6654\n",
      "Epoch 15/70\n",
      " - 5s - loss: 1.0435 - acc: 0.6674\n",
      "Epoch 16/70\n",
      " - 5s - loss: 1.0422 - acc: 0.6665\n",
      "Epoch 17/70\n",
      " - 5s - loss: 1.0332 - acc: 0.6698\n",
      "Epoch 18/70\n",
      " - 5s - loss: 1.0231 - acc: 0.6706\n",
      "Epoch 19/70\n",
      " - 6s - loss: 1.0195 - acc: 0.6722\n",
      "Epoch 20/70\n",
      " - 5s - loss: 1.0105 - acc: 0.6742\n",
      "Epoch 21/70\n",
      " - 5s - loss: 1.0060 - acc: 0.6749\n",
      "Epoch 22/70\n",
      " - 6s - loss: 1.0040 - acc: 0.6751\n",
      "Epoch 23/70\n",
      " - 5s - loss: 0.9962 - acc: 0.6760\n",
      "Epoch 24/70\n",
      " - 5s - loss: 0.9926 - acc: 0.6772\n",
      "Epoch 25/70\n",
      " - 5s - loss: 0.9904 - acc: 0.6786\n",
      "Epoch 26/70\n",
      " - 4s - loss: 0.9814 - acc: 0.6790\n",
      "Epoch 27/70\n",
      " - 5s - loss: 0.9780 - acc: 0.6803\n",
      "Epoch 28/70\n",
      " - 6s - loss: 0.9756 - acc: 0.6813\n",
      "Epoch 29/70\n",
      " - 5s - loss: 0.9705 - acc: 0.6826\n",
      "Epoch 30/70\n",
      " - 4s - loss: 0.9705 - acc: 0.6815\n",
      "Epoch 31/70\n",
      " - 5s - loss: 0.9656 - acc: 0.6841\n",
      "Epoch 32/70\n",
      " - 5s - loss: 0.9642 - acc: 0.6845\n",
      "Epoch 33/70\n",
      " - 4s - loss: 0.9568 - acc: 0.6865\n",
      "Epoch 34/70\n",
      " - 5s - loss: 0.9540 - acc: 0.6856\n",
      "Epoch 35/70\n",
      " - 5s - loss: 0.9549 - acc: 0.6847\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9498 - acc: 0.6861\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9472 - acc: 0.6876\n",
      "Epoch 38/70\n",
      " - 3s - loss: 0.9469 - acc: 0.6861\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.9444 - acc: 0.6880\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.9408 - acc: 0.6889\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.9384 - acc: 0.6887\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.9354 - acc: 0.6896\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.9344 - acc: 0.6896\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.9341 - acc: 0.6901\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.9318 - acc: 0.6913\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.9324 - acc: 0.6899\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.9299 - acc: 0.6912\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.9257 - acc: 0.6917\n",
      "Epoch 49/70\n",
      " - 4s - loss: 0.9236 - acc: 0.6932\n",
      "Epoch 50/70\n",
      " - 4s - loss: 0.9242 - acc: 0.6922\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.9214 - acc: 0.6908\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.9219 - acc: 0.6939\n",
      "Epoch 53/70\n",
      " - 3s - loss: 0.9211 - acc: 0.6944\n",
      "Epoch 54/70\n",
      " - 4s - loss: 0.9191 - acc: 0.6932\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.9177 - acc: 0.6933\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.9130 - acc: 0.6944\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.9122 - acc: 0.6942\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.9139 - acc: 0.6957\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.9107 - acc: 0.6945\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.9088 - acc: 0.6952\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.9097 - acc: 0.6956\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.9059 - acc: 0.6963\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.9077 - acc: 0.6978\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.9069 - acc: 0.6951\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.9028 - acc: 0.6971\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.9021 - acc: 0.6984\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.9039 - acc: 0.6949\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.9033 - acc: 0.6976\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.9021 - acc: 0.6965\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.8962 - acc: 0.6993\n",
      "[CV]  nodes_l3=80, nodes_l2=140, nodes_l1=150, dropout_l3=0.1, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=1000, total= 4.9min\n",
      "[CV] nodes_l3=50, nodes_l2=120, nodes_l1=170, dropout_l3=0.2, dropout_l2=0.30000000000000004, dropout_l1=0.30000000000000004, batch_size=3000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=170)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 7s - loss: 3.0169 - acc: 0.2203\n",
      "Epoch 2/70\n",
      " - 2s - loss: 2.1891 - acc: 0.4144\n",
      "Epoch 3/70\n",
      " - 2s - loss: 1.7820 - acc: 0.5191\n",
      "Epoch 4/70\n",
      " - 2s - loss: 1.5801 - acc: 0.5638\n",
      "Epoch 5/70\n",
      " - 2s - loss: 1.4633 - acc: 0.5931\n",
      "Epoch 6/70\n",
      " - 2s - loss: 1.3836 - acc: 0.6104\n",
      "Epoch 7/70\n",
      " - 2s - loss: 1.3224 - acc: 0.6224\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.2804 - acc: 0.6286\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.2490 - acc: 0.6351\n",
      "Epoch 10/70\n",
      " - 2s - loss: 1.2156 - acc: 0.6396\n",
      "Epoch 11/70\n",
      " - 2s - loss: 1.1955 - acc: 0.6442\n",
      "Epoch 12/70\n",
      " - 2s - loss: 1.1820 - acc: 0.6460\n",
      "Epoch 13/70\n",
      " - 2s - loss: 1.1628 - acc: 0.6501\n",
      "Epoch 14/70\n",
      " - 2s - loss: 1.1425 - acc: 0.6528\n",
      "Epoch 15/70\n",
      " - 2s - loss: 1.1341 - acc: 0.6540\n",
      "Epoch 16/70\n",
      " - 2s - loss: 1.1224 - acc: 0.6539\n",
      "Epoch 17/70\n",
      " - 2s - loss: 1.1101 - acc: 0.6578\n",
      "Epoch 18/70\n",
      " - 2s - loss: 1.1036 - acc: 0.6600\n",
      "Epoch 19/70\n",
      " - 2s - loss: 1.0929 - acc: 0.6604\n",
      "Epoch 20/70\n",
      " - 2s - loss: 1.0847 - acc: 0.6625\n",
      "Epoch 21/70\n",
      " - 2s - loss: 1.0717 - acc: 0.6669\n",
      "Epoch 22/70\n",
      " - 3s - loss: 1.0675 - acc: 0.6668\n",
      "Epoch 23/70\n",
      " - 2s - loss: 1.0632 - acc: 0.6668\n",
      "Epoch 24/70\n",
      " - 2s - loss: 1.0520 - acc: 0.6698\n",
      "Epoch 25/70\n",
      " - 2s - loss: 1.0462 - acc: 0.6703\n",
      "Epoch 26/70\n",
      " - 2s - loss: 1.0403 - acc: 0.6708\n",
      "Epoch 27/70\n",
      " - 2s - loss: 1.0372 - acc: 0.6724\n",
      "Epoch 28/70\n",
      " - 2s - loss: 1.0290 - acc: 0.6745\n",
      "Epoch 29/70\n",
      " - 2s - loss: 1.0232 - acc: 0.6755\n",
      "Epoch 30/70\n",
      " - 2s - loss: 1.0179 - acc: 0.6765\n",
      "Epoch 31/70\n",
      " - 2s - loss: 1.0146 - acc: 0.6744\n",
      "Epoch 32/70\n",
      " - 2s - loss: 1.0088 - acc: 0.6787\n",
      "Epoch 33/70\n",
      " - 2s - loss: 1.0023 - acc: 0.6792\n",
      "Epoch 34/70\n",
      " - 2s - loss: 1.0033 - acc: 0.6777\n",
      "Epoch 35/70\n",
      " - 2s - loss: 0.9990 - acc: 0.6780\n",
      "Epoch 36/70\n",
      " - 2s - loss: 0.9959 - acc: 0.6803\n",
      "Epoch 37/70\n",
      " - 2s - loss: 0.9913 - acc: 0.6827\n",
      "Epoch 38/70\n",
      " - 2s - loss: 0.9858 - acc: 0.6821\n",
      "Epoch 39/70\n",
      " - 2s - loss: 0.9834 - acc: 0.6840\n",
      "Epoch 40/70\n",
      " - 2s - loss: 0.9808 - acc: 0.6836\n",
      "Epoch 41/70\n",
      " - 2s - loss: 0.9758 - acc: 0.6838\n",
      "Epoch 42/70\n",
      " - 2s - loss: 0.9764 - acc: 0.6847\n",
      "Epoch 43/70\n",
      " - 2s - loss: 0.9690 - acc: 0.6858\n",
      "Epoch 44/70\n",
      " - 2s - loss: 0.9660 - acc: 0.6876\n",
      "Epoch 45/70\n",
      " - 2s - loss: 0.9638 - acc: 0.6873\n",
      "Epoch 46/70\n",
      " - 2s - loss: 0.9613 - acc: 0.6884\n",
      "Epoch 47/70\n",
      " - 2s - loss: 0.9564 - acc: 0.6872\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.9576 - acc: 0.6894\n",
      "Epoch 49/70\n",
      " - 4s - loss: 0.9503 - acc: 0.6901\n",
      "Epoch 50/70\n",
      " - 4s - loss: 0.9530 - acc: 0.6883\n",
      "Epoch 51/70\n",
      " - 4s - loss: 0.9499 - acc: 0.6910\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.9474 - acc: 0.6922\n",
      "Epoch 53/70\n",
      " - 3s - loss: 0.9460 - acc: 0.6919\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.9444 - acc: 0.6915\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.9408 - acc: 0.6917\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.9415 - acc: 0.6908\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.9386 - acc: 0.6933\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.9413 - acc: 0.6916\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.9367 - acc: 0.6930\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.9302 - acc: 0.6940\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.9312 - acc: 0.6929\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.9297 - acc: 0.6937\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.9296 - acc: 0.6953\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.9280 - acc: 0.6937\n",
      "Epoch 65/70\n",
      " - 4s - loss: 0.9263 - acc: 0.6950\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.9241 - acc: 0.6949\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.9221 - acc: 0.6965\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.9256 - acc: 0.6946\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.9217 - acc: 0.6954\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.9178 - acc: 0.6954\n",
      "[CV]  nodes_l3=50, nodes_l2=120, nodes_l1=170, dropout_l3=0.2, dropout_l2=0.30000000000000004, dropout_l1=0.30000000000000004, batch_size=3000, total= 3.2min\n",
      "[CV] nodes_l3=50, nodes_l2=120, nodes_l1=170, dropout_l3=0.2, dropout_l2=0.30000000000000004, dropout_l1=0.30000000000000004, batch_size=3000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=170)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 10s - loss: 3.0966 - acc: 0.2089\n",
      "Epoch 2/70\n",
      " - 3s - loss: 2.2566 - acc: 0.3987\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.8200 - acc: 0.5137\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.5920 - acc: 0.5633\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.4598 - acc: 0.5918\n",
      "Epoch 6/70\n",
      " - 4s - loss: 1.3812 - acc: 0.6089\n",
      "Epoch 7/70\n",
      " - 4s - loss: 1.3142 - acc: 0.6189\n",
      "Epoch 8/70\n",
      " - 4s - loss: 1.2721 - acc: 0.6295\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.2404 - acc: 0.6325\n",
      "Epoch 10/70\n",
      " - 4s - loss: 1.2131 - acc: 0.6407\n",
      "Epoch 11/70\n",
      " - 4s - loss: 1.1944 - acc: 0.6430\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.1732 - acc: 0.6463\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.1544 - acc: 0.6497\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.1495 - acc: 0.6502\n",
      "Epoch 15/70\n",
      " - 4s - loss: 1.1326 - acc: 0.6532\n",
      "Epoch 16/70\n",
      " - 4s - loss: 1.1181 - acc: 0.6569\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.1116 - acc: 0.6574\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.0995 - acc: 0.6597\n",
      "Epoch 19/70\n",
      " - 5s - loss: 1.0892 - acc: 0.6614\n",
      "Epoch 20/70\n",
      " - 5s - loss: 1.0795 - acc: 0.6640\n",
      "Epoch 21/70\n",
      " - 4s - loss: 1.0733 - acc: 0.6649\n",
      "Epoch 22/70\n",
      " - 3s - loss: 1.0679 - acc: 0.6666\n",
      "Epoch 23/70\n",
      " - 4s - loss: 1.0579 - acc: 0.6690\n",
      "Epoch 24/70\n",
      " - 4s - loss: 1.0528 - acc: 0.6698\n",
      "Epoch 25/70\n",
      " - 1397s - loss: 1.0456 - acc: 0.6697\n",
      "Epoch 26/70\n",
      " - 3s - loss: 1.0393 - acc: 0.6715\n",
      "Epoch 27/70\n",
      " - 3s - loss: 1.0383 - acc: 0.6715\n",
      "Epoch 28/70\n",
      " - 3s - loss: 1.0319 - acc: 0.6744\n",
      "Epoch 29/70\n",
      " - 2s - loss: 1.0252 - acc: 0.6753\n",
      "Epoch 30/70\n",
      " - 3s - loss: 1.0192 - acc: 0.6758\n",
      "Epoch 31/70\n",
      " - 3s - loss: 1.0127 - acc: 0.6798\n",
      "Epoch 32/70\n",
      " - 3s - loss: 1.0109 - acc: 0.6781\n",
      "Epoch 33/70\n",
      " - 3s - loss: 1.0087 - acc: 0.6784\n",
      "Epoch 34/70\n",
      " - 3s - loss: 1.0009 - acc: 0.6814\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9995 - acc: 0.6797\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9929 - acc: 0.6812\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9897 - acc: 0.6817\n",
      "Epoch 38/70\n",
      " - 3s - loss: 0.9863 - acc: 0.6835\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.9832 - acc: 0.6831\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.9819 - acc: 0.6855\n",
      "Epoch 41/70\n",
      " - 2s - loss: 0.9787 - acc: 0.6832\n",
      "Epoch 42/70\n",
      " - 2s - loss: 0.9739 - acc: 0.6843\n",
      "Epoch 43/70\n",
      " - 2s - loss: 0.9729 - acc: 0.6833\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.9654 - acc: 0.6871\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.9650 - acc: 0.6858\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.9613 - acc: 0.6887\n",
      "Epoch 47/70\n",
      " - 2s - loss: 0.9580 - acc: 0.6881\n",
      "Epoch 48/70\n",
      " - 2s - loss: 0.9578 - acc: 0.6891\n",
      "Epoch 49/70\n",
      " - 2s - loss: 0.9552 - acc: 0.6881\n",
      "Epoch 50/70\n",
      " - 2s - loss: 0.9507 - acc: 0.6899\n",
      "Epoch 51/70\n",
      " - 2s - loss: 0.9504 - acc: 0.6901\n",
      "Epoch 52/70\n",
      " - 2s - loss: 0.9480 - acc: 0.6925\n",
      "Epoch 53/70\n",
      " - 2s - loss: 0.9470 - acc: 0.6905\n",
      "Epoch 54/70\n",
      " - 2s - loss: 0.9405 - acc: 0.6919\n",
      "Epoch 55/70\n",
      " - 2s - loss: 0.9398 - acc: 0.6917\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.9390 - acc: 0.6936\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.9379 - acc: 0.6922\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.9349 - acc: 0.6948\n",
      "Epoch 59/70\n",
      " - 2s - loss: 0.9378 - acc: 0.6926\n",
      "Epoch 60/70\n",
      " - 2s - loss: 0.9336 - acc: 0.6925\n",
      "Epoch 61/70\n",
      " - 2s - loss: 0.9322 - acc: 0.6939\n",
      "Epoch 62/70\n",
      " - 2s - loss: 0.9305 - acc: 0.6934\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.9297 - acc: 0.6936\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.9295 - acc: 0.6929\n",
      "Epoch 65/70\n",
      " - 2s - loss: 0.9239 - acc: 0.6972\n",
      "Epoch 66/70\n",
      " - 2s - loss: 0.9215 - acc: 0.6951\n",
      "Epoch 67/70\n",
      " - 2s - loss: 0.9252 - acc: 0.6955\n",
      "Epoch 68/70\n",
      " - 2s - loss: 0.9210 - acc: 0.6953\n",
      "Epoch 69/70\n",
      " - 2s - loss: 0.9195 - acc: 0.6959\n",
      "Epoch 70/70\n",
      " - 2s - loss: 0.9205 - acc: 0.6962\n",
      "[CV]  nodes_l3=50, nodes_l2=120, nodes_l1=170, dropout_l3=0.2, dropout_l2=0.30000000000000004, dropout_l1=0.30000000000000004, batch_size=3000, total=26.8min\n",
      "[CV] nodes_l3=50, nodes_l2=120, nodes_l1=170, dropout_l3=0.2, dropout_l2=0.30000000000000004, dropout_l1=0.30000000000000004, batch_size=3000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=170)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 7s - loss: 3.0732 - acc: 0.2056\n",
      "Epoch 2/70\n",
      " - 2s - loss: 2.2391 - acc: 0.4040\n",
      "Epoch 3/70\n",
      " - 2s - loss: 1.8291 - acc: 0.5048\n",
      "Epoch 4/70\n",
      " - 2s - loss: 1.6018 - acc: 0.5608\n",
      "Epoch 5/70\n",
      " - 2s - loss: 1.4697 - acc: 0.5896\n",
      "Epoch 6/70\n",
      " - 2s - loss: 1.3759 - acc: 0.6091\n",
      "Epoch 7/70\n",
      " - 2s - loss: 1.3103 - acc: 0.6205\n",
      "Epoch 8/70\n",
      " - 2s - loss: 1.2677 - acc: 0.6287\n",
      "Epoch 9/70\n",
      " - 2s - loss: 1.2319 - acc: 0.6356\n",
      "Epoch 10/70\n",
      " - 2s - loss: 1.2052 - acc: 0.6387\n",
      "Epoch 11/70\n",
      " - 2s - loss: 1.1841 - acc: 0.6464\n",
      "Epoch 12/70\n",
      " - 2s - loss: 1.1670 - acc: 0.6487\n",
      "Epoch 13/70\n",
      " - 2s - loss: 1.1488 - acc: 0.6525\n",
      "Epoch 14/70\n",
      " - 2s - loss: 1.1333 - acc: 0.6540\n",
      "Epoch 15/70\n",
      " - 2s - loss: 1.1164 - acc: 0.6587\n",
      "Epoch 16/70\n",
      " - 2s - loss: 1.1120 - acc: 0.6575\n",
      "Epoch 17/70\n",
      " - 2s - loss: 1.0968 - acc: 0.6609\n",
      "Epoch 18/70\n",
      " - 2s - loss: 1.0879 - acc: 0.6621\n",
      "Epoch 19/70\n",
      " - 2s - loss: 1.0777 - acc: 0.6655\n",
      "Epoch 20/70\n",
      " - 2s - loss: 1.0644 - acc: 0.6658\n",
      "Epoch 21/70\n",
      " - 2s - loss: 1.0579 - acc: 0.6679\n",
      "Epoch 22/70\n",
      " - 2s - loss: 1.0488 - acc: 0.6700\n",
      "Epoch 23/70\n",
      " - 2s - loss: 1.0430 - acc: 0.6713\n",
      "Epoch 24/70\n",
      " - 2s - loss: 1.0406 - acc: 0.6713\n",
      "Epoch 25/70\n",
      " - 2s - loss: 1.0333 - acc: 0.6737\n",
      "Epoch 26/70\n",
      " - 2s - loss: 1.0280 - acc: 0.6760\n",
      "Epoch 27/70\n",
      " - 2s - loss: 1.0177 - acc: 0.6746\n",
      "Epoch 28/70\n",
      " - 2s - loss: 1.0149 - acc: 0.6766\n",
      "Epoch 29/70\n",
      " - 2s - loss: 1.0059 - acc: 0.6784\n",
      "Epoch 30/70\n",
      " - 2s - loss: 1.0048 - acc: 0.6785\n",
      "Epoch 31/70\n",
      " - 2s - loss: 1.0014 - acc: 0.6796\n",
      "Epoch 32/70\n",
      " - 2s - loss: 0.9926 - acc: 0.6820\n",
      "Epoch 33/70\n",
      " - 2s - loss: 0.9913 - acc: 0.6832\n",
      "Epoch 34/70\n",
      " - 2s - loss: 0.9851 - acc: 0.6829\n",
      "Epoch 35/70\n",
      " - 2s - loss: 0.9803 - acc: 0.6844\n",
      "Epoch 36/70\n",
      " - 2s - loss: 0.9817 - acc: 0.6840\n",
      "Epoch 37/70\n",
      " - 2s - loss: 0.9746 - acc: 0.6842\n",
      "Epoch 38/70\n",
      " - 2s - loss: 0.9690 - acc: 0.6863\n",
      "Epoch 39/70\n",
      " - 2s - loss: 0.9642 - acc: 0.6875\n",
      "Epoch 40/70\n",
      " - 2s - loss: 0.9635 - acc: 0.6867\n",
      "Epoch 41/70\n",
      " - 2s - loss: 0.9609 - acc: 0.6870\n",
      "Epoch 42/70\n",
      " - 2s - loss: 0.9592 - acc: 0.6887\n",
      "Epoch 43/70\n",
      " - 2s - loss: 0.9562 - acc: 0.6890\n",
      "Epoch 44/70\n",
      " - 2s - loss: 0.9544 - acc: 0.6896\n",
      "Epoch 45/70\n",
      " - 2s - loss: 0.9463 - acc: 0.6895\n",
      "Epoch 46/70\n",
      " - 2s - loss: 0.9452 - acc: 0.6918\n",
      "Epoch 47/70\n",
      " - 2s - loss: 0.9438 - acc: 0.6902\n",
      "Epoch 48/70\n",
      " - 2s - loss: 0.9394 - acc: 0.6934\n",
      "Epoch 49/70\n",
      " - 2s - loss: 0.9410 - acc: 0.6925\n",
      "Epoch 50/70\n",
      " - 2s - loss: 0.9344 - acc: 0.6931\n",
      "Epoch 51/70\n",
      " - 2s - loss: 0.9322 - acc: 0.6930\n",
      "Epoch 52/70\n",
      " - 2s - loss: 0.9357 - acc: 0.6925\n",
      "Epoch 53/70\n",
      " - 2s - loss: 0.9308 - acc: 0.6931\n",
      "Epoch 54/70\n",
      " - 2s - loss: 0.9300 - acc: 0.6957\n",
      "Epoch 55/70\n",
      " - 2s - loss: 0.9248 - acc: 0.6958\n",
      "Epoch 56/70\n",
      " - 2s - loss: 0.9224 - acc: 0.6940\n",
      "Epoch 57/70\n",
      " - 2s - loss: 0.9213 - acc: 0.6978\n",
      "Epoch 58/70\n",
      " - 2s - loss: 0.9162 - acc: 0.6987\n",
      "Epoch 59/70\n",
      " - 2s - loss: 0.9202 - acc: 0.6972\n",
      "Epoch 60/70\n",
      " - 2s - loss: 0.9138 - acc: 0.6971\n",
      "Epoch 61/70\n",
      " - 2s - loss: 0.9144 - acc: 0.6973\n",
      "Epoch 62/70\n",
      " - 2s - loss: 0.9109 - acc: 0.6988\n",
      "Epoch 63/70\n",
      " - 2s - loss: 0.9082 - acc: 0.6975\n",
      "Epoch 64/70\n",
      " - 2s - loss: 0.9126 - acc: 0.6977\n",
      "Epoch 65/70\n",
      " - 2s - loss: 0.9098 - acc: 0.7003\n",
      "Epoch 66/70\n",
      " - 2s - loss: 0.9093 - acc: 0.6982\n",
      "Epoch 67/70\n",
      " - 2s - loss: 0.9029 - acc: 0.6990\n",
      "Epoch 68/70\n",
      " - 2s - loss: 0.9039 - acc: 0.6993\n",
      "Epoch 69/70\n",
      " - 2s - loss: 0.9003 - acc: 0.6996\n",
      "Epoch 70/70\n",
      " - 2s - loss: 0.9022 - acc: 0.7000\n",
      "[CV]  nodes_l3=50, nodes_l2=120, nodes_l1=170, dropout_l3=0.2, dropout_l2=0.30000000000000004, dropout_l1=0.30000000000000004, batch_size=3000, total= 2.8min\n",
      "[CV] nodes_l3=50, nodes_l2=120, nodes_l1=170, dropout_l3=0.2, dropout_l2=0.30000000000000004, dropout_l1=0.30000000000000004, batch_size=3000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=170)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 8s - loss: 2.9674 - acc: 0.2239\n",
      "Epoch 2/70\n",
      " - 2s - loss: 2.1368 - acc: 0.4296\n",
      "Epoch 3/70\n",
      " - 2s - loss: 1.7599 - acc: 0.5248\n",
      "Epoch 4/70\n",
      " - 2s - loss: 1.5716 - acc: 0.5689\n",
      "Epoch 5/70\n",
      " - 2s - loss: 1.4544 - acc: 0.5912\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.3779 - acc: 0.6063\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.3148 - acc: 0.6175\n",
      "Epoch 8/70\n",
      " - 2s - loss: 1.2743 - acc: 0.6267\n",
      "Epoch 9/70\n",
      " - 2s - loss: 1.2399 - acc: 0.6311\n",
      "Epoch 10/70\n",
      " - 2s - loss: 1.2182 - acc: 0.6352\n",
      "Epoch 11/70\n",
      " - 2s - loss: 1.1976 - acc: 0.6389\n",
      "Epoch 12/70\n",
      " - 2s - loss: 1.1738 - acc: 0.6435\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.1602 - acc: 0.6467\n",
      "Epoch 14/70\n",
      " - 2s - loss: 1.1394 - acc: 0.6509\n",
      "Epoch 15/70\n",
      " - 2s - loss: 1.1315 - acc: 0.6514\n",
      "Epoch 16/70\n",
      " - 2s - loss: 1.1198 - acc: 0.6547\n",
      "Epoch 17/70\n",
      " - 2s - loss: 1.1122 - acc: 0.6550\n",
      "Epoch 18/70\n",
      " - 2s - loss: 1.0997 - acc: 0.6582\n",
      "Epoch 19/70\n",
      " - 2s - loss: 1.0879 - acc: 0.6610\n",
      "Epoch 20/70\n",
      " - 2s - loss: 1.0802 - acc: 0.6619\n",
      "Epoch 21/70\n",
      " - 3s - loss: 1.0743 - acc: 0.6641\n",
      "Epoch 22/70\n",
      " - 2s - loss: 1.0658 - acc: 0.6636\n",
      "Epoch 23/70\n",
      " - 2s - loss: 1.0587 - acc: 0.6661\n",
      "Epoch 24/70\n",
      " - 2s - loss: 1.0551 - acc: 0.6680\n",
      "Epoch 25/70\n",
      " - 2s - loss: 1.0472 - acc: 0.6693\n",
      "Epoch 26/70\n",
      " - 2s - loss: 1.0410 - acc: 0.6698\n",
      "Epoch 27/70\n",
      " - 2s - loss: 1.0360 - acc: 0.6697\n",
      "Epoch 28/70\n",
      " - 2s - loss: 1.0286 - acc: 0.6717\n",
      "Epoch 29/70\n",
      " - 2s - loss: 1.0268 - acc: 0.6736\n",
      "Epoch 30/70\n",
      " - 2s - loss: 1.0205 - acc: 0.6702\n",
      "Epoch 31/70\n",
      " - 2s - loss: 1.0184 - acc: 0.6742\n",
      "Epoch 32/70\n",
      " - 2s - loss: 1.0108 - acc: 0.6755\n",
      "Epoch 33/70\n",
      " - 2s - loss: 1.0065 - acc: 0.6779\n",
      "Epoch 34/70\n",
      " - 2s - loss: 1.0009 - acc: 0.6773\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9999 - acc: 0.6798\n",
      "Epoch 36/70\n",
      " - 2s - loss: 0.9962 - acc: 0.6785\n",
      "Epoch 37/70\n",
      " - 2s - loss: 0.9932 - acc: 0.6820\n",
      "Epoch 38/70\n",
      " - 2s - loss: 0.9875 - acc: 0.6820\n",
      "Epoch 39/70\n",
      " - 2s - loss: 0.9829 - acc: 0.6816\n",
      "Epoch 40/70\n",
      " - 2s - loss: 0.9828 - acc: 0.6832\n",
      "Epoch 41/70\n",
      " - 2s - loss: 0.9774 - acc: 0.6818\n",
      "Epoch 42/70\n",
      " - 2s - loss: 0.9750 - acc: 0.6848\n",
      "Epoch 43/70\n",
      " - 2s - loss: 0.9686 - acc: 0.6850\n",
      "Epoch 44/70\n",
      " - 2s - loss: 0.9669 - acc: 0.6835\n",
      "Epoch 45/70\n",
      " - 2s - loss: 0.9706 - acc: 0.6843\n",
      "Epoch 46/70\n",
      " - 2s - loss: 0.9637 - acc: 0.6857\n",
      "Epoch 47/70\n",
      " - 2s - loss: 0.9604 - acc: 0.6849\n",
      "Epoch 48/70\n",
      " - 2s - loss: 0.9596 - acc: 0.6849\n",
      "Epoch 49/70\n",
      " - 2s - loss: 0.9546 - acc: 0.6869\n",
      "Epoch 50/70\n",
      " - 2s - loss: 0.9553 - acc: 0.6868\n",
      "Epoch 51/70\n",
      " - 2s - loss: 0.9530 - acc: 0.6883\n",
      "Epoch 52/70\n",
      " - 2s - loss: 0.9474 - acc: 0.6878\n",
      "Epoch 53/70\n",
      " - 2s - loss: 0.9484 - acc: 0.6887\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.9483 - acc: 0.6893\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.9444 - acc: 0.6907\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.9439 - acc: 0.6900\n",
      "Epoch 57/70\n",
      " - 2s - loss: 0.9418 - acc: 0.6896\n",
      "Epoch 58/70\n",
      " - 2s - loss: 0.9371 - acc: 0.6912\n",
      "Epoch 59/70\n",
      " - 2s - loss: 0.9355 - acc: 0.6921\n",
      "Epoch 60/70\n",
      " - 2s - loss: 0.9325 - acc: 0.6925\n",
      "Epoch 61/70\n",
      " - 2s - loss: 0.9357 - acc: 0.6914\n",
      "Epoch 62/70\n",
      " - 2s - loss: 0.9307 - acc: 0.6923\n",
      "Epoch 63/70\n",
      " - 2s - loss: 0.9352 - acc: 0.6914\n",
      "Epoch 64/70\n",
      " - 2s - loss: 0.9301 - acc: 0.6924\n",
      "Epoch 65/70\n",
      " - 2s - loss: 0.9276 - acc: 0.6933\n",
      "Epoch 66/70\n",
      " - 2s - loss: 0.9258 - acc: 0.6942\n",
      "Epoch 67/70\n",
      " - 2s - loss: 0.9222 - acc: 0.6945\n",
      "Epoch 68/70\n",
      " - 2s - loss: 0.9223 - acc: 0.6937\n",
      "Epoch 69/70\n",
      " - 2s - loss: 0.9202 - acc: 0.6934\n",
      "Epoch 70/70\n",
      " - 2s - loss: 0.9227 - acc: 0.6938\n",
      "[CV]  nodes_l3=50, nodes_l2=120, nodes_l1=170, dropout_l3=0.2, dropout_l2=0.30000000000000004, dropout_l1=0.30000000000000004, batch_size=3000, total= 2.9min\n",
      "[CV] nodes_l3=80, nodes_l2=110, nodes_l1=180, dropout_l3=0.30000000000000004, dropout_l2=0.4, dropout_l1=0.2, batch_size=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=180)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=110)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=110)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 9s - loss: 2.5812 - acc: 0.3165\n",
      "Epoch 2/70\n",
      " - 3s - loss: 1.7099 - acc: 0.5365\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.4638 - acc: 0.5952\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.3451 - acc: 0.6187\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.2812 - acc: 0.6310\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.2335 - acc: 0.6385\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.2033 - acc: 0.6453\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.1751 - acc: 0.6499\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.1500 - acc: 0.6546\n",
      "Epoch 10/70\n",
      " - 4s - loss: 1.1320 - acc: 0.6595\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.1216 - acc: 0.6599\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.1085 - acc: 0.6634\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.0931 - acc: 0.6647\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.0855 - acc: 0.6662\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.0707 - acc: 0.6699\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.0614 - acc: 0.6716\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.0552 - acc: 0.6715\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.0463 - acc: 0.6737\n",
      "Epoch 19/70\n",
      " - 3s - loss: 1.0392 - acc: 0.6763\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.0325 - acc: 0.6786\n",
      "Epoch 21/70\n",
      " - 3s - loss: 1.0266 - acc: 0.6791\n",
      "Epoch 22/70\n",
      " - 3s - loss: 1.0230 - acc: 0.6798\n",
      "Epoch 23/70\n",
      " - 3s - loss: 1.0165 - acc: 0.6811\n",
      "Epoch 24/70\n",
      " - 3s - loss: 1.0114 - acc: 0.6832\n",
      "Epoch 25/70\n",
      " - 3s - loss: 1.0012 - acc: 0.6837\n",
      "Epoch 26/70\n",
      " - 3s - loss: 1.0036 - acc: 0.6854\n",
      "Epoch 27/70\n",
      " - 3s - loss: 1.0017 - acc: 0.6847\n",
      "Epoch 28/70\n",
      " - 3s - loss: 0.9956 - acc: 0.6856\n",
      "Epoch 29/70\n",
      " - 3s - loss: 0.9905 - acc: 0.6865\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.9865 - acc: 0.6865\n",
      "Epoch 31/70\n",
      " - 3s - loss: 0.9840 - acc: 0.6871\n",
      "Epoch 32/70\n",
      " - 3s - loss: 0.9818 - acc: 0.6887\n",
      "Epoch 33/70\n",
      " - 3s - loss: 0.9784 - acc: 0.6884\n",
      "Epoch 34/70\n",
      " - 3s - loss: 0.9712 - acc: 0.6892\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9756 - acc: 0.6894\n",
      "Epoch 36/70\n",
      " - 4s - loss: 0.9683 - acc: 0.6894\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9684 - acc: 0.6904\n",
      "Epoch 38/70\n",
      " - 3s - loss: 0.9639 - acc: 0.6905\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.9584 - acc: 0.6924\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.9584 - acc: 0.6928\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.9560 - acc: 0.6919\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.9530 - acc: 0.6931\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.9509 - acc: 0.6935\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.9509 - acc: 0.6933\n",
      "Epoch 45/70\n",
      " - 4s - loss: 0.9436 - acc: 0.6959\n",
      "Epoch 46/70\n",
      " - 4s - loss: 0.9436 - acc: 0.6953\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.9412 - acc: 0.6963\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.9445 - acc: 0.6959\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.9408 - acc: 0.6974\n",
      "Epoch 50/70\n",
      " - 3s - loss: 0.9402 - acc: 0.6948\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.9367 - acc: 0.6970\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.9354 - acc: 0.6985\n",
      "Epoch 53/70\n",
      " - 3s - loss: 0.9353 - acc: 0.6974\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.9297 - acc: 0.6994\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.9367 - acc: 0.6956\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.9311 - acc: 0.6972\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.9262 - acc: 0.6997\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.9263 - acc: 0.6979\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.9258 - acc: 0.6996\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.9230 - acc: 0.6990\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.9169 - acc: 0.7008\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.9178 - acc: 0.7005\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.9190 - acc: 0.7019\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.9171 - acc: 0.7013\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.9178 - acc: 0.7013\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.9203 - acc: 0.7018\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.9175 - acc: 0.7003\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.9183 - acc: 0.7017\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.9132 - acc: 0.7016\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.9152 - acc: 0.7005\n",
      "[CV]  nodes_l3=80, nodes_l2=110, nodes_l1=180, dropout_l3=0.30000000000000004, dropout_l2=0.4, dropout_l1=0.2, batch_size=1000, total= 3.9min\n",
      "[CV] nodes_l3=80, nodes_l2=110, nodes_l1=180, dropout_l3=0.30000000000000004, dropout_l2=0.4, dropout_l1=0.2, batch_size=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=180)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=110)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=110)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 14s - loss: 2.5364 - acc: 0.3372\n",
      "Epoch 2/70\n",
      " - 3s - loss: 1.6966 - acc: 0.5378\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.4570 - acc: 0.5944\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.3453 - acc: 0.6179\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.2850 - acc: 0.6287\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.2321 - acc: 0.6392\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.1996 - acc: 0.6447\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.1739 - acc: 0.6494\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.1546 - acc: 0.6534\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.1417 - acc: 0.6545\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.1208 - acc: 0.6613\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.1065 - acc: 0.6623\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.0971 - acc: 0.6640\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.0829 - acc: 0.6689\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.0725 - acc: 0.6694\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.0665 - acc: 0.6689\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.0587 - acc: 0.6725\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.0492 - acc: 0.6741\n",
      "Epoch 19/70\n",
      " - 3s - loss: 1.0393 - acc: 0.6769\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.0340 - acc: 0.6769\n",
      "Epoch 21/70\n",
      " - 3s - loss: 1.0312 - acc: 0.6785\n",
      "Epoch 22/70\n",
      " - 3s - loss: 1.0287 - acc: 0.6784\n",
      "Epoch 23/70\n",
      " - 3s - loss: 1.0195 - acc: 0.6781\n",
      "Epoch 24/70\n",
      " - 3s - loss: 1.0145 - acc: 0.6808\n",
      "Epoch 25/70\n",
      " - 3s - loss: 1.0041 - acc: 0.6832\n",
      "Epoch 26/70\n",
      " - 3s - loss: 1.0026 - acc: 0.6829\n",
      "Epoch 27/70\n",
      " - 3s - loss: 0.9996 - acc: 0.6843\n",
      "Epoch 28/70\n",
      " - 3s - loss: 0.9939 - acc: 0.6865\n",
      "Epoch 29/70\n",
      " - 3s - loss: 0.9951 - acc: 0.6870\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.9912 - acc: 0.6857\n",
      "Epoch 31/70\n",
      " - 3s - loss: 0.9831 - acc: 0.6887\n",
      "Epoch 32/70\n",
      " - 3s - loss: 0.9825 - acc: 0.6871\n",
      "Epoch 33/70\n",
      " - 3s - loss: 0.9801 - acc: 0.6894\n",
      "Epoch 34/70\n",
      " - 3s - loss: 0.9716 - acc: 0.6906\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9691 - acc: 0.6909\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9726 - acc: 0.6885\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9666 - acc: 0.6916\n",
      "Epoch 38/70\n",
      " - 3s - loss: 0.9648 - acc: 0.6920\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.9638 - acc: 0.6917\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.9613 - acc: 0.6920\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.9580 - acc: 0.6936\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.9578 - acc: 0.6917\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.9554 - acc: 0.6946\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.9515 - acc: 0.6948\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.9512 - acc: 0.6936\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.9472 - acc: 0.6953\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.9439 - acc: 0.6957\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.9437 - acc: 0.6961\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.9378 - acc: 0.6976\n",
      "Epoch 50/70\n",
      " - 3s - loss: 0.9385 - acc: 0.6968\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.9363 - acc: 0.6976\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.9371 - acc: 0.6969\n",
      "Epoch 53/70\n",
      " - 3s - loss: 0.9363 - acc: 0.6975\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.9325 - acc: 0.6981\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.9318 - acc: 0.6978\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.9282 - acc: 0.6987\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.9270 - acc: 0.7000\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.9295 - acc: 0.6998\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.9255 - acc: 0.6987\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.9242 - acc: 0.7002\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.9231 - acc: 0.6992\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.9214 - acc: 0.7008\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.9215 - acc: 0.7007\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.9210 - acc: 0.7012\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.9200 - acc: 0.7028\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.9215 - acc: 0.7017\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.9209 - acc: 0.7011\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.9188 - acc: 0.7009\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.9160 - acc: 0.7017\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.9158 - acc: 0.7026\n",
      "[CV]  nodes_l3=80, nodes_l2=110, nodes_l1=180, dropout_l3=0.30000000000000004, dropout_l2=0.4, dropout_l1=0.2, batch_size=1000, total= 6.7min\n",
      "[CV] nodes_l3=80, nodes_l2=110, nodes_l1=180, dropout_l3=0.30000000000000004, dropout_l2=0.4, dropout_l1=0.2, batch_size=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=180)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=110)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=110)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 10s - loss: 2.5740 - acc: 0.3214\n",
      "Epoch 2/70\n",
      " - 3s - loss: 1.7046 - acc: 0.5386\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.4420 - acc: 0.5993\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.3309 - acc: 0.6221\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.2635 - acc: 0.6344\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.2134 - acc: 0.6456\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.1835 - acc: 0.6508\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.1554 - acc: 0.6535\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.1381 - acc: 0.6583\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.1158 - acc: 0.6610\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.1041 - acc: 0.6637\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.0919 - acc: 0.6645\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.0784 - acc: 0.6696\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.0617 - acc: 0.6725\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.0589 - acc: 0.6735\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.0459 - acc: 0.6750\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.0375 - acc: 0.6765\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.0291 - acc: 0.6793\n",
      "Epoch 19/70\n",
      " - 3s - loss: 1.0266 - acc: 0.6800\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.0146 - acc: 0.6812\n",
      "Epoch 21/70\n",
      " - 3s - loss: 1.0125 - acc: 0.6827\n",
      "Epoch 22/70\n",
      " - 3s - loss: 1.0092 - acc: 0.6841\n",
      "Epoch 23/70\n",
      " - 3s - loss: 1.0017 - acc: 0.6849\n",
      "Epoch 24/70\n",
      " - 3s - loss: 0.9925 - acc: 0.6870\n",
      "Epoch 25/70\n",
      " - 3s - loss: 0.9887 - acc: 0.6873\n",
      "Epoch 26/70\n",
      " - 4s - loss: 0.9845 - acc: 0.6887\n",
      "Epoch 27/70\n",
      " - 3s - loss: 0.9851 - acc: 0.6879\n",
      "Epoch 28/70\n",
      " - 3s - loss: 0.9775 - acc: 0.6907\n",
      "Epoch 29/70\n",
      " - 3s - loss: 0.9724 - acc: 0.6901\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.9734 - acc: 0.6911\n",
      "Epoch 31/70\n",
      " - 3s - loss: 0.9662 - acc: 0.6913\n",
      "Epoch 32/70\n",
      " - 3s - loss: 0.9615 - acc: 0.6916\n",
      "Epoch 33/70\n",
      " - 4s - loss: 0.9601 - acc: 0.6921\n",
      "Epoch 34/70\n",
      " - 3s - loss: 0.9563 - acc: 0.6927\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9550 - acc: 0.6948\n",
      "Epoch 36/70\n",
      " - 4s - loss: 0.9505 - acc: 0.6954\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9498 - acc: 0.6954\n",
      "Epoch 38/70\n",
      " - 3s - loss: 0.9474 - acc: 0.6953\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.9405 - acc: 0.6956\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.9443 - acc: 0.6972\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.9385 - acc: 0.6969\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.9376 - acc: 0.6982\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.9360 - acc: 0.7003\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.9336 - acc: 0.6966\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.9308 - acc: 0.6979\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.9273 - acc: 0.6989\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.9278 - acc: 0.7002\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.9247 - acc: 0.6987\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.9217 - acc: 0.7014\n",
      "Epoch 50/70\n",
      " - 4s - loss: 0.9245 - acc: 0.7000\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.9201 - acc: 0.7005\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.9169 - acc: 0.7026\n",
      "Epoch 53/70\n",
      " - 3s - loss: 0.9171 - acc: 0.7014\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.9160 - acc: 0.7018\n",
      "Epoch 55/70\n",
      " - 4s - loss: 0.9140 - acc: 0.7035\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.9097 - acc: 0.7040\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.9113 - acc: 0.7033\n",
      "Epoch 58/70\n",
      " - 4s - loss: 0.9118 - acc: 0.7024\n",
      "Epoch 59/70\n",
      " - 4s - loss: 0.9076 - acc: 0.7030\n",
      "Epoch 60/70\n",
      " - 4s - loss: 0.9082 - acc: 0.7046\n",
      "Epoch 61/70\n",
      " - 4s - loss: 0.9063 - acc: 0.7053\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.9030 - acc: 0.7051\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.9029 - acc: 0.7051\n",
      "Epoch 64/70\n",
      " - 4s - loss: 0.9029 - acc: 0.7048\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.9025 - acc: 0.7048\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.9004 - acc: 0.7060\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.8993 - acc: 0.7083\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.9000 - acc: 0.7059\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.9005 - acc: 0.7049\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.8968 - acc: 0.7058\n",
      "[CV]  nodes_l3=80, nodes_l2=110, nodes_l1=180, dropout_l3=0.30000000000000004, dropout_l2=0.4, dropout_l1=0.2, batch_size=1000, total= 4.1min\n",
      "[CV] nodes_l3=80, nodes_l2=110, nodes_l1=180, dropout_l3=0.30000000000000004, dropout_l2=0.4, dropout_l1=0.2, batch_size=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=180)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=110)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=110)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 14s - loss: 2.5794 - acc: 0.3232\n",
      "Epoch 2/70\n",
      " - 3s - loss: 1.7068 - acc: 0.5347\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.4624 - acc: 0.5924\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.3492 - acc: 0.6152\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.2813 - acc: 0.6256\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.2296 - acc: 0.6386\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.2008 - acc: 0.6440\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.1767 - acc: 0.6462\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.1586 - acc: 0.6521\n",
      "Epoch 10/70\n",
      " - 4s - loss: 1.1403 - acc: 0.6546\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.1233 - acc: 0.6574\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.1099 - acc: 0.6590\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.1028 - acc: 0.6617\n",
      "Epoch 14/70\n",
      " - 4s - loss: 1.0882 - acc: 0.6640\n",
      "Epoch 15/70\n",
      " - 4s - loss: 1.0821 - acc: 0.6646\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.0688 - acc: 0.6679\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.0630 - acc: 0.6680\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.0522 - acc: 0.6704\n",
      "Epoch 19/70\n",
      " - 3s - loss: 1.0509 - acc: 0.6715\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.0407 - acc: 0.6741\n",
      "Epoch 21/70\n",
      " - 3s - loss: 1.0343 - acc: 0.6747\n",
      "Epoch 22/70\n",
      " - 3s - loss: 1.0303 - acc: 0.6749\n",
      "Epoch 23/70\n",
      " - 3s - loss: 1.0242 - acc: 0.6770\n",
      "Epoch 24/70\n",
      " - 3s - loss: 1.0194 - acc: 0.6785\n",
      "Epoch 25/70\n",
      " - 3s - loss: 1.0162 - acc: 0.6796\n",
      "Epoch 26/70\n",
      " - 3s - loss: 1.0090 - acc: 0.6785\n",
      "Epoch 27/70\n",
      " - 3s - loss: 1.0051 - acc: 0.6810\n",
      "Epoch 28/70\n",
      " - 3s - loss: 1.0037 - acc: 0.6828\n",
      "Epoch 29/70\n",
      " - 3s - loss: 1.0007 - acc: 0.6813\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.9973 - acc: 0.6834\n",
      "Epoch 31/70\n",
      " - 4s - loss: 0.9907 - acc: 0.6829\n",
      "Epoch 32/70\n",
      " - 3s - loss: 0.9904 - acc: 0.6849\n",
      "Epoch 33/70\n",
      " - 3s - loss: 0.9890 - acc: 0.6831\n",
      "Epoch 34/70\n",
      " - 4s - loss: 0.9871 - acc: 0.6835\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9787 - acc: 0.6854\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9774 - acc: 0.6866\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9763 - acc: 0.6843\n",
      "Epoch 38/70\n",
      " - 3s - loss: 0.9740 - acc: 0.6867\n",
      "Epoch 39/70\n",
      " - 4s - loss: 0.9700 - acc: 0.6878\n",
      "Epoch 40/70\n",
      " - 4s - loss: 0.9687 - acc: 0.6873\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.9666 - acc: 0.6887\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.9625 - acc: 0.6881\n",
      "Epoch 43/70\n",
      " - 4s - loss: 0.9611 - acc: 0.6905\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.9599 - acc: 0.6907\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.9588 - acc: 0.6895\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.9546 - acc: 0.6897\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.9518 - acc: 0.6935\n",
      "Epoch 48/70\n",
      " - 4s - loss: 0.9497 - acc: 0.6928\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.9480 - acc: 0.6920\n",
      "Epoch 50/70\n",
      " - 3s - loss: 0.9499 - acc: 0.6931\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.9452 - acc: 0.6935\n",
      "Epoch 52/70\n",
      " - 4s - loss: 0.9458 - acc: 0.6919\n",
      "Epoch 53/70\n",
      " - 5s - loss: 0.9423 - acc: 0.6945\n",
      "Epoch 54/70\n",
      " - 5s - loss: 0.9431 - acc: 0.6953\n",
      "Epoch 55/70\n",
      " - 4s - loss: 0.9428 - acc: 0.6933\n",
      "Epoch 56/70\n",
      " - 5s - loss: 0.9407 - acc: 0.6932\n",
      "Epoch 57/70\n",
      " - 5s - loss: 0.9343 - acc: 0.6950\n",
      "Epoch 58/70\n",
      " - 4s - loss: 0.9358 - acc: 0.6956\n",
      "Epoch 59/70\n",
      " - 5s - loss: 0.9368 - acc: 0.6970\n",
      "Epoch 60/70\n",
      " - 5s - loss: 0.9336 - acc: 0.6960\n",
      "Epoch 61/70\n",
      " - 5s - loss: 0.9308 - acc: 0.6971\n",
      "Epoch 62/70\n",
      " - 5s - loss: 0.9292 - acc: 0.6968\n",
      "Epoch 63/70\n",
      " - 5s - loss: 0.9285 - acc: 0.6956\n",
      "Epoch 64/70\n",
      " - 5s - loss: 0.9251 - acc: 0.6977\n",
      "Epoch 65/70\n",
      " - 5s - loss: 0.9265 - acc: 0.6991\n",
      "Epoch 66/70\n",
      " - 5s - loss: 0.9265 - acc: 0.6967\n",
      "Epoch 67/70\n",
      " - 5s - loss: 0.9250 - acc: 0.6976\n",
      "Epoch 68/70\n",
      " - 5s - loss: 0.9262 - acc: 0.6982\n",
      "Epoch 69/70\n",
      " - 5s - loss: 0.9236 - acc: 0.6964\n",
      "Epoch 70/70\n",
      " - 5s - loss: 0.9230 - acc: 0.6993\n",
      "[CV]  nodes_l3=80, nodes_l2=110, nodes_l1=180, dropout_l3=0.30000000000000004, dropout_l2=0.4, dropout_l1=0.2, batch_size=1000, total= 4.8min\n",
      "[CV] nodes_l3=80, nodes_l2=120, nodes_l1=150, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.30000000000000004, batch_size=3000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=150)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 13s - loss: 2.9847 - acc: 0.2359\n",
      "Epoch 2/70\n",
      " - 3s - loss: 2.1535 - acc: 0.4232\n",
      "Epoch 3/70\n",
      " - 4s - loss: 1.7660 - acc: 0.5268\n",
      "Epoch 4/70\n",
      " - 4s - loss: 1.5597 - acc: 0.5748\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.4458 - acc: 0.5960\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.3675 - acc: 0.6121\n",
      "Epoch 7/70\n",
      " - 4s - loss: 1.3095 - acc: 0.6234\n",
      "Epoch 8/70\n",
      " - 4s - loss: 1.2645 - acc: 0.6318\n",
      "Epoch 9/70\n",
      " - 4s - loss: 1.2272 - acc: 0.6375\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.2000 - acc: 0.6439\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.1737 - acc: 0.6474\n",
      "Epoch 12/70\n",
      " - 4s - loss: 1.1561 - acc: 0.6496\n",
      "Epoch 13/70\n",
      " - 4s - loss: 1.1440 - acc: 0.6515\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.1304 - acc: 0.6534\n",
      "Epoch 15/70\n",
      " - 4s - loss: 1.1181 - acc: 0.6558\n",
      "Epoch 16/70\n",
      " - 4s - loss: 1.1039 - acc: 0.6575\n",
      "Epoch 17/70\n",
      " - 4s - loss: 1.0964 - acc: 0.6603\n",
      "Epoch 18/70\n",
      " - 4s - loss: 1.0847 - acc: 0.6611\n",
      "Epoch 19/70\n",
      " - 5s - loss: 1.0782 - acc: 0.6633\n",
      "Epoch 20/70\n",
      " - 5s - loss: 1.0669 - acc: 0.6636\n",
      "Epoch 21/70\n",
      " - 4s - loss: 1.0621 - acc: 0.6641\n",
      "Epoch 22/70\n",
      " - 5s - loss: 1.0516 - acc: 0.6668\n",
      "Epoch 23/70\n",
      " - 5s - loss: 1.0464 - acc: 0.6687\n",
      "Epoch 24/70\n",
      " - 4s - loss: 1.0403 - acc: 0.6700\n",
      "Epoch 25/70\n",
      " - 4s - loss: 1.0343 - acc: 0.6711\n",
      "Epoch 26/70\n",
      " - 3s - loss: 1.0277 - acc: 0.6720\n",
      "Epoch 27/70\n",
      " - 4s - loss: 1.0231 - acc: 0.6737\n",
      "Epoch 28/70\n",
      " - 4s - loss: 1.0179 - acc: 0.6729\n",
      "Epoch 29/70\n",
      " - 3s - loss: 1.0108 - acc: 0.6751\n",
      "Epoch 30/70\n",
      " - 4s - loss: 1.0065 - acc: 0.6760\n",
      "Epoch 31/70\n",
      " - 4s - loss: 1.0014 - acc: 0.6773\n",
      "Epoch 32/70\n",
      " - 5s - loss: 0.9988 - acc: 0.6785\n",
      "Epoch 33/70\n",
      " - 5s - loss: 0.9933 - acc: 0.6808\n",
      "Epoch 34/70\n",
      " - 4s - loss: 0.9874 - acc: 0.6800\n",
      "Epoch 35/70\n",
      " - 6s - loss: 0.9873 - acc: 0.6793\n",
      "Epoch 36/70\n",
      " - 5s - loss: 0.9823 - acc: 0.6822\n",
      "Epoch 37/70\n",
      " - 4s - loss: 0.9764 - acc: 0.6841\n",
      "Epoch 38/70\n",
      " - 5s - loss: 0.9768 - acc: 0.6813\n",
      "Epoch 39/70\n",
      " - 4s - loss: 0.9755 - acc: 0.6827\n",
      "Epoch 40/70\n",
      " - 4s - loss: 0.9719 - acc: 0.6847\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.9642 - acc: 0.6861\n",
      "Epoch 42/70\n",
      " - 4s - loss: 0.9637 - acc: 0.6869\n",
      "Epoch 43/70\n",
      " - 5s - loss: 0.9591 - acc: 0.6864\n",
      "Epoch 44/70\n",
      " - 4s - loss: 0.9595 - acc: 0.6860\n",
      "Epoch 45/70\n",
      " - 4s - loss: 0.9532 - acc: 0.6875\n",
      "Epoch 46/70\n",
      " - 6s - loss: 0.9520 - acc: 0.6872\n",
      "Epoch 47/70\n",
      " - 6s - loss: 0.9501 - acc: 0.6887\n",
      "Epoch 48/70\n",
      " - 6s - loss: 0.9461 - acc: 0.6889\n",
      "Epoch 49/70\n",
      " - 4s - loss: 0.9479 - acc: 0.6898\n",
      "Epoch 50/70\n",
      " - 5s - loss: 0.9424 - acc: 0.6908\n",
      "Epoch 51/70\n",
      " - 4s - loss: 0.9412 - acc: 0.6898\n",
      "Epoch 52/70\n",
      " - 4s - loss: 0.9350 - acc: 0.6918\n",
      "Epoch 53/70\n",
      " - 6s - loss: 0.9360 - acc: 0.6906\n",
      "Epoch 54/70\n",
      " - 6s - loss: 0.9346 - acc: 0.6918\n",
      "Epoch 55/70\n",
      " - 4s - loss: 0.9327 - acc: 0.6911\n",
      "Epoch 56/70\n",
      " - 5s - loss: 0.9277 - acc: 0.6925\n",
      "Epoch 57/70\n",
      " - 4s - loss: 0.9280 - acc: 0.6933\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.9270 - acc: 0.6932\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.9235 - acc: 0.6947\n",
      "Epoch 60/70\n",
      " - 4s - loss: 0.9234 - acc: 0.6938\n",
      "Epoch 61/70\n",
      " - 4s - loss: 0.9205 - acc: 0.6955\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.9183 - acc: 0.6954\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.9149 - acc: 0.6961\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.9143 - acc: 0.6959\n",
      "Epoch 65/70\n",
      " - 4s - loss: 0.9123 - acc: 0.6936\n",
      "Epoch 66/70\n",
      " - 4s - loss: 0.9089 - acc: 0.6969\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.9127 - acc: 0.6957\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.9094 - acc: 0.6981\n",
      "Epoch 69/70\n",
      " - 4s - loss: 0.9100 - acc: 0.6970\n",
      "Epoch 70/70\n",
      " - 4s - loss: 0.9070 - acc: 0.6981\n",
      "[CV]  nodes_l3=80, nodes_l2=120, nodes_l1=150, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.30000000000000004, batch_size=3000, total= 5.1min\n",
      "[CV] nodes_l3=80, nodes_l2=120, nodes_l1=150, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.30000000000000004, batch_size=3000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=150)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 14s - loss: 3.0925 - acc: 0.2119\n",
      "Epoch 2/70\n",
      " - 4s - loss: 2.2417 - acc: 0.4035\n",
      "Epoch 3/70\n",
      " - 4s - loss: 1.7987 - acc: 0.5126\n",
      "Epoch 4/70\n",
      " - 4s - loss: 1.5698 - acc: 0.5667\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.4388 - acc: 0.5934\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.3538 - acc: 0.6135\n",
      "Epoch 7/70\n",
      " - 4s - loss: 1.2978 - acc: 0.6253\n",
      "Epoch 8/70\n",
      " - 4s - loss: 1.2486 - acc: 0.6335\n",
      "Epoch 9/70\n",
      " - 4s - loss: 1.2178 - acc: 0.6387\n",
      "Epoch 10/70\n",
      " - 4s - loss: 1.1943 - acc: 0.6426\n",
      "Epoch 11/70\n",
      " - 4s - loss: 1.1732 - acc: 0.6458\n",
      "Epoch 12/70\n",
      " - 4s - loss: 1.1520 - acc: 0.6511\n",
      "Epoch 13/70\n",
      " - 4s - loss: 1.1410 - acc: 0.6530\n",
      "Epoch 14/70\n",
      " - 4s - loss: 1.1226 - acc: 0.6566\n",
      "Epoch 15/70\n",
      " - 4s - loss: 1.1159 - acc: 0.6553\n",
      "Epoch 16/70\n",
      " - 4s - loss: 1.0994 - acc: 0.6602\n",
      "Epoch 17/70\n",
      " - 4s - loss: 1.0904 - acc: 0.6618\n",
      "Epoch 18/70\n",
      " - 4s - loss: 1.0853 - acc: 0.6622\n",
      "Epoch 19/70\n",
      " - 4s - loss: 1.0737 - acc: 0.6643\n",
      "Epoch 20/70\n",
      " - 4s - loss: 1.0648 - acc: 0.6662\n",
      "Epoch 21/70\n",
      " - 4s - loss: 1.0610 - acc: 0.6663\n",
      "Epoch 22/70\n",
      " - 4s - loss: 1.0530 - acc: 0.6693\n",
      "Epoch 23/70\n",
      " - 4s - loss: 1.0451 - acc: 0.6703\n",
      "Epoch 24/70\n",
      " - 4s - loss: 1.0381 - acc: 0.6716\n",
      "Epoch 25/70\n",
      " - 4s - loss: 1.0360 - acc: 0.6716\n",
      "Epoch 26/70\n",
      " - 4s - loss: 1.0278 - acc: 0.6723\n",
      "Epoch 27/70\n",
      " - 3s - loss: 1.0249 - acc: 0.6730\n",
      "Epoch 28/70\n",
      " - 4s - loss: 1.0172 - acc: 0.6741\n",
      "Epoch 29/70\n",
      " - 4s - loss: 1.0134 - acc: 0.6751\n",
      "Epoch 30/70\n",
      " - 4s - loss: 1.0079 - acc: 0.6772\n",
      "Epoch 31/70\n",
      " - 4s - loss: 1.0053 - acc: 0.6783\n",
      "Epoch 32/70\n",
      " - 4s - loss: 0.9988 - acc: 0.6778\n",
      "Epoch 33/70\n",
      " - 4s - loss: 0.9938 - acc: 0.6809\n",
      "Epoch 34/70\n",
      " - 4s - loss: 0.9932 - acc: 0.6788\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9880 - acc: 0.6795\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9847 - acc: 0.6794\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9827 - acc: 0.6807\n",
      "Epoch 38/70\n",
      " - 3s - loss: 0.9795 - acc: 0.6852\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.9739 - acc: 0.6841\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.9673 - acc: 0.6839\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.9708 - acc: 0.6840\n",
      "Epoch 42/70\n",
      " - 4s - loss: 0.9680 - acc: 0.6844\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.9643 - acc: 0.6851\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.9608 - acc: 0.6850\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.9594 - acc: 0.6872\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.9555 - acc: 0.6880\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.9534 - acc: 0.6870\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.9512 - acc: 0.6897\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.9485 - acc: 0.6890\n",
      "Epoch 50/70\n",
      " - 3s - loss: 0.9427 - acc: 0.6924\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.9447 - acc: 0.6900\n",
      "Epoch 52/70\n",
      " - 4s - loss: 0.9415 - acc: 0.6902\n",
      "Epoch 53/70\n",
      " - 4s - loss: 0.9373 - acc: 0.6919\n",
      "Epoch 54/70\n",
      " - 4s - loss: 0.9365 - acc: 0.6901\n",
      "Epoch 55/70\n",
      " - 4s - loss: 0.9320 - acc: 0.6923\n",
      "Epoch 56/70\n",
      " - 4s - loss: 0.9332 - acc: 0.6915\n",
      "Epoch 57/70\n",
      " - 4s - loss: 0.9294 - acc: 0.6926\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.9298 - acc: 0.6930\n",
      "Epoch 59/70\n",
      " - 4s - loss: 0.9267 - acc: 0.6932\n",
      "Epoch 60/70\n",
      " - 6s - loss: 0.9253 - acc: 0.6930\n",
      "Epoch 61/70\n",
      " - 4s - loss: 0.9229 - acc: 0.6946\n",
      "Epoch 62/70\n",
      " - 4s - loss: 0.9230 - acc: 0.6945\n",
      "Epoch 63/70\n",
      " - 4s - loss: 0.9194 - acc: 0.6955\n",
      "Epoch 64/70\n",
      " - 5s - loss: 0.9192 - acc: 0.6950\n",
      "Epoch 65/70\n",
      " - 5s - loss: 0.9172 - acc: 0.6936\n",
      "Epoch 66/70\n",
      " - 4s - loss: 0.9169 - acc: 0.6947\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.9134 - acc: 0.6965\n",
      "Epoch 68/70\n",
      " - 5s - loss: 0.9117 - acc: 0.6958\n",
      "Epoch 69/70\n",
      " - 4s - loss: 0.9126 - acc: 0.6958\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.9098 - acc: 0.6966\n",
      "[CV]  nodes_l3=80, nodes_l2=120, nodes_l1=150, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.30000000000000004, batch_size=3000, total= 4.6min\n",
      "[CV] nodes_l3=80, nodes_l2=120, nodes_l1=150, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.30000000000000004, batch_size=3000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=150)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 13s - loss: 3.0400 - acc: 0.2283\n",
      "Epoch 2/70\n",
      " - 4s - loss: 2.1933 - acc: 0.4156\n",
      "Epoch 3/70\n",
      " - 4s - loss: 1.7843 - acc: 0.5173\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.5630 - acc: 0.5702\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.4329 - acc: 0.5998\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.3557 - acc: 0.6136\n",
      "Epoch 7/70\n",
      " - 4s - loss: 1.2968 - acc: 0.6261\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.2545 - acc: 0.6345\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.2125 - acc: 0.6411\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.1871 - acc: 0.6443\n",
      "Epoch 11/70\n",
      " - 5s - loss: 1.1647 - acc: 0.6476\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.1496 - acc: 0.6494\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.1335 - acc: 0.6537\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.1162 - acc: 0.6540\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.1008 - acc: 0.6604\n",
      "Epoch 16/70\n",
      " - 4s - loss: 1.0917 - acc: 0.6605\n",
      "Epoch 17/70\n",
      " - 4s - loss: 1.0805 - acc: 0.6621\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.0711 - acc: 0.6635\n",
      "Epoch 19/70\n",
      " - 5s - loss: 1.0620 - acc: 0.6674\n",
      "Epoch 20/70\n",
      " - 4s - loss: 1.0523 - acc: 0.6681\n",
      "Epoch 21/70\n",
      " - 5s - loss: 1.0481 - acc: 0.6693\n",
      "Epoch 22/70\n",
      " - 4s - loss: 1.0440 - acc: 0.6701\n",
      "Epoch 23/70\n",
      " - 4s - loss: 1.0322 - acc: 0.6734\n",
      "Epoch 24/70\n",
      " - 5s - loss: 1.0251 - acc: 0.6737\n",
      "Epoch 25/70\n",
      " - 5s - loss: 1.0213 - acc: 0.6740\n",
      "Epoch 26/70\n",
      " - 4s - loss: 1.0121 - acc: 0.6757\n",
      "Epoch 27/70\n",
      " - 4s - loss: 1.0069 - acc: 0.6772\n",
      "Epoch 28/70\n",
      " - 5s - loss: 1.0003 - acc: 0.6772\n",
      "Epoch 29/70\n",
      " - 5s - loss: 0.9972 - acc: 0.6804\n",
      "Epoch 30/70\n",
      " - 5s - loss: 0.9911 - acc: 0.6815\n",
      "Epoch 31/70\n",
      " - 5s - loss: 0.9863 - acc: 0.6813\n",
      "Epoch 32/70\n",
      " - 4s - loss: 0.9812 - acc: 0.6833\n",
      "Epoch 33/70\n",
      " - 4s - loss: 0.9807 - acc: 0.6810\n",
      "Epoch 34/70\n",
      " - 4s - loss: 0.9731 - acc: 0.6828\n",
      "Epoch 35/70\n",
      " - 4s - loss: 0.9700 - acc: 0.6851\n",
      "Epoch 36/70\n",
      " - 4s - loss: 0.9667 - acc: 0.6850\n",
      "Epoch 37/70\n",
      " - 4s - loss: 0.9662 - acc: 0.6866\n",
      "Epoch 38/70\n",
      " - 4s - loss: 0.9545 - acc: 0.6872\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.9550 - acc: 0.6873\n",
      "Epoch 40/70\n",
      " - 4s - loss: 0.9510 - acc: 0.6881\n",
      "Epoch 41/70\n",
      " - 4s - loss: 0.9486 - acc: 0.6878\n",
      "Epoch 42/70\n",
      " - 4s - loss: 0.9484 - acc: 0.6893\n",
      "Epoch 43/70\n",
      " - 5s - loss: 0.9437 - acc: 0.6912\n",
      "Epoch 44/70\n",
      " - 5s - loss: 0.9403 - acc: 0.6924\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.9356 - acc: 0.6931\n",
      "Epoch 46/70\n",
      " - 4s - loss: 0.9373 - acc: 0.6917\n",
      "Epoch 47/70\n",
      " - 4s - loss: 0.9306 - acc: 0.6931\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.9277 - acc: 0.6941\n",
      "Epoch 49/70\n",
      " - 4s - loss: 0.9289 - acc: 0.6941\n",
      "Epoch 50/70\n",
      " - 4s - loss: 0.9236 - acc: 0.6932\n",
      "Epoch 51/70\n",
      " - 4s - loss: 0.9224 - acc: 0.6931\n",
      "Epoch 52/70\n",
      " - 6s - loss: 0.9209 - acc: 0.6945\n",
      "Epoch 53/70\n",
      " - 5s - loss: 0.9161 - acc: 0.6960\n",
      "Epoch 54/70\n",
      " - 4s - loss: 0.9146 - acc: 0.6952\n",
      "Epoch 55/70\n",
      " - 5s - loss: 0.9147 - acc: 0.6955\n",
      "Epoch 56/70\n",
      " - 4s - loss: 0.9101 - acc: 0.6972\n",
      "Epoch 57/70\n",
      " - 4s - loss: 0.9118 - acc: 0.6962\n",
      "Epoch 58/70\n",
      " - 4s - loss: 0.9117 - acc: 0.6974\n",
      "Epoch 59/70\n",
      " - 5s - loss: 0.9029 - acc: 0.6978\n",
      "Epoch 60/70\n",
      " - 5s - loss: 0.9038 - acc: 0.6980\n",
      "Epoch 61/70\n",
      " - 5s - loss: 0.9026 - acc: 0.6980\n",
      "Epoch 62/70\n",
      " - 4s - loss: 0.9028 - acc: 0.6988\n",
      "Epoch 63/70\n",
      " - 4s - loss: 0.8996 - acc: 0.6992\n",
      "Epoch 64/70\n",
      " - 4s - loss: 0.8982 - acc: 0.6994\n",
      "Epoch 65/70\n",
      " - 5s - loss: 0.8970 - acc: 0.7002\n",
      "Epoch 66/70\n",
      " - 5s - loss: 0.8961 - acc: 0.6992\n",
      "Epoch 67/70\n",
      " - 5s - loss: 0.8933 - acc: 0.7013\n",
      "Epoch 68/70\n",
      " - 5s - loss: 0.8899 - acc: 0.7017\n",
      "Epoch 69/70\n",
      " - 4s - loss: 0.8931 - acc: 0.7011\n",
      "Epoch 70/70\n",
      " - 4s - loss: 0.8889 - acc: 0.7015\n",
      "[CV]  nodes_l3=80, nodes_l2=120, nodes_l1=150, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.30000000000000004, batch_size=3000, total= 5.1min\n",
      "[CV] nodes_l3=80, nodes_l2=120, nodes_l1=150, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.30000000000000004, batch_size=3000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=150)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 12s - loss: 3.0584 - acc: 0.2322\n",
      "Epoch 2/70\n",
      " - 3s - loss: 2.2256 - acc: 0.4124\n",
      "Epoch 3/70\n",
      " - 2s - loss: 1.7875 - acc: 0.5167\n",
      "Epoch 4/70\n",
      " - 2s - loss: 1.5747 - acc: 0.5659\n",
      "Epoch 5/70\n",
      " - 2s - loss: 1.4481 - acc: 0.5936\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.3711 - acc: 0.6081\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.3075 - acc: 0.6206\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.2665 - acc: 0.6287\n",
      "Epoch 9/70\n",
      " - 2s - loss: 1.2224 - acc: 0.6364\n",
      "Epoch 10/70\n",
      " - 2s - loss: 1.1975 - acc: 0.6408\n",
      "Epoch 11/70\n",
      " - 2s - loss: 1.1802 - acc: 0.6450\n",
      "Epoch 12/70\n",
      " - 2s - loss: 1.1574 - acc: 0.6467\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.1419 - acc: 0.6496\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.1264 - acc: 0.6531\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.1102 - acc: 0.6554\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.1039 - acc: 0.6585\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.0959 - acc: 0.6583\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.0856 - acc: 0.6623\n",
      "Epoch 19/70\n",
      " - 3s - loss: 1.0748 - acc: 0.6607\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.0692 - acc: 0.6612\n",
      "Epoch 21/70\n",
      " - 3s - loss: 1.0621 - acc: 0.6648\n",
      "Epoch 22/70\n",
      " - 3s - loss: 1.0548 - acc: 0.6642\n",
      "Epoch 23/70\n",
      " - 3s - loss: 1.0488 - acc: 0.6677\n",
      "Epoch 24/70\n",
      " - 3s - loss: 1.0425 - acc: 0.6683\n",
      "Epoch 25/70\n",
      " - 3s - loss: 1.0339 - acc: 0.6694\n",
      "Epoch 26/70\n",
      " - 3s - loss: 1.0303 - acc: 0.6701\n",
      "Epoch 27/70\n",
      " - 3s - loss: 1.0263 - acc: 0.6711\n",
      "Epoch 28/70\n",
      " - 3s - loss: 1.0205 - acc: 0.6718\n",
      "Epoch 29/70\n",
      " - 3s - loss: 1.0116 - acc: 0.6749\n",
      "Epoch 30/70\n",
      " - 2s - loss: 1.0108 - acc: 0.6745\n",
      "Epoch 31/70\n",
      " - 3s - loss: 1.0064 - acc: 0.6749\n",
      "Epoch 32/70\n",
      " - 2s - loss: 1.0023 - acc: 0.6757\n",
      "Epoch 33/70\n",
      " - 2s - loss: 0.9995 - acc: 0.6761\n",
      "Epoch 34/70\n",
      " - 2s - loss: 0.9953 - acc: 0.6764\n",
      "Epoch 35/70\n",
      " - 2s - loss: 0.9924 - acc: 0.6773\n",
      "Epoch 36/70\n",
      " - 2s - loss: 0.9890 - acc: 0.6789\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9802 - acc: 0.6801\n",
      "Epoch 38/70\n",
      " - 3s - loss: 0.9781 - acc: 0.6811\n",
      "Epoch 39/70\n",
      " - 2s - loss: 0.9748 - acc: 0.6821\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.9752 - acc: 0.6815\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.9678 - acc: 0.6840\n",
      "Epoch 42/70\n",
      " - 4s - loss: 0.9671 - acc: 0.6819\n",
      "Epoch 43/70\n",
      " - 4s - loss: 0.9630 - acc: 0.6841\n",
      "Epoch 44/70\n",
      " - 4s - loss: 0.9599 - acc: 0.6856\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.9579 - acc: 0.6864\n",
      "Epoch 46/70\n",
      " - 4s - loss: 0.9599 - acc: 0.6841\n",
      "Epoch 47/70\n",
      " - 5s - loss: 0.9530 - acc: 0.6855\n",
      "Epoch 48/70\n",
      " - 5s - loss: 0.9490 - acc: 0.6895\n",
      "Epoch 49/70\n",
      " - 4s - loss: 0.9482 - acc: 0.6888\n",
      "Epoch 50/70\n",
      " - 5s - loss: 0.9447 - acc: 0.6886\n",
      "Epoch 51/70\n",
      " - 5s - loss: 0.9455 - acc: 0.6893\n",
      "Epoch 52/70\n",
      " - 4s - loss: 0.9419 - acc: 0.6893\n",
      "Epoch 53/70\n",
      " - 4s - loss: 0.9395 - acc: 0.6890\n",
      "Epoch 54/70\n",
      " - 5s - loss: 0.9335 - acc: 0.6919\n",
      "Epoch 55/70\n",
      " - 5s - loss: 0.9335 - acc: 0.6914\n",
      "Epoch 56/70\n",
      " - 4s - loss: 0.9317 - acc: 0.6913\n",
      "Epoch 57/70\n",
      " - 6s - loss: 0.9306 - acc: 0.6928\n",
      "Epoch 58/70\n",
      " - 4s - loss: 0.9290 - acc: 0.6909\n",
      "Epoch 59/70\n",
      " - 4s - loss: 0.9266 - acc: 0.6926\n",
      "Epoch 60/70\n",
      " - 4s - loss: 0.9254 - acc: 0.6922\n",
      "Epoch 61/70\n",
      " - 4s - loss: 0.9231 - acc: 0.6915\n",
      "Epoch 62/70\n",
      " - 4s - loss: 0.9218 - acc: 0.6930\n",
      "Epoch 63/70\n",
      " - 4s - loss: 0.9189 - acc: 0.6932\n",
      "Epoch 64/70\n",
      " - 4s - loss: 0.9194 - acc: 0.6940\n",
      "Epoch 65/70\n",
      " - 4s - loss: 0.9141 - acc: 0.6959\n",
      "Epoch 66/70\n",
      " - 4s - loss: 0.9152 - acc: 0.6929\n",
      "Epoch 67/70\n",
      " - 4s - loss: 0.9150 - acc: 0.6940\n",
      "Epoch 68/70\n",
      " - 4s - loss: 0.9104 - acc: 0.6943\n",
      "Epoch 69/70\n",
      " - 4s - loss: 0.9142 - acc: 0.6946\n",
      "Epoch 70/70\n",
      " - 5s - loss: 0.9093 - acc: 0.6953\n",
      "[CV]  nodes_l3=80, nodes_l2=120, nodes_l1=150, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.30000000000000004, batch_size=3000, total= 4.2min\n",
      "[CV] nodes_l3=80, nodes_l2=120, nodes_l1=170, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.1, batch_size=2000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=170)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 17s - loss: 2.6816 - acc: 0.3172\n",
      "Epoch 2/70\n",
      " - 4s - loss: 1.7183 - acc: 0.5396\n",
      "Epoch 3/70\n",
      " - 4s - loss: 1.4287 - acc: 0.6016\n",
      "Epoch 4/70\n",
      " - 4s - loss: 1.3049 - acc: 0.6246\n",
      "Epoch 5/70\n",
      " - 4s - loss: 1.2315 - acc: 0.6366\n",
      "Epoch 6/70\n",
      " - 4s - loss: 1.1818 - acc: 0.6438\n",
      "Epoch 7/70\n",
      " - 4s - loss: 1.1491 - acc: 0.6513\n",
      "Epoch 8/70\n",
      " - 4s - loss: 1.1167 - acc: 0.6556\n",
      "Epoch 9/70\n",
      " - 4s - loss: 1.1007 - acc: 0.6585\n",
      "Epoch 10/70\n",
      " - 4s - loss: 1.0807 - acc: 0.6624\n",
      "Epoch 11/70\n",
      " - 4s - loss: 1.0648 - acc: 0.6666\n",
      "Epoch 12/70\n",
      " - 4s - loss: 1.0504 - acc: 0.6679\n",
      "Epoch 13/70\n",
      " - 4s - loss: 1.0419 - acc: 0.6686\n",
      "Epoch 14/70\n",
      " - 4s - loss: 1.0278 - acc: 0.6714\n",
      "Epoch 15/70\n",
      " - 4s - loss: 1.0171 - acc: 0.6742\n",
      "Epoch 16/70\n",
      " - 4s - loss: 1.0096 - acc: 0.6773\n",
      "Epoch 17/70\n",
      " - 4s - loss: 1.0011 - acc: 0.6774\n",
      "Epoch 18/70\n",
      " - 5s - loss: 0.9898 - acc: 0.6792\n",
      "Epoch 19/70\n",
      " - 4s - loss: 0.9855 - acc: 0.6806\n",
      "Epoch 20/70\n",
      " - 3s - loss: 0.9766 - acc: 0.6819\n",
      "Epoch 21/70\n",
      " - 4s - loss: 0.9695 - acc: 0.6844\n",
      "Epoch 22/70\n",
      " - 4s - loss: 0.9638 - acc: 0.6843\n",
      "Epoch 23/70\n",
      " - 4s - loss: 0.9562 - acc: 0.6847\n",
      "Epoch 24/70\n",
      " - 4s - loss: 0.9536 - acc: 0.6846\n",
      "Epoch 25/70\n",
      " - 4s - loss: 0.9439 - acc: 0.6887\n",
      "Epoch 26/70\n",
      " - 4s - loss: 0.9428 - acc: 0.6889\n",
      "Epoch 27/70\n",
      " - 4s - loss: 0.9375 - acc: 0.6901\n",
      "Epoch 28/70\n",
      " - 4s - loss: 0.9350 - acc: 0.6903\n",
      "Epoch 29/70\n",
      " - 4s - loss: 0.9267 - acc: 0.6934\n",
      "Epoch 30/70\n",
      " - 4s - loss: 0.9245 - acc: 0.6921\n",
      "Epoch 31/70\n",
      " - 4s - loss: 0.9195 - acc: 0.6943\n",
      "Epoch 32/70\n",
      " - 4s - loss: 0.9185 - acc: 0.6952\n",
      "Epoch 33/70\n",
      " - 4s - loss: 0.9089 - acc: 0.6963\n",
      "Epoch 34/70\n",
      " - 4s - loss: 0.9076 - acc: 0.6970\n",
      "Epoch 35/70\n",
      " - 4s - loss: 0.9062 - acc: 0.6973\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9042 - acc: 0.6967\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.8969 - acc: 0.6983\n",
      "Epoch 38/70\n",
      " - 4s - loss: 0.8977 - acc: 0.6993\n",
      "Epoch 39/70\n",
      " - 4s - loss: 0.8948 - acc: 0.6973\n",
      "Epoch 40/70\n",
      " - 4s - loss: 0.8931 - acc: 0.7005\n",
      "Epoch 41/70\n",
      " - 4s - loss: 0.8915 - acc: 0.6992\n",
      "Epoch 42/70\n",
      " - 4s - loss: 0.8843 - acc: 0.7007\n",
      "Epoch 43/70\n",
      " - 4s - loss: 0.8797 - acc: 0.7003\n",
      "Epoch 44/70\n",
      " - 4s - loss: 0.8811 - acc: 0.7020\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.8788 - acc: 0.7026\n",
      "Epoch 46/70\n",
      " - 4s - loss: 0.8785 - acc: 0.7015\n",
      "Epoch 47/70\n",
      " - 4s - loss: 0.8763 - acc: 0.7030\n",
      "Epoch 48/70\n",
      " - 4s - loss: 0.8706 - acc: 0.7032\n",
      "Epoch 49/70\n",
      " - 4s - loss: 0.8716 - acc: 0.7037\n",
      "Epoch 50/70\n",
      " - 4s - loss: 0.8671 - acc: 0.7030\n",
      "Epoch 51/70\n",
      " - 4s - loss: 0.8667 - acc: 0.7049\n",
      "Epoch 52/70\n",
      " - 4s - loss: 0.8613 - acc: 0.7075\n",
      "Epoch 53/70\n",
      " - 4s - loss: 0.8639 - acc: 0.7063\n",
      "Epoch 54/70\n",
      " - 4s - loss: 0.8590 - acc: 0.7066\n",
      "Epoch 55/70\n",
      " - 4s - loss: 0.8576 - acc: 0.7060\n",
      "Epoch 56/70\n",
      " - 4s - loss: 0.8574 - acc: 0.7083\n",
      "Epoch 57/70\n",
      " - 4s - loss: 0.8541 - acc: 0.7076\n",
      "Epoch 58/70\n",
      " - 4s - loss: 0.8565 - acc: 0.7076\n",
      "Epoch 59/70\n",
      " - 4s - loss: 0.8509 - acc: 0.7089\n",
      "Epoch 60/70\n",
      " - 4s - loss: 0.8507 - acc: 0.7081\n",
      "Epoch 61/70\n",
      " - 4s - loss: 0.8508 - acc: 0.7062\n",
      "Epoch 62/70\n",
      " - 4s - loss: 0.8473 - acc: 0.7092\n",
      "Epoch 63/70\n",
      " - 4s - loss: 0.8457 - acc: 0.7096\n",
      "Epoch 64/70\n",
      " - 5s - loss: 0.8441 - acc: 0.7101\n",
      "Epoch 65/70\n",
      " - 4s - loss: 0.8442 - acc: 0.7104\n",
      "Epoch 66/70\n",
      " - 4s - loss: 0.8375 - acc: 0.7109\n",
      "Epoch 67/70\n",
      " - 4s - loss: 0.8433 - acc: 0.7099\n",
      "Epoch 68/70\n",
      " - 4s - loss: 0.8404 - acc: 0.7101\n",
      "Epoch 69/70\n",
      " - 4s - loss: 0.8379 - acc: 0.7116\n",
      "Epoch 70/70\n",
      " - 4s - loss: 0.8373 - acc: 0.7130\n",
      "[CV]  nodes_l3=80, nodes_l2=120, nodes_l1=170, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.1, batch_size=2000, total= 4.8min\n",
      "[CV] nodes_l3=80, nodes_l2=120, nodes_l1=170, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.1, batch_size=2000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=170)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 8s - loss: 2.6049 - acc: 0.3223\n",
      "Epoch 2/70\n",
      " - 2s - loss: 1.7233 - acc: 0.5341\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.4360 - acc: 0.5969\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.3013 - acc: 0.6272\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.2269 - acc: 0.6390\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.1776 - acc: 0.6475\n",
      "Epoch 7/70\n",
      " - 2s - loss: 1.1433 - acc: 0.6546\n",
      "Epoch 8/70\n",
      " - 2s - loss: 1.1163 - acc: 0.6572\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.0961 - acc: 0.6625\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.0798 - acc: 0.6640\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.0620 - acc: 0.6670\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.0489 - acc: 0.6689\n",
      "Epoch 13/70\n",
      " - 2s - loss: 1.0356 - acc: 0.6721\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.0267 - acc: 0.6729\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.0152 - acc: 0.6747\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.0091 - acc: 0.6761\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.0003 - acc: 0.6777\n",
      "Epoch 18/70\n",
      " - 2s - loss: 0.9916 - acc: 0.6797\n",
      "Epoch 19/70\n",
      " - 2s - loss: 0.9850 - acc: 0.6818\n",
      "Epoch 20/70\n",
      " - 2s - loss: 0.9745 - acc: 0.6841\n",
      "Epoch 21/70\n",
      " - 3s - loss: 0.9704 - acc: 0.6845\n",
      "Epoch 22/70\n",
      " - 3s - loss: 0.9633 - acc: 0.6834\n",
      "Epoch 23/70\n",
      " - 3s - loss: 0.9599 - acc: 0.6870\n",
      "Epoch 24/70\n",
      " - 3s - loss: 0.9489 - acc: 0.6883\n",
      "Epoch 25/70\n",
      " - 2s - loss: 0.9499 - acc: 0.6863\n",
      "Epoch 26/70\n",
      " - 2s - loss: 0.9399 - acc: 0.6895\n",
      "Epoch 27/70\n",
      " - 2s - loss: 0.9370 - acc: 0.6896\n",
      "Epoch 28/70\n",
      " - 3s - loss: 0.9313 - acc: 0.6926\n",
      "Epoch 29/70\n",
      " - 3s - loss: 0.9287 - acc: 0.6912\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.9276 - acc: 0.6920\n",
      "Epoch 31/70\n",
      " - 2s - loss: 0.9196 - acc: 0.6934\n",
      "Epoch 32/70\n",
      " - 2s - loss: 0.9155 - acc: 0.6960\n",
      "Epoch 33/70\n",
      " - 3s - loss: 0.9101 - acc: 0.6950\n",
      "Epoch 34/70\n",
      " - 3s - loss: 0.9066 - acc: 0.6969\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9041 - acc: 0.6956\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9014 - acc: 0.6981\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.8996 - acc: 0.6979\n",
      "Epoch 38/70\n",
      " - 2s - loss: 0.8959 - acc: 0.6989\n",
      "Epoch 39/70\n",
      " - 2s - loss: 0.8916 - acc: 0.6995\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.8904 - acc: 0.6993\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.8858 - acc: 0.7002\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.8817 - acc: 0.7033\n",
      "Epoch 43/70\n",
      " - 2s - loss: 0.8793 - acc: 0.7034\n",
      "Epoch 44/70\n",
      " - 2s - loss: 0.8797 - acc: 0.7024\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.8776 - acc: 0.7025\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.8709 - acc: 0.7053\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.8697 - acc: 0.7057\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.8667 - acc: 0.7052\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.8672 - acc: 0.7061\n",
      "Epoch 50/70\n",
      " - 3s - loss: 0.8650 - acc: 0.7058\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.8635 - acc: 0.7056\n",
      "Epoch 52/70\n",
      " - 4s - loss: 0.8611 - acc: 0.7056\n",
      "Epoch 53/70\n",
      " - 4s - loss: 0.8582 - acc: 0.7051\n",
      "Epoch 54/70\n",
      " - 4s - loss: 0.8553 - acc: 0.7078\n",
      "Epoch 55/70\n",
      " - 4s - loss: 0.8557 - acc: 0.7071\n",
      "Epoch 56/70\n",
      " - 4s - loss: 0.8562 - acc: 0.7082\n",
      "Epoch 57/70\n",
      " - 4s - loss: 0.8536 - acc: 0.7087\n",
      "Epoch 58/70\n",
      " - 4s - loss: 0.8479 - acc: 0.7088\n",
      "Epoch 59/70\n",
      " - 4s - loss: 0.8466 - acc: 0.7078\n",
      "Epoch 60/70\n",
      " - 4s - loss: 0.8495 - acc: 0.7076\n",
      "Epoch 61/70\n",
      " - 4s - loss: 0.8462 - acc: 0.7087\n",
      "Epoch 62/70\n",
      " - 4s - loss: 0.8453 - acc: 0.7095\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.8458 - acc: 0.7086\n",
      "Epoch 64/70\n",
      " - 4s - loss: 0.8411 - acc: 0.7122\n",
      "Epoch 65/70\n",
      " - 4s - loss: 0.8408 - acc: 0.7101\n",
      "Epoch 66/70\n",
      " - 4s - loss: 0.8392 - acc: 0.7104\n",
      "Epoch 67/70\n",
      " - 4s - loss: 0.8376 - acc: 0.7090\n",
      "Epoch 68/70\n",
      " - 4s - loss: 0.8365 - acc: 0.7113\n",
      "Epoch 69/70\n",
      " - 4s - loss: 0.8340 - acc: 0.7137\n",
      "Epoch 70/70\n",
      " - 4s - loss: 0.8308 - acc: 0.7136\n",
      "[CV]  nodes_l3=80, nodes_l2=120, nodes_l1=170, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.1, batch_size=2000, total= 3.6min\n",
      "[CV] nodes_l3=80, nodes_l2=120, nodes_l1=170, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.1, batch_size=2000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=170)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 12s - loss: 2.6359 - acc: 0.3247\n",
      "Epoch 2/70\n",
      " - 4s - loss: 1.7128 - acc: 0.5407\n",
      "Epoch 3/70\n",
      " - 4s - loss: 1.4141 - acc: 0.6046\n",
      "Epoch 4/70\n",
      " - 4s - loss: 1.2863 - acc: 0.6305\n",
      "Epoch 5/70\n",
      " - 4s - loss: 1.2047 - acc: 0.6434\n",
      "Epoch 6/70\n",
      " - 4s - loss: 1.1629 - acc: 0.6488\n",
      "Epoch 7/70\n",
      " - 4s - loss: 1.1319 - acc: 0.6543\n",
      "Epoch 8/70\n",
      " - 5s - loss: 1.1003 - acc: 0.6613\n",
      "Epoch 9/70\n",
      " - 4s - loss: 1.0838 - acc: 0.6626\n",
      "Epoch 10/70\n",
      " - 4s - loss: 1.0617 - acc: 0.6667\n",
      "Epoch 11/70\n",
      " - 5s - loss: 1.0527 - acc: 0.6689\n",
      "Epoch 12/70\n",
      " - 4s - loss: 1.0343 - acc: 0.6735\n",
      "Epoch 13/70\n",
      " - 4s - loss: 1.0229 - acc: 0.6754\n",
      "Epoch 14/70\n",
      " - 4s - loss: 1.0094 - acc: 0.6768\n",
      "Epoch 15/70\n",
      " - 4s - loss: 1.0012 - acc: 0.6785\n",
      "Epoch 16/70\n",
      " - 4s - loss: 0.9940 - acc: 0.6803\n",
      "Epoch 17/70\n",
      " - 4s - loss: 0.9849 - acc: 0.6799\n",
      "Epoch 18/70\n",
      " - 4s - loss: 0.9779 - acc: 0.6828\n",
      "Epoch 19/70\n",
      " - 4s - loss: 0.9666 - acc: 0.6834\n",
      "Epoch 20/70\n",
      " - 4s - loss: 0.9574 - acc: 0.6873\n",
      "Epoch 21/70\n",
      " - 4s - loss: 0.9543 - acc: 0.6869\n",
      "Epoch 22/70\n",
      " - 3s - loss: 0.9482 - acc: 0.6884\n",
      "Epoch 23/70\n",
      " - 3s - loss: 0.9441 - acc: 0.6893\n",
      "Epoch 24/70\n",
      " - 4s - loss: 0.9345 - acc: 0.6909\n",
      "Epoch 25/70\n",
      " - 5s - loss: 0.9318 - acc: 0.6926\n",
      "Epoch 26/70\n",
      " - 4s - loss: 0.9250 - acc: 0.6931\n",
      "Epoch 27/70\n",
      " - 4s - loss: 0.9215 - acc: 0.6946\n",
      "Epoch 28/70\n",
      " - 5s - loss: 0.9154 - acc: 0.6964\n",
      "Epoch 29/70\n",
      " - 4s - loss: 0.9100 - acc: 0.6963\n",
      "Epoch 30/70\n",
      " - 4s - loss: 0.9099 - acc: 0.6960\n",
      "Epoch 31/70\n",
      " - 4s - loss: 0.9025 - acc: 0.6984\n",
      "Epoch 32/70\n",
      " - 4s - loss: 0.8997 - acc: 0.6992\n",
      "Epoch 33/70\n",
      " - 5s - loss: 0.8961 - acc: 0.7004\n",
      "Epoch 34/70\n",
      " - 4s - loss: 0.8934 - acc: 0.6993\n",
      "Epoch 35/70\n",
      " - 4s - loss: 0.8888 - acc: 0.7019\n",
      "Epoch 36/70\n",
      " - 4s - loss: 0.8854 - acc: 0.7007\n",
      "Epoch 37/70\n",
      " - 4s - loss: 0.8852 - acc: 0.7014\n",
      "Epoch 38/70\n",
      " - 4s - loss: 0.8788 - acc: 0.7017\n",
      "Epoch 39/70\n",
      " - 4s - loss: 0.8762 - acc: 0.7038\n",
      "Epoch 40/70\n",
      " - 4s - loss: 0.8723 - acc: 0.7050\n",
      "Epoch 41/70\n",
      " - 4s - loss: 0.8737 - acc: 0.7039\n",
      "Epoch 42/70\n",
      " - 4s - loss: 0.8684 - acc: 0.7036\n",
      "Epoch 43/70\n",
      " - 4s - loss: 0.8655 - acc: 0.7043\n",
      "Epoch 44/70\n",
      " - 4s - loss: 0.8641 - acc: 0.7065\n",
      "Epoch 45/70\n",
      " - 4s - loss: 0.8606 - acc: 0.7056\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.8592 - acc: 0.7051\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.8575 - acc: 0.7065\n",
      "Epoch 48/70\n",
      " - 4s - loss: 0.8539 - acc: 0.7086\n",
      "Epoch 49/70\n",
      " - 4s - loss: 0.8524 - acc: 0.7090\n",
      "Epoch 50/70\n",
      " - 4s - loss: 0.8541 - acc: 0.7082\n",
      "Epoch 51/70\n",
      " - 4s - loss: 0.8441 - acc: 0.7103\n",
      "Epoch 52/70\n",
      " - 4s - loss: 0.8470 - acc: 0.7085\n",
      "Epoch 53/70\n",
      " - 4s - loss: 0.8449 - acc: 0.7093\n",
      "Epoch 54/70\n",
      " - 4s - loss: 0.8460 - acc: 0.7088\n",
      "Epoch 55/70\n",
      " - 4s - loss: 0.8375 - acc: 0.7129\n",
      "Epoch 56/70\n",
      " - 4s - loss: 0.8413 - acc: 0.7094\n",
      "Epoch 57/70\n",
      " - 4s - loss: 0.8380 - acc: 0.7118\n",
      "Epoch 58/70\n",
      " - 4s - loss: 0.8365 - acc: 0.7133\n",
      "Epoch 59/70\n",
      " - 4s - loss: 0.8352 - acc: 0.7107\n",
      "Epoch 60/70\n",
      " - 4s - loss: 0.8307 - acc: 0.7129\n",
      "Epoch 61/70\n",
      " - 4s - loss: 0.8311 - acc: 0.7125\n",
      "Epoch 62/70\n",
      " - 4s - loss: 0.8282 - acc: 0.7139\n",
      "Epoch 63/70\n",
      " - 4s - loss: 0.8268 - acc: 0.7133\n",
      "Epoch 64/70\n",
      " - 4s - loss: 0.8258 - acc: 0.7135\n",
      "Epoch 65/70\n",
      " - 4s - loss: 0.8261 - acc: 0.7141\n",
      "Epoch 66/70\n",
      " - 4s - loss: 0.8234 - acc: 0.7151\n",
      "Epoch 67/70\n",
      " - 4s - loss: 0.8237 - acc: 0.7135\n",
      "Epoch 68/70\n",
      " - 4s - loss: 0.8199 - acc: 0.7161\n",
      "Epoch 69/70\n",
      " - 4s - loss: 0.8205 - acc: 0.7154\n",
      "Epoch 70/70\n",
      " - 4s - loss: 0.8176 - acc: 0.7155\n",
      "[CV]  nodes_l3=80, nodes_l2=120, nodes_l1=170, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.1, batch_size=2000, total= 4.8min\n",
      "[CV] nodes_l3=80, nodes_l2=120, nodes_l1=170, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.1, batch_size=2000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=170)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 9s - loss: 2.7606 - acc: 0.2858\n",
      "Epoch 2/70\n",
      " - 3s - loss: 1.7801 - acc: 0.5201\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.4583 - acc: 0.5906\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.3095 - acc: 0.6240\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.2304 - acc: 0.6379\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.1807 - acc: 0.6449\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.1465 - acc: 0.6509\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.1213 - acc: 0.6561\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.0991 - acc: 0.6603\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.0831 - acc: 0.6614\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.0697 - acc: 0.6636\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.0552 - acc: 0.6658\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.0439 - acc: 0.6684\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.0307 - acc: 0.6721\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.0231 - acc: 0.6722\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.0107 - acc: 0.6754\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.0040 - acc: 0.6752\n",
      "Epoch 18/70\n",
      " - 3s - loss: 0.9956 - acc: 0.6779\n",
      "Epoch 19/70\n",
      " - 3s - loss: 0.9885 - acc: 0.6793\n",
      "Epoch 20/70\n",
      " - 3s - loss: 0.9827 - acc: 0.6802\n",
      "Epoch 21/70\n",
      " - 3s - loss: 0.9760 - acc: 0.6794\n",
      "Epoch 22/70\n",
      " - 3s - loss: 0.9673 - acc: 0.6818\n",
      "Epoch 23/70\n",
      " - 3s - loss: 0.9598 - acc: 0.6843\n",
      "Epoch 24/70\n",
      " - 3s - loss: 0.9568 - acc: 0.6843\n",
      "Epoch 25/70\n",
      " - 3s - loss: 0.9535 - acc: 0.6863\n",
      "Epoch 26/70\n",
      " - 3s - loss: 0.9463 - acc: 0.6866\n",
      "Epoch 27/70\n",
      " - 3s - loss: 0.9377 - acc: 0.6884\n",
      "Epoch 28/70\n",
      " - 3s - loss: 0.9322 - acc: 0.6901\n",
      "Epoch 29/70\n",
      " - 3s - loss: 0.9290 - acc: 0.6882\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.9280 - acc: 0.6889\n",
      "Epoch 31/70\n",
      " - 4s - loss: 0.9224 - acc: 0.6922\n",
      "Epoch 32/70\n",
      " - 3s - loss: 0.9164 - acc: 0.6942\n",
      "Epoch 33/70\n",
      " - 3s - loss: 0.9153 - acc: 0.6946\n",
      "Epoch 34/70\n",
      " - 3s - loss: 0.9123 - acc: 0.6941\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9054 - acc: 0.6938\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9036 - acc: 0.6956\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9003 - acc: 0.6956\n",
      "Epoch 38/70\n",
      " - 4s - loss: 0.8982 - acc: 0.6971\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.8953 - acc: 0.6982\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.8927 - acc: 0.6981\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.8910 - acc: 0.6991\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.8873 - acc: 0.6991\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.8857 - acc: 0.6988\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.8808 - acc: 0.7006\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.8794 - acc: 0.7001\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.8758 - acc: 0.7031\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.8738 - acc: 0.7024\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.8729 - acc: 0.7034\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.8717 - acc: 0.7019\n",
      "Epoch 50/70\n",
      " - 3s - loss: 0.8684 - acc: 0.7043\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.8672 - acc: 0.7037\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.8649 - acc: 0.7045\n",
      "Epoch 53/70\n",
      " - 3s - loss: 0.8630 - acc: 0.7036\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.8603 - acc: 0.7040\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.8571 - acc: 0.7065\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.8534 - acc: 0.7052\n",
      "Epoch 57/70\n",
      " - 4s - loss: 0.8536 - acc: 0.7053\n",
      "Epoch 58/70\n",
      " - 4s - loss: 0.8557 - acc: 0.7063\n",
      "Epoch 59/70\n",
      " - 4s - loss: 0.8506 - acc: 0.7070\n",
      "Epoch 60/70\n",
      " - 4s - loss: 0.8550 - acc: 0.7054\n",
      "Epoch 61/70\n",
      " - 4s - loss: 0.8509 - acc: 0.7056\n",
      "Epoch 62/70\n",
      " - 4s - loss: 0.8492 - acc: 0.7085\n",
      "Epoch 63/70\n",
      " - 4s - loss: 0.8444 - acc: 0.7088\n",
      "Epoch 64/70\n",
      " - 4s - loss: 0.8451 - acc: 0.7082\n",
      "Epoch 65/70\n",
      " - 5s - loss: 0.8428 - acc: 0.7075\n",
      "Epoch 66/70\n",
      " - 4s - loss: 0.8409 - acc: 0.7108\n",
      "Epoch 67/70\n",
      " - 6s - loss: 0.8425 - acc: 0.7075\n",
      "Epoch 68/70\n",
      " - 5s - loss: 0.8409 - acc: 0.7083\n",
      "Epoch 69/70\n",
      " - 4s - loss: 0.8392 - acc: 0.7096\n",
      "Epoch 70/70\n",
      " - 4s - loss: 0.8366 - acc: 0.7096\n",
      "[CV]  nodes_l3=80, nodes_l2=120, nodes_l1=170, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.1, batch_size=2000, total= 3.9min\n",
      "[CV] nodes_l3=70, nodes_l2=130, nodes_l1=160, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.1, batch_size=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=160)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=130)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=130)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 21s - loss: 2.1967 - acc: 0.4281\n",
      "Epoch 2/70\n",
      " - 6s - loss: 1.4062 - acc: 0.6077\n",
      "Epoch 3/70\n",
      " - 7s - loss: 1.2358 - acc: 0.6345\n",
      "Epoch 4/70\n",
      " - 7s - loss: 1.1601 - acc: 0.6488\n",
      "Epoch 5/70\n",
      " - 6s - loss: 1.1146 - acc: 0.6574\n",
      "Epoch 6/70\n",
      " - 6s - loss: 1.0809 - acc: 0.6618\n",
      "Epoch 7/70\n",
      " - 5s - loss: 1.0584 - acc: 0.6664\n",
      "Epoch 8/70\n",
      " - 6s - loss: 1.0370 - acc: 0.6693\n",
      "Epoch 9/70\n",
      " - 6s - loss: 1.0185 - acc: 0.6744\n",
      "Epoch 10/70\n",
      " - 6s - loss: 1.0043 - acc: 0.6767\n",
      "Epoch 11/70\n",
      " - 6s - loss: 0.9906 - acc: 0.6797\n",
      "Epoch 12/70\n",
      " - 5s - loss: 0.9766 - acc: 0.6821\n",
      "Epoch 13/70\n",
      " - 6s - loss: 0.9694 - acc: 0.6833\n",
      "Epoch 14/70\n",
      " - 5s - loss: 0.9598 - acc: 0.6866\n",
      "Epoch 15/70\n",
      " - 5s - loss: 0.9531 - acc: 0.6866\n",
      "Epoch 16/70\n",
      " - 6s - loss: 0.9403 - acc: 0.6896\n",
      "Epoch 17/70\n",
      " - 5s - loss: 0.9330 - acc: 0.6915\n",
      "Epoch 18/70\n",
      " - 5s - loss: 0.9268 - acc: 0.6937\n",
      "Epoch 19/70\n",
      " - 6s - loss: 0.9201 - acc: 0.6954\n",
      "Epoch 20/70\n",
      " - 5s - loss: 0.9141 - acc: 0.6964\n",
      "Epoch 21/70\n",
      " - 6s - loss: 0.9083 - acc: 0.6960\n",
      "Epoch 22/70\n",
      " - 6s - loss: 0.9055 - acc: 0.6954\n",
      "Epoch 23/70\n",
      " - 5s - loss: 0.8984 - acc: 0.6982\n",
      "Epoch 24/70\n",
      " - 5s - loss: 0.8922 - acc: 0.7009\n",
      "Epoch 25/70\n",
      " - 5s - loss: 0.8910 - acc: 0.6994\n",
      "Epoch 26/70\n",
      " - 5s - loss: 0.8859 - acc: 0.7007\n",
      "Epoch 27/70\n",
      " - 5s - loss: 0.8808 - acc: 0.7023\n",
      "Epoch 28/70\n",
      " - 6s - loss: 0.8778 - acc: 0.7031\n",
      "Epoch 29/70\n",
      " - 5s - loss: 0.8778 - acc: 0.7026\n",
      "Epoch 30/70\n",
      " - 5s - loss: 0.8729 - acc: 0.7044\n",
      "Epoch 31/70\n",
      " - 7s - loss: 0.8676 - acc: 0.7032\n",
      "Epoch 32/70\n",
      " - 5s - loss: 0.8660 - acc: 0.7051\n",
      "Epoch 33/70\n",
      " - 5s - loss: 0.8634 - acc: 0.7055\n",
      "Epoch 34/70\n",
      " - 6s - loss: 0.8590 - acc: 0.7066\n",
      "Epoch 35/70\n",
      " - 6s - loss: 0.8571 - acc: 0.7070\n",
      "Epoch 36/70\n",
      " - 5s - loss: 0.8529 - acc: 0.7083\n",
      "Epoch 37/70\n",
      " - 5s - loss: 0.8519 - acc: 0.7090\n",
      "Epoch 38/70\n",
      " - 5s - loss: 0.8492 - acc: 0.7083\n",
      "Epoch 39/70\n",
      " - 5s - loss: 0.8474 - acc: 0.7088\n",
      "Epoch 40/70\n",
      " - 6s - loss: 0.8455 - acc: 0.7102\n",
      "Epoch 41/70\n",
      " - 5s - loss: 0.8449 - acc: 0.7091\n",
      "Epoch 42/70\n",
      " - 6s - loss: 0.8370 - acc: 0.7105\n",
      "Epoch 43/70\n",
      " - 5s - loss: 0.8392 - acc: 0.7101\n",
      "Epoch 44/70\n",
      " - 5s - loss: 0.8387 - acc: 0.7089\n",
      "Epoch 45/70\n",
      " - 5s - loss: 0.8361 - acc: 0.7110\n",
      "Epoch 46/70\n",
      " - 5s - loss: 0.8343 - acc: 0.7114\n",
      "Epoch 47/70\n",
      " - 5s - loss: 0.8311 - acc: 0.7118\n",
      "Epoch 48/70\n",
      " - 6s - loss: 0.8295 - acc: 0.7131\n",
      "Epoch 49/70\n",
      " - 6s - loss: 0.8288 - acc: 0.7129\n",
      "Epoch 50/70\n",
      " - 5s - loss: 0.8243 - acc: 0.7136\n",
      "Epoch 51/70\n",
      " - 5s - loss: 0.8248 - acc: 0.7135\n",
      "Epoch 52/70\n",
      " - 5s - loss: 0.8252 - acc: 0.7142\n",
      "Epoch 53/70\n",
      " - 5s - loss: 0.8214 - acc: 0.7142\n",
      "Epoch 54/70\n",
      " - 6s - loss: 0.8206 - acc: 0.7154\n",
      "Epoch 55/70\n",
      " - 5s - loss: 0.8179 - acc: 0.7154\n",
      "Epoch 56/70\n",
      " - 6s - loss: 0.8174 - acc: 0.7158\n",
      "Epoch 57/70\n",
      " - 5s - loss: 0.8151 - acc: 0.7151\n",
      "Epoch 58/70\n",
      " - 5s - loss: 0.8113 - acc: 0.7167\n",
      "Epoch 59/70\n",
      " - 5s - loss: 0.8141 - acc: 0.7159\n",
      "Epoch 60/70\n",
      " - 6s - loss: 0.8129 - acc: 0.7156\n",
      "Epoch 61/70\n",
      " - 5s - loss: 0.8110 - acc: 0.7166\n",
      "Epoch 62/70\n",
      " - 4s - loss: 0.8083 - acc: 0.7172\n",
      "Epoch 63/70\n",
      " - 4s - loss: 0.8078 - acc: 0.7185\n",
      "Epoch 64/70\n",
      " - 4s - loss: 0.8110 - acc: 0.7168\n",
      "Epoch 65/70\n",
      " - 4s - loss: 0.8037 - acc: 0.7171\n",
      "Epoch 66/70\n",
      " - 4s - loss: 0.8014 - acc: 0.7182\n",
      "Epoch 67/70\n",
      " - 4s - loss: 0.8016 - acc: 0.7186\n",
      "Epoch 68/70\n",
      " - 4s - loss: 0.8034 - acc: 0.7193\n",
      "Epoch 69/70\n",
      " - 4s - loss: 0.7993 - acc: 0.7200\n",
      "Epoch 70/70\n",
      " - 4s - loss: 0.8008 - acc: 0.7183\n",
      "[CV]  nodes_l3=70, nodes_l2=130, nodes_l1=160, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.1, batch_size=1000, total= 6.6min\n",
      "[CV] nodes_l3=70, nodes_l2=130, nodes_l1=160, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.1, batch_size=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=160)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=130)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=130)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 11s - loss: 2.2410 - acc: 0.4163\n",
      "Epoch 2/70\n",
      " - 4s - loss: 1.4254 - acc: 0.6046\n",
      "Epoch 3/70\n",
      " - 4s - loss: 1.2423 - acc: 0.6357\n",
      "Epoch 4/70\n",
      " - 4s - loss: 1.1618 - acc: 0.6488\n",
      "Epoch 5/70\n",
      " - 4s - loss: 1.1195 - acc: 0.6555\n",
      "Epoch 6/70\n",
      " - 4s - loss: 1.0827 - acc: 0.6637\n",
      "Epoch 7/70\n",
      " - 4s - loss: 1.0588 - acc: 0.6679\n",
      "Epoch 8/70\n",
      " - 4s - loss: 1.0384 - acc: 0.6708\n",
      "Epoch 9/70\n",
      " - 4s - loss: 1.0202 - acc: 0.6753\n",
      "Epoch 10/70\n",
      " - 4s - loss: 1.0061 - acc: 0.6775\n",
      "Epoch 11/70\n",
      " - 4s - loss: 0.9941 - acc: 0.6783\n",
      "Epoch 12/70\n",
      " - 4s - loss: 0.9813 - acc: 0.6818\n",
      "Epoch 13/70\n",
      " - 4s - loss: 0.9721 - acc: 0.6827\n",
      "Epoch 14/70\n",
      " - 3s - loss: 0.9582 - acc: 0.6863\n",
      "Epoch 15/70\n",
      " - 4s - loss: 0.9539 - acc: 0.6868\n",
      "Epoch 16/70\n",
      " - 4s - loss: 0.9456 - acc: 0.6900\n",
      "Epoch 17/70\n",
      " - 4s - loss: 0.9371 - acc: 0.6898\n",
      "Epoch 18/70\n",
      " - 4s - loss: 0.9297 - acc: 0.6929\n",
      "Epoch 19/70\n",
      " - 4s - loss: 0.9238 - acc: 0.6941\n",
      "Epoch 20/70\n",
      " - 4s - loss: 0.9170 - acc: 0.6942\n",
      "Epoch 21/70\n",
      " - 4s - loss: 0.9113 - acc: 0.6964\n",
      "Epoch 22/70\n",
      " - 4s - loss: 0.9073 - acc: 0.6960\n",
      "Epoch 23/70\n",
      " - 4s - loss: 0.9013 - acc: 0.6983\n",
      "Epoch 24/70\n",
      " - 4s - loss: 0.8954 - acc: 0.6993\n",
      "Epoch 25/70\n",
      " - 4s - loss: 0.8898 - acc: 0.7034\n",
      "Epoch 26/70\n",
      " - 4s - loss: 0.8872 - acc: 0.7019\n",
      "Epoch 27/70\n",
      " - 4s - loss: 0.8847 - acc: 0.7004\n",
      "Epoch 28/70\n",
      " - 4s - loss: 0.8809 - acc: 0.7008\n",
      "Epoch 29/70\n",
      " - 4s - loss: 0.8748 - acc: 0.7034\n",
      "Epoch 30/70\n",
      " - 4s - loss: 0.8758 - acc: 0.7026\n",
      "Epoch 31/70\n",
      " - 5s - loss: 0.8687 - acc: 0.7048\n",
      "Epoch 32/70\n",
      " - 4s - loss: 0.8643 - acc: 0.7071\n",
      "Epoch 33/70\n",
      " - 4s - loss: 0.8634 - acc: 0.7064\n",
      "Epoch 34/70\n",
      " - 4s - loss: 0.8662 - acc: 0.7050\n",
      "Epoch 35/70\n",
      " - 5s - loss: 0.8565 - acc: 0.7082\n",
      "Epoch 36/70\n",
      " - 4s - loss: 0.8547 - acc: 0.7077\n",
      "Epoch 37/70\n",
      " - 6s - loss: 0.8544 - acc: 0.7096\n",
      "Epoch 38/70\n",
      " - 5s - loss: 0.8534 - acc: 0.7072\n",
      "Epoch 39/70\n",
      " - 5s - loss: 0.8479 - acc: 0.7083\n",
      "Epoch 40/70\n",
      " - 5s - loss: 0.8466 - acc: 0.7094\n",
      "Epoch 41/70\n",
      " - 6s - loss: 0.8443 - acc: 0.7100\n",
      "Epoch 42/70\n",
      " - 6s - loss: 0.8444 - acc: 0.7099\n",
      "Epoch 43/70\n",
      " - 5s - loss: 0.8403 - acc: 0.7111\n",
      "Epoch 44/70\n",
      " - 6s - loss: 0.8370 - acc: 0.7127\n",
      "Epoch 45/70\n",
      " - 5s - loss: 0.8379 - acc: 0.7132\n",
      "Epoch 46/70\n",
      " - 5s - loss: 0.8373 - acc: 0.7138\n",
      "Epoch 47/70\n",
      " - 6s - loss: 0.8304 - acc: 0.7133\n",
      "Epoch 48/70\n",
      " - 5s - loss: 0.8316 - acc: 0.7135\n",
      "Epoch 49/70\n",
      " - 5s - loss: 0.8296 - acc: 0.7139\n",
      "Epoch 50/70\n",
      " - 6s - loss: 0.8259 - acc: 0.7156\n",
      "Epoch 51/70\n",
      " - 5s - loss: 0.8251 - acc: 0.7149\n",
      "Epoch 52/70\n",
      " - 5s - loss: 0.8240 - acc: 0.7137\n",
      "Epoch 53/70\n",
      " - 7s - loss: 0.8220 - acc: 0.7153\n",
      "Epoch 54/70\n",
      " - 5s - loss: 0.8234 - acc: 0.7134\n",
      "Epoch 55/70\n",
      " - 5s - loss: 0.8218 - acc: 0.7153\n",
      "Epoch 56/70\n",
      " - 5s - loss: 0.8193 - acc: 0.7158\n",
      "Epoch 57/70\n",
      " - 6s - loss: 0.8178 - acc: 0.7164\n",
      "Epoch 58/70\n",
      " - 8s - loss: 0.8142 - acc: 0.7161\n",
      "Epoch 59/70\n",
      " - 7s - loss: 0.8143 - acc: 0.7166\n",
      "Epoch 60/70\n",
      " - 6s - loss: 0.8114 - acc: 0.7173\n",
      "Epoch 61/70\n",
      " - 6s - loss: 0.8102 - acc: 0.7177\n",
      "Epoch 62/70\n",
      " - 5s - loss: 0.8096 - acc: 0.7171\n",
      "Epoch 63/70\n",
      " - 6s - loss: 0.8073 - acc: 0.7182\n",
      "Epoch 64/70\n",
      " - 6s - loss: 0.8080 - acc: 0.7174\n",
      "Epoch 65/70\n",
      " - 5s - loss: 0.8063 - acc: 0.7178\n",
      "Epoch 66/70\n",
      " - 5s - loss: 0.8059 - acc: 0.7187\n",
      "Epoch 67/70\n",
      " - 6s - loss: 0.8048 - acc: 0.7201\n",
      "Epoch 68/70\n",
      " - 5s - loss: 0.8026 - acc: 0.7197\n",
      "Epoch 69/70\n",
      " - 5s - loss: 0.7998 - acc: 0.7201\n",
      "Epoch 70/70\n",
      " - 6s - loss: 0.7998 - acc: 0.7187\n",
      "[CV]  nodes_l3=70, nodes_l2=130, nodes_l1=160, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.1, batch_size=1000, total= 5.8min\n",
      "[CV] nodes_l3=70, nodes_l2=130, nodes_l1=160, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.1, batch_size=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=160)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=130)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=130)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 15s - loss: 2.2325 - acc: 0.4117\n",
      "Epoch 2/70\n",
      " - 5s - loss: 1.4073 - acc: 0.6056\n",
      "Epoch 3/70\n",
      " - 5s - loss: 1.2313 - acc: 0.6354\n",
      "Epoch 4/70\n",
      " - 5s - loss: 1.1507 - acc: 0.6516\n",
      "Epoch 5/70\n",
      " - 5s - loss: 1.1065 - acc: 0.6565\n",
      "Epoch 6/70\n",
      " - 5s - loss: 1.0672 - acc: 0.6651\n",
      "Epoch 7/70\n",
      " - 5s - loss: 1.0378 - acc: 0.6705\n",
      "Epoch 8/70\n",
      " - 5s - loss: 1.0258 - acc: 0.6727\n",
      "Epoch 9/70\n",
      " - 5s - loss: 1.0039 - acc: 0.6766\n",
      "Epoch 10/70\n",
      " - 5s - loss: 0.9914 - acc: 0.6789\n",
      "Epoch 11/70\n",
      " - 5s - loss: 0.9770 - acc: 0.6813\n",
      "Epoch 12/70\n",
      " - 5s - loss: 0.9660 - acc: 0.6848\n",
      "Epoch 13/70\n",
      " - 5s - loss: 0.9557 - acc: 0.6865\n",
      "Epoch 14/70\n",
      " - 5s - loss: 0.9452 - acc: 0.6868\n",
      "Epoch 15/70\n",
      " - 5s - loss: 0.9372 - acc: 0.6898\n",
      "Epoch 16/70\n",
      " - 5s - loss: 0.9295 - acc: 0.6898\n",
      "Epoch 17/70\n",
      " - 5s - loss: 0.9221 - acc: 0.6938\n",
      "Epoch 18/70\n",
      " - 6s - loss: 0.9146 - acc: 0.6962\n",
      "Epoch 19/70\n",
      " - 6s - loss: 0.9120 - acc: 0.6963\n",
      "Epoch 20/70\n",
      " - 5s - loss: 0.9039 - acc: 0.6969\n",
      "Epoch 21/70\n",
      " - 6s - loss: 0.8970 - acc: 0.6995\n",
      "Epoch 22/70\n",
      " - 5s - loss: 0.8926 - acc: 0.7001\n",
      "Epoch 23/70\n",
      " - 5s - loss: 0.8853 - acc: 0.7009\n",
      "Epoch 24/70\n",
      " - 5s - loss: 0.8814 - acc: 0.6999\n",
      "Epoch 25/70\n",
      " - 5s - loss: 0.8771 - acc: 0.7029\n",
      "Epoch 26/70\n",
      " - 5s - loss: 0.8738 - acc: 0.7036\n",
      "Epoch 27/70\n",
      " - 5s - loss: 0.8677 - acc: 0.7030\n",
      "Epoch 28/70\n",
      " - 5s - loss: 0.8676 - acc: 0.7051\n",
      "Epoch 29/70\n",
      " - 5s - loss: 0.8633 - acc: 0.7056\n",
      "Epoch 30/70\n",
      " - 5s - loss: 0.8591 - acc: 0.7088\n",
      "Epoch 31/70\n",
      " - 5s - loss: 0.8565 - acc: 0.7070\n",
      "Epoch 32/70\n",
      " - 5s - loss: 0.8519 - acc: 0.7073\n",
      "Epoch 33/70\n",
      " - 5s - loss: 0.8485 - acc: 0.7092\n",
      "Epoch 34/70\n",
      " - 4s - loss: 0.8458 - acc: 0.7102\n",
      "Epoch 35/70\n",
      " - 4s - loss: 0.8432 - acc: 0.7092\n",
      "Epoch 36/70\n",
      " - 4s - loss: 0.8424 - acc: 0.7093\n",
      "Epoch 37/70\n",
      " - 4s - loss: 0.8415 - acc: 0.7114\n",
      "Epoch 38/70\n",
      " - 4s - loss: 0.8381 - acc: 0.7109\n",
      "Epoch 39/70\n",
      " - 4s - loss: 0.8340 - acc: 0.7111\n",
      "Epoch 40/70\n",
      " - 4s - loss: 0.8334 - acc: 0.7108\n",
      "Epoch 41/70\n",
      " - 4s - loss: 0.8299 - acc: 0.7133\n",
      "Epoch 42/70\n",
      " - 4s - loss: 0.8290 - acc: 0.7130\n",
      "Epoch 43/70\n",
      " - 4s - loss: 0.8271 - acc: 0.7136\n",
      "Epoch 44/70\n",
      " - 4s - loss: 0.8249 - acc: 0.7143\n",
      "Epoch 45/70\n",
      " - 4s - loss: 0.8210 - acc: 0.7149\n",
      "Epoch 46/70\n",
      " - 4s - loss: 0.8199 - acc: 0.7156\n",
      "Epoch 47/70\n",
      " - 4s - loss: 0.8178 - acc: 0.7162\n",
      "Epoch 48/70\n",
      " - 4s - loss: 0.8186 - acc: 0.7155\n",
      "Epoch 49/70\n",
      " - 4s - loss: 0.8172 - acc: 0.7147\n",
      "Epoch 50/70\n",
      " - 4s - loss: 0.8138 - acc: 0.7163\n",
      "Epoch 51/70\n",
      " - 4s - loss: 0.8140 - acc: 0.7170\n",
      "Epoch 52/70\n",
      " - 4s - loss: 0.8118 - acc: 0.7167\n",
      "Epoch 53/70\n",
      " - 4s - loss: 0.8091 - acc: 0.7177\n",
      "Epoch 54/70\n",
      " - 4s - loss: 0.8075 - acc: 0.7186\n",
      "Epoch 55/70\n",
      " - 4s - loss: 0.8029 - acc: 0.7178\n",
      "Epoch 56/70\n",
      " - 4s - loss: 0.8062 - acc: 0.7177\n",
      "Epoch 57/70\n",
      " - 4s - loss: 0.8033 - acc: 0.7190\n",
      "Epoch 58/70\n",
      " - 4s - loss: 0.8015 - acc: 0.7195\n",
      "Epoch 59/70\n",
      " - 4s - loss: 0.8013 - acc: 0.7189\n",
      "Epoch 60/70\n",
      " - 4s - loss: 0.8005 - acc: 0.7183\n",
      "Epoch 61/70\n",
      " - 4s - loss: 0.7980 - acc: 0.7205\n",
      "Epoch 62/70\n",
      " - 4s - loss: 0.7957 - acc: 0.7197\n",
      "Epoch 63/70\n",
      " - 4s - loss: 0.7965 - acc: 0.7211\n",
      "Epoch 64/70\n",
      " - 4s - loss: 0.7957 - acc: 0.7206\n",
      "Epoch 65/70\n",
      " - 4s - loss: 0.7928 - acc: 0.7207\n",
      "Epoch 66/70\n",
      " - 4s - loss: 0.7927 - acc: 0.7219\n",
      "Epoch 67/70\n",
      " - 4s - loss: 0.7924 - acc: 0.7216\n",
      "Epoch 68/70\n",
      " - 4s - loss: 0.7923 - acc: 0.7221\n",
      "Epoch 69/70\n",
      " - 4s - loss: 0.7907 - acc: 0.7228\n",
      "Epoch 70/70\n",
      " - 4s - loss: 0.7886 - acc: 0.7219\n",
      "[CV]  nodes_l3=70, nodes_l2=130, nodes_l1=160, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.1, batch_size=1000, total= 5.4min\n",
      "[CV] nodes_l3=70, nodes_l2=130, nodes_l1=160, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.1, batch_size=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=160)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=130)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=130)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 9s - loss: 2.2950 - acc: 0.4075\n",
      "Epoch 2/70\n",
      " - 4s - loss: 1.4433 - acc: 0.5965\n",
      "Epoch 3/70\n",
      " - 4s - loss: 1.2517 - acc: 0.6330\n",
      "Epoch 4/70\n",
      " - 4s - loss: 1.1689 - acc: 0.6474\n",
      "Epoch 5/70\n",
      " - 4s - loss: 1.1228 - acc: 0.6557\n",
      "Epoch 6/70\n",
      " - 4s - loss: 1.0877 - acc: 0.6597\n",
      "Epoch 7/70\n",
      " - 4s - loss: 1.0611 - acc: 0.6649\n",
      "Epoch 8/70\n",
      " - 4s - loss: 1.0387 - acc: 0.6695\n",
      "Epoch 9/70\n",
      " - 4s - loss: 1.0237 - acc: 0.6721\n",
      "Epoch 10/70\n",
      " - 4s - loss: 1.0079 - acc: 0.6746\n",
      "Epoch 11/70\n",
      " - 4s - loss: 0.9915 - acc: 0.6796\n",
      "Epoch 12/70\n",
      " - 4s - loss: 0.9846 - acc: 0.6813\n",
      "Epoch 13/70\n",
      " - 4s - loss: 0.9737 - acc: 0.6823\n",
      "Epoch 14/70\n",
      " - 4s - loss: 0.9609 - acc: 0.6830\n",
      "Epoch 15/70\n",
      " - 4s - loss: 0.9471 - acc: 0.6867\n",
      "Epoch 16/70\n",
      " - 4s - loss: 0.9458 - acc: 0.6873\n",
      "Epoch 17/70\n",
      " - 4s - loss: 0.9356 - acc: 0.6898\n",
      "Epoch 18/70\n",
      " - 4s - loss: 0.9260 - acc: 0.6910\n",
      "Epoch 19/70\n",
      " - 4s - loss: 0.9250 - acc: 0.6906\n",
      "Epoch 20/70\n",
      " - 4s - loss: 0.9169 - acc: 0.6947\n",
      "Epoch 21/70\n",
      " - 4s - loss: 0.9135 - acc: 0.6951\n",
      "Epoch 22/70\n",
      " - 4s - loss: 0.9080 - acc: 0.6961\n",
      "Epoch 23/70\n",
      " - 4s - loss: 0.9006 - acc: 0.6983\n",
      "Epoch 24/70\n",
      " - 4s - loss: 0.8994 - acc: 0.6961\n",
      "Epoch 25/70\n",
      " - 4s - loss: 0.8959 - acc: 0.6977\n",
      "Epoch 26/70\n",
      " - 4s - loss: 0.8900 - acc: 0.6984\n",
      "Epoch 27/70\n",
      " - 4s - loss: 0.8869 - acc: 0.7011\n",
      "Epoch 28/70\n",
      " - 4s - loss: 0.8811 - acc: 0.7008\n",
      "Epoch 29/70\n",
      " - 4s - loss: 0.8792 - acc: 0.7018\n",
      "Epoch 30/70\n",
      " - 4s - loss: 0.8773 - acc: 0.7029\n",
      "Epoch 31/70\n",
      " - 4s - loss: 0.8750 - acc: 0.7006\n",
      "Epoch 32/70\n",
      " - 4s - loss: 0.8706 - acc: 0.7026\n",
      "Epoch 33/70\n",
      " - 4s - loss: 0.8671 - acc: 0.7030\n",
      "Epoch 34/70\n",
      " - 4s - loss: 0.8657 - acc: 0.7032\n",
      "Epoch 35/70\n",
      " - 4s - loss: 0.8637 - acc: 0.7037\n",
      "Epoch 36/70\n",
      " - 4s - loss: 0.8597 - acc: 0.7045\n",
      "Epoch 37/70\n",
      " - 4s - loss: 0.8576 - acc: 0.7044\n",
      "Epoch 38/70\n",
      " - 4s - loss: 0.8563 - acc: 0.7057\n",
      "Epoch 39/70\n",
      " - 4s - loss: 0.8549 - acc: 0.7050\n",
      "Epoch 40/70\n",
      " - 4s - loss: 0.8493 - acc: 0.7079\n",
      "Epoch 41/70\n",
      " - 4s - loss: 0.8484 - acc: 0.7073\n",
      "Epoch 42/70\n",
      " - 4s - loss: 0.8453 - acc: 0.7083\n",
      "Epoch 43/70\n",
      " - 4s - loss: 0.8470 - acc: 0.7067\n",
      "Epoch 44/70\n",
      " - 4s - loss: 0.8419 - acc: 0.7085\n",
      "Epoch 45/70\n",
      " - 4s - loss: 0.8403 - acc: 0.7096\n",
      "Epoch 46/70\n",
      " - 4s - loss: 0.8390 - acc: 0.7099\n",
      "Epoch 47/70\n",
      " - 4s - loss: 0.8363 - acc: 0.7102\n",
      "Epoch 48/70\n",
      " - 4s - loss: 0.8338 - acc: 0.7098\n",
      "Epoch 49/70\n",
      " - 4s - loss: 0.8311 - acc: 0.7126\n",
      "Epoch 50/70\n",
      " - 4s - loss: 0.8333 - acc: 0.7103\n",
      "Epoch 51/70\n",
      " - 4s - loss: 0.8288 - acc: 0.7112\n",
      "Epoch 52/70\n",
      " - 4s - loss: 0.8258 - acc: 0.7135\n",
      "Epoch 53/70\n",
      " - 4s - loss: 0.8263 - acc: 0.7124\n",
      "Epoch 54/70\n",
      " - 5s - loss: 0.8282 - acc: 0.7131\n",
      "Epoch 55/70\n",
      " - 6s - loss: 0.8229 - acc: 0.7143\n",
      "Epoch 56/70\n",
      " - 6s - loss: 0.8224 - acc: 0.7136\n",
      "Epoch 57/70\n",
      " - 6s - loss: 0.8227 - acc: 0.7148\n",
      "Epoch 58/70\n",
      " - 6s - loss: 0.8209 - acc: 0.7142\n",
      "Epoch 59/70\n",
      " - 5s - loss: 0.8187 - acc: 0.7145\n",
      "Epoch 60/70\n",
      " - 5s - loss: 0.8167 - acc: 0.7165\n",
      "Epoch 61/70\n",
      " - 5s - loss: 0.8185 - acc: 0.7146\n",
      "Epoch 62/70\n",
      " - 5s - loss: 0.8153 - acc: 0.7148\n",
      "Epoch 63/70\n",
      " - 5s - loss: 0.8139 - acc: 0.7152\n",
      "Epoch 64/70\n",
      " - 5s - loss: 0.8104 - acc: 0.7161\n",
      "Epoch 65/70\n",
      " - 5s - loss: 0.8099 - acc: 0.7167\n",
      "Epoch 66/70\n",
      " - 6s - loss: 0.8097 - acc: 0.7169\n",
      "Epoch 67/70\n",
      " - 5s - loss: 0.8092 - acc: 0.7164\n",
      "Epoch 68/70\n",
      " - 5s - loss: 0.8095 - acc: 0.7168\n",
      "Epoch 69/70\n",
      " - 6s - loss: 0.8091 - acc: 0.7169\n",
      "Epoch 70/70\n",
      " - 5s - loss: 0.8060 - acc: 0.7169\n",
      "[CV]  nodes_l3=70, nodes_l2=130, nodes_l1=160, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.1, batch_size=1000, total= 5.0min\n",
      "[CV] nodes_l3=60, nodes_l2=100, nodes_l1=150, dropout_l3=0.30000000000000004, dropout_l2=0.4, dropout_l1=0.1, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=150)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 17s - loss: 2.2772 - acc: 0.3997\n",
      "Epoch 2/70\n",
      " - 6s - loss: 1.5221 - acc: 0.5811\n",
      "Epoch 3/70\n",
      " - 7s - loss: 1.3375 - acc: 0.6213\n",
      "Epoch 4/70\n",
      " - 7s - loss: 1.2493 - acc: 0.6383\n",
      "Epoch 5/70\n",
      " - 6s - loss: 1.2010 - acc: 0.6464\n",
      "Epoch 6/70\n",
      " - 7s - loss: 1.1705 - acc: 0.6482\n",
      "Epoch 7/70\n",
      " - 6s - loss: 1.1467 - acc: 0.6553\n",
      "Epoch 8/70\n",
      " - 7s - loss: 1.1278 - acc: 0.6594\n",
      "Epoch 9/70\n",
      " - 6s - loss: 1.1108 - acc: 0.6616\n",
      "Epoch 10/70\n",
      " - 6s - loss: 1.0947 - acc: 0.6632\n",
      "Epoch 11/70\n",
      " - 7s - loss: 1.0826 - acc: 0.6699\n",
      "Epoch 12/70\n",
      " - 6s - loss: 1.0712 - acc: 0.6699\n",
      "Epoch 13/70\n",
      " - 6s - loss: 1.0594 - acc: 0.6713\n",
      "Epoch 14/70\n",
      " - 7s - loss: 1.0555 - acc: 0.6737\n",
      "Epoch 15/70\n",
      " - 6s - loss: 1.0435 - acc: 0.6758\n",
      "Epoch 16/70\n",
      " - 7s - loss: 1.0362 - acc: 0.6768\n",
      "Epoch 17/70\n",
      " - 6s - loss: 1.0261 - acc: 0.6801\n",
      "Epoch 18/70\n",
      " - 6s - loss: 1.0235 - acc: 0.6775\n",
      "Epoch 19/70\n",
      " - 7s - loss: 1.0187 - acc: 0.6807\n",
      "Epoch 20/70\n",
      " - 6s - loss: 1.0143 - acc: 0.6830\n",
      "Epoch 21/70\n",
      " - 6s - loss: 1.0053 - acc: 0.6827\n",
      "Epoch 22/70\n",
      " - 6s - loss: 1.0017 - acc: 0.6850\n",
      "Epoch 23/70\n",
      " - 6s - loss: 0.9996 - acc: 0.6859\n",
      "Epoch 24/70\n",
      " - 7s - loss: 0.9927 - acc: 0.6869\n",
      "Epoch 25/70\n",
      " - 5s - loss: 0.9874 - acc: 0.6882\n",
      "Epoch 26/70\n",
      " - 4s - loss: 0.9814 - acc: 0.6885\n",
      "Epoch 27/70\n",
      " - 5s - loss: 0.9869 - acc: 0.6871\n",
      "Epoch 28/70\n",
      " - 4s - loss: 0.9798 - acc: 0.6887\n",
      "Epoch 29/70\n",
      " - 4s - loss: 0.9748 - acc: 0.6892\n",
      "Epoch 30/70\n",
      " - 5s - loss: 0.9770 - acc: 0.6894\n",
      "Epoch 31/70\n",
      " - 5s - loss: 0.9730 - acc: 0.6904\n",
      "Epoch 32/70\n",
      " - 4s - loss: 0.9670 - acc: 0.6922\n",
      "Epoch 33/70\n",
      " - 4s - loss: 0.9664 - acc: 0.6929\n",
      "Epoch 34/70\n",
      " - 5s - loss: 0.9603 - acc: 0.6942\n",
      "Epoch 35/70\n",
      " - 4s - loss: 0.9588 - acc: 0.6935\n",
      "Epoch 36/70\n",
      " - 4s - loss: 0.9562 - acc: 0.6950\n",
      "Epoch 37/70\n",
      " - 4s - loss: 0.9584 - acc: 0.6938\n",
      "Epoch 38/70\n",
      " - 5s - loss: 0.9564 - acc: 0.6940\n",
      "Epoch 39/70\n",
      " - 4s - loss: 0.9543 - acc: 0.6950\n",
      "Epoch 40/70\n",
      " - 4s - loss: 0.9497 - acc: 0.6967\n",
      "Epoch 41/70\n",
      " - 5s - loss: 0.9475 - acc: 0.6959\n",
      "Epoch 42/70\n",
      " - 4s - loss: 0.9486 - acc: 0.6963\n",
      "Epoch 43/70\n",
      " - 4s - loss: 0.9426 - acc: 0.6975\n",
      "Epoch 44/70\n",
      " - 4s - loss: 0.9431 - acc: 0.6969\n",
      "Epoch 45/70\n",
      " - 5s - loss: 0.9449 - acc: 0.6976\n",
      "Epoch 46/70\n",
      " - 4s - loss: 0.9384 - acc: 0.6963\n",
      "Epoch 47/70\n",
      " - 4s - loss: 0.9400 - acc: 0.6986\n",
      "Epoch 48/70\n",
      " - 5s - loss: 0.9385 - acc: 0.6983\n",
      "Epoch 49/70\n",
      " - 5s - loss: 0.9342 - acc: 0.6977\n",
      "Epoch 50/70\n",
      " - 5s - loss: 0.9332 - acc: 0.7012\n",
      "Epoch 51/70\n",
      " - 4s - loss: 0.9303 - acc: 0.6998\n",
      "Epoch 52/70\n",
      " - 5s - loss: 0.9313 - acc: 0.7000\n",
      "Epoch 53/70\n",
      " - 4s - loss: 0.9290 - acc: 0.7006\n",
      "Epoch 54/70\n",
      " - 4s - loss: 0.9319 - acc: 0.7003\n",
      "Epoch 55/70\n",
      " - 4s - loss: 0.9304 - acc: 0.6995\n",
      "Epoch 56/70\n",
      " - 5s - loss: 0.9310 - acc: 0.6995\n",
      "Epoch 57/70\n",
      " - 4s - loss: 0.9289 - acc: 0.6997\n",
      "Epoch 58/70\n",
      " - 4s - loss: 0.9267 - acc: 0.7015\n",
      "Epoch 59/70\n",
      " - 5s - loss: 0.9214 - acc: 0.7009\n",
      "Epoch 60/70\n",
      " - 4s - loss: 0.9219 - acc: 0.7022\n",
      "Epoch 61/70\n",
      " - 4s - loss: 0.9233 - acc: 0.7002\n",
      "Epoch 62/70\n",
      " - 4s - loss: 0.9224 - acc: 0.7011\n",
      "Epoch 63/70\n",
      " - 5s - loss: 0.9248 - acc: 0.7007\n",
      "Epoch 64/70\n",
      " - 4s - loss: 0.9234 - acc: 0.7011\n",
      "Epoch 65/70\n",
      " - 4s - loss: 0.9145 - acc: 0.7031\n",
      "Epoch 66/70\n",
      " - 5s - loss: 0.9198 - acc: 0.7017\n",
      "Epoch 67/70\n",
      " - 4s - loss: 0.9137 - acc: 0.7034\n",
      "Epoch 68/70\n",
      " - 4s - loss: 0.9161 - acc: 0.7032\n",
      "Epoch 69/70\n",
      " - 4s - loss: 0.9181 - acc: 0.7031\n",
      "Epoch 70/70\n",
      " - 5s - loss: 0.9136 - acc: 0.7049\n",
      "[CV]  nodes_l3=60, nodes_l2=100, nodes_l1=150, dropout_l3=0.30000000000000004, dropout_l2=0.4, dropout_l1=0.1, batch_size=500, total= 6.3min\n",
      "[CV] nodes_l3=60, nodes_l2=100, nodes_l1=150, dropout_l3=0.30000000000000004, dropout_l2=0.4, dropout_l1=0.1, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=150)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 11s - loss: 2.2918 - acc: 0.3872\n",
      "Epoch 2/70\n",
      " - 5s - loss: 1.5171 - acc: 0.5843\n",
      "Epoch 3/70\n",
      " - 4s - loss: 1.3353 - acc: 0.6216\n",
      "Epoch 4/70\n",
      " - 5s - loss: 1.2556 - acc: 0.6376\n",
      "Epoch 5/70\n",
      " - 5s - loss: 1.2094 - acc: 0.6442\n",
      "Epoch 6/70\n",
      " - 5s - loss: 1.1773 - acc: 0.6495\n",
      "Epoch 7/70\n",
      " - 5s - loss: 1.1492 - acc: 0.6547\n",
      "Epoch 8/70\n",
      " - 5s - loss: 1.1269 - acc: 0.6594\n",
      "Epoch 9/70\n",
      " - 4s - loss: 1.1097 - acc: 0.6625\n",
      "Epoch 10/70\n",
      " - 4s - loss: 1.0905 - acc: 0.6676\n",
      "Epoch 11/70\n",
      " - 5s - loss: 1.0820 - acc: 0.6669\n",
      "Epoch 12/70\n",
      " - 4s - loss: 1.0706 - acc: 0.6711\n",
      "Epoch 13/70\n",
      " - 5s - loss: 1.0604 - acc: 0.6730\n",
      "Epoch 14/70\n",
      " - 5s - loss: 1.0493 - acc: 0.6741\n",
      "Epoch 15/70\n",
      " - 5s - loss: 1.0425 - acc: 0.6755\n",
      "Epoch 16/70\n",
      " - 5s - loss: 1.0351 - acc: 0.6790\n",
      "Epoch 17/70\n",
      " - 5s - loss: 1.0282 - acc: 0.6787\n",
      "Epoch 18/70\n",
      " - 5s - loss: 1.0185 - acc: 0.6811\n",
      "Epoch 19/70\n",
      " - 5s - loss: 1.0174 - acc: 0.6818\n",
      "Epoch 20/70\n",
      " - 4s - loss: 1.0078 - acc: 0.6833\n",
      "Epoch 21/70\n",
      " - 5s - loss: 1.0041 - acc: 0.6840\n",
      "Epoch 22/70\n",
      " - 5s - loss: 0.9996 - acc: 0.6865\n",
      "Epoch 23/70\n",
      " - 5s - loss: 0.9973 - acc: 0.6842\n",
      "Epoch 24/70\n",
      " - 4s - loss: 0.9890 - acc: 0.6869\n",
      "Epoch 25/70\n",
      " - 5s - loss: 0.9887 - acc: 0.6875\n",
      "Epoch 26/70\n",
      " - 5s - loss: 0.9848 - acc: 0.6881\n",
      "Epoch 27/70\n",
      " - 4s - loss: 0.9792 - acc: 0.6908\n",
      "Epoch 28/70\n",
      " - 5s - loss: 0.9751 - acc: 0.6893\n",
      "Epoch 29/70\n",
      " - 5s - loss: 0.9752 - acc: 0.6902\n",
      "Epoch 30/70\n",
      " - 4s - loss: 0.9685 - acc: 0.6908\n",
      "Epoch 31/70\n",
      " - 5s - loss: 0.9648 - acc: 0.6916\n",
      "Epoch 32/70\n",
      " - 5s - loss: 0.9616 - acc: 0.6934\n",
      "Epoch 33/70\n",
      " - 4s - loss: 0.9615 - acc: 0.6948\n",
      "Epoch 34/70\n",
      " - 5s - loss: 0.9644 - acc: 0.6907\n",
      "Epoch 35/70\n",
      " - 5s - loss: 0.9571 - acc: 0.6945\n",
      "Epoch 36/70\n",
      " - 5s - loss: 0.9546 - acc: 0.6949\n",
      "Epoch 37/70\n",
      " - 4s - loss: 0.9523 - acc: 0.6959\n",
      "Epoch 38/70\n",
      " - 5s - loss: 0.9484 - acc: 0.6963\n",
      "Epoch 39/70\n",
      " - 5s - loss: 0.9476 - acc: 0.6954\n",
      "Epoch 40/70\n",
      " - 4s - loss: 0.9473 - acc: 0.6952\n",
      "Epoch 41/70\n",
      " - 5s - loss: 0.9507 - acc: 0.6953\n",
      "Epoch 42/70\n",
      " - 5s - loss: 0.9415 - acc: 0.6968\n",
      "Epoch 43/70\n",
      " - 4s - loss: 0.9430 - acc: 0.6981\n",
      "Epoch 44/70\n",
      " - 4s - loss: 0.9407 - acc: 0.6955\n",
      "Epoch 45/70\n",
      " - 5s - loss: 0.9376 - acc: 0.6974\n",
      "Epoch 46/70\n",
      " - 5s - loss: 0.9380 - acc: 0.6980\n",
      "Epoch 47/70\n",
      " - 4s - loss: 0.9367 - acc: 0.6974\n",
      "Epoch 48/70\n",
      " - 4s - loss: 0.9355 - acc: 0.6975\n",
      "Epoch 49/70\n",
      " - 5s - loss: 0.9329 - acc: 0.7002\n",
      "Epoch 50/70\n",
      " - 5s - loss: 0.9317 - acc: 0.7005\n",
      "Epoch 51/70\n",
      " - 5s - loss: 0.9345 - acc: 0.6989\n",
      "Epoch 52/70\n",
      " - 5s - loss: 0.9287 - acc: 0.6999\n",
      "Epoch 53/70\n",
      " - 5s - loss: 0.9273 - acc: 0.6995\n",
      "Epoch 54/70\n",
      " - 4s - loss: 0.9255 - acc: 0.7005\n",
      "Epoch 55/70\n",
      " - 5s - loss: 0.9257 - acc: 0.7000\n",
      "Epoch 56/70\n",
      " - 5s - loss: 0.9215 - acc: 0.6997\n",
      "Epoch 57/70\n",
      " - 4s - loss: 0.9205 - acc: 0.7009\n",
      "Epoch 58/70\n",
      " - 5s - loss: 0.9198 - acc: 0.7029\n",
      "Epoch 59/70\n",
      " - 5s - loss: 0.9207 - acc: 0.7023\n",
      "Epoch 60/70\n",
      " - 5s - loss: 0.9208 - acc: 0.7014\n",
      "Epoch 61/70\n",
      " - 4s - loss: 0.9206 - acc: 0.7024\n",
      "Epoch 62/70\n",
      " - 5s - loss: 0.9166 - acc: 0.7032\n",
      "Epoch 63/70\n",
      " - 4s - loss: 0.9161 - acc: 0.7034\n",
      "Epoch 64/70\n",
      " - 4s - loss: 0.9180 - acc: 0.7023\n",
      "Epoch 65/70\n",
      " - 5s - loss: 0.9127 - acc: 0.7032\n",
      "Epoch 66/70\n",
      " - 5s - loss: 0.9153 - acc: 0.7028\n",
      "Epoch 67/70\n",
      " - 4s - loss: 0.9125 - acc: 0.7031\n",
      "Epoch 68/70\n",
      " - 4s - loss: 0.9156 - acc: 0.7028\n",
      "Epoch 69/70\n",
      " - 5s - loss: 0.9088 - acc: 0.7041\n",
      "Epoch 70/70\n",
      " - 5s - loss: 0.9114 - acc: 0.7033\n",
      "[CV]  nodes_l3=60, nodes_l2=100, nodes_l1=150, dropout_l3=0.30000000000000004, dropout_l2=0.4, dropout_l1=0.1, batch_size=500, total= 5.7min\n",
      "[CV] nodes_l3=60, nodes_l2=100, nodes_l1=150, dropout_l3=0.30000000000000004, dropout_l2=0.4, dropout_l1=0.1, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=150)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 15s - loss: 2.2741 - acc: 0.3903\n",
      "Epoch 2/70\n",
      " - 5s - loss: 1.4970 - acc: 0.5863\n",
      "Epoch 3/70\n",
      " - 4s - loss: 1.3209 - acc: 0.6248\n",
      "Epoch 4/70\n",
      " - 4s - loss: 1.2389 - acc: 0.6372\n",
      "Epoch 5/70\n",
      " - 5s - loss: 1.1861 - acc: 0.6504\n",
      "Epoch 6/70\n",
      " - 5s - loss: 1.1543 - acc: 0.6546\n",
      "Epoch 7/70\n",
      " - 4s - loss: 1.1260 - acc: 0.6599\n",
      "Epoch 8/70\n",
      " - 4s - loss: 1.1078 - acc: 0.6648\n",
      "Epoch 9/70\n",
      " - 5s - loss: 1.0866 - acc: 0.6673\n",
      "Epoch 10/70\n",
      " - 4s - loss: 1.0703 - acc: 0.6707\n",
      "Epoch 11/70\n",
      " - 4s - loss: 1.0582 - acc: 0.6753\n",
      "Epoch 12/70\n",
      " - 5s - loss: 1.0484 - acc: 0.6761\n",
      "Epoch 13/70\n",
      " - 5s - loss: 1.0350 - acc: 0.6779\n",
      "Epoch 14/70\n",
      " - 4s - loss: 1.0287 - acc: 0.6796\n",
      "Epoch 15/70\n",
      " - 4s - loss: 1.0215 - acc: 0.6796\n",
      "Epoch 16/70\n",
      " - 5s - loss: 1.0099 - acc: 0.6840\n",
      "Epoch 17/70\n",
      " - 4s - loss: 1.0050 - acc: 0.6859\n",
      "Epoch 18/70\n",
      " - 5s - loss: 0.9994 - acc: 0.6852\n",
      "Epoch 19/70\n",
      " - 5s - loss: 0.9895 - acc: 0.6884\n",
      "Epoch 20/70\n",
      " - 5s - loss: 0.9889 - acc: 0.6880\n",
      "Epoch 21/70\n",
      " - 4s - loss: 0.9821 - acc: 0.6906\n",
      "Epoch 22/70\n",
      " - 4s - loss: 0.9807 - acc: 0.6892\n",
      "Epoch 23/70\n",
      " - 5s - loss: 0.9757 - acc: 0.6896\n",
      "Epoch 24/70\n",
      " - 4s - loss: 0.9755 - acc: 0.6890\n",
      "Epoch 25/70\n",
      " - 5s - loss: 0.9649 - acc: 0.6918\n",
      "Epoch 26/70\n",
      " - 5s - loss: 0.9646 - acc: 0.6927\n",
      "Epoch 27/70\n",
      " - 4s - loss: 0.9575 - acc: 0.6935\n",
      "Epoch 28/70\n",
      " - 4s - loss: 0.9556 - acc: 0.6928\n",
      "Epoch 29/70\n",
      " - 5s - loss: 0.9547 - acc: 0.6947\n",
      "Epoch 30/70\n",
      " - 5s - loss: 0.9544 - acc: 0.6962\n",
      "Epoch 31/70\n",
      " - 4s - loss: 0.9498 - acc: 0.6954\n",
      "Epoch 32/70\n",
      " - 4s - loss: 0.9459 - acc: 0.6955\n",
      "Epoch 33/70\n",
      " - 5s - loss: 0.9468 - acc: 0.6967\n",
      "Epoch 34/70\n",
      " - 4s - loss: 0.9416 - acc: 0.6980\n",
      "Epoch 35/70\n",
      " - 4s - loss: 0.9415 - acc: 0.6985\n",
      "Epoch 36/70\n",
      " - 5s - loss: 0.9366 - acc: 0.6987\n",
      "Epoch 37/70\n",
      " - 5s - loss: 0.9383 - acc: 0.6976\n",
      "Epoch 38/70\n",
      " - 5s - loss: 0.9374 - acc: 0.6982\n",
      "Epoch 39/70\n",
      " - 4s - loss: 0.9339 - acc: 0.6987\n",
      "Epoch 40/70\n",
      " - 5s - loss: 0.9293 - acc: 0.6998\n",
      "Epoch 41/70\n",
      " - 4s - loss: 0.9259 - acc: 0.7014\n",
      "Epoch 42/70\n",
      " - 4s - loss: 0.9256 - acc: 0.7020\n",
      "Epoch 43/70\n",
      " - 5s - loss: 0.9287 - acc: 0.7010\n",
      "Epoch 44/70\n",
      " - 5s - loss: 0.9198 - acc: 0.7010\n",
      "Epoch 45/70\n",
      " - 4s - loss: 0.9235 - acc: 0.7020\n",
      "Epoch 46/70\n",
      " - 4s - loss: 0.9198 - acc: 0.7018\n",
      "Epoch 47/70\n",
      " - 5s - loss: 0.9195 - acc: 0.7024\n",
      "Epoch 48/70\n",
      " - 4s - loss: 0.9183 - acc: 0.7030\n",
      "Epoch 49/70\n",
      " - 4s - loss: 0.9141 - acc: 0.7036\n",
      "Epoch 50/70\n",
      " - 5s - loss: 0.9171 - acc: 0.7034\n",
      "Epoch 51/70\n",
      " - 5s - loss: 0.9111 - acc: 0.7042\n",
      "Epoch 52/70\n",
      " - 4s - loss: 0.9114 - acc: 0.7038\n",
      "Epoch 53/70\n",
      " - 4s - loss: 0.9111 - acc: 0.7034\n",
      "Epoch 54/70\n",
      " - 5s - loss: 0.9151 - acc: 0.7056\n",
      "Epoch 55/70\n",
      " - 5s - loss: 0.9056 - acc: 0.7059\n",
      "Epoch 56/70\n",
      " - 5s - loss: 0.9084 - acc: 0.7061\n",
      "Epoch 57/70\n",
      " - 5s - loss: 0.9091 - acc: 0.7034\n",
      "Epoch 58/70\n",
      " - 5s - loss: 0.9059 - acc: 0.7058\n",
      "Epoch 59/70\n",
      " - 5s - loss: 0.9068 - acc: 0.7042\n",
      "Epoch 60/70\n",
      " - 5s - loss: 0.9040 - acc: 0.7063\n",
      "Epoch 61/70\n",
      " - 2947s - loss: 0.9046 - acc: 0.7049\n",
      "Epoch 62/70\n",
      " - 5s - loss: 0.9021 - acc: 0.7056\n",
      "Epoch 63/70\n",
      " - 5s - loss: 0.9021 - acc: 0.7070\n",
      "Epoch 64/70\n",
      " - 5s - loss: 0.9037 - acc: 0.7059\n",
      "Epoch 65/70\n",
      " - 5s - loss: 0.9003 - acc: 0.7072\n",
      "Epoch 66/70\n",
      " - 5s - loss: 0.8980 - acc: 0.7064\n",
      "Epoch 67/70\n",
      " - 5s - loss: 0.9021 - acc: 0.7055\n",
      "Epoch 68/70\n",
      " - 5s - loss: 0.9001 - acc: 0.7051\n",
      "Epoch 69/70\n",
      " - 5s - loss: 0.9003 - acc: 0.7071\n",
      "Epoch 70/70\n",
      " - 5s - loss: 0.8981 - acc: 0.7070\n",
      "[CV]  nodes_l3=60, nodes_l2=100, nodes_l1=150, dropout_l3=0.30000000000000004, dropout_l2=0.4, dropout_l1=0.1, batch_size=500, total=56.9min\n",
      "[CV] nodes_l3=60, nodes_l2=100, nodes_l1=150, dropout_l3=0.30000000000000004, dropout_l2=0.4, dropout_l1=0.1, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=150)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 26s - loss: 2.2625 - acc: 0.3947\n",
      "Epoch 2/70\n",
      " - 5s - loss: 1.5030 - acc: 0.5843\n",
      "Epoch 3/70\n",
      " - 5s - loss: 1.3326 - acc: 0.6183\n",
      "Epoch 4/70\n",
      " - 5s - loss: 1.2530 - acc: 0.6342\n",
      "Epoch 5/70\n",
      " - 5s - loss: 1.2118 - acc: 0.6427\n",
      "Epoch 6/70\n",
      " - 6s - loss: 1.1743 - acc: 0.6506\n",
      "Epoch 7/70\n",
      " - 5s - loss: 1.1507 - acc: 0.6529\n",
      "Epoch 8/70\n",
      " - 6s - loss: 1.1271 - acc: 0.6594\n",
      "Epoch 9/70\n",
      " - 5s - loss: 1.1101 - acc: 0.6625\n",
      "Epoch 10/70\n",
      " - 5s - loss: 1.0969 - acc: 0.6648\n",
      "Epoch 11/70\n",
      " - 5s - loss: 1.0853 - acc: 0.6658\n",
      "Epoch 12/70\n",
      " - 7s - loss: 1.0739 - acc: 0.6689\n",
      "Epoch 13/70\n",
      " - 7s - loss: 1.0654 - acc: 0.6702\n",
      "Epoch 14/70\n",
      " - 6s - loss: 1.0586 - acc: 0.6711\n",
      "Epoch 15/70\n",
      " - 5s - loss: 1.0514 - acc: 0.6714\n",
      "Epoch 16/70\n",
      " - 5s - loss: 1.0377 - acc: 0.6743\n",
      "Epoch 17/70\n",
      " - 6s - loss: 1.0358 - acc: 0.6754\n",
      "Epoch 18/70\n",
      " - 5s - loss: 1.0263 - acc: 0.6766\n",
      "Epoch 19/70\n",
      " - 6s - loss: 1.0226 - acc: 0.6776\n",
      "Epoch 20/70\n",
      " - 5s - loss: 1.0141 - acc: 0.6802\n",
      "Epoch 21/70\n",
      " - 5s - loss: 1.0113 - acc: 0.6806\n",
      "Epoch 22/70\n",
      " - 5s - loss: 1.0070 - acc: 0.6809\n",
      "Epoch 23/70\n",
      " - 5s - loss: 1.0009 - acc: 0.6831\n",
      "Epoch 24/70\n",
      " - 6s - loss: 1.0015 - acc: 0.6837\n",
      "Epoch 25/70\n",
      " - 5s - loss: 0.9932 - acc: 0.6853\n",
      "Epoch 26/70\n",
      " - 5s - loss: 0.9950 - acc: 0.6841\n",
      "Epoch 27/70\n",
      " - 5s - loss: 0.9861 - acc: 0.6858\n",
      "Epoch 28/70\n",
      " - 5s - loss: 0.9834 - acc: 0.6860\n",
      "Epoch 29/70\n",
      " - 5s - loss: 0.9801 - acc: 0.6878\n",
      "Epoch 30/70\n",
      " - 5s - loss: 0.9761 - acc: 0.6881\n",
      "Epoch 31/70\n",
      " - 5s - loss: 0.9696 - acc: 0.6899\n",
      "Epoch 32/70\n",
      " - 5s - loss: 0.9726 - acc: 0.6870\n",
      "Epoch 33/70\n",
      " - 5s - loss: 0.9696 - acc: 0.6895\n",
      "Epoch 34/70\n",
      " - 5s - loss: 0.9642 - acc: 0.6897\n",
      "Epoch 35/70\n",
      " - 5s - loss: 0.9626 - acc: 0.6921\n",
      "Epoch 36/70\n",
      " - 6s - loss: 0.9629 - acc: 0.6918\n",
      "Epoch 37/70\n",
      " - 6s - loss: 0.9651 - acc: 0.6900\n",
      "Epoch 38/70\n",
      " - 6s - loss: 0.9590 - acc: 0.6919\n",
      "Epoch 39/70\n",
      " - 6s - loss: 0.9587 - acc: 0.6929\n",
      "Epoch 40/70\n",
      " - 5s - loss: 0.9588 - acc: 0.6917\n",
      "Epoch 41/70\n",
      " - 6s - loss: 0.9514 - acc: 0.6928\n",
      "Epoch 42/70\n",
      " - 5s - loss: 0.9477 - acc: 0.6921\n",
      "Epoch 43/70\n",
      " - 5s - loss: 0.9470 - acc: 0.6936\n",
      "Epoch 44/70\n",
      " - 5s - loss: 0.9436 - acc: 0.6957\n",
      "Epoch 45/70\n",
      " - 5s - loss: 0.9499 - acc: 0.6945\n",
      "Epoch 46/70\n",
      " - 5s - loss: 0.9464 - acc: 0.6944\n",
      "Epoch 47/70\n",
      " - 5s - loss: 0.9413 - acc: 0.6956\n",
      "Epoch 48/70\n",
      " - 5s - loss: 0.9450 - acc: 0.6949\n",
      "Epoch 49/70\n",
      " - 5s - loss: 0.9372 - acc: 0.6949\n",
      "Epoch 50/70\n",
      " - 5s - loss: 0.9409 - acc: 0.6952\n",
      "Epoch 51/70\n",
      " - 5s - loss: 0.9380 - acc: 0.6965\n",
      "Epoch 52/70\n",
      " - 5s - loss: 0.9354 - acc: 0.6982\n",
      "Epoch 53/70\n",
      " - 5s - loss: 0.9350 - acc: 0.6970\n",
      "Epoch 54/70\n",
      " - 6s - loss: 0.9328 - acc: 0.6982\n",
      "Epoch 55/70\n",
      " - 5s - loss: 0.9310 - acc: 0.6952\n",
      "Epoch 56/70\n",
      " - 5s - loss: 0.9334 - acc: 0.6974\n",
      "Epoch 57/70\n",
      " - 5s - loss: 0.9277 - acc: 0.6981\n",
      "Epoch 58/70\n",
      " - 5s - loss: 0.9288 - acc: 0.6977\n",
      "Epoch 59/70\n",
      " - 5s - loss: 0.9306 - acc: 0.6997\n",
      "Epoch 60/70\n",
      " - 5s - loss: 0.9286 - acc: 0.6988\n",
      "Epoch 61/70\n",
      " - 6s - loss: 0.9269 - acc: 0.6990\n",
      "Epoch 62/70\n",
      " - 5s - loss: 0.9263 - acc: 0.7007\n",
      "Epoch 63/70\n",
      " - 5s - loss: 0.9256 - acc: 0.7012\n",
      "Epoch 64/70\n",
      " - 5s - loss: 0.9232 - acc: 0.6997\n",
      "Epoch 65/70\n",
      " - 5s - loss: 0.9197 - acc: 0.7004\n",
      "Epoch 66/70\n",
      " - 5s - loss: 0.9201 - acc: 0.7002\n",
      "Epoch 67/70\n",
      " - 5s - loss: 0.9209 - acc: 0.7006\n",
      "Epoch 68/70\n",
      " - 5s - loss: 0.9225 - acc: 0.7004\n",
      "Epoch 69/70\n",
      " - 5s - loss: 0.9209 - acc: 0.7007\n",
      "Epoch 70/70\n",
      " - 5s - loss: 0.9237 - acc: 0.7001\n",
      "[CV]  nodes_l3=60, nodes_l2=100, nodes_l1=150, dropout_l3=0.30000000000000004, dropout_l2=0.4, dropout_l1=0.1, batch_size=500, total= 8.4min\n",
      "[CV] nodes_l3=60, nodes_l2=90, nodes_l1=170, dropout_l3=0.30000000000000004, dropout_l2=0.2, dropout_l1=0.1, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=170)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 15s - loss: 2.1495 - acc: 0.4239\n",
      "Epoch 2/70\n",
      " - 4s - loss: 1.3876 - acc: 0.6112\n",
      "Epoch 3/70\n",
      " - 4s - loss: 1.2332 - acc: 0.6403\n",
      "Epoch 4/70\n",
      " - 5s - loss: 1.1701 - acc: 0.6507\n",
      "Epoch 5/70\n",
      " - 5s - loss: 1.1235 - acc: 0.6591\n",
      "Epoch 6/70\n",
      " - 4s - loss: 1.0953 - acc: 0.6659\n",
      "Epoch 7/70\n",
      " - 4s - loss: 1.0704 - acc: 0.6694\n",
      "Epoch 8/70\n",
      " - 5s - loss: 1.0513 - acc: 0.6723\n",
      "Epoch 9/70\n",
      " - 4s - loss: 1.0360 - acc: 0.6752\n",
      "Epoch 10/70\n",
      " - 4s - loss: 1.0210 - acc: 0.6783\n",
      "Epoch 11/70\n",
      " - 5s - loss: 1.0109 - acc: 0.6803\n",
      "Epoch 12/70\n",
      " - 5s - loss: 0.9993 - acc: 0.6840\n",
      "Epoch 13/70\n",
      " - 4s - loss: 0.9903 - acc: 0.6827\n",
      "Epoch 14/70\n",
      " - 4s - loss: 0.9794 - acc: 0.6862\n",
      "Epoch 15/70\n",
      " - 5s - loss: 0.9724 - acc: 0.6882\n",
      "Epoch 16/70\n",
      " - 5s - loss: 0.9669 - acc: 0.6882\n",
      "Epoch 17/70\n",
      " - 5s - loss: 0.9584 - acc: 0.6898\n",
      "Epoch 18/70\n",
      " - 5s - loss: 0.9544 - acc: 0.6916\n",
      "Epoch 19/70\n",
      " - 5s - loss: 0.9497 - acc: 0.6933\n",
      "Epoch 20/70\n",
      " - 5s - loss: 0.9453 - acc: 0.6925\n",
      "Epoch 21/70\n",
      " - 5s - loss: 0.9370 - acc: 0.6939\n",
      "Epoch 22/70\n",
      " - 6s - loss: 0.9364 - acc: 0.6952\n",
      "Epoch 23/70\n",
      " - 5s - loss: 0.9330 - acc: 0.6944\n",
      "Epoch 24/70\n",
      " - 5s - loss: 0.9266 - acc: 0.6961\n",
      "Epoch 25/70\n",
      " - 5s - loss: 0.9242 - acc: 0.6980\n",
      "Epoch 26/70\n",
      " - 5s - loss: 0.9206 - acc: 0.6972\n",
      "Epoch 27/70\n",
      " - 6s - loss: 0.9157 - acc: 0.7005\n",
      "Epoch 28/70\n",
      " - 5s - loss: 0.9118 - acc: 0.6995\n",
      "Epoch 29/70\n",
      " - 5s - loss: 0.9109 - acc: 0.7005\n",
      "Epoch 30/70\n",
      " - 6s - loss: 0.9067 - acc: 0.6996\n",
      "Epoch 31/70\n",
      " - 5s - loss: 0.9024 - acc: 0.7017\n",
      "Epoch 32/70\n",
      " - 4s - loss: 0.9041 - acc: 0.7022\n",
      "Epoch 33/70\n",
      " - 4s - loss: 0.8970 - acc: 0.7025\n",
      "Epoch 34/70\n",
      " - 5s - loss: 0.8969 - acc: 0.7028\n",
      "Epoch 35/70\n",
      " - 5s - loss: 0.8977 - acc: 0.7033\n",
      "Epoch 36/70\n",
      " - 5s - loss: 0.8927 - acc: 0.7042\n",
      "Epoch 37/70\n",
      " - 6s - loss: 0.8911 - acc: 0.7030\n",
      "Epoch 38/70\n",
      " - 6s - loss: 0.8879 - acc: 0.7057\n",
      "Epoch 39/70\n",
      " - 6s - loss: 0.8876 - acc: 0.7030\n",
      "Epoch 40/70\n",
      " - 6s - loss: 0.8864 - acc: 0.7061\n",
      "Epoch 41/70\n",
      " - 6s - loss: 0.8828 - acc: 0.7054\n",
      "Epoch 42/70\n",
      " - 5s - loss: 0.8811 - acc: 0.7062\n",
      "Epoch 43/70\n",
      " - 5s - loss: 0.8804 - acc: 0.7054\n",
      "Epoch 44/70\n",
      " - 5s - loss: 0.8797 - acc: 0.7043\n",
      "Epoch 45/70\n",
      " - 5s - loss: 0.8759 - acc: 0.7073\n",
      "Epoch 46/70\n",
      " - 5s - loss: 0.8755 - acc: 0.7071\n",
      "Epoch 47/70\n",
      " - 5s - loss: 0.8730 - acc: 0.7073\n",
      "Epoch 48/70\n",
      " - 5s - loss: 0.8746 - acc: 0.7057\n",
      "Epoch 49/70\n",
      " - 5s - loss: 0.8677 - acc: 0.7079\n",
      "Epoch 50/70\n",
      " - 5s - loss: 0.8704 - acc: 0.7082\n",
      "Epoch 51/70\n",
      " - 5s - loss: 0.8697 - acc: 0.7064\n",
      "Epoch 52/70\n",
      " - 5s - loss: 0.8680 - acc: 0.7091\n",
      "Epoch 53/70\n",
      " - 5s - loss: 0.8656 - acc: 0.7096\n",
      "Epoch 54/70\n",
      " - 5s - loss: 0.8662 - acc: 0.7100\n",
      "Epoch 55/70\n",
      " - 5s - loss: 0.8644 - acc: 0.7102\n",
      "Epoch 56/70\n",
      " - 5s - loss: 0.8594 - acc: 0.7105\n",
      "Epoch 57/70\n",
      " - 4s - loss: 0.8607 - acc: 0.7099\n",
      "Epoch 58/70\n",
      " - 4s - loss: 0.8613 - acc: 0.7107\n",
      "Epoch 59/70\n",
      " - 5s - loss: 0.8587 - acc: 0.7102\n",
      "Epoch 60/70\n",
      " - 5s - loss: 0.8568 - acc: 0.7095\n",
      "Epoch 61/70\n",
      " - 5s - loss: 0.8566 - acc: 0.7116\n",
      "Epoch 62/70\n",
      " - 4s - loss: 0.8567 - acc: 0.7109\n",
      "Epoch 63/70\n",
      " - 5s - loss: 0.8582 - acc: 0.7104\n",
      "Epoch 64/70\n",
      " - 5s - loss: 0.8541 - acc: 0.7118\n",
      "Epoch 65/70\n",
      " - 5s - loss: 0.8588 - acc: 0.7109\n",
      "Epoch 66/70\n",
      " - 5s - loss: 0.8561 - acc: 0.7110\n",
      "Epoch 67/70\n",
      " - 5s - loss: 0.8509 - acc: 0.7116\n",
      "Epoch 68/70\n",
      " - 4s - loss: 0.8540 - acc: 0.7116\n",
      "Epoch 69/70\n",
      " - 5s - loss: 0.8500 - acc: 0.7115\n",
      "Epoch 70/70\n",
      " - 5s - loss: 0.8473 - acc: 0.7145\n",
      "[CV]  nodes_l3=60, nodes_l2=90, nodes_l1=170, dropout_l3=0.30000000000000004, dropout_l2=0.2, dropout_l1=0.1, batch_size=500, total= 6.2min\n",
      "[CV] nodes_l3=60, nodes_l2=90, nodes_l1=170, dropout_l3=0.30000000000000004, dropout_l2=0.2, dropout_l1=0.1, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=170)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 13s - loss: 2.1255 - acc: 0.4401\n",
      "Epoch 2/70\n",
      " - 4s - loss: 1.3827 - acc: 0.6115\n",
      "Epoch 3/70\n",
      " - 5s - loss: 1.2336 - acc: 0.6411\n",
      "Epoch 4/70\n",
      " - 4s - loss: 1.1696 - acc: 0.6516\n",
      "Epoch 5/70\n",
      " - 5s - loss: 1.1259 - acc: 0.6601\n",
      "Epoch 6/70\n",
      " - 5s - loss: 1.0944 - acc: 0.6654\n",
      "Epoch 7/70\n",
      " - 5s - loss: 1.0718 - acc: 0.6695\n",
      "Epoch 8/70\n",
      " - 5s - loss: 1.0521 - acc: 0.6723\n",
      "Epoch 9/70\n",
      " - 5s - loss: 1.0322 - acc: 0.6766\n",
      "Epoch 10/70\n",
      " - 5s - loss: 1.0203 - acc: 0.6789\n",
      "Epoch 11/70\n",
      " - 4s - loss: 1.0093 - acc: 0.6824\n",
      "Epoch 12/70\n",
      " - 4s - loss: 1.0011 - acc: 0.6814\n",
      "Epoch 13/70\n",
      " - 5s - loss: 0.9873 - acc: 0.6847\n",
      "Epoch 14/70\n",
      " - 4s - loss: 0.9821 - acc: 0.6874\n",
      "Epoch 15/70\n",
      " - 4s - loss: 0.9738 - acc: 0.6873\n",
      "Epoch 16/70\n",
      " - 5s - loss: 0.9650 - acc: 0.6897\n",
      "Epoch 17/70\n",
      " - 5s - loss: 0.9598 - acc: 0.6910\n",
      "Epoch 18/70\n",
      " - 4s - loss: 0.9516 - acc: 0.6925\n",
      "Epoch 19/70\n",
      " - 5s - loss: 0.9485 - acc: 0.6942\n",
      "Epoch 20/70\n",
      " - 5s - loss: 0.9430 - acc: 0.6931\n",
      "Epoch 21/70\n",
      " - 5s - loss: 0.9391 - acc: 0.6937\n",
      "Epoch 22/70\n",
      " - 4s - loss: 0.9325 - acc: 0.6951\n",
      "Epoch 23/70\n",
      " - 5s - loss: 0.9293 - acc: 0.6953\n",
      "Epoch 24/70\n",
      " - 5s - loss: 0.9236 - acc: 0.6987\n",
      "Epoch 25/70\n",
      " - 5s - loss: 0.9229 - acc: 0.6972\n",
      "Epoch 26/70\n",
      " - 4s - loss: 0.9193 - acc: 0.6987\n",
      "Epoch 27/70\n",
      " - 5s - loss: 0.9157 - acc: 0.6987\n",
      "Epoch 28/70\n",
      " - 4s - loss: 0.9116 - acc: 0.6995\n",
      "Epoch 29/70\n",
      " - 5s - loss: 0.9098 - acc: 0.7004\n",
      "Epoch 30/70\n",
      " - 5s - loss: 0.9066 - acc: 0.6996\n",
      "Epoch 31/70\n",
      " - 5s - loss: 0.9023 - acc: 0.7025\n",
      "Epoch 32/70\n",
      " - 4s - loss: 0.9034 - acc: 0.7006\n",
      "Epoch 33/70\n",
      " - 4s - loss: 0.9010 - acc: 0.7022\n",
      "Epoch 34/70\n",
      " - 5s - loss: 0.9006 - acc: 0.7017\n",
      "Epoch 35/70\n",
      " - 4s - loss: 0.8957 - acc: 0.7024\n",
      "Epoch 36/70\n",
      " - 4s - loss: 0.8953 - acc: 0.7033\n",
      "Epoch 37/70\n",
      " - 6s - loss: 0.8901 - acc: 0.7048\n",
      "Epoch 38/70\n",
      " - 5s - loss: 0.8909 - acc: 0.7041\n",
      "Epoch 39/70\n",
      " - 5s - loss: 0.8892 - acc: 0.7029\n",
      "Epoch 40/70\n",
      " - 5s - loss: 0.8877 - acc: 0.7045\n",
      "Epoch 41/70\n",
      " - 5s - loss: 0.8826 - acc: 0.7058\n",
      "Epoch 42/70\n",
      " - 4s - loss: 0.8792 - acc: 0.7052\n",
      "Epoch 43/70\n",
      " - 4s - loss: 0.8789 - acc: 0.7061\n",
      "Epoch 44/70\n",
      " - 5s - loss: 0.8756 - acc: 0.7077\n",
      "Epoch 45/70\n",
      " - 4s - loss: 0.8756 - acc: 0.7080\n",
      "Epoch 46/70\n",
      " - 5s - loss: 0.8753 - acc: 0.7079\n",
      "Epoch 47/70\n",
      " - 5s - loss: 0.8743 - acc: 0.7080\n",
      "Epoch 48/70\n",
      " - 5s - loss: 0.8718 - acc: 0.7086\n",
      "Epoch 49/70\n",
      " - 4s - loss: 0.8693 - acc: 0.7095\n",
      "Epoch 50/70\n",
      " - 4s - loss: 0.8686 - acc: 0.7096\n",
      "Epoch 51/70\n",
      " - 5s - loss: 0.8688 - acc: 0.7082\n",
      "Epoch 52/70\n",
      " - 5s - loss: 0.8667 - acc: 0.7101\n",
      "Epoch 53/70\n",
      " - 4s - loss: 0.8665 - acc: 0.7098\n",
      "Epoch 54/70\n",
      " - 5s - loss: 0.8675 - acc: 0.7090\n",
      "Epoch 55/70\n",
      " - 5s - loss: 0.8613 - acc: 0.7105\n",
      "Epoch 56/70\n",
      " - 4s - loss: 0.8637 - acc: 0.7091\n",
      "Epoch 57/70\n",
      " - 4s - loss: 0.8609 - acc: 0.7113\n",
      "Epoch 58/70\n",
      " - 5s - loss: 0.8585 - acc: 0.7116\n",
      "Epoch 59/70\n",
      " - 4s - loss: 0.8596 - acc: 0.7116\n",
      "Epoch 60/70\n",
      " - 4s - loss: 0.8590 - acc: 0.7102\n",
      "Epoch 61/70\n",
      " - 5s - loss: 0.8601 - acc: 0.7109\n",
      "Epoch 62/70\n",
      " - 5s - loss: 0.8552 - acc: 0.7121\n",
      "Epoch 63/70\n",
      " - 4s - loss: 0.8525 - acc: 0.7132\n",
      "Epoch 64/70\n",
      " - 4s - loss: 0.8546 - acc: 0.7112\n",
      "Epoch 65/70\n",
      " - 5s - loss: 0.8509 - acc: 0.7129\n",
      "Epoch 66/70\n",
      " - 4s - loss: 0.8518 - acc: 0.7132\n",
      "Epoch 67/70\n",
      " - 4s - loss: 0.8486 - acc: 0.7134\n",
      "Epoch 68/70\n",
      " - 5s - loss: 0.8548 - acc: 0.7119\n",
      "Epoch 69/70\n",
      " - 5s - loss: 0.8490 - acc: 0.7122\n",
      "Epoch 70/70\n",
      " - 4s - loss: 0.8467 - acc: 0.7128\n",
      "[CV]  nodes_l3=60, nodes_l2=90, nodes_l1=170, dropout_l3=0.30000000000000004, dropout_l2=0.2, dropout_l1=0.1, batch_size=500, total= 5.7min\n",
      "[CV] nodes_l3=60, nodes_l2=90, nodes_l1=170, dropout_l3=0.30000000000000004, dropout_l2=0.2, dropout_l1=0.1, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=170)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 11s - loss: 2.1270 - acc: 0.4370\n",
      "Epoch 2/70\n",
      " - 5s - loss: 1.3738 - acc: 0.6141\n",
      "Epoch 3/70\n",
      " - 5s - loss: 1.2309 - acc: 0.6428\n",
      "Epoch 4/70\n",
      " - 5s - loss: 1.1571 - acc: 0.6551\n",
      "Epoch 5/70\n",
      " - 4s - loss: 1.1175 - acc: 0.6606\n",
      "Epoch 6/70\n",
      " - 5s - loss: 1.0882 - acc: 0.6677\n",
      "Epoch 7/70\n",
      " - 4s - loss: 1.0632 - acc: 0.6722\n",
      "Epoch 8/70\n",
      " - 5s - loss: 1.0504 - acc: 0.6738\n",
      "Epoch 9/70\n",
      " - 5s - loss: 1.0313 - acc: 0.6780\n",
      "Epoch 10/70\n",
      " - 5s - loss: 1.0166 - acc: 0.6807\n",
      "Epoch 11/70\n",
      " - 4s - loss: 1.0037 - acc: 0.6828\n",
      "Epoch 12/70\n",
      " - 5s - loss: 0.9921 - acc: 0.6864\n",
      "Epoch 13/70\n",
      " - 5s - loss: 0.9840 - acc: 0.6865\n",
      "Epoch 14/70\n",
      " - 4s - loss: 0.9734 - acc: 0.6890\n",
      "Epoch 15/70\n",
      " - 4s - loss: 0.9636 - acc: 0.6904\n",
      "Epoch 16/70\n",
      " - 5s - loss: 0.9568 - acc: 0.6922\n",
      "Epoch 17/70\n",
      " - 5s - loss: 0.9473 - acc: 0.6939\n",
      "Epoch 18/70\n",
      " - 4s - loss: 0.9446 - acc: 0.6937\n",
      "Epoch 19/70\n",
      " - 5s - loss: 0.9358 - acc: 0.6954\n",
      "Epoch 20/70\n",
      " - 5s - loss: 0.9319 - acc: 0.6970\n",
      "Epoch 21/70\n",
      " - 5s - loss: 0.9288 - acc: 0.6986\n",
      "Epoch 22/70\n",
      " - 5s - loss: 0.9230 - acc: 0.6988\n",
      "Epoch 23/70\n",
      " - 5s - loss: 0.9215 - acc: 0.6989\n",
      "Epoch 24/70\n",
      " - 4s - loss: 0.9158 - acc: 0.6996\n",
      "Epoch 25/70\n",
      " - 5s - loss: 0.9112 - acc: 0.7009\n",
      "Epoch 26/70\n",
      " - 5s - loss: 0.9094 - acc: 0.7012\n",
      "Epoch 27/70\n",
      " - 5s - loss: 0.9087 - acc: 0.7007\n",
      "Epoch 28/70\n",
      " - 4s - loss: 0.9038 - acc: 0.7019\n",
      "Epoch 29/70\n",
      " - 5s - loss: 0.8967 - acc: 0.7039\n",
      "Epoch 30/70\n",
      " - 5s - loss: 0.8939 - acc: 0.7054\n",
      "Epoch 31/70\n",
      " - 4s - loss: 0.8955 - acc: 0.7051\n",
      "Epoch 32/70\n",
      " - 4s - loss: 0.8887 - acc: 0.7059\n",
      "Epoch 33/70\n",
      " - 5s - loss: 0.8868 - acc: 0.7061\n",
      "Epoch 34/70\n",
      " - 5s - loss: 0.8890 - acc: 0.7065\n",
      "Epoch 35/70\n",
      " - 5s - loss: 0.8851 - acc: 0.7056\n",
      "Epoch 36/70\n",
      " - 5s - loss: 0.8812 - acc: 0.7064\n",
      "Epoch 37/70\n",
      " - 5s - loss: 0.8789 - acc: 0.7077\n",
      "Epoch 38/70\n",
      " - 5s - loss: 0.8788 - acc: 0.7087\n",
      "Epoch 39/70\n",
      " - 4s - loss: 0.8780 - acc: 0.7082\n",
      "Epoch 40/70\n",
      " - 5s - loss: 0.8715 - acc: 0.7087\n",
      "Epoch 41/70\n",
      " - 5s - loss: 0.8717 - acc: 0.7097\n",
      "Epoch 42/70\n",
      " - 5s - loss: 0.8711 - acc: 0.7093\n",
      "Epoch 43/70\n",
      " - 5s - loss: 0.8651 - acc: 0.7094\n",
      "Epoch 44/70\n",
      " - 5s - loss: 0.8633 - acc: 0.7107\n",
      "Epoch 45/70\n",
      " - 4s - loss: 0.8640 - acc: 0.7109\n",
      "Epoch 46/70\n",
      " - 4s - loss: 0.8652 - acc: 0.7109\n",
      "Epoch 47/70\n",
      " - 5s - loss: 0.8625 - acc: 0.7109\n",
      "Epoch 48/70\n",
      " - 5s - loss: 0.8607 - acc: 0.7107\n",
      "Epoch 49/70\n",
      " - 4s - loss: 0.8629 - acc: 0.7112\n",
      "Epoch 50/70\n",
      " - 5s - loss: 0.8582 - acc: 0.7116\n",
      "Epoch 51/70\n",
      " - 5s - loss: 0.8554 - acc: 0.7119\n",
      "Epoch 52/70\n",
      " - 4s - loss: 0.8554 - acc: 0.7130\n",
      "Epoch 53/70\n",
      " - 5s - loss: 0.8559 - acc: 0.7124\n",
      "Epoch 54/70\n",
      " - 5s - loss: 0.8538 - acc: 0.7133\n",
      "Epoch 55/70\n",
      " - 5s - loss: 0.8498 - acc: 0.7131\n",
      "Epoch 56/70\n",
      " - 4s - loss: 0.8506 - acc: 0.7124\n",
      "Epoch 57/70\n",
      " - 5s - loss: 0.8516 - acc: 0.7140\n",
      "Epoch 58/70\n",
      " - 5s - loss: 0.8490 - acc: 0.7145\n",
      "Epoch 59/70\n",
      " - 4s - loss: 0.8479 - acc: 0.7156\n",
      "Epoch 60/70\n",
      " - 5s - loss: 0.8480 - acc: 0.7143\n",
      "Epoch 61/70\n",
      " - 5s - loss: 0.8451 - acc: 0.7147\n",
      "Epoch 62/70\n",
      " - 5s - loss: 0.8435 - acc: 0.7158\n",
      "Epoch 63/70\n",
      " - 4s - loss: 0.8440 - acc: 0.7158\n",
      "Epoch 64/70\n",
      " - 5s - loss: 0.8445 - acc: 0.7147\n",
      "Epoch 65/70\n",
      " - 4s - loss: 0.8407 - acc: 0.7168\n",
      "Epoch 66/70\n",
      " - 4s - loss: 0.8406 - acc: 0.7164\n",
      "Epoch 67/70\n",
      " - 5s - loss: 0.8392 - acc: 0.7164\n",
      "Epoch 68/70\n",
      " - 5s - loss: 0.8381 - acc: 0.7171\n",
      "Epoch 69/70\n",
      " - 4s - loss: 0.8341 - acc: 0.7177\n",
      "Epoch 70/70\n",
      " - 4s - loss: 0.8375 - acc: 0.7166\n",
      "[CV]  nodes_l3=60, nodes_l2=90, nodes_l1=170, dropout_l3=0.30000000000000004, dropout_l2=0.2, dropout_l1=0.1, batch_size=500, total= 5.7min\n",
      "[CV] nodes_l3=60, nodes_l2=90, nodes_l1=170, dropout_l3=0.30000000000000004, dropout_l2=0.2, dropout_l1=0.1, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=170)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 11s - loss: 2.1661 - acc: 0.4286\n",
      "Epoch 2/70\n",
      " - 5s - loss: 1.3928 - acc: 0.6074\n",
      "Epoch 3/70\n",
      " - 5s - loss: 1.2451 - acc: 0.6356\n",
      "Epoch 4/70\n",
      " - 5s - loss: 1.1750 - acc: 0.6496\n",
      "Epoch 5/70\n",
      " - 5s - loss: 1.1386 - acc: 0.6528\n",
      "Epoch 6/70\n",
      " - 4s - loss: 1.1082 - acc: 0.6617\n",
      "Epoch 7/70\n",
      " - 4s - loss: 1.0834 - acc: 0.6645\n",
      "Epoch 8/70\n",
      " - 5s - loss: 1.0630 - acc: 0.6690\n",
      "Epoch 9/70\n",
      " - 5s - loss: 1.0473 - acc: 0.6710\n",
      "Epoch 10/70\n",
      " - 5s - loss: 1.0333 - acc: 0.6748\n",
      "Epoch 11/70\n",
      " - 5s - loss: 1.0161 - acc: 0.6781\n",
      "Epoch 12/70\n",
      " - 5s - loss: 1.0083 - acc: 0.6780\n",
      "Epoch 13/70\n",
      " - 4s - loss: 1.0010 - acc: 0.6820\n",
      "Epoch 14/70\n",
      " - 5s - loss: 0.9911 - acc: 0.6804\n",
      "Epoch 15/70\n",
      " - 5s - loss: 0.9864 - acc: 0.6831\n",
      "Epoch 16/70\n",
      " - 5s - loss: 0.9762 - acc: 0.6875\n",
      "Epoch 17/70\n",
      " - 5s - loss: 0.9694 - acc: 0.6881\n",
      "Epoch 18/70\n",
      " - 4s - loss: 0.9648 - acc: 0.6888\n",
      "Epoch 19/70\n",
      " - 5s - loss: 0.9585 - acc: 0.6884\n",
      "Epoch 20/70\n",
      " - 5s - loss: 0.9519 - acc: 0.6922\n",
      "Epoch 21/70\n",
      " - 5s - loss: 0.9480 - acc: 0.6917\n",
      "Epoch 22/70\n",
      " - 5s - loss: 0.9431 - acc: 0.6915\n",
      "Epoch 23/70\n",
      " - 5s - loss: 0.9439 - acc: 0.6934\n",
      "Epoch 24/70\n",
      " - 5s - loss: 0.9361 - acc: 0.6936\n",
      "Epoch 25/70\n",
      " - 5s - loss: 0.9296 - acc: 0.6939\n",
      "Epoch 26/70\n",
      " - 5s - loss: 0.9296 - acc: 0.6944\n",
      "Epoch 27/70\n",
      " - 5s - loss: 0.9258 - acc: 0.6958\n",
      "Epoch 28/70\n",
      " - 4s - loss: 0.9209 - acc: 0.6964\n",
      "Epoch 29/70\n",
      " - 5s - loss: 0.9234 - acc: 0.6948\n",
      "Epoch 30/70\n",
      " - 5s - loss: 0.9137 - acc: 0.6981\n",
      "Epoch 31/70\n",
      " - 5s - loss: 0.9150 - acc: 0.6986\n",
      "Epoch 32/70\n",
      " - 5s - loss: 0.9098 - acc: 0.6994\n",
      "Epoch 33/70\n",
      " - 5s - loss: 0.9078 - acc: 0.7007\n",
      "Epoch 34/70\n",
      " - 5s - loss: 0.9058 - acc: 0.6983\n",
      "Epoch 35/70\n",
      " - 5s - loss: 0.9050 - acc: 0.6991\n",
      "Epoch 36/70\n",
      " - 5s - loss: 0.9025 - acc: 0.7010\n",
      "Epoch 37/70\n",
      " - 4s - loss: 0.9002 - acc: 0.7005\n",
      "Epoch 38/70\n",
      " - 5s - loss: 0.8990 - acc: 0.7015\n",
      "Epoch 39/70\n",
      " - 5s - loss: 0.8931 - acc: 0.7027\n",
      "Epoch 40/70\n",
      " - 5s - loss: 0.8933 - acc: 0.7023\n",
      "Epoch 41/70\n",
      " - 5s - loss: 0.8910 - acc: 0.7027\n",
      "Epoch 42/70\n",
      " - 5s - loss: 0.8887 - acc: 0.7035\n",
      "Epoch 43/70\n",
      " - 5s - loss: 0.8875 - acc: 0.7025\n",
      "Epoch 44/70\n",
      " - 5s - loss: 0.8868 - acc: 0.7024\n",
      "Epoch 45/70\n",
      " - 5s - loss: 0.8840 - acc: 0.7027\n",
      "Epoch 46/70\n",
      " - 5s - loss: 0.8843 - acc: 0.7036\n",
      "Epoch 47/70\n",
      " - 5s - loss: 0.8824 - acc: 0.7042\n",
      "Epoch 48/70\n",
      " - 5s - loss: 0.8793 - acc: 0.7055\n",
      "Epoch 49/70\n",
      " - 5s - loss: 0.8795 - acc: 0.7058\n",
      "Epoch 50/70\n",
      " - 5s - loss: 0.8783 - acc: 0.7054\n",
      "Epoch 51/70\n",
      " - 5s - loss: 0.8769 - acc: 0.7044\n",
      "Epoch 52/70\n",
      " - 4s - loss: 0.8765 - acc: 0.7056\n",
      "Epoch 53/70\n",
      " - 5s - loss: 0.8724 - acc: 0.7069\n",
      "Epoch 54/70\n",
      " - 5s - loss: 0.8712 - acc: 0.7075\n",
      "Epoch 55/70\n",
      " - 5s - loss: 0.8729 - acc: 0.7071\n",
      "Epoch 56/70\n",
      " - 5s - loss: 0.8705 - acc: 0.7082\n",
      "Epoch 57/70\n",
      " - 5s - loss: 0.8695 - acc: 0.7072\n",
      "Epoch 58/70\n",
      " - 4s - loss: 0.8710 - acc: 0.7068\n",
      "Epoch 59/70\n",
      " - 4s - loss: 0.8666 - acc: 0.7067\n",
      "Epoch 60/70\n",
      " - 5s - loss: 0.8650 - acc: 0.7096\n",
      "Epoch 61/70\n",
      " - 5s - loss: 0.8689 - acc: 0.7080\n",
      "Epoch 62/70\n",
      " - 5s - loss: 0.8656 - acc: 0.7081\n",
      "Epoch 63/70\n",
      " - 5s - loss: 0.8629 - acc: 0.7081\n",
      "Epoch 64/70\n",
      " - 5s - loss: 0.8633 - acc: 0.7093\n",
      "Epoch 65/70\n",
      " - 5s - loss: 0.8609 - acc: 0.7107\n",
      "Epoch 66/70\n",
      " - 5s - loss: 0.8566 - acc: 0.7094\n",
      "Epoch 67/70\n",
      " - 5s - loss: 0.8606 - acc: 0.7101\n",
      "Epoch 68/70\n",
      " - 5s - loss: 0.8561 - acc: 0.7107\n",
      "Epoch 69/70\n",
      " - 4s - loss: 0.8600 - acc: 0.7107\n",
      "Epoch 70/70\n",
      " - 5s - loss: 0.8582 - acc: 0.7087\n",
      "[CV]  nodes_l3=60, nodes_l2=90, nodes_l1=170, dropout_l3=0.30000000000000004, dropout_l2=0.2, dropout_l1=0.1, batch_size=500, total= 5.7min\n",
      "[CV] nodes_l3=80, nodes_l2=120, nodes_l1=180, dropout_l3=0.1, dropout_l2=0.1, dropout_l1=0.30000000000000004, batch_size=3000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=180)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 10s - loss: 2.9535 - acc: 0.2442\n",
      "Epoch 2/70\n",
      " - 3s - loss: 2.0823 - acc: 0.4415\n",
      "Epoch 3/70\n",
      " - 2s - loss: 1.6765 - acc: 0.5543\n",
      "Epoch 4/70\n",
      " - 2s - loss: 1.4748 - acc: 0.5925\n",
      "Epoch 5/70\n",
      " - 2s - loss: 1.3561 - acc: 0.6160\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.2843 - acc: 0.6273\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.2271 - acc: 0.6379\n",
      "Epoch 8/70\n",
      " - 2s - loss: 1.1912 - acc: 0.6430\n",
      "Epoch 9/70\n",
      " - 2s - loss: 1.1590 - acc: 0.6483\n",
      "Epoch 10/70\n",
      " - 2s - loss: 1.1392 - acc: 0.6497\n",
      "Epoch 11/70\n",
      " - 2s - loss: 1.1187 - acc: 0.6534\n",
      "Epoch 12/70\n",
      " - 2s - loss: 1.1040 - acc: 0.6564\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.0835 - acc: 0.6599\n",
      "Epoch 14/70\n",
      " - 4s - loss: 1.0702 - acc: 0.6625\n",
      "Epoch 15/70\n",
      " - 2s - loss: 1.0605 - acc: 0.6645\n",
      "Epoch 16/70\n",
      " - 2s - loss: 1.0475 - acc: 0.6668\n",
      "Epoch 17/70\n",
      " - 2s - loss: 1.0400 - acc: 0.6661\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.0301 - acc: 0.6694\n",
      "Epoch 19/70\n",
      " - 3s - loss: 1.0242 - acc: 0.6697\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.0166 - acc: 0.6724\n",
      "Epoch 21/70\n",
      " - 2s - loss: 1.0084 - acc: 0.6732\n",
      "Epoch 22/70\n",
      " - 3s - loss: 1.0048 - acc: 0.6733\n",
      "Epoch 23/70\n",
      " - 2s - loss: 0.9926 - acc: 0.6757\n",
      "Epoch 24/70\n",
      " - 2s - loss: 0.9883 - acc: 0.6771\n",
      "Epoch 25/70\n",
      " - 3s - loss: 0.9830 - acc: 0.6786\n",
      "Epoch 26/70\n",
      " - 3s - loss: 0.9787 - acc: 0.6782\n",
      "Epoch 27/70\n",
      " - 2s - loss: 0.9735 - acc: 0.6798\n",
      "Epoch 28/70\n",
      " - 2s - loss: 0.9679 - acc: 0.6809\n",
      "Epoch 29/70\n",
      " - 2s - loss: 0.9631 - acc: 0.6837\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.9586 - acc: 0.6834\n",
      "Epoch 31/70\n",
      " - 2s - loss: 0.9565 - acc: 0.6817\n",
      "Epoch 32/70\n",
      " - 3s - loss: 0.9476 - acc: 0.6843\n",
      "Epoch 33/70\n",
      " - 3s - loss: 0.9441 - acc: 0.6847\n",
      "Epoch 34/70\n",
      " - 3s - loss: 0.9417 - acc: 0.6884\n",
      "Epoch 35/70\n",
      " - 2s - loss: 0.9348 - acc: 0.6868\n",
      "Epoch 36/70\n",
      " - 2s - loss: 0.9319 - acc: 0.6884\n",
      "Epoch 37/70\n",
      " - 2s - loss: 0.9337 - acc: 0.6872\n",
      "Epoch 38/70\n",
      " - 3s - loss: 0.9282 - acc: 0.6911\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.9292 - acc: 0.6891\n",
      "Epoch 40/70\n",
      " - 2s - loss: 0.9230 - acc: 0.6902\n",
      "Epoch 41/70\n",
      " - 2s - loss: 0.9180 - acc: 0.6914\n",
      "Epoch 42/70\n",
      " - 2s - loss: 0.9153 - acc: 0.6916\n",
      "Epoch 43/70\n",
      " - 2s - loss: 0.9160 - acc: 0.6916\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.9106 - acc: 0.6929\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.9093 - acc: 0.6933\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.9049 - acc: 0.6940\n",
      "Epoch 47/70\n",
      " - 2s - loss: 0.9036 - acc: 0.6947\n",
      "Epoch 48/70\n",
      " - 2s - loss: 0.9021 - acc: 0.6937\n",
      "Epoch 49/70\n",
      " - 2s - loss: 0.8985 - acc: 0.6939\n",
      "Epoch 50/70\n",
      " - 2s - loss: 0.8960 - acc: 0.6962\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.8970 - acc: 0.6959\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.8937 - acc: 0.6960\n",
      "Epoch 53/70\n",
      " - 2s - loss: 0.8883 - acc: 0.6978\n",
      "Epoch 54/70\n",
      " - 2s - loss: 0.8877 - acc: 0.6978\n",
      "Epoch 55/70\n",
      " - 2s - loss: 0.8871 - acc: 0.6978\n",
      "Epoch 56/70\n",
      " - 2s - loss: 0.8846 - acc: 0.6982\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.8861 - acc: 0.6983\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.8816 - acc: 0.6997\n",
      "Epoch 59/70\n",
      " - 2s - loss: 0.8790 - acc: 0.7008\n",
      "Epoch 60/70\n",
      " - 2s - loss: 0.8762 - acc: 0.7010\n",
      "Epoch 61/70\n",
      " - 2s - loss: 0.8734 - acc: 0.7013\n",
      "Epoch 62/70\n",
      " - 2s - loss: 0.8726 - acc: 0.7029\n",
      "Epoch 63/70\n",
      " - 2s - loss: 0.8734 - acc: 0.7005\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.8694 - acc: 0.7021\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.8688 - acc: 0.7014\n",
      "Epoch 66/70\n",
      " - 2s - loss: 0.8641 - acc: 0.7031\n",
      "Epoch 67/70\n",
      " - 2s - loss: 0.8638 - acc: 0.7035\n",
      "Epoch 68/70\n",
      " - 2s - loss: 0.8643 - acc: 0.7026\n",
      "Epoch 69/70\n",
      " - 2s - loss: 0.8643 - acc: 0.7034\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.8595 - acc: 0.7036\n",
      "[CV]  nodes_l3=80, nodes_l2=120, nodes_l1=180, dropout_l3=0.1, dropout_l2=0.1, dropout_l1=0.30000000000000004, batch_size=3000, total= 3.2min\n",
      "[CV] nodes_l3=80, nodes_l2=120, nodes_l1=180, dropout_l3=0.1, dropout_l2=0.1, dropout_l1=0.30000000000000004, batch_size=3000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=180)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 9s - loss: 2.9206 - acc: 0.2557\n",
      "Epoch 2/70\n",
      " - 3s - loss: 2.0135 - acc: 0.4691\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.6314 - acc: 0.5574\n",
      "Epoch 4/70\n",
      " - 2s - loss: 1.4438 - acc: 0.5963\n",
      "Epoch 5/70\n",
      " - 2s - loss: 1.3404 - acc: 0.6172\n",
      "Epoch 6/70\n",
      " - 2s - loss: 1.2677 - acc: 0.6277\n",
      "Epoch 7/70\n",
      " - 2s - loss: 1.2157 - acc: 0.6374\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.1814 - acc: 0.6446\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.1528 - acc: 0.6481\n",
      "Epoch 10/70\n",
      " - 2s - loss: 1.1328 - acc: 0.6501\n",
      "Epoch 11/70\n",
      " - 2s - loss: 1.1104 - acc: 0.6567\n",
      "Epoch 12/70\n",
      " - 2s - loss: 1.0972 - acc: 0.6580\n",
      "Epoch 13/70\n",
      " - 2s - loss: 1.0792 - acc: 0.6605\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.0707 - acc: 0.6629\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.0537 - acc: 0.6658\n",
      "Epoch 16/70\n",
      " - 2s - loss: 1.0445 - acc: 0.6661\n",
      "Epoch 17/70\n",
      " - 2s - loss: 1.0364 - acc: 0.6687\n",
      "Epoch 18/70\n",
      " - 2s - loss: 1.0271 - acc: 0.6702\n",
      "Epoch 19/70\n",
      " - 2s - loss: 1.0200 - acc: 0.6705\n",
      "Epoch 20/70\n",
      " - 2s - loss: 1.0098 - acc: 0.6729\n",
      "Epoch 21/70\n",
      " - 3s - loss: 1.0044 - acc: 0.6749\n",
      "Epoch 22/70\n",
      " - 3s - loss: 1.0005 - acc: 0.6746\n",
      "Epoch 23/70\n",
      " - 2s - loss: 0.9928 - acc: 0.6752\n",
      "Epoch 24/70\n",
      " - 2s - loss: 0.9842 - acc: 0.6784\n",
      "Epoch 25/70\n",
      " - 2s - loss: 0.9833 - acc: 0.6777\n",
      "Epoch 26/70\n",
      " - 2s - loss: 0.9725 - acc: 0.6803\n",
      "Epoch 27/70\n",
      " - 3s - loss: 0.9674 - acc: 0.6839\n",
      "Epoch 28/70\n",
      " - 3s - loss: 0.9632 - acc: 0.6823\n",
      "Epoch 29/70\n",
      " - 2s - loss: 0.9588 - acc: 0.6845\n",
      "Epoch 30/70\n",
      " - 2s - loss: 0.9515 - acc: 0.6844\n",
      "Epoch 31/70\n",
      " - 3s - loss: 0.9520 - acc: 0.6847\n",
      "Epoch 32/70\n",
      " - 2s - loss: 0.9481 - acc: 0.6847\n",
      "Epoch 33/70\n",
      " - 3s - loss: 0.9433 - acc: 0.6859\n",
      "Epoch 34/70\n",
      " - 3s - loss: 0.9412 - acc: 0.6862\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9360 - acc: 0.6881\n",
      "Epoch 36/70\n",
      " - 2s - loss: 0.9327 - acc: 0.6878\n",
      "Epoch 37/70\n",
      " - 2s - loss: 0.9260 - acc: 0.6905\n",
      "Epoch 38/70\n",
      " - 2s - loss: 0.9279 - acc: 0.6897\n",
      "Epoch 39/70\n",
      " - 2s - loss: 0.9232 - acc: 0.6912\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.9171 - acc: 0.6911\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.9186 - acc: 0.6920\n",
      "Epoch 42/70\n",
      " - 2s - loss: 0.9138 - acc: 0.6910\n",
      "Epoch 43/70\n",
      " - 2s - loss: 0.9090 - acc: 0.6929\n",
      "Epoch 44/70\n",
      " - 2s - loss: 0.9084 - acc: 0.6941\n",
      "Epoch 45/70\n",
      " - 2s - loss: 0.9091 - acc: 0.6943\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.9038 - acc: 0.6940\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.9005 - acc: 0.6956\n",
      "Epoch 48/70\n",
      " - 2s - loss: 0.8960 - acc: 0.6966\n",
      "Epoch 49/70\n",
      " - 2s - loss: 0.8978 - acc: 0.6957\n",
      "Epoch 50/70\n",
      " - 2s - loss: 0.8937 - acc: 0.6989\n",
      "Epoch 51/70\n",
      " - 2s - loss: 0.8926 - acc: 0.6966\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.8883 - acc: 0.6990\n",
      "Epoch 53/70\n",
      " - 3s - loss: 0.8864 - acc: 0.6983\n",
      "Epoch 54/70\n",
      " - 2s - loss: 0.8829 - acc: 0.7009\n",
      "Epoch 55/70\n",
      " - 2s - loss: 0.8807 - acc: 0.6993\n",
      "Epoch 56/70\n",
      " - 2s - loss: 0.8793 - acc: 0.7002\n",
      "Epoch 57/70\n",
      " - 2s - loss: 0.8783 - acc: 0.7029\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.8789 - acc: 0.7002\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.8753 - acc: 0.7018\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.8717 - acc: 0.7032\n",
      "Epoch 61/70\n",
      " - 2s - loss: 0.8745 - acc: 0.7010\n",
      "Epoch 62/70\n",
      " - 2s - loss: 0.8690 - acc: 0.7028\n",
      "Epoch 63/70\n",
      " - 2s - loss: 0.8680 - acc: 0.7045\n",
      "Epoch 64/70\n",
      " - 2s - loss: 0.8650 - acc: 0.7037\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.8686 - acc: 0.7019\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.8632 - acc: 0.7036\n",
      "Epoch 67/70\n",
      " - 2s - loss: 0.8618 - acc: 0.7049\n",
      "Epoch 68/70\n",
      " - 2s - loss: 0.8620 - acc: 0.7037\n",
      "Epoch 69/70\n",
      " - 2s - loss: 0.8613 - acc: 0.7044\n",
      "Epoch 70/70\n",
      " - 2s - loss: 0.8596 - acc: 0.7053\n",
      "[CV]  nodes_l3=80, nodes_l2=120, nodes_l1=180, dropout_l3=0.1, dropout_l2=0.1, dropout_l1=0.30000000000000004, batch_size=3000, total= 3.1min\n",
      "[CV] nodes_l3=80, nodes_l2=120, nodes_l1=180, dropout_l3=0.1, dropout_l2=0.1, dropout_l1=0.30000000000000004, batch_size=3000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=180)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 9s - loss: 2.9099 - acc: 0.2666\n",
      "Epoch 2/70\n",
      " - 2s - loss: 2.0554 - acc: 0.4596\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.6465 - acc: 0.5533\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.4523 - acc: 0.5944\n",
      "Epoch 5/70\n",
      " - 2s - loss: 1.3384 - acc: 0.6180\n",
      "Epoch 6/70\n",
      " - 2s - loss: 1.2557 - acc: 0.6317\n",
      "Epoch 7/70\n",
      " - 2s - loss: 1.2103 - acc: 0.6391\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.1738 - acc: 0.6460\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.1437 - acc: 0.6505\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.1193 - acc: 0.6568\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.1014 - acc: 0.6582\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.0846 - acc: 0.6625\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.0718 - acc: 0.6616\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.0592 - acc: 0.6649\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.0506 - acc: 0.6667\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.0312 - acc: 0.6709\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.0272 - acc: 0.6711\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.0181 - acc: 0.6736\n",
      "Epoch 19/70\n",
      " - 3s - loss: 1.0085 - acc: 0.6741\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.0023 - acc: 0.6748\n",
      "Epoch 21/70\n",
      " - 4s - loss: 0.9909 - acc: 0.6776\n",
      "Epoch 22/70\n",
      " - 5s - loss: 0.9909 - acc: 0.6774\n",
      "Epoch 23/70\n",
      " - 4s - loss: 0.9825 - acc: 0.6793\n",
      "Epoch 24/70\n",
      " - 4s - loss: 0.9752 - acc: 0.6808\n",
      "Epoch 25/70\n",
      " - 5s - loss: 0.9704 - acc: 0.6815\n",
      "Epoch 26/70\n",
      " - 5s - loss: 0.9630 - acc: 0.6838\n",
      "Epoch 27/70\n",
      " - 4s - loss: 0.9586 - acc: 0.6849\n",
      "Epoch 28/70\n",
      " - 5s - loss: 0.9548 - acc: 0.6860\n",
      "Epoch 29/70\n",
      " - 4s - loss: 0.9485 - acc: 0.6871\n",
      "Epoch 30/70\n",
      " - 4s - loss: 0.9455 - acc: 0.6876\n",
      "Epoch 31/70\n",
      " - 4s - loss: 0.9406 - acc: 0.6891\n",
      "Epoch 32/70\n",
      " - 4s - loss: 0.9375 - acc: 0.6864\n",
      "Epoch 33/70\n",
      " - 4s - loss: 0.9336 - acc: 0.6896\n",
      "Epoch 34/70\n",
      " - 4s - loss: 0.9308 - acc: 0.6889\n",
      "Epoch 35/70\n",
      " - 4s - loss: 0.9253 - acc: 0.6909\n",
      "Epoch 36/70\n",
      " - 4s - loss: 0.9182 - acc: 0.6922\n",
      "Epoch 37/70\n",
      " - 4s - loss: 0.9180 - acc: 0.6921\n",
      "Epoch 38/70\n",
      " - 4s - loss: 0.9148 - acc: 0.6922\n",
      "Epoch 39/70\n",
      " - 4s - loss: 0.9090 - acc: 0.6933\n",
      "Epoch 40/70\n",
      " - 4s - loss: 0.9059 - acc: 0.6945\n",
      "Epoch 41/70\n",
      " - 4s - loss: 0.9028 - acc: 0.6964\n",
      "Epoch 42/70\n",
      " - 4s - loss: 0.9017 - acc: 0.6951\n",
      "Epoch 43/70\n",
      " - 4s - loss: 0.8970 - acc: 0.6977\n",
      "Epoch 44/70\n",
      " - 4s - loss: 0.8931 - acc: 0.6972\n",
      "Epoch 45/70\n",
      " - 4s - loss: 0.8958 - acc: 0.6967\n",
      "Epoch 46/70\n",
      " - 4s - loss: 0.8886 - acc: 0.6989\n",
      "Epoch 47/70\n",
      " - 4s - loss: 0.8835 - acc: 0.6989\n",
      "Epoch 48/70\n",
      " - 4s - loss: 0.8837 - acc: 0.6994\n",
      "Epoch 49/70\n",
      " - 4s - loss: 0.8816 - acc: 0.7000\n",
      "Epoch 50/70\n",
      " - 4s - loss: 0.8772 - acc: 0.7015\n",
      "Epoch 51/70\n",
      " - 4s - loss: 0.8762 - acc: 0.7006\n",
      "Epoch 52/70\n",
      " - 4s - loss: 0.8755 - acc: 0.7006\n",
      "Epoch 53/70\n",
      " - 4s - loss: 0.8735 - acc: 0.7008\n",
      "Epoch 54/70\n",
      " - 4s - loss: 0.8708 - acc: 0.7021\n",
      "Epoch 55/70\n",
      " - 4s - loss: 0.8714 - acc: 0.7028\n",
      "Epoch 56/70\n",
      " - 5s - loss: 0.8667 - acc: 0.7038\n",
      "Epoch 57/70\n",
      " - 5s - loss: 0.8633 - acc: 0.7039\n",
      "Epoch 58/70\n",
      " - 4s - loss: 0.8644 - acc: 0.7036\n",
      "Epoch 59/70\n",
      " - 5s - loss: 0.8583 - acc: 0.7056\n",
      "Epoch 60/70\n",
      " - 5s - loss: 0.8568 - acc: 0.7063\n",
      "Epoch 61/70\n",
      " - 5s - loss: 0.8574 - acc: 0.7049\n",
      "Epoch 62/70\n",
      " - 5s - loss: 0.8567 - acc: 0.7055\n",
      "Epoch 63/70\n",
      " - 5s - loss: 0.8544 - acc: 0.7055\n",
      "Epoch 64/70\n",
      " - 4s - loss: 0.8505 - acc: 0.7070\n",
      "Epoch 65/70\n",
      " - 4s - loss: 0.8492 - acc: 0.7071\n",
      "Epoch 66/70\n",
      " - 4s - loss: 0.8517 - acc: 0.7050\n",
      "Epoch 67/70\n",
      " - 4s - loss: 0.8473 - acc: 0.7070\n",
      "Epoch 68/70\n",
      " - 4s - loss: 0.8415 - acc: 0.7084\n",
      "Epoch 69/70\n",
      " - 4s - loss: 0.8475 - acc: 0.7054\n",
      "Epoch 70/70\n",
      " - 4s - loss: 0.8419 - acc: 0.7075\n",
      "[CV]  nodes_l3=80, nodes_l2=120, nodes_l1=180, dropout_l3=0.1, dropout_l2=0.1, dropout_l1=0.30000000000000004, batch_size=3000, total= 4.7min\n",
      "[CV] nodes_l3=80, nodes_l2=120, nodes_l1=180, dropout_l3=0.1, dropout_l2=0.1, dropout_l1=0.30000000000000004, batch_size=3000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=180)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 11s - loss: 2.9326 - acc: 0.2610\n",
      "Epoch 2/70\n",
      " - 3s - loss: 2.0462 - acc: 0.4581\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.6646 - acc: 0.5523\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.4703 - acc: 0.5904\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.3548 - acc: 0.6137\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.2754 - acc: 0.6284\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.2319 - acc: 0.6333\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.1857 - acc: 0.6422\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.1573 - acc: 0.6476\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.1376 - acc: 0.6498\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.1170 - acc: 0.6519\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.0979 - acc: 0.6563\n",
      "Epoch 13/70\n",
      " - 2s - loss: 1.0854 - acc: 0.6588\n",
      "Epoch 14/70\n",
      " - 2s - loss: 1.0707 - acc: 0.6613\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.0599 - acc: 0.6623\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.0497 - acc: 0.6630\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.0394 - acc: 0.6649\n",
      "Epoch 18/70\n",
      " - 2s - loss: 1.0298 - acc: 0.6681\n",
      "Epoch 19/70\n",
      " - 2s - loss: 1.0222 - acc: 0.6708\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.0110 - acc: 0.6732\n",
      "Epoch 21/70\n",
      " - 3s - loss: 1.0052 - acc: 0.6746\n",
      "Epoch 22/70\n",
      " - 3s - loss: 0.9977 - acc: 0.6743\n",
      "Epoch 23/70\n",
      " - 3s - loss: 0.9909 - acc: 0.6745\n",
      "Epoch 24/70\n",
      " - 3s - loss: 0.9879 - acc: 0.6762\n",
      "Epoch 25/70\n",
      " - 3s - loss: 0.9809 - acc: 0.6776\n",
      "Epoch 26/70\n",
      " - 3s - loss: 0.9731 - acc: 0.6805\n",
      "Epoch 27/70\n",
      " - 3s - loss: 0.9732 - acc: 0.6775\n",
      "Epoch 28/70\n",
      " - 3s - loss: 0.9672 - acc: 0.6790\n",
      "Epoch 29/70\n",
      " - 3s - loss: 0.9613 - acc: 0.6807\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.9592 - acc: 0.6823\n",
      "Epoch 31/70\n",
      " - 3s - loss: 0.9531 - acc: 0.6838\n",
      "Epoch 32/70\n",
      " - 3s - loss: 0.9490 - acc: 0.6824\n",
      "Epoch 33/70\n",
      " - 3s - loss: 0.9471 - acc: 0.6849\n",
      "Epoch 34/70\n",
      " - 3s - loss: 0.9430 - acc: 0.6838\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9426 - acc: 0.6860\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9330 - acc: 0.6866\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9282 - acc: 0.6897\n",
      "Epoch 38/70\n",
      " - 3s - loss: 0.9272 - acc: 0.6874\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.9274 - acc: 0.6885\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.9191 - acc: 0.6910\n",
      "Epoch 41/70\n",
      " - 2s - loss: 0.9188 - acc: 0.6923\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.9163 - acc: 0.6898\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.9104 - acc: 0.6934\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.9125 - acc: 0.6916\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.9078 - acc: 0.6911\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.9036 - acc: 0.6948\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.9046 - acc: 0.6931\n",
      "Epoch 48/70\n",
      " - 2s - loss: 0.8992 - acc: 0.6947\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.8973 - acc: 0.6948\n",
      "Epoch 50/70\n",
      " - 2s - loss: 0.8970 - acc: 0.6959\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.8937 - acc: 0.6963\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.8896 - acc: 0.6980\n",
      "Epoch 53/70\n",
      " - 2s - loss: 0.8874 - acc: 0.6969\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.8894 - acc: 0.6979\n",
      "Epoch 55/70\n",
      " - 2s - loss: 0.8860 - acc: 0.6983\n",
      "Epoch 56/70\n",
      " - 2s - loss: 0.8845 - acc: 0.6988\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.8823 - acc: 0.6992\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.8808 - acc: 0.7001\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.8791 - acc: 0.6992\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.8762 - acc: 0.6991\n",
      "Epoch 61/70\n",
      " - 2s - loss: 0.8767 - acc: 0.6999\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.8728 - acc: 0.7008\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.8721 - acc: 0.7009\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.8726 - acc: 0.7008\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.8682 - acc: 0.7024\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.8669 - acc: 0.7017\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.8650 - acc: 0.7022\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.8641 - acc: 0.7019\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.8598 - acc: 0.7047\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.8636 - acc: 0.7031\n",
      "[CV]  nodes_l3=80, nodes_l2=120, nodes_l1=180, dropout_l3=0.1, dropout_l2=0.1, dropout_l1=0.30000000000000004, batch_size=3000, total= 3.5min\n",
      "[CV] nodes_l3=80, nodes_l2=130, nodes_l1=170, dropout_l3=0.4, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=3000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=170)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=130)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=130)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 11s - loss: 3.2448 - acc: 0.1629\n",
      "Epoch 2/70\n",
      " - 3s - loss: 2.4762 - acc: 0.3230\n",
      "Epoch 3/70\n",
      " - 3s - loss: 2.0282 - acc: 0.4501\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.7568 - acc: 0.5256\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.6048 - acc: 0.5651\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.5058 - acc: 0.5858\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.4369 - acc: 0.6019\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.3794 - acc: 0.6142\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.3328 - acc: 0.6214\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.3032 - acc: 0.6277\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.2754 - acc: 0.6334\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.2541 - acc: 0.6369\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.2266 - acc: 0.6422\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.2193 - acc: 0.6431\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.1933 - acc: 0.6490\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.1904 - acc: 0.6484\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.1740 - acc: 0.6515\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.1613 - acc: 0.6526\n",
      "Epoch 19/70\n",
      " - 3s - loss: 1.1551 - acc: 0.6546\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.1416 - acc: 0.6580\n",
      "Epoch 21/70\n",
      " - 3s - loss: 1.1387 - acc: 0.6564\n",
      "Epoch 22/70\n",
      " - 3s - loss: 1.1268 - acc: 0.6584\n",
      "Epoch 23/70\n",
      " - 3s - loss: 1.1173 - acc: 0.6623\n",
      "Epoch 24/70\n",
      " - 3s - loss: 1.1082 - acc: 0.6626\n",
      "Epoch 25/70\n",
      " - 4s - loss: 1.1089 - acc: 0.6635\n",
      "Epoch 26/70\n",
      " - 4s - loss: 1.0942 - acc: 0.6660\n",
      "Epoch 27/70\n",
      " - 3s - loss: 1.0933 - acc: 0.6646\n",
      "Epoch 28/70\n",
      " - 3s - loss: 1.0886 - acc: 0.6683\n",
      "Epoch 29/70\n",
      " - 3s - loss: 1.0810 - acc: 0.6683\n",
      "Epoch 30/70\n",
      " - 3s - loss: 1.0705 - acc: 0.6697\n",
      "Epoch 31/70\n",
      " - 3s - loss: 1.0650 - acc: 0.6722\n",
      "Epoch 32/70\n",
      " - 4s - loss: 1.0618 - acc: 0.6702\n",
      "Epoch 33/70\n",
      " - 5s - loss: 1.0567 - acc: 0.6717\n",
      "Epoch 34/70\n",
      " - 4s - loss: 1.0562 - acc: 0.6734\n",
      "Epoch 35/70\n",
      " - 6s - loss: 1.0517 - acc: 0.6740\n",
      "Epoch 36/70\n",
      " - 5s - loss: 1.0472 - acc: 0.6749\n",
      "Epoch 37/70\n",
      " - 5s - loss: 1.0426 - acc: 0.6748\n",
      "Epoch 38/70\n",
      " - 7s - loss: 1.0377 - acc: 0.6779\n",
      "Epoch 39/70\n",
      " - 6s - loss: 1.0349 - acc: 0.6779\n",
      "Epoch 40/70\n",
      " - 5s - loss: 1.0322 - acc: 0.6786\n",
      "Epoch 41/70\n",
      " - 4s - loss: 1.0288 - acc: 0.6785\n",
      "Epoch 42/70\n",
      " - 4s - loss: 1.0228 - acc: 0.6796\n",
      "Epoch 43/70\n",
      " - 4s - loss: 1.0238 - acc: 0.6777\n",
      "Epoch 44/70\n",
      " - 4s - loss: 1.0174 - acc: 0.6807\n",
      "Epoch 45/70\n",
      " - 4s - loss: 1.0167 - acc: 0.6792\n",
      "Epoch 46/70\n",
      " - 4s - loss: 1.0148 - acc: 0.6809\n",
      "Epoch 47/70\n",
      " - 4s - loss: 1.0088 - acc: 0.6825\n",
      "Epoch 48/70\n",
      " - 5s - loss: 1.0084 - acc: 0.6818\n",
      "Epoch 49/70\n",
      " - 4s - loss: 1.0078 - acc: 0.6837\n",
      "Epoch 50/70\n",
      " - 4s - loss: 1.0048 - acc: 0.6829\n",
      "Epoch 51/70\n",
      " - 5s - loss: 1.0028 - acc: 0.6830\n",
      "Epoch 52/70\n",
      " - 5s - loss: 0.9987 - acc: 0.6846\n",
      "Epoch 53/70\n",
      " - 5s - loss: 0.9928 - acc: 0.6849\n",
      "Epoch 54/70\n",
      " - 5s - loss: 0.9978 - acc: 0.6835\n",
      "Epoch 55/70\n",
      " - 5s - loss: 0.9906 - acc: 0.6857\n",
      "Epoch 56/70\n",
      " - 4s - loss: 0.9912 - acc: 0.6863\n",
      "Epoch 57/70\n",
      " - 4s - loss: 0.9919 - acc: 0.6854\n",
      "Epoch 58/70\n",
      " - 4s - loss: 0.9890 - acc: 0.6855\n",
      "Epoch 59/70\n",
      " - 4s - loss: 0.9838 - acc: 0.6872\n",
      "Epoch 60/70\n",
      " - 4s - loss: 0.9834 - acc: 0.6852\n",
      "Epoch 61/70\n",
      " - 4s - loss: 0.9822 - acc: 0.6859\n",
      "Epoch 62/70\n",
      " - 4s - loss: 0.9786 - acc: 0.6891\n",
      "Epoch 63/70\n",
      " - 4s - loss: 0.9851 - acc: 0.6858\n",
      "Epoch 64/70\n",
      " - 4s - loss: 0.9744 - acc: 0.6892\n",
      "Epoch 65/70\n",
      " - 4s - loss: 0.9727 - acc: 0.6885\n",
      "Epoch 66/70\n",
      " - 4s - loss: 0.9748 - acc: 0.6877\n",
      "Epoch 67/70\n",
      " - 4s - loss: 0.9694 - acc: 0.6900\n",
      "Epoch 68/70\n",
      " - 4s - loss: 0.9668 - acc: 0.6890\n",
      "Epoch 69/70\n",
      " - 4s - loss: 0.9718 - acc: 0.6889\n",
      "Epoch 70/70\n",
      " - 4s - loss: 0.9687 - acc: 0.6894\n",
      "[CV]  nodes_l3=80, nodes_l2=130, nodes_l1=170, dropout_l3=0.4, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=3000, total= 4.7min\n",
      "[CV] nodes_l3=80, nodes_l2=130, nodes_l1=170, dropout_l3=0.4, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=3000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=170)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=130)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=130)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 10s - loss: 3.1795 - acc: 0.1894\n",
      "Epoch 2/70\n",
      " - 3s - loss: 2.4106 - acc: 0.3470\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.9812 - acc: 0.4626\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.7472 - acc: 0.5250\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.6031 - acc: 0.5612\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.5105 - acc: 0.5834\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.4450 - acc: 0.5961\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.3895 - acc: 0.6078\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.3441 - acc: 0.6167\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.3092 - acc: 0.6233\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.2814 - acc: 0.6300\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.2580 - acc: 0.6355\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.2366 - acc: 0.6375\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.2231 - acc: 0.6423\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.2060 - acc: 0.6453\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.1849 - acc: 0.6477\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.1781 - acc: 0.6504\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.1670 - acc: 0.6499\n",
      "Epoch 19/70\n",
      " - 3s - loss: 1.1561 - acc: 0.6547\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.1471 - acc: 0.6536\n",
      "Epoch 21/70\n",
      " - 3s - loss: 1.1382 - acc: 0.6571\n",
      "Epoch 22/70\n",
      " - 3s - loss: 1.1317 - acc: 0.6564\n",
      "Epoch 23/70\n",
      " - 3s - loss: 1.1204 - acc: 0.6597\n",
      "Epoch 24/70\n",
      " - 3s - loss: 1.1151 - acc: 0.6586\n",
      "Epoch 25/70\n",
      " - 3s - loss: 1.1047 - acc: 0.6617\n",
      "Epoch 26/70\n",
      " - 3s - loss: 1.0990 - acc: 0.6640\n",
      "Epoch 27/70\n",
      " - 3s - loss: 1.0938 - acc: 0.6651\n",
      "Epoch 28/70\n",
      " - 3s - loss: 1.0922 - acc: 0.6656\n",
      "Epoch 29/70\n",
      " - 3s - loss: 1.0845 - acc: 0.6656\n",
      "Epoch 30/70\n",
      " - 3s - loss: 1.0783 - acc: 0.6664\n",
      "Epoch 31/70\n",
      " - 3s - loss: 1.0726 - acc: 0.6682\n",
      "Epoch 32/70\n",
      " - 3s - loss: 1.0642 - acc: 0.6686\n",
      "Epoch 33/70\n",
      " - 3s - loss: 1.0605 - acc: 0.6712\n",
      "Epoch 34/70\n",
      " - 3s - loss: 1.0581 - acc: 0.6725\n",
      "Epoch 35/70\n",
      " - 3s - loss: 1.0554 - acc: 0.6716\n",
      "Epoch 36/70\n",
      " - 3s - loss: 1.0477 - acc: 0.6731\n",
      "Epoch 37/70\n",
      " - 3s - loss: 1.0476 - acc: 0.6730\n",
      "Epoch 38/70\n",
      " - 3s - loss: 1.0396 - acc: 0.6756\n",
      "Epoch 39/70\n",
      " - 3s - loss: 1.0349 - acc: 0.6781\n",
      "Epoch 40/70\n",
      " - 3s - loss: 1.0306 - acc: 0.6774\n",
      "Epoch 41/70\n",
      " - 3s - loss: 1.0323 - acc: 0.6775\n",
      "Epoch 42/70\n",
      " - 3s - loss: 1.0258 - acc: 0.6772\n",
      "Epoch 43/70\n",
      " - 3s - loss: 1.0225 - acc: 0.6804\n",
      "Epoch 44/70\n",
      " - 3s - loss: 1.0189 - acc: 0.6786\n",
      "Epoch 45/70\n",
      " - 3s - loss: 1.0194 - acc: 0.6796\n",
      "Epoch 46/70\n",
      " - 3s - loss: 1.0143 - acc: 0.6812\n",
      "Epoch 47/70\n",
      " - 3s - loss: 1.0148 - acc: 0.6831\n",
      "Epoch 48/70\n",
      " - 3s - loss: 1.0144 - acc: 0.6792\n",
      "Epoch 49/70\n",
      " - 3s - loss: 1.0103 - acc: 0.6814\n",
      "Epoch 50/70\n",
      " - 3s - loss: 1.0020 - acc: 0.6825\n",
      "Epoch 51/70\n",
      " - 3s - loss: 1.0030 - acc: 0.6848\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.9997 - acc: 0.6830\n",
      "Epoch 53/70\n",
      " - 3s - loss: 0.9980 - acc: 0.6839\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.9939 - acc: 0.6864\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.9934 - acc: 0.6839\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.9906 - acc: 0.6856\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.9921 - acc: 0.6843\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.9902 - acc: 0.6868\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.9844 - acc: 0.6885\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.9830 - acc: 0.6869\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.9788 - acc: 0.6865\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.9806 - acc: 0.6876\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.9786 - acc: 0.6880\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.9804 - acc: 0.6874\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.9740 - acc: 0.6886\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.9751 - acc: 0.6893\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.9757 - acc: 0.6877\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.9733 - acc: 0.6883\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.9690 - acc: 0.6905\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.9690 - acc: 0.6889\n",
      "[CV]  nodes_l3=80, nodes_l2=130, nodes_l1=170, dropout_l3=0.4, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=3000, total= 3.5min\n",
      "[CV] nodes_l3=80, nodes_l2=130, nodes_l1=170, dropout_l3=0.4, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=3000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=170)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=130)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=130)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 10s - loss: 3.2184 - acc: 0.1737\n",
      "Epoch 2/70\n",
      " - 3s - loss: 2.4574 - acc: 0.3366\n",
      "Epoch 3/70\n",
      " - 3s - loss: 2.0087 - acc: 0.4574\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.7547 - acc: 0.5259\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.6031 - acc: 0.5622\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.5081 - acc: 0.5854\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.4349 - acc: 0.5989\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.3757 - acc: 0.6121\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.3359 - acc: 0.6201\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.2954 - acc: 0.6276\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.2722 - acc: 0.6316\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.2457 - acc: 0.6369\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.2218 - acc: 0.6407\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.2074 - acc: 0.6426\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.1923 - acc: 0.6463\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.1761 - acc: 0.6503\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.1600 - acc: 0.6502\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.1560 - acc: 0.6538\n",
      "Epoch 19/70\n",
      " - 4s - loss: 1.1443 - acc: 0.6557\n",
      "Epoch 20/70\n",
      " - 4s - loss: 1.1350 - acc: 0.6582\n",
      "Epoch 21/70\n",
      " - 4s - loss: 1.1223 - acc: 0.6588\n",
      "Epoch 22/70\n",
      " - 4s - loss: 1.1157 - acc: 0.6602\n",
      "Epoch 23/70\n",
      " - 4s - loss: 1.1066 - acc: 0.6612\n",
      "Epoch 24/70\n",
      " - 4s - loss: 1.1016 - acc: 0.6633\n",
      "Epoch 25/70\n",
      " - 4s - loss: 1.0951 - acc: 0.6634\n",
      "Epoch 26/70\n",
      " - 4s - loss: 1.0887 - acc: 0.6669\n",
      "Epoch 27/70\n",
      " - 4s - loss: 1.0791 - acc: 0.6670\n",
      "Epoch 28/70\n",
      " - 4s - loss: 1.0751 - acc: 0.6685\n",
      "Epoch 29/70\n",
      " - 4s - loss: 1.0695 - acc: 0.6705\n",
      "Epoch 30/70\n",
      " - 4s - loss: 1.0656 - acc: 0.6694\n",
      "Epoch 31/70\n",
      " - 4s - loss: 1.0619 - acc: 0.6709\n",
      "Epoch 32/70\n",
      " - 4s - loss: 1.0617 - acc: 0.6701\n",
      "Epoch 33/70\n",
      " - 4s - loss: 1.0515 - acc: 0.6730\n",
      "Epoch 34/70\n",
      " - 4s - loss: 1.0473 - acc: 0.6762\n",
      "Epoch 35/70\n",
      " - 4s - loss: 1.0451 - acc: 0.6759\n",
      "Epoch 36/70\n",
      " - 4s - loss: 1.0382 - acc: 0.6762\n",
      "Epoch 37/70\n",
      " - 4s - loss: 1.0338 - acc: 0.6769\n",
      "Epoch 38/70\n",
      " - 4s - loss: 1.0303 - acc: 0.6783\n",
      "Epoch 39/70\n",
      " - 4s - loss: 1.0271 - acc: 0.6779\n",
      "Epoch 40/70\n",
      " - 4s - loss: 1.0260 - acc: 0.6809\n",
      "Epoch 41/70\n",
      " - 4s - loss: 1.0189 - acc: 0.6807\n",
      "Epoch 42/70\n",
      " - 4s - loss: 1.0173 - acc: 0.6804\n",
      "Epoch 43/70\n",
      " - 4s - loss: 1.0138 - acc: 0.6818\n",
      "Epoch 44/70\n",
      " - 4s - loss: 1.0107 - acc: 0.6822\n",
      "Epoch 45/70\n",
      " - 4s - loss: 1.0070 - acc: 0.6826\n",
      "Epoch 46/70\n",
      " - 4s - loss: 1.0030 - acc: 0.6833\n",
      "Epoch 47/70\n",
      " - 4s - loss: 1.0014 - acc: 0.6853\n",
      "Epoch 48/70\n",
      " - 4s - loss: 0.9983 - acc: 0.6848\n",
      "Epoch 49/70\n",
      " - 4s - loss: 0.9948 - acc: 0.6865\n",
      "Epoch 50/70\n",
      " - 4s - loss: 0.9959 - acc: 0.6844\n",
      "Epoch 51/70\n",
      " - 4s - loss: 0.9906 - acc: 0.6853\n",
      "Epoch 52/70\n",
      " - 4s - loss: 0.9912 - acc: 0.6854\n",
      "Epoch 53/70\n",
      " - 4s - loss: 0.9884 - acc: 0.6878\n",
      "Epoch 54/70\n",
      " - 4s - loss: 0.9871 - acc: 0.6871\n",
      "Epoch 55/70\n",
      " - 4s - loss: 0.9851 - acc: 0.6871\n",
      "Epoch 56/70\n",
      " - 5s - loss: 0.9813 - acc: 0.6897\n",
      "Epoch 57/70\n",
      " - 5s - loss: 0.9788 - acc: 0.6890\n",
      "Epoch 58/70\n",
      " - 4s - loss: 0.9795 - acc: 0.6889\n",
      "Epoch 59/70\n",
      " - 4s - loss: 0.9783 - acc: 0.6889\n",
      "Epoch 60/70\n",
      " - 4s - loss: 0.9743 - acc: 0.6890\n",
      "Epoch 61/70\n",
      " - 4572s - loss: 0.9717 - acc: 0.6909\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.9726 - acc: 0.6897\n",
      "Epoch 63/70\n",
      " - 4s - loss: 0.9687 - acc: 0.6906\n",
      "Epoch 64/70\n",
      " - 4s - loss: 0.9658 - acc: 0.6906\n",
      "Epoch 65/70\n",
      " - 4s - loss: 0.9669 - acc: 0.6916\n",
      "Epoch 66/70\n",
      " - 4s - loss: 0.9614 - acc: 0.6908\n",
      "Epoch 67/70\n",
      " - 4s - loss: 0.9625 - acc: 0.6930\n",
      "Epoch 68/70\n",
      " - 5s - loss: 0.9586 - acc: 0.6938\n",
      "Epoch 69/70\n",
      " - 4s - loss: 0.9587 - acc: 0.6914\n",
      "Epoch 70/70\n",
      " - 4s - loss: 0.9567 - acc: 0.6925\n",
      "[CV]  nodes_l3=80, nodes_l2=130, nodes_l1=170, dropout_l3=0.4, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=3000, total=80.5min\n",
      "[CV] nodes_l3=80, nodes_l2=130, nodes_l1=170, dropout_l3=0.4, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=3000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=170)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=130)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=130)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 12s - loss: 3.1105 - acc: 0.1927\n",
      "Epoch 2/70\n",
      " - 4s - loss: 2.3336 - acc: 0.3697\n",
      "Epoch 3/70\n",
      " - 4s - loss: 1.9225 - acc: 0.4853\n",
      "Epoch 4/70\n",
      " - 4s - loss: 1.7069 - acc: 0.5410\n",
      "Epoch 5/70\n",
      " - 4s - loss: 1.5852 - acc: 0.5696\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.4988 - acc: 0.5866\n",
      "Epoch 7/70\n",
      " - 4s - loss: 1.4206 - acc: 0.6038\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.3748 - acc: 0.6106\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.3418 - acc: 0.6170\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.3060 - acc: 0.6222\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.2811 - acc: 0.6268\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.2490 - acc: 0.6360\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.2340 - acc: 0.6372\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.2181 - acc: 0.6385\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.2015 - acc: 0.6412\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.1902 - acc: 0.6434\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.1816 - acc: 0.6445\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.1736 - acc: 0.6461\n",
      "Epoch 19/70\n",
      " - 3s - loss: 1.1610 - acc: 0.6496\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.1462 - acc: 0.6513\n",
      "Epoch 21/70\n",
      " - 4s - loss: 1.1392 - acc: 0.6536\n",
      "Epoch 22/70\n",
      " - 3s - loss: 1.1314 - acc: 0.6553\n",
      "Epoch 23/70\n",
      " - 3s - loss: 1.1248 - acc: 0.6582\n",
      "Epoch 24/70\n",
      " - 3s - loss: 1.1168 - acc: 0.6581\n",
      "Epoch 25/70\n",
      " - 3s - loss: 1.1153 - acc: 0.6589\n",
      "Epoch 26/70\n",
      " - 3s - loss: 1.1039 - acc: 0.6598\n",
      "Epoch 27/70\n",
      " - 3s - loss: 1.0949 - acc: 0.6627\n",
      "Epoch 28/70\n",
      " - 3s - loss: 1.0944 - acc: 0.6627\n",
      "Epoch 29/70\n",
      " - 3s - loss: 1.0885 - acc: 0.6645\n",
      "Epoch 30/70\n",
      " - 3s - loss: 1.0856 - acc: 0.6663\n",
      "Epoch 31/70\n",
      " - 3s - loss: 1.0828 - acc: 0.6655\n",
      "Epoch 32/70\n",
      " - 3s - loss: 1.0736 - acc: 0.6665\n",
      "Epoch 33/70\n",
      " - 3s - loss: 1.0738 - acc: 0.6664\n",
      "Epoch 34/70\n",
      " - 3s - loss: 1.0677 - acc: 0.6673\n",
      "Epoch 35/70\n",
      " - 3s - loss: 1.0635 - acc: 0.6680\n",
      "Epoch 36/70\n",
      " - 3s - loss: 1.0597 - acc: 0.6685\n",
      "Epoch 37/70\n",
      " - 3s - loss: 1.0519 - acc: 0.6714\n",
      "Epoch 38/70\n",
      " - 3s - loss: 1.0517 - acc: 0.6711\n",
      "Epoch 39/70\n",
      " - 3s - loss: 1.0497 - acc: 0.6685\n",
      "Epoch 40/70\n",
      " - 3s - loss: 1.0460 - acc: 0.6717\n",
      "Epoch 41/70\n",
      " - 3s - loss: 1.0410 - acc: 0.6739\n",
      "Epoch 42/70\n",
      " - 3s - loss: 1.0403 - acc: 0.6729\n",
      "Epoch 43/70\n",
      " - 3s - loss: 1.0334 - acc: 0.6745\n",
      "Epoch 44/70\n",
      " - 3s - loss: 1.0299 - acc: 0.6758\n",
      "Epoch 45/70\n",
      " - 3s - loss: 1.0299 - acc: 0.6752\n",
      "Epoch 46/70\n",
      " - 3s - loss: 1.0296 - acc: 0.6751\n",
      "Epoch 47/70\n",
      " - 3s - loss: 1.0190 - acc: 0.6764\n",
      "Epoch 48/70\n",
      " - 3s - loss: 1.0192 - acc: 0.6769\n",
      "Epoch 49/70\n",
      " - 3s - loss: 1.0209 - acc: 0.6767\n",
      "Epoch 50/70\n",
      " - 3s - loss: 1.0164 - acc: 0.6768\n",
      "Epoch 51/70\n",
      " - 3s - loss: 1.0136 - acc: 0.6792\n",
      "Epoch 52/70\n",
      " - 3s - loss: 1.0113 - acc: 0.6785\n",
      "Epoch 53/70\n",
      " - 3s - loss: 1.0073 - acc: 0.6786\n",
      "Epoch 54/70\n",
      " - 3s - loss: 1.0047 - acc: 0.6800\n",
      "Epoch 55/70\n",
      " - 3s - loss: 1.0014 - acc: 0.6803\n",
      "Epoch 56/70\n",
      " - 3s - loss: 1.0001 - acc: 0.6819\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.9996 - acc: 0.6817\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.9953 - acc: 0.6821\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.9968 - acc: 0.6824\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.9940 - acc: 0.6823\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.9908 - acc: 0.6819\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.9892 - acc: 0.6845\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.9870 - acc: 0.6849\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.9870 - acc: 0.6855\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.9813 - acc: 0.6850\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.9837 - acc: 0.6831\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.9814 - acc: 0.6852\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.9812 - acc: 0.6831\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.9765 - acc: 0.6873\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.9794 - acc: 0.6858\n",
      "[CV]  nodes_l3=80, nodes_l2=130, nodes_l1=170, dropout_l3=0.4, dropout_l2=0.30000000000000004, dropout_l1=0.4, batch_size=3000, total= 3.8min\n",
      "[CV] nodes_l3=60, nodes_l2=100, nodes_l1=170, dropout_l3=0.30000000000000004, dropout_l2=0.1, dropout_l1=0.1, batch_size=3000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=170)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 13s - loss: 3.0374 - acc: 0.2380\n",
      "Epoch 2/70\n",
      " - 3s - loss: 2.1372 - acc: 0.4379\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.7175 - acc: 0.5414\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.5158 - acc: 0.5881\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.4000 - acc: 0.6116\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.3214 - acc: 0.6272\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.2630 - acc: 0.6367\n",
      "Epoch 8/70\n",
      " - 2s - loss: 1.2225 - acc: 0.6427\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.1893 - acc: 0.6455\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.1640 - acc: 0.6518\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.1459 - acc: 0.6539\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.1258 - acc: 0.6575\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.1065 - acc: 0.6604\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.0958 - acc: 0.6614\n",
      "Epoch 15/70\n",
      " - 2s - loss: 1.0865 - acc: 0.6635\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.0713 - acc: 0.6674\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.0606 - acc: 0.6688\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.0522 - acc: 0.6703\n",
      "Epoch 19/70\n",
      " - 2s - loss: 1.0431 - acc: 0.6716\n",
      "Epoch 20/70\n",
      " - 2s - loss: 1.0343 - acc: 0.6729\n",
      "Epoch 21/70\n",
      " - 3s - loss: 1.0295 - acc: 0.6741\n",
      "Epoch 22/70\n",
      " - 2s - loss: 1.0195 - acc: 0.6744\n",
      "Epoch 23/70\n",
      " - 3s - loss: 1.0136 - acc: 0.6752\n",
      "Epoch 24/70\n",
      " - 3s - loss: 1.0127 - acc: 0.6775\n",
      "Epoch 25/70\n",
      " - 2s - loss: 1.0019 - acc: 0.6784\n",
      "Epoch 26/70\n",
      " - 3s - loss: 0.9970 - acc: 0.6787\n",
      "Epoch 27/70\n",
      " - 3s - loss: 0.9948 - acc: 0.6800\n",
      "Epoch 28/70\n",
      " - 3s - loss: 0.9820 - acc: 0.6832\n",
      "Epoch 29/70\n",
      " - 3s - loss: 0.9840 - acc: 0.6814\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.9760 - acc: 0.6840\n",
      "Epoch 31/70\n",
      " - 3s - loss: 0.9750 - acc: 0.6846\n",
      "Epoch 32/70\n",
      " - 3s - loss: 0.9688 - acc: 0.6857\n",
      "Epoch 33/70\n",
      " - 3s - loss: 0.9628 - acc: 0.6875\n",
      "Epoch 34/70\n",
      " - 3s - loss: 0.9608 - acc: 0.6869\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9581 - acc: 0.6859\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9528 - acc: 0.6883\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9473 - acc: 0.6903\n",
      "Epoch 38/70\n",
      " - 3s - loss: 0.9471 - acc: 0.6886\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.9408 - acc: 0.6924\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.9393 - acc: 0.6907\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.9329 - acc: 0.6919\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.9326 - acc: 0.6931\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.9316 - acc: 0.6919\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.9256 - acc: 0.6945\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.9228 - acc: 0.6943\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.9199 - acc: 0.6962\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.9193 - acc: 0.6948\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.9181 - acc: 0.6958\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.9103 - acc: 0.6971\n",
      "Epoch 50/70\n",
      " - 3s - loss: 0.9097 - acc: 0.6983\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.9097 - acc: 0.6988\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.9062 - acc: 0.6965\n",
      "Epoch 53/70\n",
      " - 3s - loss: 0.9031 - acc: 0.6987\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.8987 - acc: 0.6993\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.8957 - acc: 0.7011\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.8931 - acc: 0.7016\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.8943 - acc: 0.7012\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.8925 - acc: 0.6997\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.8896 - acc: 0.7003\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.8871 - acc: 0.7018\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.8863 - acc: 0.7038\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.8862 - acc: 0.7024\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.8813 - acc: 0.7031\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.8827 - acc: 0.7024\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.8796 - acc: 0.7041\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.8745 - acc: 0.7029\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.8726 - acc: 0.7054\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.8755 - acc: 0.7048\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.8727 - acc: 0.7043\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.8679 - acc: 0.7058\n",
      "[CV]  nodes_l3=60, nodes_l2=100, nodes_l1=170, dropout_l3=0.30000000000000004, dropout_l2=0.1, dropout_l1=0.1, batch_size=3000, total= 3.5min\n",
      "[CV] nodes_l3=60, nodes_l2=100, nodes_l1=170, dropout_l3=0.30000000000000004, dropout_l2=0.1, dropout_l1=0.1, batch_size=3000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=170)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 16s - loss: 2.9980 - acc: 0.2386\n",
      "Epoch 2/70\n",
      " - 3s - loss: 2.0985 - acc: 0.4422\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.6959 - acc: 0.5468\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.5027 - acc: 0.5876\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.3855 - acc: 0.6102\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.3089 - acc: 0.6243\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.2485 - acc: 0.6371\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.2109 - acc: 0.6433\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.1827 - acc: 0.6467\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.1581 - acc: 0.6520\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.1362 - acc: 0.6552\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.1174 - acc: 0.6579\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.1028 - acc: 0.6603\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.0931 - acc: 0.6622\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.0781 - acc: 0.6647\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.0691 - acc: 0.6656\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.0554 - acc: 0.6687\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.0500 - acc: 0.6703\n",
      "Epoch 19/70\n",
      " - 3s - loss: 1.0429 - acc: 0.6711\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.0301 - acc: 0.6752\n",
      "Epoch 21/70\n",
      " - 3s - loss: 1.0241 - acc: 0.6760\n",
      "Epoch 22/70\n",
      " - 3s - loss: 1.0212 - acc: 0.6762\n",
      "Epoch 23/70\n",
      " - 3s - loss: 1.0068 - acc: 0.6789\n",
      "Epoch 24/70\n",
      " - 3s - loss: 1.0065 - acc: 0.6778\n",
      "Epoch 25/70\n",
      " - 3s - loss: 0.9995 - acc: 0.6791\n",
      "Epoch 26/70\n",
      " - 3s - loss: 0.9947 - acc: 0.6794\n",
      "Epoch 27/70\n",
      " - 3s - loss: 0.9906 - acc: 0.6801\n",
      "Epoch 28/70\n",
      " - 3s - loss: 0.9832 - acc: 0.6822\n",
      "Epoch 29/70\n",
      " - 3s - loss: 0.9782 - acc: 0.6837\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.9757 - acc: 0.6833\n",
      "Epoch 31/70\n",
      " - 3s - loss: 0.9684 - acc: 0.6845\n",
      "Epoch 32/70\n",
      " - 3s - loss: 0.9686 - acc: 0.6861\n",
      "Epoch 33/70\n",
      " - 4s - loss: 0.9606 - acc: 0.6876\n",
      "Epoch 34/70\n",
      " - 3s - loss: 0.9554 - acc: 0.6875\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9550 - acc: 0.6875\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9552 - acc: 0.6877\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9482 - acc: 0.6882\n",
      "Epoch 38/70\n",
      " - 2s - loss: 0.9437 - acc: 0.6894\n",
      "Epoch 39/70\n",
      " - 2s - loss: 0.9428 - acc: 0.6905\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.9378 - acc: 0.6905\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.9307 - acc: 0.6944\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.9292 - acc: 0.6943\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.9264 - acc: 0.6939\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.9260 - acc: 0.6947\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.9216 - acc: 0.6949\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.9188 - acc: 0.6956\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.9168 - acc: 0.6961\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.9149 - acc: 0.6948\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.9096 - acc: 0.6976\n",
      "Epoch 50/70\n",
      " - 3s - loss: 0.9133 - acc: 0.6966\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.9060 - acc: 0.6968\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.9047 - acc: 0.6974\n",
      "Epoch 53/70\n",
      " - 3s - loss: 0.8984 - acc: 0.6987\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.9040 - acc: 0.6981\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.8966 - acc: 0.7001\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.8968 - acc: 0.6988\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.8932 - acc: 0.7008\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.8916 - acc: 0.7008\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.8902 - acc: 0.7012\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.8835 - acc: 0.7049\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.8846 - acc: 0.7019\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.8889 - acc: 0.7021\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.8802 - acc: 0.7035\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.8800 - acc: 0.7037\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.8820 - acc: 0.7042\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.8755 - acc: 0.7034\n",
      "Epoch 67/70\n",
      " - 2s - loss: 0.8773 - acc: 0.7040\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.8751 - acc: 0.7050\n",
      "Epoch 69/70\n",
      " - 4s - loss: 0.8733 - acc: 0.7053\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.8699 - acc: 0.7055\n",
      "[CV]  nodes_l3=60, nodes_l2=100, nodes_l1=170, dropout_l3=0.30000000000000004, dropout_l2=0.1, dropout_l1=0.1, batch_size=3000, total= 3.7min\n",
      "[CV] nodes_l3=60, nodes_l2=100, nodes_l1=170, dropout_l3=0.30000000000000004, dropout_l2=0.1, dropout_l1=0.1, batch_size=3000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=170)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 11s - loss: 2.9350 - acc: 0.2580\n",
      "Epoch 2/70\n",
      " - 3s - loss: 2.0672 - acc: 0.4725\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.6701 - acc: 0.5570\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.4763 - acc: 0.5949\n",
      "Epoch 5/70\n",
      " - 4s - loss: 1.3606 - acc: 0.6176\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.2915 - acc: 0.6281\n",
      "Epoch 7/70\n",
      " - 2s - loss: 1.2313 - acc: 0.6402\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.1922 - acc: 0.6468\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.1650 - acc: 0.6495\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.1369 - acc: 0.6563\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.1171 - acc: 0.6566\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.1015 - acc: 0.6611\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.0836 - acc: 0.6657\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.0764 - acc: 0.6653\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.0586 - acc: 0.6701\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.0478 - acc: 0.6704\n",
      "Epoch 17/70\n",
      " - 2s - loss: 1.0363 - acc: 0.6738\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.0290 - acc: 0.6768\n",
      "Epoch 19/70\n",
      " - 3s - loss: 1.0230 - acc: 0.6745\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.0150 - acc: 0.6748\n",
      "Epoch 21/70\n",
      " - 3s - loss: 1.0102 - acc: 0.6790\n",
      "Epoch 22/70\n",
      " - 3s - loss: 1.0023 - acc: 0.6803\n",
      "Epoch 23/70\n",
      " - 3s - loss: 0.9964 - acc: 0.6801\n",
      "Epoch 24/70\n",
      " - 3s - loss: 0.9896 - acc: 0.6829\n",
      "Epoch 25/70\n",
      " - 3s - loss: 0.9827 - acc: 0.6833\n",
      "Epoch 26/70\n",
      " - 3s - loss: 0.9766 - acc: 0.6861\n",
      "Epoch 27/70\n",
      " - 3s - loss: 0.9705 - acc: 0.6838\n",
      "Epoch 28/70\n",
      " - 3s - loss: 0.9701 - acc: 0.6880\n",
      "Epoch 29/70\n",
      " - 3s - loss: 0.9629 - acc: 0.6872\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.9584 - acc: 0.6866\n",
      "Epoch 31/70\n",
      " - 3s - loss: 0.9526 - acc: 0.6890\n",
      "Epoch 32/70\n",
      " - 3s - loss: 0.9502 - acc: 0.6906\n",
      "Epoch 33/70\n",
      " - 3s - loss: 0.9434 - acc: 0.6906\n",
      "Epoch 34/70\n",
      " - 4s - loss: 0.9397 - acc: 0.6923\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9366 - acc: 0.6938\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9323 - acc: 0.6945\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9300 - acc: 0.6941\n",
      "Epoch 38/70\n",
      " - 3s - loss: 0.9262 - acc: 0.6940\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.9217 - acc: 0.6957\n",
      "Epoch 40/70\n",
      " - 2s - loss: 0.9195 - acc: 0.6964\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.9184 - acc: 0.6972\n",
      "Epoch 42/70\n",
      " - 2s - loss: 0.9122 - acc: 0.6982\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.9079 - acc: 0.6993\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.9049 - acc: 0.6997\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.9049 - acc: 0.6992\n",
      "Epoch 46/70\n",
      " - 2s - loss: 0.8983 - acc: 0.7000\n",
      "Epoch 47/70\n",
      " - 2s - loss: 0.8970 - acc: 0.7000\n",
      "Epoch 48/70\n",
      " - 2s - loss: 0.8939 - acc: 0.7009\n",
      "Epoch 49/70\n",
      " - 2s - loss: 0.8948 - acc: 0.7007\n",
      "Epoch 50/70\n",
      " - 3s - loss: 0.8906 - acc: 0.7027\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.8890 - acc: 0.7034\n",
      "Epoch 52/70\n",
      " - 2s - loss: 0.8865 - acc: 0.7032\n",
      "Epoch 53/70\n",
      " - 2s - loss: 0.8818 - acc: 0.7032\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.8823 - acc: 0.7042\n",
      "Epoch 55/70\n",
      " - 2s - loss: 0.8821 - acc: 0.7041\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.8786 - acc: 0.7039\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.8776 - acc: 0.7034\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.8760 - acc: 0.7045\n",
      "Epoch 59/70\n",
      " - 2s - loss: 0.8727 - acc: 0.7061\n",
      "Epoch 60/70\n",
      " - 2s - loss: 0.8745 - acc: 0.7050\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.8693 - acc: 0.7062\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.8654 - acc: 0.7070\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.8643 - acc: 0.7070\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.8613 - acc: 0.7088\n",
      "Epoch 65/70\n",
      " - 2s - loss: 0.8614 - acc: 0.7083\n",
      "Epoch 66/70\n",
      " - 2s - loss: 0.8601 - acc: 0.7081\n",
      "Epoch 67/70\n",
      " - 2s - loss: 0.8589 - acc: 0.7098\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.8577 - acc: 0.7081\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.8579 - acc: 0.7090\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.8536 - acc: 0.7093\n",
      "[CV]  nodes_l3=60, nodes_l2=100, nodes_l1=170, dropout_l3=0.30000000000000004, dropout_l2=0.1, dropout_l1=0.1, batch_size=3000, total= 3.4min\n",
      "[CV] nodes_l3=60, nodes_l2=100, nodes_l1=170, dropout_l3=0.30000000000000004, dropout_l2=0.1, dropout_l1=0.1, batch_size=3000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=170)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 11s - loss: 2.9529 - acc: 0.2635\n",
      "Epoch 2/70\n",
      " - 3s - loss: 2.0898 - acc: 0.4492\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.7080 - acc: 0.5410\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.5082 - acc: 0.5850\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.3863 - acc: 0.6105\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.3106 - acc: 0.6238\n",
      "Epoch 7/70\n",
      " - 2s - loss: 1.2490 - acc: 0.6338\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.2100 - acc: 0.6412\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.1813 - acc: 0.6448\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.1528 - acc: 0.6504\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.1340 - acc: 0.6524\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.1175 - acc: 0.6559\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.1023 - acc: 0.6601\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.0890 - acc: 0.6615\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.0812 - acc: 0.6637\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.0633 - acc: 0.6668\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.0562 - acc: 0.6662\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.0497 - acc: 0.6685\n",
      "Epoch 19/70\n",
      " - 3s - loss: 1.0339 - acc: 0.6738\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.0328 - acc: 0.6709\n",
      "Epoch 21/70\n",
      " - 3s - loss: 1.0256 - acc: 0.6747\n",
      "Epoch 22/70\n",
      " - 3s - loss: 1.0152 - acc: 0.6755\n",
      "Epoch 23/70\n",
      " - 3s - loss: 1.0105 - acc: 0.6766\n",
      "Epoch 24/70\n",
      " - 3s - loss: 1.0052 - acc: 0.6769\n",
      "Epoch 25/70\n",
      " - 3s - loss: 1.0007 - acc: 0.6774\n",
      "Epoch 26/70\n",
      " - 3s - loss: 0.9904 - acc: 0.6790\n",
      "Epoch 27/70\n",
      " - 3s - loss: 0.9851 - acc: 0.6803\n",
      "Epoch 28/70\n",
      " - 3s - loss: 0.9780 - acc: 0.6827\n",
      "Epoch 29/70\n",
      " - 3s - loss: 0.9766 - acc: 0.6818\n",
      "Epoch 30/70\n",
      " - 2s - loss: 0.9717 - acc: 0.6834\n",
      "Epoch 31/70\n",
      " - 3s - loss: 0.9677 - acc: 0.6852\n",
      "Epoch 32/70\n",
      " - 2s - loss: 0.9608 - acc: 0.6852\n",
      "Epoch 33/70\n",
      " - 3s - loss: 0.9562 - acc: 0.6859\n",
      "Epoch 34/70\n",
      " - 3s - loss: 0.9513 - acc: 0.6876\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9504 - acc: 0.6882\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9454 - acc: 0.6888\n",
      "Epoch 37/70\n",
      " - 2s - loss: 0.9412 - acc: 0.6894\n",
      "Epoch 38/70\n",
      " - 2s - loss: 0.9377 - acc: 0.6896\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.9394 - acc: 0.6894\n",
      "Epoch 40/70\n",
      " - 2s - loss: 0.9302 - acc: 0.6922\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.9310 - acc: 0.6931\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.9262 - acc: 0.6930\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.9254 - acc: 0.6920\n",
      "Epoch 44/70\n",
      " - 2s - loss: 0.9213 - acc: 0.6928\n",
      "Epoch 45/70\n",
      " - 2s - loss: 0.9169 - acc: 0.6951\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.9133 - acc: 0.6958\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.9121 - acc: 0.6969\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.9123 - acc: 0.6965\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.9121 - acc: 0.6983\n",
      "Epoch 50/70\n",
      " - 2s - loss: 0.9014 - acc: 0.6983\n",
      "Epoch 51/70\n",
      " - 2s - loss: 0.9011 - acc: 0.6994\n",
      "Epoch 52/70\n",
      " - 2s - loss: 0.9012 - acc: 0.6978\n",
      "Epoch 53/70\n",
      " - 3s - loss: 0.8966 - acc: 0.6980\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.8933 - acc: 0.6989\n",
      "Epoch 55/70\n",
      " - 2s - loss: 0.8936 - acc: 0.7016\n",
      "Epoch 56/70\n",
      " - 2s - loss: 0.8930 - acc: 0.7017\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.8908 - acc: 0.7019\n",
      "Epoch 58/70\n",
      " - 2s - loss: 0.8890 - acc: 0.7002\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.8866 - acc: 0.7002\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.8857 - acc: 0.7018\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.8812 - acc: 0.7024\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.8838 - acc: 0.7020\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.8806 - acc: 0.7033\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.8780 - acc: 0.7014\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.8768 - acc: 0.7029\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.8757 - acc: 0.7050\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.8726 - acc: 0.7048\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.8735 - acc: 0.7037\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.8697 - acc: 0.7040\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.8683 - acc: 0.7050\n",
      "[CV]  nodes_l3=60, nodes_l2=100, nodes_l1=170, dropout_l3=0.30000000000000004, dropout_l2=0.1, dropout_l1=0.1, batch_size=3000, total= 3.4min\n",
      "[CV] nodes_l3=60, nodes_l2=110, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.2, dropout_l1=0.2, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=160)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=110)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=110)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 14s - loss: 2.0246 - acc: 0.4537\n",
      "Epoch 2/70\n",
      " - 6s - loss: 1.3022 - acc: 0.6237\n",
      "Epoch 3/70\n",
      " - 6s - loss: 1.1718 - acc: 0.6467\n",
      "Epoch 4/70\n",
      " - 6s - loss: 1.1196 - acc: 0.6550\n",
      "Epoch 5/70\n",
      " - 6s - loss: 1.0736 - acc: 0.6640\n",
      "Epoch 6/70\n",
      " - 6s - loss: 1.0490 - acc: 0.6672\n",
      "Epoch 7/70\n",
      " - 6s - loss: 1.0272 - acc: 0.6716\n",
      "Epoch 8/70\n",
      " - 6s - loss: 1.0084 - acc: 0.6759\n",
      "Epoch 9/70\n",
      " - 6s - loss: 0.9923 - acc: 0.6792\n",
      "Epoch 10/70\n",
      " - 6s - loss: 0.9818 - acc: 0.6804\n",
      "Epoch 11/70\n",
      " - 6s - loss: 0.9693 - acc: 0.6821\n",
      "Epoch 12/70\n",
      " - 6s - loss: 0.9603 - acc: 0.6846\n",
      "Epoch 13/70\n",
      " - 6s - loss: 0.9495 - acc: 0.6893\n",
      "Epoch 14/70\n",
      " - 6s - loss: 0.9413 - acc: 0.6886\n",
      "Epoch 15/70\n",
      " - 6s - loss: 0.9337 - acc: 0.6918\n",
      "Epoch 16/70\n",
      " - 6s - loss: 0.9270 - acc: 0.6909\n",
      "Epoch 17/70\n",
      " - 6s - loss: 0.9204 - acc: 0.6935\n",
      "Epoch 18/70\n",
      " - 6s - loss: 0.9182 - acc: 0.6939\n",
      "Epoch 19/70\n",
      " - 6s - loss: 0.9121 - acc: 0.6959\n",
      "Epoch 20/70\n",
      " - 6s - loss: 0.9073 - acc: 0.6963\n",
      "Epoch 21/70\n",
      " - 6s - loss: 0.9039 - acc: 0.6973\n",
      "Epoch 22/70\n",
      " - 6s - loss: 0.8984 - acc: 0.6997\n",
      "Epoch 23/70\n",
      " - 6s - loss: 0.8948 - acc: 0.6971\n",
      "Epoch 24/70\n",
      " - 6s - loss: 0.8905 - acc: 0.7006\n",
      "Epoch 25/70\n",
      " - 6s - loss: 0.8864 - acc: 0.7004\n",
      "Epoch 26/70\n",
      " - 7s - loss: 0.8851 - acc: 0.7013\n",
      "Epoch 27/70\n",
      " - 6s - loss: 0.8808 - acc: 0.7018\n",
      "Epoch 28/70\n",
      " - 6s - loss: 0.8800 - acc: 0.7025\n",
      "Epoch 29/70\n",
      " - 6s - loss: 0.8769 - acc: 0.7028\n",
      "Epoch 30/70\n",
      " - 6s - loss: 0.8741 - acc: 0.7043\n",
      "Epoch 31/70\n",
      " - 6s - loss: 0.8729 - acc: 0.7024\n",
      "Epoch 32/70\n",
      " - 6s - loss: 0.8691 - acc: 0.7045\n",
      "Epoch 33/70\n",
      " - 7s - loss: 0.8660 - acc: 0.7072\n",
      "Epoch 34/70\n",
      " - 6s - loss: 0.8659 - acc: 0.7065\n",
      "Epoch 35/70\n",
      " - 6s - loss: 0.8637 - acc: 0.7061\n",
      "Epoch 36/70\n",
      " - 7s - loss: 0.8597 - acc: 0.7064\n",
      "Epoch 37/70\n",
      " - 6s - loss: 0.8576 - acc: 0.7066\n",
      "Epoch 38/70\n",
      " - 7s - loss: 0.8563 - acc: 0.7065\n",
      "Epoch 39/70\n",
      " - 6s - loss: 0.8539 - acc: 0.7103\n",
      "Epoch 40/70\n",
      " - 7s - loss: 0.8549 - acc: 0.7087\n",
      "Epoch 41/70\n",
      " - 7s - loss: 0.8529 - acc: 0.7104\n",
      "Epoch 42/70\n",
      " - 6s - loss: 0.8516 - acc: 0.7101\n",
      "Epoch 43/70\n",
      " - 7s - loss: 0.8488 - acc: 0.7105\n",
      "Epoch 44/70\n",
      " - 6s - loss: 0.8484 - acc: 0.7095\n",
      "Epoch 45/70\n",
      " - 6s - loss: 0.8483 - acc: 0.7107\n",
      "Epoch 46/70\n",
      " - 6s - loss: 0.8424 - acc: 0.7124\n",
      "Epoch 47/70\n",
      " - 6s - loss: 0.8444 - acc: 0.7100\n",
      "Epoch 48/70\n",
      " - 6s - loss: 0.8413 - acc: 0.7118\n",
      "Epoch 49/70\n",
      " - 6s - loss: 0.8392 - acc: 0.7124\n",
      "Epoch 50/70\n",
      " - 6s - loss: 0.8401 - acc: 0.7124\n",
      "Epoch 51/70\n",
      " - 6s - loss: 0.8395 - acc: 0.7123\n",
      "Epoch 52/70\n",
      " - 6s - loss: 0.8390 - acc: 0.7107\n",
      "Epoch 53/70\n",
      " - 6s - loss: 0.8371 - acc: 0.7125\n",
      "Epoch 54/70\n",
      " - 6s - loss: 0.8327 - acc: 0.7141\n",
      "Epoch 55/70\n",
      " - 6s - loss: 0.8341 - acc: 0.7127\n",
      "Epoch 56/70\n",
      " - 6s - loss: 0.8338 - acc: 0.7135\n",
      "Epoch 57/70\n",
      " - 6s - loss: 0.8311 - acc: 0.7142\n",
      "Epoch 58/70\n",
      " - 6s - loss: 0.8308 - acc: 0.7152\n",
      "Epoch 59/70\n",
      " - 7s - loss: 0.8299 - acc: 0.7136\n",
      "Epoch 60/70\n",
      " - 6s - loss: 0.8268 - acc: 0.7160\n",
      "Epoch 61/70\n",
      " - 6s - loss: 0.8293 - acc: 0.7152\n",
      "Epoch 62/70\n",
      " - 6s - loss: 0.8294 - acc: 0.7146\n",
      "Epoch 63/70\n",
      " - 6s - loss: 0.8257 - acc: 0.7149\n",
      "Epoch 64/70\n",
      " - 6s - loss: 0.8271 - acc: 0.7148\n",
      "Epoch 65/70\n",
      " - 6s - loss: 0.8229 - acc: 0.7164\n",
      "Epoch 66/70\n",
      " - 6s - loss: 0.8216 - acc: 0.7165\n",
      "Epoch 67/70\n",
      " - 6s - loss: 0.8245 - acc: 0.7156\n",
      "Epoch 68/70\n",
      " - 6s - loss: 0.8201 - acc: 0.7160\n",
      "Epoch 69/70\n",
      " - 6s - loss: 0.8199 - acc: 0.7174\n",
      "Epoch 70/70\n",
      " - 6s - loss: 0.8199 - acc: 0.7163\n",
      "[CV]  nodes_l3=60, nodes_l2=110, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.2, dropout_l1=0.2, batch_size=500, total= 7.3min\n",
      "[CV] nodes_l3=60, nodes_l2=110, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.2, dropout_l1=0.2, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=160)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=110)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=110)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 16s - loss: 2.0070 - acc: 0.4695\n",
      "Epoch 2/70\n",
      " - 7s - loss: 1.3072 - acc: 0.6218\n",
      "Epoch 3/70\n",
      " - 6s - loss: 1.1728 - acc: 0.6450\n",
      "Epoch 4/70\n",
      " - 6s - loss: 1.1182 - acc: 0.6550\n",
      "Epoch 5/70\n",
      " - 6s - loss: 1.0786 - acc: 0.6603\n",
      "Epoch 6/70\n",
      " - 6s - loss: 1.0499 - acc: 0.6656\n",
      "Epoch 7/70\n",
      " - 6s - loss: 1.0295 - acc: 0.6709\n",
      "Epoch 8/70\n",
      " - 6s - loss: 1.0112 - acc: 0.6734\n",
      "Epoch 9/70\n",
      " - 6s - loss: 0.9998 - acc: 0.6768\n",
      "Epoch 10/70\n",
      " - 6s - loss: 0.9852 - acc: 0.6806\n",
      "Epoch 11/70\n",
      " - 6s - loss: 0.9738 - acc: 0.6815\n",
      "Epoch 12/70\n",
      " - 6s - loss: 0.9619 - acc: 0.6834\n",
      "Epoch 13/70\n",
      " - 6s - loss: 0.9540 - acc: 0.6853\n",
      "Epoch 14/70\n",
      " - 6s - loss: 0.9481 - acc: 0.6872\n",
      "Epoch 15/70\n",
      " - 6s - loss: 0.9377 - acc: 0.6897\n",
      "Epoch 16/70\n",
      " - 6s - loss: 0.9299 - acc: 0.6907\n",
      "Epoch 17/70\n",
      " - 6s - loss: 0.9255 - acc: 0.6921\n",
      "Epoch 18/70\n",
      " - 6s - loss: 0.9216 - acc: 0.6924\n",
      "Epoch 19/70\n",
      " - 6s - loss: 0.9136 - acc: 0.6957\n",
      "Epoch 20/70\n",
      " - 6s - loss: 0.9127 - acc: 0.6943\n",
      "Epoch 21/70\n",
      " - 6s - loss: 0.9070 - acc: 0.6956\n",
      "Epoch 22/70\n",
      " - 6s - loss: 0.8983 - acc: 0.6982\n",
      "Epoch 23/70\n",
      " - 6s - loss: 0.8962 - acc: 0.6976\n",
      "Epoch 24/70\n",
      " - 6s - loss: 0.8930 - acc: 0.6978\n",
      "Epoch 25/70\n",
      " - 6s - loss: 0.8864 - acc: 0.7007\n",
      "Epoch 26/70\n",
      " - 6s - loss: 0.8852 - acc: 0.7010\n",
      "Epoch 27/70\n",
      " - 6s - loss: 0.8807 - acc: 0.7040\n",
      "Epoch 28/70\n",
      " - 7s - loss: 0.8805 - acc: 0.7011\n",
      "Epoch 29/70\n",
      " - 6s - loss: 0.8749 - acc: 0.7038\n",
      "Epoch 30/70\n",
      " - 6s - loss: 0.8727 - acc: 0.7048\n",
      "Epoch 31/70\n",
      " - 6s - loss: 0.8721 - acc: 0.7047\n",
      "Epoch 32/70\n",
      " - 6s - loss: 0.8709 - acc: 0.7045\n",
      "Epoch 33/70\n",
      " - 6s - loss: 0.8668 - acc: 0.7045\n",
      "Epoch 34/70\n",
      " - 7s - loss: 0.8641 - acc: 0.7053\n",
      "Epoch 35/70\n",
      " - 6s - loss: 0.8627 - acc: 0.7069\n",
      "Epoch 36/70\n",
      " - 6s - loss: 0.8592 - acc: 0.7059\n",
      "Epoch 37/70\n",
      " - 6s - loss: 0.8565 - acc: 0.7076\n",
      "Epoch 38/70\n",
      " - 6s - loss: 0.8588 - acc: 0.7075\n",
      "Epoch 39/70\n",
      " - 6s - loss: 0.8548 - acc: 0.7078\n",
      "Epoch 40/70\n",
      " - 6s - loss: 0.8512 - acc: 0.7084\n",
      "Epoch 41/70\n",
      " - 6s - loss: 0.8480 - acc: 0.7094\n",
      "Epoch 42/70\n",
      " - 6s - loss: 0.8479 - acc: 0.7095\n",
      "Epoch 43/70\n",
      " - 6s - loss: 0.8484 - acc: 0.7087\n",
      "Epoch 44/70\n",
      " - 6s - loss: 0.8457 - acc: 0.7101\n",
      "Epoch 45/70\n",
      " - 6s - loss: 0.8425 - acc: 0.7106\n",
      "Epoch 46/70\n",
      " - 6s - loss: 0.8462 - acc: 0.7089\n",
      "Epoch 47/70\n",
      " - 6s - loss: 0.8411 - acc: 0.7101\n",
      "Epoch 48/70\n",
      " - 6s - loss: 0.8378 - acc: 0.7118\n",
      "Epoch 49/70\n",
      " - 6s - loss: 0.8409 - acc: 0.7107\n",
      "Epoch 50/70\n",
      " - 7s - loss: 0.8412 - acc: 0.7114\n",
      "Epoch 51/70\n",
      " - 6s - loss: 0.8354 - acc: 0.7140\n",
      "Epoch 52/70\n",
      " - 7s - loss: 0.8375 - acc: 0.7131\n",
      "Epoch 53/70\n",
      " - 6s - loss: 0.8355 - acc: 0.7119\n",
      "Epoch 54/70\n",
      " - 6s - loss: 0.8361 - acc: 0.7131\n",
      "Epoch 55/70\n",
      " - 6s - loss: 0.8315 - acc: 0.7145\n",
      "Epoch 56/70\n",
      " - 6s - loss: 0.8320 - acc: 0.7135\n",
      "Epoch 57/70\n",
      " - 6s - loss: 0.8298 - acc: 0.7133\n",
      "Epoch 58/70\n",
      " - 6s - loss: 0.8293 - acc: 0.7142\n",
      "Epoch 59/70\n",
      " - 6s - loss: 0.8318 - acc: 0.7160\n",
      "Epoch 60/70\n",
      " - 6s - loss: 0.8293 - acc: 0.7149\n",
      "Epoch 61/70\n",
      " - 6s - loss: 0.8255 - acc: 0.7147\n",
      "Epoch 62/70\n",
      " - 6s - loss: 0.8240 - acc: 0.7153\n",
      "Epoch 63/70\n",
      " - 6s - loss: 0.8259 - acc: 0.7142\n",
      "Epoch 64/70\n",
      " - 6s - loss: 0.8236 - acc: 0.7159\n",
      "Epoch 65/70\n",
      " - 6s - loss: 0.8262 - acc: 0.7173\n",
      "Epoch 66/70\n",
      " - 6s - loss: 0.8211 - acc: 0.7157\n",
      "Epoch 67/70\n",
      " - 6s - loss: 0.8239 - acc: 0.7168\n",
      "Epoch 68/70\n",
      " - 6s - loss: 0.8210 - acc: 0.7159\n",
      "Epoch 69/70\n",
      " - 6s - loss: 0.8176 - acc: 0.7167\n",
      "Epoch 70/70\n",
      " - 6s - loss: 0.8230 - acc: 0.7153\n",
      "[CV]  nodes_l3=60, nodes_l2=110, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.2, dropout_l1=0.2, batch_size=500, total= 7.4min\n",
      "[CV] nodes_l3=60, nodes_l2=110, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.2, dropout_l1=0.2, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=160)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=110)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=110)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 15s - loss: 2.0103 - acc: 0.4695\n",
      "Epoch 2/70\n",
      " - 6s - loss: 1.2941 - acc: 0.6268\n",
      "Epoch 3/70\n",
      " - 6s - loss: 1.1663 - acc: 0.6499\n",
      "Epoch 4/70\n",
      " - 6s - loss: 1.1029 - acc: 0.6604\n",
      "Epoch 5/70\n",
      " - 6s - loss: 1.0662 - acc: 0.6662\n",
      "Epoch 6/70\n",
      " - 6s - loss: 1.0394 - acc: 0.6699\n",
      "Epoch 7/70\n",
      " - 6s - loss: 1.0201 - acc: 0.6737\n",
      "Epoch 8/70\n",
      " - 6s - loss: 0.9982 - acc: 0.6786\n",
      "Epoch 9/70\n",
      " - 6s - loss: 0.9814 - acc: 0.6818\n",
      "Epoch 10/70\n",
      " - 6s - loss: 0.9700 - acc: 0.6829\n",
      "Epoch 11/70\n",
      " - 7s - loss: 0.9596 - acc: 0.6864\n",
      "Epoch 12/70\n",
      " - 6s - loss: 0.9478 - acc: 0.6901\n",
      "Epoch 13/70\n",
      " - 6s - loss: 0.9375 - acc: 0.6908\n",
      "Epoch 14/70\n",
      " - 7s - loss: 0.9311 - acc: 0.6910\n",
      "Epoch 15/70\n",
      " - 6s - loss: 0.9251 - acc: 0.6938\n",
      "Epoch 16/70\n",
      " - 7s - loss: 0.9143 - acc: 0.6958\n",
      "Epoch 17/70\n",
      " - 6s - loss: 0.9094 - acc: 0.6963\n",
      "Epoch 18/70\n",
      " - 6s - loss: 0.9019 - acc: 0.6978\n",
      "Epoch 19/70\n",
      " - 6s - loss: 0.8984 - acc: 0.6988\n",
      "Epoch 20/70\n",
      " - 6s - loss: 0.8923 - acc: 0.6995\n",
      "Epoch 21/70\n",
      " - 6s - loss: 0.8890 - acc: 0.7003\n",
      "Epoch 22/70\n",
      " - 6s - loss: 0.8858 - acc: 0.7007\n",
      "Epoch 23/70\n",
      " - 6s - loss: 0.8837 - acc: 0.7013\n",
      "Epoch 24/70\n",
      " - 6s - loss: 0.8761 - acc: 0.7030\n",
      "Epoch 25/70\n",
      " - 6s - loss: 0.8752 - acc: 0.7032\n",
      "Epoch 26/70\n",
      " - 6s - loss: 0.8686 - acc: 0.7050\n",
      "Epoch 27/70\n",
      " - 6s - loss: 0.8676 - acc: 0.7052\n",
      "Epoch 28/70\n",
      " - 6s - loss: 0.8646 - acc: 0.7056\n",
      "Epoch 29/70\n",
      " - 6s - loss: 0.8620 - acc: 0.7055\n",
      "Epoch 30/70\n",
      " - 6s - loss: 0.8577 - acc: 0.7075\n",
      "Epoch 31/70\n",
      " - 6s - loss: 0.8566 - acc: 0.7072\n",
      "Epoch 32/70\n",
      " - 6s - loss: 0.8554 - acc: 0.7077\n",
      "Epoch 33/70\n",
      " - 6s - loss: 0.8510 - acc: 0.7080\n",
      "Epoch 34/70\n",
      " - 6s - loss: 0.8511 - acc: 0.7091\n",
      "Epoch 35/70\n",
      " - 6s - loss: 0.8482 - acc: 0.7111\n",
      "Epoch 36/70\n",
      " - 6s - loss: 0.8479 - acc: 0.7082\n",
      "Epoch 37/70\n",
      " - 6s - loss: 0.8435 - acc: 0.7097\n",
      "Epoch 38/70\n",
      " - 6s - loss: 0.8425 - acc: 0.7107\n",
      "Epoch 39/70\n",
      " - 6s - loss: 0.8392 - acc: 0.7123\n",
      "Epoch 40/70\n",
      " - 6s - loss: 0.8397 - acc: 0.7123\n",
      "Epoch 41/70\n",
      " - 6s - loss: 0.8350 - acc: 0.7139\n",
      "Epoch 42/70\n",
      " - 6s - loss: 0.8354 - acc: 0.7125\n",
      "Epoch 43/70\n",
      " - 6s - loss: 0.8347 - acc: 0.7126\n",
      "Epoch 44/70\n",
      " - 6s - loss: 0.8286 - acc: 0.7138\n",
      "Epoch 45/70\n",
      " - 6s - loss: 0.8319 - acc: 0.7148\n",
      "Epoch 46/70\n",
      " - 6s - loss: 0.8280 - acc: 0.7151\n",
      "Epoch 47/70\n",
      " - 6s - loss: 0.8276 - acc: 0.7135\n",
      "Epoch 48/70\n",
      " - 7s - loss: 0.8270 - acc: 0.7146\n",
      "Epoch 49/70\n",
      " - 8s - loss: 0.8245 - acc: 0.7148\n",
      "Epoch 50/70\n",
      " - 6s - loss: 0.8272 - acc: 0.7135\n",
      "Epoch 51/70\n",
      " - 7s - loss: 0.8252 - acc: 0.7151\n",
      "Epoch 52/70\n",
      " - 7s - loss: 0.8235 - acc: 0.7152\n",
      "Epoch 53/70\n",
      " - 7s - loss: 0.8217 - acc: 0.7151\n",
      "Epoch 54/70\n",
      " - 9s - loss: 0.8231 - acc: 0.7155\n",
      "Epoch 55/70\n",
      " - 7s - loss: 0.8197 - acc: 0.7166\n",
      "Epoch 56/70\n",
      " - 7s - loss: 0.8166 - acc: 0.7188\n",
      "Epoch 57/70\n",
      " - 7s - loss: 0.8168 - acc: 0.7191\n",
      "Epoch 58/70\n",
      " - 7s - loss: 0.8161 - acc: 0.7185\n",
      "Epoch 59/70\n",
      " - 7s - loss: 0.8136 - acc: 0.7178\n",
      "Epoch 60/70\n",
      " - 8s - loss: 0.8138 - acc: 0.7173\n",
      "Epoch 61/70\n",
      " - 7s - loss: 0.8138 - acc: 0.7181\n",
      "Epoch 62/70\n",
      " - 9s - loss: 0.8134 - acc: 0.7174\n",
      "Epoch 63/70\n",
      " - 8s - loss: 0.8132 - acc: 0.7171\n",
      "Epoch 64/70\n",
      " - 8s - loss: 0.8132 - acc: 0.7182\n",
      "Epoch 65/70\n",
      " - 7s - loss: 0.8089 - acc: 0.7204\n",
      "Epoch 66/70\n",
      " - 7s - loss: 0.8116 - acc: 0.7191\n",
      "Epoch 67/70\n",
      " - 7s - loss: 0.8118 - acc: 0.7186\n",
      "Epoch 68/70\n",
      " - 6s - loss: 0.8066 - acc: 0.7197\n",
      "Epoch 69/70\n",
      " - 6s - loss: 0.8076 - acc: 0.7183\n",
      "Epoch 70/70\n",
      " - 6s - loss: 0.8087 - acc: 0.7198\n",
      "[CV]  nodes_l3=60, nodes_l2=110, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.2, dropout_l1=0.2, batch_size=500, total=13.9min\n",
      "[CV] nodes_l3=60, nodes_l2=110, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.2, dropout_l1=0.2, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=160)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=110)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=110)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 316s - loss: 2.0683 - acc: 0.4488\n",
      "Epoch 2/70\n",
      " - 6s - loss: 1.3220 - acc: 0.6191\n",
      "Epoch 3/70\n",
      " - 7s - loss: 1.1797 - acc: 0.6449\n",
      "Epoch 4/70\n",
      " - 6s - loss: 1.1206 - acc: 0.6546\n",
      "Epoch 5/70\n",
      " - 7s - loss: 1.0846 - acc: 0.6614\n",
      "Epoch 6/70\n",
      " - 6s - loss: 1.0586 - acc: 0.6663\n",
      "Epoch 7/70\n",
      " - 6s - loss: 1.0360 - acc: 0.6700\n",
      "Epoch 8/70\n",
      " - 6s - loss: 1.0167 - acc: 0.6740\n",
      "Epoch 9/70\n",
      " - 6s - loss: 1.0005 - acc: 0.6770\n",
      "Epoch 10/70\n",
      " - 6s - loss: 0.9861 - acc: 0.6788\n",
      "Epoch 11/70\n",
      " - 6s - loss: 0.9752 - acc: 0.6819\n",
      "Epoch 12/70\n",
      " - 6s - loss: 0.9689 - acc: 0.6835\n",
      "Epoch 13/70\n",
      " - 6s - loss: 0.9571 - acc: 0.6854\n",
      "Epoch 14/70\n",
      " - 7s - loss: 0.9449 - acc: 0.6878\n",
      "Epoch 15/70\n",
      " - 7s - loss: 0.9429 - acc: 0.6880\n",
      "Epoch 16/70\n",
      " - 6s - loss: 0.9330 - acc: 0.6899\n",
      "Epoch 17/70\n",
      " - 6s - loss: 0.9259 - acc: 0.6916\n",
      "Epoch 18/70\n",
      " - 7s - loss: 0.9180 - acc: 0.6945\n",
      "Epoch 19/70\n",
      " - 6s - loss: 0.9143 - acc: 0.6942\n",
      "Epoch 20/70\n",
      " - 6s - loss: 0.9084 - acc: 0.6966\n",
      "Epoch 21/70\n",
      " - 7s - loss: 0.9040 - acc: 0.6963\n",
      "Epoch 22/70\n",
      " - 6s - loss: 0.8985 - acc: 0.6966\n",
      "Epoch 23/70\n",
      " - 7s - loss: 0.9000 - acc: 0.6971\n",
      "Epoch 24/70\n",
      " - 6s - loss: 0.8932 - acc: 0.7003\n",
      "Epoch 25/70\n",
      " - 7s - loss: 0.8890 - acc: 0.6993\n",
      "Epoch 26/70\n",
      " - 6s - loss: 0.8900 - acc: 0.6973\n",
      "Epoch 27/70\n",
      " - 6s - loss: 0.8849 - acc: 0.7002\n",
      "Epoch 28/70\n",
      " - 6s - loss: 0.8813 - acc: 0.7010\n",
      "Epoch 29/70\n",
      " - 6s - loss: 0.8790 - acc: 0.7022\n",
      "Epoch 30/70\n",
      " - 7s - loss: 0.8738 - acc: 0.7038\n",
      "Epoch 31/70\n",
      " - 6s - loss: 0.8738 - acc: 0.7026\n",
      "Epoch 32/70\n",
      " - 6s - loss: 0.8733 - acc: 0.7046\n",
      "Epoch 33/70\n",
      " - 6s - loss: 0.8696 - acc: 0.7055\n",
      "Epoch 34/70\n",
      " - 6s - loss: 0.8688 - acc: 0.7034\n",
      "Epoch 35/70\n",
      " - 7s - loss: 0.8616 - acc: 0.7051\n",
      "Epoch 36/70\n",
      " - 6s - loss: 0.8624 - acc: 0.7044\n",
      "Epoch 37/70\n",
      " - 6s - loss: 0.8624 - acc: 0.7052\n",
      "Epoch 38/70\n",
      " - 6s - loss: 0.8604 - acc: 0.7053\n",
      "Epoch 39/70\n",
      " - 6s - loss: 0.8599 - acc: 0.7064\n",
      "Epoch 40/70\n",
      " - 7s - loss: 0.8550 - acc: 0.7073\n",
      "Epoch 41/70\n",
      " - 6s - loss: 0.8580 - acc: 0.7064\n",
      "Epoch 42/70\n",
      " - 7s - loss: 0.8546 - acc: 0.7068\n",
      "Epoch 43/70\n",
      " - 6s - loss: 0.8513 - acc: 0.7076\n",
      "Epoch 44/70\n",
      " - 6s - loss: 0.8502 - acc: 0.7086\n",
      "Epoch 45/70\n",
      " - 6s - loss: 0.8489 - acc: 0.7073\n",
      "Epoch 46/70\n",
      " - 6s - loss: 0.8470 - acc: 0.7091\n",
      "Epoch 47/70\n",
      " - 7s - loss: 0.8439 - acc: 0.7101\n",
      "Epoch 48/70\n",
      " - 7s - loss: 0.8440 - acc: 0.7096\n",
      "Epoch 49/70\n",
      " - 7s - loss: 0.8418 - acc: 0.7080\n",
      "Epoch 50/70\n",
      " - 7s - loss: 0.8412 - acc: 0.7103\n",
      "Epoch 51/70\n",
      " - 6s - loss: 0.8433 - acc: 0.7097\n",
      "Epoch 52/70\n",
      " - 6s - loss: 0.8406 - acc: 0.7101\n",
      "Epoch 53/70\n",
      " - 6s - loss: 0.8403 - acc: 0.7099\n",
      "Epoch 54/70\n",
      " - 6s - loss: 0.8387 - acc: 0.7090\n",
      "Epoch 55/70\n",
      " - 6s - loss: 0.8364 - acc: 0.7101\n",
      "Epoch 56/70\n",
      " - 6s - loss: 0.8368 - acc: 0.7121\n",
      "Epoch 57/70\n",
      " - 6s - loss: 0.8349 - acc: 0.7116\n",
      "Epoch 58/70\n",
      " - 6s - loss: 0.8346 - acc: 0.7119\n",
      "Epoch 59/70\n",
      " - 6s - loss: 0.8354 - acc: 0.7115\n",
      "Epoch 60/70\n",
      " - 6s - loss: 0.8327 - acc: 0.7126\n",
      "Epoch 61/70\n",
      " - 6s - loss: 0.8316 - acc: 0.7133\n",
      "Epoch 62/70\n",
      " - 6s - loss: 0.8324 - acc: 0.7125\n",
      "Epoch 63/70\n",
      " - 6s - loss: 0.8311 - acc: 0.7132\n",
      "Epoch 64/70\n",
      " - 6s - loss: 0.8286 - acc: 0.7146\n",
      "Epoch 65/70\n",
      " - 6s - loss: 0.8279 - acc: 0.7136\n",
      "Epoch 66/70\n",
      " - 6s - loss: 0.8289 - acc: 0.7123\n",
      "Epoch 67/70\n",
      " - 6s - loss: 0.8279 - acc: 0.7125\n",
      "Epoch 68/70\n",
      " - 6s - loss: 0.8278 - acc: 0.7144\n",
      "Epoch 69/70\n",
      " - 6s - loss: 0.8246 - acc: 0.7151\n",
      "Epoch 70/70\n",
      " - 6s - loss: 0.8249 - acc: 0.7148\n",
      "[CV]  nodes_l3=60, nodes_l2=110, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.2, dropout_l1=0.2, batch_size=500, total=38.8min\n",
      "[CV] nodes_l3=80, nodes_l2=100, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.4, dropout_l1=0.30000000000000004, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=160)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 15s - loss: 2.3195 - acc: 0.3837\n",
      "Epoch 2/70\n",
      " - 6s - loss: 1.5239 - acc: 0.5785\n",
      "Epoch 3/70\n",
      " - 5s - loss: 1.3367 - acc: 0.6159\n",
      "Epoch 4/70\n",
      " - 5s - loss: 1.2549 - acc: 0.6352\n",
      "Epoch 5/70\n",
      " - 6s - loss: 1.2060 - acc: 0.6419\n",
      "Epoch 6/70\n",
      " - 5s - loss: 1.1713 - acc: 0.6490\n",
      "Epoch 7/70\n",
      " - 5s - loss: 1.1547 - acc: 0.6514\n",
      "Epoch 8/70\n",
      " - 6s - loss: 1.1348 - acc: 0.6541\n",
      "Epoch 9/70\n",
      " - 5s - loss: 1.1134 - acc: 0.6574\n",
      "Epoch 10/70\n",
      " - 5s - loss: 1.1007 - acc: 0.6599\n",
      "Epoch 11/70\n",
      " - 6s - loss: 1.0901 - acc: 0.6635\n",
      "Epoch 12/70\n",
      " - 5s - loss: 1.0769 - acc: 0.6652\n",
      "Epoch 13/70\n",
      " - 5s - loss: 1.0652 - acc: 0.6673\n",
      "Epoch 14/70\n",
      " - 6s - loss: 1.0595 - acc: 0.6686\n",
      "Epoch 15/70\n",
      " - 5s - loss: 1.0491 - acc: 0.6707\n",
      "Epoch 16/70\n",
      " - 6s - loss: 1.0391 - acc: 0.6721\n",
      "Epoch 17/70\n",
      " - 6s - loss: 1.0346 - acc: 0.6736\n",
      "Epoch 18/70\n",
      " - 5s - loss: 1.0288 - acc: 0.6746\n",
      "Epoch 19/70\n",
      " - 6s - loss: 1.0222 - acc: 0.6752\n",
      "Epoch 20/70\n",
      " - 6s - loss: 1.0203 - acc: 0.6770\n",
      "Epoch 21/70\n",
      " - 6s - loss: 1.0097 - acc: 0.6790\n",
      "Epoch 22/70\n",
      " - 6s - loss: 1.0061 - acc: 0.6795\n",
      "Epoch 23/70\n",
      " - 6s - loss: 1.0022 - acc: 0.6811\n",
      "Epoch 24/70\n",
      " - 6s - loss: 0.9993 - acc: 0.6815\n",
      "Epoch 25/70\n",
      " - 6s - loss: 0.9984 - acc: 0.6806\n",
      "Epoch 26/70\n",
      " - 5s - loss: 0.9899 - acc: 0.6836\n",
      "Epoch 27/70\n",
      " - 5s - loss: 0.9837 - acc: 0.6847\n",
      "Epoch 28/70\n",
      " - 6s - loss: 0.9852 - acc: 0.6851\n",
      "Epoch 29/70\n",
      " - 5s - loss: 0.9811 - acc: 0.6844\n",
      "Epoch 30/70\n",
      " - 5s - loss: 0.9773 - acc: 0.6864\n",
      "Epoch 31/70\n",
      " - 5s - loss: 0.9724 - acc: 0.6884\n",
      "Epoch 32/70\n",
      " - 5s - loss: 0.9698 - acc: 0.6886\n",
      "Epoch 33/70\n",
      " - 5s - loss: 0.9696 - acc: 0.6883\n",
      "Epoch 34/70\n",
      " - 5s - loss: 0.9699 - acc: 0.6885\n",
      "Epoch 35/70\n",
      " - 5s - loss: 0.9640 - acc: 0.6897\n",
      "Epoch 36/70\n",
      " - 5s - loss: 0.9663 - acc: 0.6884\n",
      "Epoch 37/70\n",
      " - 6s - loss: 0.9640 - acc: 0.6898\n",
      "Epoch 38/70\n",
      " - 5s - loss: 0.9593 - acc: 0.6904\n",
      "Epoch 39/70\n",
      " - 6s - loss: 0.9562 - acc: 0.6909\n",
      "Epoch 40/70\n",
      " - 5s - loss: 0.9575 - acc: 0.6911\n",
      "Epoch 41/70\n",
      " - 5s - loss: 0.9554 - acc: 0.6909\n",
      "Epoch 42/70\n",
      " - 6s - loss: 0.9508 - acc: 0.6925\n",
      "Epoch 43/70\n",
      " - 5s - loss: 0.9517 - acc: 0.6927\n",
      "Epoch 44/70\n",
      " - 5s - loss: 0.9517 - acc: 0.6909\n",
      "Epoch 45/70\n",
      " - 6s - loss: 0.9492 - acc: 0.6928\n",
      "Epoch 46/70\n",
      " - 5s - loss: 0.9464 - acc: 0.6939\n",
      "Epoch 47/70\n",
      " - 6s - loss: 0.9454 - acc: 0.6941\n",
      "Epoch 48/70\n",
      " - 6s - loss: 0.9434 - acc: 0.6945\n",
      "Epoch 49/70\n",
      " - 5s - loss: 0.9446 - acc: 0.6942\n",
      "Epoch 50/70\n",
      " - 5s - loss: 0.9468 - acc: 0.6932\n",
      "Epoch 51/70\n",
      " - 6s - loss: 0.9404 - acc: 0.6949\n",
      "Epoch 52/70\n",
      " - 5s - loss: 0.9354 - acc: 0.6957\n",
      "Epoch 53/70\n",
      " - 5s - loss: 0.9379 - acc: 0.6950\n",
      "Epoch 54/70\n",
      " - 6s - loss: 0.9356 - acc: 0.6964\n",
      "Epoch 55/70\n",
      " - 5s - loss: 0.9371 - acc: 0.6947\n",
      "Epoch 56/70\n",
      " - 5s - loss: 0.9385 - acc: 0.6948\n",
      "Epoch 57/70\n",
      " - 6s - loss: 0.9346 - acc: 0.6963\n",
      "Epoch 58/70\n",
      " - 5s - loss: 0.9346 - acc: 0.6970\n",
      "Epoch 59/70\n",
      " - 5s - loss: 0.9319 - acc: 0.6969\n",
      "Epoch 60/70\n",
      " - 6s - loss: 0.9292 - acc: 0.6958\n",
      "Epoch 61/70\n",
      " - 5s - loss: 0.9312 - acc: 0.6965\n",
      "Epoch 62/70\n",
      " - 5s - loss: 0.9303 - acc: 0.6966\n",
      "Epoch 63/70\n",
      " - 6s - loss: 0.9335 - acc: 0.6956\n",
      "Epoch 64/70\n",
      " - 5s - loss: 0.9267 - acc: 0.6987\n",
      "Epoch 65/70\n",
      " - 5s - loss: 0.9269 - acc: 0.6978\n",
      "Epoch 66/70\n",
      " - 6s - loss: 0.9265 - acc: 0.6985\n",
      "Epoch 67/70\n",
      " - 5s - loss: 0.9275 - acc: 0.6977\n",
      "Epoch 68/70\n",
      " - 6s - loss: 0.9270 - acc: 0.6982\n",
      "Epoch 69/70\n",
      " - 6s - loss: 0.9286 - acc: 0.6994\n",
      "Epoch 70/70\n",
      " - 5s - loss: 0.9253 - acc: 0.6986\n",
      "[CV]  nodes_l3=80, nodes_l2=100, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.4, dropout_l1=0.30000000000000004, batch_size=500, total= 6.8min\n",
      "[CV] nodes_l3=80, nodes_l2=100, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.4, dropout_l1=0.30000000000000004, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=160)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 15s - loss: 2.2953 - acc: 0.3869\n",
      "Epoch 2/70\n",
      " - 5s - loss: 1.5151 - acc: 0.5804\n",
      "Epoch 3/70\n",
      " - 5s - loss: 1.3314 - acc: 0.6202\n",
      "Epoch 4/70\n",
      " - 6s - loss: 1.2513 - acc: 0.6313\n",
      "Epoch 5/70\n",
      " - 6s - loss: 1.2064 - acc: 0.6415\n",
      "Epoch 6/70\n",
      " - 6s - loss: 1.1760 - acc: 0.6468\n",
      "Epoch 7/70\n",
      " - 6s - loss: 1.1482 - acc: 0.6532\n",
      "Epoch 8/70\n",
      " - 6s - loss: 1.1253 - acc: 0.6568\n",
      "Epoch 9/70\n",
      " - 5s - loss: 1.1133 - acc: 0.6598\n",
      "Epoch 10/70\n",
      " - 6s - loss: 1.1007 - acc: 0.6590\n",
      "Epoch 11/70\n",
      " - 5s - loss: 1.0876 - acc: 0.6622\n",
      "Epoch 12/70\n",
      " - 6s - loss: 1.0744 - acc: 0.6666\n",
      "Epoch 13/70\n",
      " - 6s - loss: 1.0635 - acc: 0.6696\n",
      "Epoch 14/70\n",
      " - 5s - loss: 1.0523 - acc: 0.6722\n",
      "Epoch 15/70\n",
      " - 6s - loss: 1.0504 - acc: 0.6709\n",
      "Epoch 16/70\n",
      " - 6s - loss: 1.0426 - acc: 0.6728\n",
      "Epoch 17/70\n",
      " - 6s - loss: 1.0336 - acc: 0.6742\n",
      "Epoch 18/70\n",
      " - 6s - loss: 1.0233 - acc: 0.6781\n",
      "Epoch 19/70\n",
      " - 6s - loss: 1.0198 - acc: 0.6774\n",
      "Epoch 20/70\n",
      " - 6s - loss: 1.0185 - acc: 0.6776\n",
      "Epoch 21/70\n",
      " - 6s - loss: 1.0111 - acc: 0.6805\n",
      "Epoch 22/70\n",
      " - 5s - loss: 1.0079 - acc: 0.6783\n",
      "Epoch 23/70\n",
      " - 5s - loss: 1.0044 - acc: 0.6810\n",
      "Epoch 24/70\n",
      " - 6s - loss: 0.9977 - acc: 0.6815\n",
      "Epoch 25/70\n",
      " - 5s - loss: 0.9923 - acc: 0.6835\n",
      "Epoch 26/70\n",
      " - 6s - loss: 0.9898 - acc: 0.6859\n",
      "Epoch 27/70\n",
      " - 6s - loss: 0.9885 - acc: 0.6832\n",
      "Epoch 28/70\n",
      " - 6s - loss: 0.9841 - acc: 0.6851\n",
      "Epoch 29/70\n",
      " - 6s - loss: 0.9808 - acc: 0.6858\n",
      "Epoch 30/70\n",
      " - 5s - loss: 0.9763 - acc: 0.6885\n",
      "Epoch 31/70\n",
      " - 5s - loss: 0.9758 - acc: 0.6867\n",
      "Epoch 32/70\n",
      " - 6s - loss: 0.9736 - acc: 0.6893\n",
      "Epoch 33/70\n",
      " - 5s - loss: 0.9705 - acc: 0.6891\n",
      "Epoch 34/70\n",
      " - 6s - loss: 0.9675 - acc: 0.6914\n",
      "Epoch 35/70\n",
      " - 6s - loss: 0.9615 - acc: 0.6897\n",
      "Epoch 36/70\n",
      " - 6s - loss: 0.9620 - acc: 0.6906\n",
      "Epoch 37/70\n",
      " - 6s - loss: 0.9603 - acc: 0.6914\n",
      "Epoch 38/70\n",
      " - 6s - loss: 0.9568 - acc: 0.6929\n",
      "Epoch 39/70\n",
      " - 5s - loss: 0.9572 - acc: 0.6928\n",
      "Epoch 40/70\n",
      " - 6s - loss: 0.9546 - acc: 0.6924\n",
      "Epoch 41/70\n",
      " - 6s - loss: 0.9574 - acc: 0.6904\n",
      "Epoch 42/70\n",
      " - 5s - loss: 0.9519 - acc: 0.6924\n",
      "Epoch 43/70\n",
      " - 6s - loss: 0.9461 - acc: 0.6940\n",
      "Epoch 44/70\n",
      " - 6s - loss: 0.9498 - acc: 0.6935\n",
      "Epoch 45/70\n",
      " - 6s - loss: 0.9447 - acc: 0.6945\n",
      "Epoch 46/70\n",
      " - 6s - loss: 0.9461 - acc: 0.6951\n",
      "Epoch 47/70\n",
      " - 6s - loss: 0.9435 - acc: 0.6955\n",
      "Epoch 48/70\n",
      " - 6s - loss: 0.9430 - acc: 0.6956\n",
      "Epoch 49/70\n",
      " - 6s - loss: 0.9393 - acc: 0.6964\n",
      "Epoch 50/70\n",
      " - 6s - loss: 0.9421 - acc: 0.6953\n",
      "Epoch 51/70\n",
      " - 5s - loss: 0.9392 - acc: 0.6960\n",
      "Epoch 52/70\n",
      " - 6s - loss: 0.9383 - acc: 0.6960\n",
      "Epoch 53/70\n",
      " - 5s - loss: 0.9403 - acc: 0.6963\n",
      "Epoch 54/70\n",
      " - 5s - loss: 0.9388 - acc: 0.6958\n",
      "Epoch 55/70\n",
      " - 6s - loss: 0.9330 - acc: 0.6979\n",
      "Epoch 56/70\n",
      " - 6s - loss: 0.9347 - acc: 0.6970\n",
      "Epoch 57/70\n",
      " - 7s - loss: 0.9311 - acc: 0.6987\n",
      "Epoch 58/70\n",
      " - 6s - loss: 0.9327 - acc: 0.6977\n",
      "Epoch 59/70\n",
      " - 6s - loss: 0.9295 - acc: 0.6985\n",
      "Epoch 60/70\n",
      " - 6s - loss: 0.9290 - acc: 0.6975\n",
      "Epoch 61/70\n",
      " - 5s - loss: 0.9306 - acc: 0.6976\n",
      "Epoch 62/70\n",
      " - 6s - loss: 0.9293 - acc: 0.6982\n",
      "Epoch 63/70\n",
      " - 6s - loss: 0.9290 - acc: 0.6972\n",
      "Epoch 64/70\n",
      " - 6s - loss: 0.9279 - acc: 0.6987\n",
      "Epoch 65/70\n",
      " - 6s - loss: 0.9311 - acc: 0.6989\n",
      "Epoch 66/70\n",
      " - 6s - loss: 0.9276 - acc: 0.6983\n",
      "Epoch 67/70\n",
      " - 5s - loss: 0.9248 - acc: 0.7002\n",
      "Epoch 68/70\n",
      " - 6s - loss: 0.9261 - acc: 0.6989\n",
      "Epoch 69/70\n",
      " - 6s - loss: 0.9253 - acc: 0.6993\n",
      "Epoch 70/70\n",
      " - 5s - loss: 0.9273 - acc: 0.6985\n",
      "[CV]  nodes_l3=80, nodes_l2=100, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.4, dropout_l1=0.30000000000000004, batch_size=500, total= 6.9min\n",
      "[CV] nodes_l3=80, nodes_l2=100, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.4, dropout_l1=0.30000000000000004, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=160)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 14s - loss: 2.2863 - acc: 0.3981\n",
      "Epoch 2/70\n",
      " - 6s - loss: 1.5017 - acc: 0.5849\n",
      "Epoch 3/70\n",
      " - 5s - loss: 1.3199 - acc: 0.6202\n",
      "Epoch 4/70\n",
      " - 6s - loss: 1.2360 - acc: 0.6359\n",
      "Epoch 5/70\n",
      " - 5s - loss: 1.1921 - acc: 0.6426\n",
      "Epoch 6/70\n",
      " - 5s - loss: 1.1605 - acc: 0.6497\n",
      "Epoch 7/70\n",
      " - 6s - loss: 1.1408 - acc: 0.6517\n",
      "Epoch 8/70\n",
      " - 6s - loss: 1.1155 - acc: 0.6566\n",
      "Epoch 9/70\n",
      " - 5s - loss: 1.1019 - acc: 0.6613\n",
      "Epoch 10/70\n",
      " - 6s - loss: 1.0889 - acc: 0.6656\n",
      "Epoch 11/70\n",
      " - 5s - loss: 1.0707 - acc: 0.6649\n",
      "Epoch 12/70\n",
      " - 5s - loss: 1.0604 - acc: 0.6671\n",
      "Epoch 13/70\n",
      " - 6s - loss: 1.0499 - acc: 0.6699\n",
      "Epoch 14/70\n",
      " - 5s - loss: 1.0396 - acc: 0.6731\n",
      "Epoch 15/70\n",
      " - 5s - loss: 1.0305 - acc: 0.6744\n",
      "Epoch 16/70\n",
      " - 6s - loss: 1.0260 - acc: 0.6736\n",
      "Epoch 17/70\n",
      " - 5s - loss: 1.0161 - acc: 0.6773\n",
      "Epoch 18/70\n",
      " - 5s - loss: 1.0173 - acc: 0.6781\n",
      "Epoch 19/70\n",
      " - 6s - loss: 1.0082 - acc: 0.6793\n",
      "Epoch 20/70\n",
      " - 5s - loss: 1.0020 - acc: 0.6802\n",
      "Epoch 21/70\n",
      " - 5s - loss: 0.9950 - acc: 0.6831\n",
      "Epoch 22/70\n",
      " - 6s - loss: 0.9923 - acc: 0.6827\n",
      "Epoch 23/70\n",
      " - 5s - loss: 0.9886 - acc: 0.6829\n",
      "Epoch 24/70\n",
      " - 5s - loss: 0.9864 - acc: 0.6843\n",
      "Epoch 25/70\n",
      " - 6s - loss: 0.9776 - acc: 0.6849\n",
      "Epoch 26/70\n",
      " - 5s - loss: 0.9772 - acc: 0.6872\n",
      "Epoch 27/70\n",
      " - 5s - loss: 0.9727 - acc: 0.6869\n",
      "Epoch 28/70\n",
      " - 6s - loss: 0.9652 - acc: 0.6877\n",
      "Epoch 29/70\n",
      " - 5s - loss: 0.9657 - acc: 0.6903\n",
      "Epoch 30/70\n",
      " - 6s - loss: 0.9630 - acc: 0.6881\n",
      "Epoch 31/70\n",
      " - 6s - loss: 0.9611 - acc: 0.6896\n",
      "Epoch 32/70\n",
      " - 5s - loss: 0.9599 - acc: 0.6885\n",
      "Epoch 33/70\n",
      " - 6s - loss: 0.9553 - acc: 0.6930\n",
      "Epoch 34/70\n",
      " - 6s - loss: 0.9538 - acc: 0.6916\n",
      "Epoch 35/70\n",
      " - 5s - loss: 0.9521 - acc: 0.6920\n",
      "Epoch 36/70\n",
      " - 6s - loss: 0.9485 - acc: 0.6914\n",
      "Epoch 37/70\n",
      " - 5s - loss: 0.9508 - acc: 0.6908\n",
      "Epoch 38/70\n",
      " - 5s - loss: 0.9454 - acc: 0.6942\n",
      "Epoch 39/70\n",
      " - 6s - loss: 0.9435 - acc: 0.6937\n",
      "Epoch 40/70\n",
      " - 5s - loss: 0.9394 - acc: 0.6952\n",
      "Epoch 41/70\n",
      " - 5s - loss: 0.9408 - acc: 0.6952\n",
      "Epoch 42/70\n",
      " - 6s - loss: 0.9406 - acc: 0.6956\n",
      "Epoch 43/70\n",
      " - 5s - loss: 0.9344 - acc: 0.6971\n",
      "Epoch 44/70\n",
      " - 5s - loss: 0.9352 - acc: 0.6932\n",
      "Epoch 45/70\n",
      " - 6s - loss: 0.9359 - acc: 0.6946\n",
      "Epoch 46/70\n",
      " - 5s - loss: 0.9306 - acc: 0.6959\n",
      "Epoch 47/70\n",
      " - 5s - loss: 0.9312 - acc: 0.6971\n",
      "Epoch 48/70\n",
      " - 6s - loss: 0.9272 - acc: 0.6968\n",
      "Epoch 49/70\n",
      " - 5s - loss: 0.9292 - acc: 0.6974\n",
      "Epoch 50/70\n",
      " - 5s - loss: 0.9233 - acc: 0.6980\n",
      "Epoch 51/70\n",
      " - 6s - loss: 0.9300 - acc: 0.6969\n",
      "Epoch 52/70\n",
      " - 5s - loss: 0.9233 - acc: 0.6979\n",
      "Epoch 53/70\n",
      " - 5s - loss: 0.9225 - acc: 0.6981\n",
      "Epoch 54/70\n",
      " - 6s - loss: 0.9236 - acc: 0.6988\n",
      "Epoch 55/70\n",
      " - 5s - loss: 0.9209 - acc: 0.6997\n",
      "Epoch 56/70\n",
      " - 5s - loss: 0.9187 - acc: 0.7003\n",
      "Epoch 57/70\n",
      " - 6s - loss: 0.9202 - acc: 0.6986\n",
      "Epoch 58/70\n",
      " - 5s - loss: 0.9140 - acc: 0.6996\n",
      "Epoch 59/70\n",
      " - 5s - loss: 0.9115 - acc: 0.6989\n",
      "Epoch 60/70\n",
      " - 6s - loss: 0.9175 - acc: 0.7000\n",
      "Epoch 61/70\n",
      " - 5s - loss: 0.9153 - acc: 0.7009\n",
      "Epoch 62/70\n",
      " - 5s - loss: 0.9128 - acc: 0.7017\n",
      "Epoch 63/70\n",
      " - 6s - loss: 0.9124 - acc: 0.7013\n",
      "Epoch 64/70\n",
      " - 5s - loss: 0.9105 - acc: 0.7024\n",
      "Epoch 65/70\n",
      " - 5s - loss: 0.9124 - acc: 0.7020\n",
      "Epoch 66/70\n",
      " - 6s - loss: 0.9102 - acc: 0.7009\n",
      "Epoch 67/70\n",
      " - 5s - loss: 0.9086 - acc: 0.7017\n",
      "Epoch 68/70\n",
      " - 5s - loss: 0.9083 - acc: 0.7013\n",
      "Epoch 69/70\n",
      " - 6s - loss: 0.9118 - acc: 0.7025\n",
      "Epoch 70/70\n",
      " - 5s - loss: 0.9071 - acc: 0.7012\n",
      "[CV]  nodes_l3=80, nodes_l2=100, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.4, dropout_l1=0.30000000000000004, batch_size=500, total= 6.7min\n",
      "[CV] nodes_l3=80, nodes_l2=100, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.4, dropout_l1=0.30000000000000004, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=160)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 15s - loss: 2.3189 - acc: 0.3842\n",
      "Epoch 2/70\n",
      " - 6s - loss: 1.5090 - acc: 0.5797\n",
      "Epoch 3/70\n",
      " - 6s - loss: 1.3308 - acc: 0.6159\n",
      "Epoch 4/70\n",
      " - 6s - loss: 1.2511 - acc: 0.6321\n",
      "Epoch 5/70\n",
      " - 6s - loss: 1.2090 - acc: 0.6383\n",
      "Epoch 6/70\n",
      " - 6s - loss: 1.1775 - acc: 0.6445\n",
      "Epoch 7/70\n",
      " - 6s - loss: 1.1503 - acc: 0.6495\n",
      "Epoch 8/70\n",
      " - 6s - loss: 1.1281 - acc: 0.6541\n",
      "Epoch 9/70\n",
      " - 6s - loss: 1.1114 - acc: 0.6582\n",
      "Epoch 10/70\n",
      " - 6s - loss: 1.1004 - acc: 0.6598\n",
      "Epoch 11/70\n",
      " - 6s - loss: 1.0853 - acc: 0.6626\n",
      "Epoch 12/70\n",
      " - 6s - loss: 1.0720 - acc: 0.6657\n",
      "Epoch 13/70\n",
      " - 6s - loss: 1.0634 - acc: 0.6687\n",
      "Epoch 14/70\n",
      " - 6s - loss: 1.0557 - acc: 0.6668\n",
      "Epoch 15/70\n",
      " - 6s - loss: 1.0457 - acc: 0.6704\n",
      "Epoch 16/70\n",
      " - 6s - loss: 1.0388 - acc: 0.6745\n",
      "Epoch 17/70\n",
      " - 6s - loss: 1.0318 - acc: 0.6729\n",
      "Epoch 18/70\n",
      " - 6s - loss: 1.0278 - acc: 0.6744\n",
      "Epoch 19/70\n",
      " - 6s - loss: 1.0227 - acc: 0.6748\n",
      "Epoch 20/70\n",
      " - 6s - loss: 1.0117 - acc: 0.6769\n",
      "Epoch 21/70\n",
      " - 6s - loss: 1.0112 - acc: 0.6805\n",
      "Epoch 22/70\n",
      " - 6s - loss: 1.0069 - acc: 0.6796\n",
      "Epoch 23/70\n",
      " - 6s - loss: 0.9992 - acc: 0.6804\n",
      "Epoch 24/70\n",
      " - 6s - loss: 0.9962 - acc: 0.6809\n",
      "Epoch 25/70\n",
      " - 6s - loss: 0.9910 - acc: 0.6810\n",
      "Epoch 26/70\n",
      " - 6s - loss: 0.9862 - acc: 0.6834\n",
      "Epoch 27/70\n",
      " - 6s - loss: 0.9855 - acc: 0.6822\n",
      "Epoch 28/70\n",
      " - 6s - loss: 0.9825 - acc: 0.6852\n",
      "Epoch 29/70\n",
      " - 6s - loss: 0.9770 - acc: 0.6849\n",
      "Epoch 30/70\n",
      " - 6s - loss: 0.9765 - acc: 0.6861\n",
      "Epoch 31/70\n",
      " - 6s - loss: 0.9721 - acc: 0.6869\n",
      "Epoch 32/70\n",
      " - 6s - loss: 0.9703 - acc: 0.6862\n",
      "Epoch 33/70\n",
      " - 6s - loss: 0.9674 - acc: 0.6874\n",
      "Epoch 34/70\n",
      " - 6s - loss: 0.9662 - acc: 0.6891\n",
      "Epoch 35/70\n",
      " - 6s - loss: 0.9658 - acc: 0.6862\n",
      "Epoch 36/70\n",
      " - 6s - loss: 0.9617 - acc: 0.6888\n",
      "Epoch 37/70\n",
      " - 6s - loss: 0.9594 - acc: 0.6897\n",
      "Epoch 38/70\n",
      " - 6s - loss: 0.9581 - acc: 0.6891\n",
      "Epoch 39/70\n",
      " - 6s - loss: 0.9573 - acc: 0.6894\n",
      "Epoch 40/70\n",
      " - 6s - loss: 0.9503 - acc: 0.6932\n",
      "Epoch 41/70\n",
      " - 6s - loss: 0.9522 - acc: 0.6904\n",
      "Epoch 42/70\n",
      " - 6s - loss: 0.9485 - acc: 0.6933\n",
      "Epoch 43/70\n",
      " - 6s - loss: 0.9489 - acc: 0.6905\n",
      "Epoch 44/70\n",
      " - 6s - loss: 0.9460 - acc: 0.6920\n",
      "Epoch 45/70\n",
      " - 6s - loss: 0.9427 - acc: 0.6937\n",
      "Epoch 46/70\n",
      " - 6s - loss: 0.9475 - acc: 0.6912\n",
      "Epoch 47/70\n",
      " - 6s - loss: 0.9411 - acc: 0.6938\n",
      "Epoch 48/70\n",
      " - 6s - loss: 0.9404 - acc: 0.6931\n",
      "Epoch 49/70\n",
      " - 6s - loss: 0.9394 - acc: 0.6935\n",
      "Epoch 50/70\n",
      " - 6s - loss: 0.9389 - acc: 0.6938\n",
      "Epoch 51/70\n",
      " - 6s - loss: 0.9414 - acc: 0.6933\n",
      "Epoch 52/70\n",
      " - 6s - loss: 0.9339 - acc: 0.6934\n",
      "Epoch 53/70\n",
      " - 6s - loss: 0.9386 - acc: 0.6961\n",
      "Epoch 54/70\n",
      " - 6s - loss: 0.9351 - acc: 0.6964\n",
      "Epoch 55/70\n",
      " - 6s - loss: 0.9375 - acc: 0.6948\n",
      "Epoch 56/70\n",
      " - 6s - loss: 0.9335 - acc: 0.6952\n",
      "Epoch 57/70\n",
      " - 6s - loss: 0.9340 - acc: 0.6956\n",
      "Epoch 58/70\n",
      " - 6s - loss: 0.9331 - acc: 0.6962\n",
      "Epoch 59/70\n",
      " - 6s - loss: 0.9315 - acc: 0.6962\n",
      "Epoch 60/70\n",
      " - 6s - loss: 0.9336 - acc: 0.6956\n",
      "Epoch 61/70\n",
      " - 6s - loss: 0.9301 - acc: 0.6961\n",
      "Epoch 62/70\n",
      " - 6s - loss: 0.9312 - acc: 0.6960\n",
      "Epoch 63/70\n",
      " - 6s - loss: 0.9323 - acc: 0.6969\n",
      "Epoch 64/70\n",
      " - 6s - loss: 0.9261 - acc: 0.6969\n",
      "Epoch 65/70\n",
      " - 6s - loss: 0.9253 - acc: 0.6961\n",
      "Epoch 66/70\n",
      " - 7s - loss: 0.9249 - acc: 0.6966\n",
      "Epoch 67/70\n",
      " - 6s - loss: 0.9271 - acc: 0.6969\n",
      "Epoch 68/70\n",
      " - 6s - loss: 0.9220 - acc: 0.6985\n",
      "Epoch 69/70\n",
      " - 6s - loss: 0.9235 - acc: 0.6992\n",
      "Epoch 70/70\n",
      " - 6s - loss: 0.9220 - acc: 0.6986\n",
      "[CV]  nodes_l3=80, nodes_l2=100, nodes_l1=160, dropout_l3=0.1, dropout_l2=0.4, dropout_l1=0.30000000000000004, batch_size=500, total= 7.1min\n",
      "[CV] nodes_l3=80, nodes_l2=110, nodes_l1=150, dropout_l3=0.30000000000000004, dropout_l2=0.30000000000000004, dropout_l1=0.30000000000000004, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=150)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=110)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=110)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 15s - loss: 2.3182 - acc: 0.3846\n",
      "Epoch 2/70\n",
      " - 6s - loss: 1.5202 - acc: 0.5808\n",
      "Epoch 3/70\n",
      " - 6s - loss: 1.3394 - acc: 0.6198\n",
      "Epoch 4/70\n",
      " - 6s - loss: 1.2532 - acc: 0.6348\n",
      "Epoch 5/70\n",
      " - 6s - loss: 1.2085 - acc: 0.6423\n",
      "Epoch 6/70\n",
      " - 6s - loss: 1.1615 - acc: 0.6525\n",
      "Epoch 7/70\n",
      " - 6s - loss: 1.1383 - acc: 0.6571\n",
      "Epoch 8/70\n",
      " - 6s - loss: 1.1175 - acc: 0.6598\n",
      "Epoch 9/70\n",
      " - 6s - loss: 1.0983 - acc: 0.6642\n",
      "Epoch 10/70\n",
      " - 6s - loss: 1.0850 - acc: 0.6659\n",
      "Epoch 11/70\n",
      " - 6s - loss: 1.0697 - acc: 0.6706\n",
      "Epoch 12/70\n",
      " - 6s - loss: 1.0608 - acc: 0.6728\n",
      "Epoch 13/70\n",
      " - 6s - loss: 1.0514 - acc: 0.6722\n",
      "Epoch 14/70\n",
      " - 6s - loss: 1.0347 - acc: 0.6747\n",
      "Epoch 15/70\n",
      " - 6s - loss: 1.0313 - acc: 0.6775\n",
      "Epoch 16/70\n",
      " - 7s - loss: 1.0272 - acc: 0.6783\n",
      "Epoch 17/70\n",
      " - 6s - loss: 1.0196 - acc: 0.6781\n",
      "Epoch 18/70\n",
      " - 6s - loss: 1.0120 - acc: 0.6828\n",
      "Epoch 19/70\n",
      " - 6s - loss: 1.0062 - acc: 0.6827\n",
      "Epoch 20/70\n",
      " - 6s - loss: 1.0013 - acc: 0.6841\n",
      "Epoch 21/70\n",
      " - 6s - loss: 0.9960 - acc: 0.6858\n",
      "Epoch 22/70\n",
      " - 6s - loss: 0.9924 - acc: 0.6857\n",
      "Epoch 23/70\n",
      " - 6s - loss: 0.9894 - acc: 0.6854\n",
      "Epoch 24/70\n",
      " - 6s - loss: 0.9869 - acc: 0.6883\n",
      "Epoch 25/70\n",
      " - 6s - loss: 0.9803 - acc: 0.6877\n",
      "Epoch 26/70\n",
      " - 6s - loss: 0.9818 - acc: 0.6878\n",
      "Epoch 27/70\n",
      " - 6s - loss: 0.9754 - acc: 0.6884\n",
      "Epoch 28/70\n",
      " - 6s - loss: 0.9711 - acc: 0.6916\n",
      "Epoch 29/70\n",
      " - 6s - loss: 0.9726 - acc: 0.6927\n",
      "Epoch 30/70\n",
      " - 6s - loss: 0.9655 - acc: 0.6914\n",
      "Epoch 31/70\n",
      " - 6s - loss: 0.9651 - acc: 0.6909\n",
      "Epoch 32/70\n",
      " - 6s - loss: 0.9576 - acc: 0.6937\n",
      "Epoch 33/70\n",
      " - 6s - loss: 0.9582 - acc: 0.6931\n",
      "Epoch 34/70\n",
      " - 6s - loss: 0.9577 - acc: 0.6921\n",
      "Epoch 35/70\n",
      " - 6s - loss: 0.9548 - acc: 0.6922\n",
      "Epoch 36/70\n",
      " - 6s - loss: 0.9549 - acc: 0.6942\n",
      "Epoch 37/70\n",
      " - 6s - loss: 0.9536 - acc: 0.6931\n",
      "Epoch 38/70\n",
      " - 6s - loss: 0.9522 - acc: 0.6923\n",
      "Epoch 39/70\n",
      " - 6s - loss: 0.9494 - acc: 0.6926\n",
      "Epoch 40/70\n",
      " - 6s - loss: 0.9464 - acc: 0.6943\n",
      "Epoch 41/70\n",
      " - 6s - loss: 0.9447 - acc: 0.6932\n",
      "Epoch 42/70\n",
      " - 6s - loss: 0.9437 - acc: 0.6963\n",
      "Epoch 43/70\n",
      " - 6s - loss: 0.9438 - acc: 0.6958\n",
      "Epoch 44/70\n",
      " - 6s - loss: 0.9373 - acc: 0.6971\n",
      "Epoch 45/70\n",
      " - 6s - loss: 0.9427 - acc: 0.6950\n",
      "Epoch 46/70\n",
      " - 6s - loss: 0.9405 - acc: 0.6952\n",
      "Epoch 47/70\n",
      " - 6s - loss: 0.9364 - acc: 0.6967\n",
      "Epoch 48/70\n",
      " - 6s - loss: 0.9360 - acc: 0.6973\n",
      "Epoch 49/70\n",
      " - 6s - loss: 0.9370 - acc: 0.6974\n",
      "Epoch 50/70\n",
      " - 6s - loss: 0.9361 - acc: 0.6976\n",
      "Epoch 51/70\n",
      " - 6s - loss: 0.9328 - acc: 0.6981\n",
      "Epoch 52/70\n",
      " - 6s - loss: 0.9325 - acc: 0.6973\n",
      "Epoch 53/70\n",
      " - 6s - loss: 0.9305 - acc: 0.6982\n",
      "Epoch 54/70\n",
      " - 6s - loss: 0.9323 - acc: 0.6977\n",
      "Epoch 55/70\n",
      " - 6s - loss: 0.9322 - acc: 0.6972\n",
      "Epoch 56/70\n",
      " - 6s - loss: 0.9303 - acc: 0.6986\n",
      "Epoch 57/70\n",
      " - 6s - loss: 0.9285 - acc: 0.6994\n",
      "Epoch 58/70\n",
      " - 6s - loss: 0.9259 - acc: 0.6993\n",
      "Epoch 59/70\n",
      " - 6s - loss: 0.9296 - acc: 0.6983\n",
      "Epoch 60/70\n",
      " - 6s - loss: 0.9327 - acc: 0.6976\n",
      "Epoch 61/70\n",
      " - 6s - loss: 0.9278 - acc: 0.7006\n",
      "Epoch 62/70\n",
      " - 6s - loss: 0.9246 - acc: 0.6989\n",
      "Epoch 63/70\n",
      " - 6s - loss: 0.9227 - acc: 0.6998\n",
      "Epoch 64/70\n",
      " - 6s - loss: 0.9269 - acc: 0.6985\n",
      "Epoch 65/70\n",
      " - 6s - loss: 0.9281 - acc: 0.6995\n",
      "Epoch 66/70\n",
      " - 6s - loss: 0.9204 - acc: 0.7006\n",
      "Epoch 67/70\n",
      " - 6s - loss: 0.9239 - acc: 0.7005\n",
      "Epoch 68/70\n",
      " - 6s - loss: 0.9207 - acc: 0.7015\n",
      "Epoch 69/70\n",
      " - 6s - loss: 0.9214 - acc: 0.7008\n",
      "Epoch 70/70\n",
      " - 7s - loss: 0.9231 - acc: 0.6994\n",
      "[CV]  nodes_l3=80, nodes_l2=110, nodes_l1=150, dropout_l3=0.30000000000000004, dropout_l2=0.30000000000000004, dropout_l1=0.30000000000000004, batch_size=500, total= 7.2min\n",
      "[CV] nodes_l3=80, nodes_l2=110, nodes_l1=150, dropout_l3=0.30000000000000004, dropout_l2=0.30000000000000004, dropout_l1=0.30000000000000004, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=150)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=110)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=110)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 15s - loss: 2.3383 - acc: 0.3859\n",
      "Epoch 2/70\n",
      " - 6s - loss: 1.5314 - acc: 0.5791\n",
      "Epoch 3/70\n",
      " - 6s - loss: 1.3375 - acc: 0.6198\n",
      "Epoch 4/70\n",
      " - 6s - loss: 1.2489 - acc: 0.6363\n",
      "Epoch 5/70\n",
      " - 6s - loss: 1.1947 - acc: 0.6463\n",
      "Epoch 6/70\n",
      " - 6s - loss: 1.1601 - acc: 0.6522\n",
      "Epoch 7/70\n",
      " - 6s - loss: 1.1334 - acc: 0.6575\n",
      "Epoch 8/70\n",
      " - 6s - loss: 1.1089 - acc: 0.6614\n",
      "Epoch 9/70\n",
      " - 6s - loss: 1.0966 - acc: 0.6635\n",
      "Epoch 10/70\n",
      " - 6s - loss: 1.0793 - acc: 0.6666\n",
      "Epoch 11/70\n",
      " - 6s - loss: 1.0650 - acc: 0.6712\n",
      "Epoch 12/70\n",
      " - 6s - loss: 1.0551 - acc: 0.6723\n",
      "Epoch 13/70\n",
      " - 6s - loss: 1.0465 - acc: 0.6752\n",
      "Epoch 14/70\n",
      " - 6s - loss: 1.0334 - acc: 0.6771\n",
      "Epoch 15/70\n",
      " - 6s - loss: 1.0224 - acc: 0.6806\n",
      "Epoch 16/70\n",
      " - 6s - loss: 1.0232 - acc: 0.6791\n",
      "Epoch 17/70\n",
      " - 6s - loss: 1.0114 - acc: 0.6817\n",
      "Epoch 18/70\n",
      " - 7s - loss: 1.0069 - acc: 0.6845\n",
      "Epoch 19/70\n",
      " - 6s - loss: 1.0054 - acc: 0.6830\n",
      "Epoch 20/70\n",
      " - 6s - loss: 0.9975 - acc: 0.6846\n",
      "Epoch 21/70\n",
      " - 6s - loss: 0.9937 - acc: 0.6852\n",
      "Epoch 22/70\n",
      " - 6s - loss: 0.9932 - acc: 0.6833\n",
      "Epoch 23/70\n",
      " - 6s - loss: 0.9865 - acc: 0.6864\n",
      "Epoch 24/70\n",
      " - 6s - loss: 0.9837 - acc: 0.6868\n",
      "Epoch 25/70\n",
      " - 6s - loss: 0.9790 - acc: 0.6887\n",
      "Epoch 26/70\n",
      " - 6s - loss: 0.9751 - acc: 0.6881\n",
      "Epoch 27/70\n",
      " - 6s - loss: 0.9730 - acc: 0.6874\n",
      "Epoch 28/70\n",
      " - 6s - loss: 0.9674 - acc: 0.6907\n",
      "Epoch 29/70\n",
      " - 6s - loss: 0.9667 - acc: 0.6900\n",
      "Epoch 30/70\n",
      " - 6s - loss: 0.9632 - acc: 0.6911\n",
      "Epoch 31/70\n",
      " - 6s - loss: 0.9623 - acc: 0.6909\n",
      "Epoch 32/70\n",
      " - 6s - loss: 0.9611 - acc: 0.6913\n",
      "Epoch 33/70\n",
      " - 6s - loss: 0.9583 - acc: 0.6904\n",
      "Epoch 34/70\n",
      " - 6s - loss: 0.9544 - acc: 0.6921\n",
      "Epoch 35/70\n",
      " - 6s - loss: 0.9523 - acc: 0.6940\n",
      "Epoch 36/70\n",
      " - 6s - loss: 0.9534 - acc: 0.6922\n",
      "Epoch 37/70\n",
      " - 6s - loss: 0.9527 - acc: 0.6934\n",
      "Epoch 38/70\n",
      " - 6s - loss: 0.9451 - acc: 0.6961\n",
      "Epoch 39/70\n",
      " - 6s - loss: 0.9499 - acc: 0.6938\n",
      "Epoch 40/70\n",
      " - 6s - loss: 0.9455 - acc: 0.6948\n",
      "Epoch 41/70\n",
      " - 6s - loss: 0.9444 - acc: 0.6945\n",
      "Epoch 42/70\n",
      " - 6s - loss: 0.9411 - acc: 0.6963\n",
      "Epoch 43/70\n",
      " - 6s - loss: 0.9397 - acc: 0.6973\n",
      "Epoch 44/70\n",
      " - 6s - loss: 0.9416 - acc: 0.6952\n",
      "Epoch 45/70\n",
      " - 6s - loss: 0.9363 - acc: 0.6964\n",
      "Epoch 46/70\n",
      " - 6s - loss: 0.9369 - acc: 0.6977\n",
      "Epoch 47/70\n",
      " - 6s - loss: 0.9368 - acc: 0.6985\n",
      "Epoch 48/70\n",
      " - 6s - loss: 0.9357 - acc: 0.6957\n",
      "Epoch 49/70\n",
      " - 6s - loss: 0.9336 - acc: 0.6975\n",
      "Epoch 50/70\n",
      " - 6s - loss: 0.9303 - acc: 0.6980\n",
      "Epoch 51/70\n",
      " - 6s - loss: 0.9318 - acc: 0.6972\n",
      "Epoch 52/70\n",
      " - 6s - loss: 0.9310 - acc: 0.6984\n",
      "Epoch 53/70\n",
      " - 6s - loss: 0.9334 - acc: 0.6990\n",
      "Epoch 54/70\n",
      " - 7s - loss: 0.9262 - acc: 0.7005\n",
      "Epoch 55/70\n",
      " - 6s - loss: 0.9295 - acc: 0.6993\n",
      "Epoch 56/70\n",
      " - 6s - loss: 0.9245 - acc: 0.6995\n",
      "Epoch 57/70\n",
      " - 6s - loss: 0.9272 - acc: 0.6982\n",
      "Epoch 58/70\n",
      " - 6s - loss: 0.9233 - acc: 0.6996\n",
      "Epoch 59/70\n",
      " - 6s - loss: 0.9244 - acc: 0.6993\n",
      "Epoch 60/70\n",
      " - 6s - loss: 0.9253 - acc: 0.7010\n",
      "Epoch 61/70\n",
      " - 6s - loss: 0.9230 - acc: 0.7019\n",
      "Epoch 62/70\n",
      " - 6s - loss: 0.9247 - acc: 0.6994\n",
      "Epoch 63/70\n",
      " - 6s - loss: 0.9230 - acc: 0.6997\n",
      "Epoch 64/70\n",
      " - 6s - loss: 0.9204 - acc: 0.7014\n",
      "Epoch 65/70\n",
      " - 6s - loss: 0.9201 - acc: 0.7022\n",
      "Epoch 66/70\n",
      " - 6s - loss: 0.9202 - acc: 0.6992\n",
      "Epoch 67/70\n",
      " - 6s - loss: 0.9167 - acc: 0.6999\n",
      "Epoch 68/70\n",
      " - 6s - loss: 0.9198 - acc: 0.7001\n",
      "Epoch 69/70\n",
      " - 6s - loss: 0.9202 - acc: 0.7003\n",
      "Epoch 70/70\n",
      " - 6s - loss: 0.9185 - acc: 0.6997\n",
      "[CV]  nodes_l3=80, nodes_l2=110, nodes_l1=150, dropout_l3=0.30000000000000004, dropout_l2=0.30000000000000004, dropout_l1=0.30000000000000004, batch_size=500, total= 7.5min\n",
      "[CV] nodes_l3=80, nodes_l2=110, nodes_l1=150, dropout_l3=0.30000000000000004, dropout_l2=0.30000000000000004, dropout_l1=0.30000000000000004, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=150)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=110)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=110)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 15s - loss: 2.3639 - acc: 0.3704\n",
      "Epoch 2/70\n",
      " - 6s - loss: 1.5302 - acc: 0.5755\n",
      "Epoch 3/70\n",
      " - 6s - loss: 1.3426 - acc: 0.6150\n",
      "Epoch 4/70\n",
      " - 6s - loss: 1.2428 - acc: 0.6353\n",
      "Epoch 5/70\n",
      " - 6s - loss: 1.1969 - acc: 0.6447\n",
      "Epoch 6/70\n",
      " - 6s - loss: 1.1578 - acc: 0.6505\n",
      "Epoch 7/70\n",
      " - 6s - loss: 1.1289 - acc: 0.6574\n",
      "Epoch 8/70\n",
      " - 6s - loss: 1.1113 - acc: 0.6610\n",
      "Epoch 9/70\n",
      " - 6s - loss: 1.0859 - acc: 0.6669\n",
      "Epoch 10/70\n",
      " - 6s - loss: 1.0736 - acc: 0.6690\n",
      "Epoch 11/70\n",
      " - 6s - loss: 1.0616 - acc: 0.6717\n",
      "Epoch 12/70\n",
      " - 6s - loss: 1.0497 - acc: 0.6737\n",
      "Epoch 13/70\n",
      " - 6s - loss: 1.0400 - acc: 0.6749\n",
      "Epoch 14/70\n",
      " - 6s - loss: 1.0281 - acc: 0.6774\n",
      "Epoch 15/70\n",
      " - 6s - loss: 1.0235 - acc: 0.6783\n",
      "Epoch 16/70\n",
      " - 6s - loss: 1.0141 - acc: 0.6825\n",
      "Epoch 17/70\n",
      " - 6s - loss: 1.0063 - acc: 0.6815\n",
      "Epoch 18/70\n",
      " - 6s - loss: 1.0027 - acc: 0.6848\n",
      "Epoch 19/70\n",
      " - 6s - loss: 0.9962 - acc: 0.6859\n",
      "Epoch 20/70\n",
      " - 6s - loss: 0.9871 - acc: 0.6869\n",
      "Epoch 21/70\n",
      " - 6s - loss: 0.9858 - acc: 0.6875\n",
      "Epoch 22/70\n",
      " - 6s - loss: 0.9803 - acc: 0.6877\n",
      "Epoch 23/70\n",
      " - 6s - loss: 0.9731 - acc: 0.6878\n",
      "Epoch 24/70\n",
      " - 6s - loss: 0.9702 - acc: 0.6887\n",
      "Epoch 25/70\n",
      " - 6s - loss: 0.9657 - acc: 0.6921\n",
      "Epoch 26/70\n",
      " - 6s - loss: 0.9624 - acc: 0.6918\n",
      "Epoch 27/70\n",
      " - 6s - loss: 0.9596 - acc: 0.6918\n",
      "Epoch 28/70\n",
      " - 6s - loss: 0.9582 - acc: 0.6912\n",
      "Epoch 29/70\n",
      " - 6s - loss: 0.9549 - acc: 0.6938\n",
      "Epoch 30/70\n",
      " - 6s - loss: 0.9527 - acc: 0.6948\n",
      "Epoch 31/70\n",
      " - 6s - loss: 0.9504 - acc: 0.6958\n",
      "Epoch 32/70\n",
      " - 6s - loss: 0.9473 - acc: 0.6954\n",
      "Epoch 33/70\n",
      " - 6s - loss: 0.9429 - acc: 0.6958\n",
      "Epoch 34/70\n",
      " - 6s - loss: 0.9385 - acc: 0.6969\n",
      "Epoch 35/70\n",
      " - 6s - loss: 0.9392 - acc: 0.6960\n",
      "Epoch 36/70\n",
      " - 6s - loss: 0.9387 - acc: 0.6951\n",
      "Epoch 37/70\n",
      " - 6s - loss: 0.9377 - acc: 0.6982\n",
      "Epoch 38/70\n",
      " - 6s - loss: 0.9357 - acc: 0.6985\n",
      "Epoch 39/70\n",
      " - 6s - loss: 0.9346 - acc: 0.6969\n",
      "Epoch 40/70\n",
      " - 6s - loss: 0.9308 - acc: 0.7002\n",
      "Epoch 41/70\n",
      " - 6s - loss: 0.9297 - acc: 0.6988\n",
      "Epoch 42/70\n",
      " - 6s - loss: 0.9261 - acc: 0.6993\n",
      "Epoch 43/70\n",
      " - 6s - loss: 0.9252 - acc: 0.6993\n",
      "Epoch 44/70\n",
      " - 6s - loss: 0.9253 - acc: 0.7013\n",
      "Epoch 45/70\n",
      " - 6s - loss: 0.9260 - acc: 0.6998\n",
      "Epoch 46/70\n",
      " - 6s - loss: 0.9221 - acc: 0.7014\n",
      "Epoch 47/70\n",
      " - 6s - loss: 0.9223 - acc: 0.7013\n",
      "Epoch 48/70\n",
      " - 6s - loss: 0.9203 - acc: 0.7024\n",
      "Epoch 49/70\n",
      " - 6s - loss: 0.9132 - acc: 0.7020\n",
      "Epoch 50/70\n",
      " - 6s - loss: 0.9167 - acc: 0.7011\n",
      "Epoch 51/70\n",
      " - 6s - loss: 0.9181 - acc: 0.7021\n",
      "Epoch 52/70\n",
      " - 6s - loss: 0.9152 - acc: 0.7009\n",
      "Epoch 53/70\n",
      " - 6s - loss: 0.9158 - acc: 0.7006\n",
      "Epoch 54/70\n",
      " - 6s - loss: 0.9107 - acc: 0.7039\n",
      "Epoch 55/70\n",
      " - 6s - loss: 0.9126 - acc: 0.7021\n",
      "Epoch 56/70\n",
      " - 6s - loss: 0.9140 - acc: 0.7021\n",
      "Epoch 57/70\n",
      " - 6s - loss: 0.9074 - acc: 0.7046\n",
      "Epoch 58/70\n",
      " - 6s - loss: 0.9136 - acc: 0.7024\n",
      "Epoch 59/70\n",
      " - 6s - loss: 0.9102 - acc: 0.7030\n",
      "Epoch 60/70\n",
      " - 6s - loss: 0.9105 - acc: 0.7032\n",
      "Epoch 61/70\n",
      " - 6s - loss: 0.9087 - acc: 0.7032\n",
      "Epoch 62/70\n",
      " - 6s - loss: 0.9096 - acc: 0.7036\n",
      "Epoch 63/70\n",
      " - 6s - loss: 0.9078 - acc: 0.7048\n",
      "Epoch 64/70\n",
      " - 6s - loss: 0.9109 - acc: 0.7034\n",
      "Epoch 65/70\n",
      " - 6s - loss: 0.9011 - acc: 0.7053\n",
      "Epoch 66/70\n",
      " - 6s - loss: 0.9060 - acc: 0.7044\n",
      "Epoch 67/70\n",
      " - 6s - loss: 0.9042 - acc: 0.7051\n",
      "Epoch 68/70\n",
      " - 6s - loss: 0.9058 - acc: 0.7048\n",
      "Epoch 69/70\n",
      " - 6s - loss: 0.9014 - acc: 0.7058\n",
      "Epoch 70/70\n",
      " - 6s - loss: 0.9064 - acc: 0.7037\n",
      "[CV]  nodes_l3=80, nodes_l2=110, nodes_l1=150, dropout_l3=0.30000000000000004, dropout_l2=0.30000000000000004, dropout_l1=0.30000000000000004, batch_size=500, total= 7.2min\n",
      "[CV] nodes_l3=80, nodes_l2=110, nodes_l1=150, dropout_l3=0.30000000000000004, dropout_l2=0.30000000000000004, dropout_l1=0.30000000000000004, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=150)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=110)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=110)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 15s - loss: 2.3642 - acc: 0.3787\n",
      "Epoch 2/70\n",
      " - 7s - loss: 1.5276 - acc: 0.5793\n",
      "Epoch 3/70\n",
      " - 6s - loss: 1.3439 - acc: 0.6147\n",
      "Epoch 4/70\n",
      " - 7s - loss: 1.2621 - acc: 0.6275\n",
      "Epoch 5/70\n",
      " - 6s - loss: 1.2102 - acc: 0.6388\n",
      "Epoch 6/70\n",
      " - 6s - loss: 1.1740 - acc: 0.6447\n",
      "Epoch 7/70\n",
      " - 7s - loss: 1.1450 - acc: 0.6521\n",
      "Epoch 8/70\n",
      " - 6s - loss: 1.1243 - acc: 0.6555\n",
      "Epoch 9/70\n",
      " - 7s - loss: 1.0987 - acc: 0.6598\n",
      "Epoch 10/70\n",
      " - 6s - loss: 1.0907 - acc: 0.6624\n",
      "Epoch 11/70\n",
      " - 6s - loss: 1.0809 - acc: 0.6640\n",
      "Epoch 12/70\n",
      " - 7s - loss: 1.0632 - acc: 0.6660\n",
      "Epoch 13/70\n",
      " - 6s - loss: 1.0564 - acc: 0.6695\n",
      "Epoch 14/70\n",
      " - 7s - loss: 1.0468 - acc: 0.6721\n",
      "Epoch 15/70\n",
      " - 6s - loss: 1.0361 - acc: 0.6728\n",
      "Epoch 16/70\n",
      " - 6s - loss: 1.0275 - acc: 0.6759\n",
      "Epoch 17/70\n",
      " - 7s - loss: 1.0228 - acc: 0.6766\n",
      "Epoch 18/70\n",
      " - 6s - loss: 1.0176 - acc: 0.6776\n",
      "Epoch 19/70\n",
      " - 7s - loss: 1.0091 - acc: 0.6793\n",
      "Epoch 20/70\n",
      " - 6s - loss: 1.0003 - acc: 0.6821\n",
      "Epoch 21/70\n",
      " - 6s - loss: 1.0005 - acc: 0.6807\n",
      "Epoch 22/70\n",
      " - 7s - loss: 0.9951 - acc: 0.6838\n",
      "Epoch 23/70\n",
      " - 6s - loss: 0.9933 - acc: 0.6817\n",
      "Epoch 24/70\n",
      " - 7s - loss: 0.9850 - acc: 0.6845\n",
      "Epoch 25/70\n",
      " - 6s - loss: 0.9822 - acc: 0.6850\n",
      "Epoch 26/70\n",
      " - 6s - loss: 0.9806 - acc: 0.6863\n",
      "Epoch 27/70\n",
      " - 8s - loss: 0.9810 - acc: 0.6857\n",
      "Epoch 28/70\n",
      " - 7s - loss: 0.9756 - acc: 0.6857\n",
      "Epoch 29/70\n",
      " - 7s - loss: 0.9705 - acc: 0.6875\n",
      "Epoch 30/70\n",
      " - 6s - loss: 0.9695 - acc: 0.6874\n",
      "Epoch 31/70\n",
      " - 7s - loss: 0.9645 - acc: 0.6888\n",
      "Epoch 32/70\n",
      " - 6s - loss: 0.9644 - acc: 0.6886\n",
      "Epoch 33/70\n",
      " - 6s - loss: 0.9635 - acc: 0.6889\n",
      "Epoch 34/70\n",
      " - 7s - loss: 0.9628 - acc: 0.6888\n",
      "Epoch 35/70\n",
      " - 7s - loss: 0.9576 - acc: 0.6907\n",
      "Epoch 36/70\n",
      " - 7s - loss: 0.9535 - acc: 0.6914\n",
      "Epoch 37/70\n",
      " - 7s - loss: 0.9534 - acc: 0.6913\n",
      "Epoch 38/70\n",
      " - 8s - loss: 0.9522 - acc: 0.6921\n",
      "Epoch 39/70\n",
      " - 7s - loss: 0.9512 - acc: 0.6925\n",
      "Epoch 40/70\n",
      " - 6s - loss: 0.9485 - acc: 0.6941\n",
      "Epoch 41/70\n",
      " - 7s - loss: 0.9474 - acc: 0.6937\n",
      "Epoch 42/70\n",
      " - 6s - loss: 0.9464 - acc: 0.6937\n",
      "Epoch 43/70\n",
      " - 7s - loss: 0.9450 - acc: 0.6918\n",
      "Epoch 44/70\n",
      " - 6s - loss: 0.9442 - acc: 0.6937\n",
      "Epoch 45/70\n",
      " - 6s - loss: 0.9402 - acc: 0.6940\n",
      "Epoch 46/70\n",
      " - 7s - loss: 0.9439 - acc: 0.6928\n",
      "Epoch 47/70\n",
      " - 6s - loss: 0.9401 - acc: 0.6944\n",
      "Epoch 48/70\n",
      " - 7s - loss: 0.9416 - acc: 0.6943\n",
      "Epoch 49/70\n",
      " - 6s - loss: 0.9425 - acc: 0.6955\n",
      "Epoch 50/70\n",
      " - 7s - loss: 0.9390 - acc: 0.6940\n",
      "Epoch 51/70\n",
      " - 7s - loss: 0.9354 - acc: 0.6965\n",
      "Epoch 52/70\n",
      " - 6s - loss: 0.9368 - acc: 0.6940\n",
      "Epoch 53/70\n",
      " - 7s - loss: 0.9320 - acc: 0.6968\n",
      "Epoch 54/70\n",
      " - 6s - loss: 0.9314 - acc: 0.6957\n",
      "Epoch 55/70\n",
      " - 7s - loss: 0.9318 - acc: 0.6967\n",
      "Epoch 56/70\n",
      " - 6s - loss: 0.9330 - acc: 0.6968\n",
      "Epoch 57/70\n",
      " - 6s - loss: 0.9326 - acc: 0.6962\n",
      "Epoch 58/70\n",
      " - 7s - loss: 0.9294 - acc: 0.6964\n",
      "Epoch 59/70\n",
      " - 6s - loss: 0.9275 - acc: 0.6971\n",
      "Epoch 60/70\n",
      " - 7s - loss: 0.9297 - acc: 0.6980\n",
      "Epoch 61/70\n",
      " - 6s - loss: 0.9278 - acc: 0.6966\n",
      "Epoch 62/70\n",
      " - 7s - loss: 0.9274 - acc: 0.6965\n",
      "Epoch 63/70\n",
      " - 7s - loss: 0.9250 - acc: 0.6980\n",
      "Epoch 64/70\n",
      " - 7s - loss: 0.9238 - acc: 0.6996\n",
      "Epoch 65/70\n",
      " - 7s - loss: 0.9240 - acc: 0.6984\n",
      "Epoch 66/70\n",
      " - 6s - loss: 0.9287 - acc: 0.6974\n",
      "Epoch 67/70\n",
      " - 6s - loss: 0.9249 - acc: 0.6983\n",
      "Epoch 68/70\n",
      " - 7s - loss: 0.9246 - acc: 0.6989\n",
      "Epoch 69/70\n",
      " - 6s - loss: 0.9237 - acc: 0.6987\n",
      "Epoch 70/70\n",
      " - 7s - loss: 0.9224 - acc: 0.6990\n",
      "[CV]  nodes_l3=80, nodes_l2=110, nodes_l1=150, dropout_l3=0.30000000000000004, dropout_l2=0.30000000000000004, dropout_l1=0.30000000000000004, batch_size=500, total= 7.9min\n",
      "[CV] nodes_l3=50, nodes_l2=120, nodes_l1=170, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.4, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=170)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 16s - loss: 2.1890 - acc: 0.4175\n",
      "Epoch 2/70\n",
      " - 7s - loss: 1.4284 - acc: 0.5971\n",
      "Epoch 3/70\n",
      " - 7s - loss: 1.2662 - acc: 0.6293\n",
      "Epoch 4/70\n",
      " - 6s - loss: 1.1979 - acc: 0.6410\n",
      "Epoch 5/70\n",
      " - 7s - loss: 1.1570 - acc: 0.6485\n",
      "Epoch 6/70\n",
      " - 6s - loss: 1.1205 - acc: 0.6541\n",
      "Epoch 7/70\n",
      " - 7s - loss: 1.0994 - acc: 0.6575\n",
      "Epoch 8/70\n",
      " - 7s - loss: 1.0784 - acc: 0.6631\n",
      "Epoch 9/70\n",
      " - 6s - loss: 1.0638 - acc: 0.6655\n",
      "Epoch 10/70\n",
      " - 7s - loss: 1.0496 - acc: 0.6665\n",
      "Epoch 11/70\n",
      " - 6s - loss: 1.0380 - acc: 0.6696\n",
      "Epoch 12/70\n",
      " - 7s - loss: 1.0280 - acc: 0.6721\n",
      "Epoch 13/70\n",
      " - 6s - loss: 1.0148 - acc: 0.6743\n",
      "Epoch 14/70\n",
      " - 6s - loss: 1.0078 - acc: 0.6737\n",
      "Epoch 15/70\n",
      " - 7s - loss: 0.9996 - acc: 0.6785\n",
      "Epoch 16/70\n",
      " - 6s - loss: 0.9895 - acc: 0.6816\n",
      "Epoch 17/70\n",
      " - 7s - loss: 0.9866 - acc: 0.6819\n",
      "Epoch 18/70\n",
      " - 6s - loss: 0.9785 - acc: 0.6832\n",
      "Epoch 19/70\n",
      " - 6s - loss: 0.9731 - acc: 0.6853\n",
      "Epoch 20/70\n",
      " - 7s - loss: 0.9683 - acc: 0.6841\n",
      "Epoch 21/70\n",
      " - 6s - loss: 0.9649 - acc: 0.6865\n",
      "Epoch 22/70\n",
      " - 7s - loss: 0.9563 - acc: 0.6857\n",
      "Epoch 23/70\n",
      " - 7s - loss: 0.9531 - acc: 0.6896\n",
      "Epoch 24/70\n",
      " - 7s - loss: 0.9494 - acc: 0.6892\n",
      "Epoch 25/70\n",
      " - 6s - loss: 0.9467 - acc: 0.6891\n",
      "Epoch 26/70\n",
      " - 6s - loss: 0.9422 - acc: 0.6902\n",
      "Epoch 27/70\n",
      " - 7s - loss: 0.9391 - acc: 0.6913\n",
      "Epoch 28/70\n",
      " - 6s - loss: 0.9367 - acc: 0.6923\n",
      "Epoch 29/70\n",
      " - 7s - loss: 0.9352 - acc: 0.6929\n",
      "Epoch 30/70\n",
      " - 6s - loss: 0.9316 - acc: 0.6934\n",
      "Epoch 31/70\n",
      " - 6s - loss: 0.9251 - acc: 0.6962\n",
      "Epoch 32/70\n",
      " - 7s - loss: 0.9236 - acc: 0.6955\n",
      "Epoch 33/70\n",
      " - 6s - loss: 0.9236 - acc: 0.6947\n",
      "Epoch 34/70\n",
      " - 7s - loss: 0.9218 - acc: 0.6961\n",
      "Epoch 35/70\n",
      " - 7s - loss: 0.9201 - acc: 0.6958\n",
      "Epoch 36/70\n",
      " - 7s - loss: 0.9175 - acc: 0.6972\n",
      "Epoch 37/70\n",
      " - 7s - loss: 0.9173 - acc: 0.6961\n",
      "Epoch 38/70\n",
      " - 6s - loss: 0.9135 - acc: 0.6972\n",
      "Epoch 39/70\n",
      " - 7s - loss: 0.9104 - acc: 0.6993\n",
      "Epoch 40/70\n",
      " - 6s - loss: 0.9127 - acc: 0.6965\n",
      "Epoch 41/70\n",
      " - 7s - loss: 0.9088 - acc: 0.6983\n",
      "Epoch 42/70\n",
      " - 7s - loss: 0.9082 - acc: 0.6984\n",
      "Epoch 43/70\n",
      " - 6s - loss: 0.9097 - acc: 0.6980\n",
      "Epoch 44/70\n",
      " - 7s - loss: 0.9042 - acc: 0.6979\n",
      "Epoch 45/70\n",
      " - 6s - loss: 0.9005 - acc: 0.7012\n",
      "Epoch 46/70\n",
      " - 7s - loss: 0.9042 - acc: 0.7001\n",
      "Epoch 47/70\n",
      " - 6s - loss: 0.9010 - acc: 0.7011\n",
      "Epoch 48/70\n",
      " - 6s - loss: 0.8987 - acc: 0.7012\n",
      "Epoch 49/70\n",
      " - 7s - loss: 0.9003 - acc: 0.7012\n",
      "Epoch 50/70\n",
      " - 6s - loss: 0.8996 - acc: 0.7019\n",
      "Epoch 51/70\n",
      " - 7s - loss: 0.8950 - acc: 0.7024\n",
      "Epoch 52/70\n",
      " - 6s - loss: 0.8932 - acc: 0.7025\n",
      "Epoch 53/70\n",
      " - 6s - loss: 0.8958 - acc: 0.7026\n",
      "Epoch 54/70\n",
      " - 7s - loss: 0.8992 - acc: 0.7023\n",
      "Epoch 55/70\n",
      " - 6s - loss: 0.8945 - acc: 0.7019\n",
      "Epoch 56/70\n",
      " - 7s - loss: 0.8928 - acc: 0.7034\n",
      "Epoch 57/70\n",
      " - 6s - loss: 0.8907 - acc: 0.7013\n",
      "Epoch 58/70\n",
      " - 6s - loss: 0.8897 - acc: 0.7033\n",
      "Epoch 59/70\n",
      " - 7s - loss: 0.8907 - acc: 0.7026\n",
      "Epoch 60/70\n",
      " - 6s - loss: 0.8904 - acc: 0.7026\n",
      "Epoch 61/70\n",
      " - 7s - loss: 0.8912 - acc: 0.7019\n",
      "Epoch 62/70\n",
      " - 6s - loss: 0.8864 - acc: 0.7033\n",
      "Epoch 63/70\n",
      " - 6s - loss: 0.8861 - acc: 0.7036\n",
      "Epoch 64/70\n",
      " - 7s - loss: 0.8901 - acc: 0.7023\n",
      "Epoch 65/70\n",
      " - 6s - loss: 0.8907 - acc: 0.7017\n",
      "Epoch 66/70\n",
      " - 7s - loss: 0.8888 - acc: 0.7038\n",
      "Epoch 67/70\n",
      " - 6s - loss: 0.8836 - acc: 0.7033\n",
      "Epoch 68/70\n",
      " - 6s - loss: 0.8829 - acc: 0.7058\n",
      "Epoch 69/70\n",
      " - 7s - loss: 0.8818 - acc: 0.7034\n",
      "Epoch 70/70\n",
      " - 6s - loss: 0.8852 - acc: 0.7045\n",
      "[CV]  nodes_l3=50, nodes_l2=120, nodes_l1=170, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.4, batch_size=500, total= 7.9min\n",
      "[CV] nodes_l3=50, nodes_l2=120, nodes_l1=170, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.4, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=170)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 16s - loss: 2.2475 - acc: 0.3996\n",
      "Epoch 2/70\n",
      " - 7s - loss: 1.4535 - acc: 0.5923\n",
      "Epoch 3/70\n",
      " - 7s - loss: 1.2820 - acc: 0.6269\n",
      "Epoch 4/70\n",
      " - 7s - loss: 1.1965 - acc: 0.6415\n",
      "Epoch 5/70\n",
      " - 7s - loss: 1.1561 - acc: 0.6510\n",
      "Epoch 6/70\n",
      " - 7s - loss: 1.1185 - acc: 0.6561\n",
      "Epoch 7/70\n",
      " - 7s - loss: 1.0997 - acc: 0.6595\n",
      "Epoch 8/70\n",
      " - 7s - loss: 1.0793 - acc: 0.6627\n",
      "Epoch 9/70\n",
      " - 7s - loss: 1.0618 - acc: 0.6675\n",
      "Epoch 10/70\n",
      " - 7s - loss: 1.0474 - acc: 0.6696\n",
      "Epoch 11/70\n",
      " - 7s - loss: 1.0334 - acc: 0.6729\n",
      "Epoch 12/70\n",
      " - 7s - loss: 1.0226 - acc: 0.6730\n",
      "Epoch 13/70\n",
      " - 7s - loss: 1.0131 - acc: 0.6757\n",
      "Epoch 14/70\n",
      " - 7s - loss: 1.0003 - acc: 0.6800\n",
      "Epoch 15/70\n",
      " - 7s - loss: 0.9979 - acc: 0.6803\n",
      "Epoch 16/70\n",
      " - 7s - loss: 0.9906 - acc: 0.6815\n",
      "Epoch 17/70\n",
      " - 7s - loss: 0.9812 - acc: 0.6836\n",
      "Epoch 18/70\n",
      " - 7s - loss: 0.9730 - acc: 0.6840\n",
      "Epoch 19/70\n",
      " - 7s - loss: 0.9694 - acc: 0.6866\n",
      "Epoch 20/70\n",
      " - 7s - loss: 0.9653 - acc: 0.6859\n",
      "Epoch 21/70\n",
      " - 7s - loss: 0.9601 - acc: 0.6881\n",
      "Epoch 22/70\n",
      " - 7s - loss: 0.9530 - acc: 0.6904\n",
      "Epoch 23/70\n",
      " - 7s - loss: 0.9508 - acc: 0.6915\n",
      "Epoch 24/70\n",
      " - 7s - loss: 0.9469 - acc: 0.6912\n",
      "Epoch 25/70\n",
      " - 7s - loss: 0.9424 - acc: 0.6916\n",
      "Epoch 26/70\n",
      " - 7s - loss: 0.9398 - acc: 0.6916\n",
      "Epoch 27/70\n",
      " - 8s - loss: 0.9343 - acc: 0.6937\n",
      "Epoch 28/70\n",
      " - 7s - loss: 0.9354 - acc: 0.6945\n",
      "Epoch 29/70\n",
      " - 7s - loss: 0.9289 - acc: 0.6936\n",
      "Epoch 30/70\n",
      " - 7s - loss: 0.9268 - acc: 0.6947\n",
      "Epoch 31/70\n",
      " - 7s - loss: 0.9252 - acc: 0.6949\n",
      "Epoch 32/70\n",
      " - 7s - loss: 0.9243 - acc: 0.6936\n",
      "Epoch 33/70\n",
      " - 7s - loss: 0.9191 - acc: 0.6972\n",
      "Epoch 34/70\n",
      " - 7s - loss: 0.9195 - acc: 0.6948\n",
      "Epoch 35/70\n",
      " - 7s - loss: 0.9192 - acc: 0.6957\n",
      "Epoch 36/70\n",
      " - 7s - loss: 0.9152 - acc: 0.6972\n",
      "Epoch 37/70\n",
      " - 7s - loss: 0.9131 - acc: 0.6959\n",
      "Epoch 38/70\n",
      " - 7s - loss: 0.9142 - acc: 0.6981\n",
      "Epoch 39/70\n",
      " - 7s - loss: 0.9107 - acc: 0.6991\n",
      "Epoch 40/70\n",
      " - 7s - loss: 0.9064 - acc: 0.6998\n",
      "Epoch 41/70\n",
      " - 7s - loss: 0.9082 - acc: 0.6979\n",
      "Epoch 42/70\n",
      " - 7s - loss: 0.9075 - acc: 0.6994\n",
      "Epoch 43/70\n",
      " - 7s - loss: 0.9057 - acc: 0.6997\n",
      "Epoch 44/70\n",
      " - 7s - loss: 0.9002 - acc: 0.6998\n",
      "Epoch 45/70\n",
      " - 7s - loss: 0.9026 - acc: 0.6988\n",
      "Epoch 46/70\n",
      " - 7s - loss: 0.8990 - acc: 0.7006\n",
      "Epoch 47/70\n",
      " - 7s - loss: 0.8993 - acc: 0.7006\n",
      "Epoch 48/70\n",
      " - 7s - loss: 0.9023 - acc: 0.7004\n",
      "Epoch 49/70\n",
      " - 7s - loss: 0.8975 - acc: 0.7016\n",
      "Epoch 50/70\n",
      " - 7s - loss: 0.9002 - acc: 0.7007\n",
      "Epoch 51/70\n",
      " - 7s - loss: 0.8935 - acc: 0.7019\n",
      "Epoch 52/70\n",
      " - 7s - loss: 0.8934 - acc: 0.7018\n",
      "Epoch 53/70\n",
      " - 7s - loss: 0.8933 - acc: 0.7003\n",
      "Epoch 54/70\n",
      " - 7s - loss: 0.8919 - acc: 0.7018\n",
      "Epoch 55/70\n",
      " - 7s - loss: 0.8933 - acc: 0.7023\n",
      "Epoch 56/70\n",
      " - 7s - loss: 0.8885 - acc: 0.7043\n",
      "Epoch 57/70\n",
      " - 7s - loss: 0.8900 - acc: 0.7035\n",
      "Epoch 58/70\n",
      " - 7s - loss: 0.8882 - acc: 0.7029\n",
      "Epoch 59/70\n",
      " - 7s - loss: 0.8866 - acc: 0.7016\n",
      "Epoch 60/70\n",
      " - 7s - loss: 0.8878 - acc: 0.7044\n",
      "Epoch 61/70\n",
      " - 7s - loss: 0.8868 - acc: 0.7026\n",
      "Epoch 62/70\n",
      " - 7s - loss: 0.8886 - acc: 0.7052\n",
      "Epoch 63/70\n",
      " - 7s - loss: 0.8882 - acc: 0.7046\n",
      "Epoch 64/70\n",
      " - 7s - loss: 0.8833 - acc: 0.7059\n",
      "Epoch 65/70\n",
      " - 7s - loss: 0.8862 - acc: 0.7028\n",
      "Epoch 66/70\n",
      " - 7s - loss: 0.8857 - acc: 0.7027\n",
      "Epoch 67/70\n",
      " - 7s - loss: 0.8827 - acc: 0.7046\n",
      "Epoch 68/70\n",
      " - 7s - loss: 0.8827 - acc: 0.7063\n",
      "Epoch 69/70\n",
      " - 7s - loss: 0.8815 - acc: 0.7045\n",
      "Epoch 70/70\n",
      " - 7s - loss: 0.8821 - acc: 0.7057\n",
      "[CV]  nodes_l3=50, nodes_l2=120, nodes_l1=170, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.4, batch_size=500, total= 8.2min\n",
      "[CV] nodes_l3=50, nodes_l2=120, nodes_l1=170, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.4, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=170)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 16s - loss: 2.2431 - acc: 0.4118\n",
      "Epoch 2/70\n",
      " - 7s - loss: 1.4421 - acc: 0.5969\n",
      "Epoch 3/70\n",
      " - 7s - loss: 1.2717 - acc: 0.6299\n",
      "Epoch 4/70\n",
      " - 7s - loss: 1.1897 - acc: 0.6430\n",
      "Epoch 5/70\n",
      " - 7s - loss: 1.1464 - acc: 0.6529\n",
      "Epoch 6/70\n",
      " - 7s - loss: 1.1116 - acc: 0.6589\n",
      "Epoch 7/70\n",
      " - 7s - loss: 1.0893 - acc: 0.6609\n",
      "Epoch 8/70\n",
      " - 7s - loss: 1.0714 - acc: 0.6658\n",
      "Epoch 9/70\n",
      " - 7s - loss: 1.0482 - acc: 0.6693\n",
      "Epoch 10/70\n",
      " - 7s - loss: 1.0340 - acc: 0.6718\n",
      "Epoch 11/70\n",
      " - 7s - loss: 1.0249 - acc: 0.6748\n",
      "Epoch 12/70\n",
      " - 7s - loss: 1.0099 - acc: 0.6772\n",
      "Epoch 13/70\n",
      " - 7s - loss: 0.9978 - acc: 0.6804\n",
      "Epoch 14/70\n",
      " - 7s - loss: 0.9876 - acc: 0.6821\n",
      "Epoch 15/70\n",
      " - 7s - loss: 0.9818 - acc: 0.6822\n",
      "Epoch 16/70\n",
      " - 7s - loss: 0.9767 - acc: 0.6847\n",
      "Epoch 17/70\n",
      " - 7s - loss: 0.9680 - acc: 0.6863\n",
      "Epoch 18/70\n",
      " - 7s - loss: 0.9609 - acc: 0.6900\n",
      "Epoch 19/70\n",
      " - 7s - loss: 0.9566 - acc: 0.6905\n",
      "Epoch 20/70\n",
      " - 7s - loss: 0.9535 - acc: 0.6888\n",
      "Epoch 21/70\n",
      " - 7s - loss: 0.9467 - acc: 0.6906\n",
      "Epoch 22/70\n",
      " - 8s - loss: 0.9405 - acc: 0.6931\n",
      "Epoch 23/70\n",
      " - 7s - loss: 0.9368 - acc: 0.6922\n",
      "Epoch 24/70\n",
      " - 7s - loss: 0.9328 - acc: 0.6961\n",
      "Epoch 25/70\n",
      " - 7s - loss: 0.9265 - acc: 0.6962\n",
      "Epoch 26/70\n",
      " - 7s - loss: 0.9316 - acc: 0.6936\n",
      "Epoch 27/70\n",
      " - 7s - loss: 0.9243 - acc: 0.6951\n",
      "Epoch 28/70\n",
      " - 7s - loss: 0.9191 - acc: 0.6976\n",
      "Epoch 29/70\n",
      " - 7s - loss: 0.9208 - acc: 0.6958\n",
      "Epoch 30/70\n",
      " - 7s - loss: 0.9149 - acc: 0.6990\n",
      "Epoch 31/70\n",
      " - 7s - loss: 0.9099 - acc: 0.6984\n",
      "Epoch 32/70\n",
      " - 7s - loss: 0.9114 - acc: 0.6990\n",
      "Epoch 33/70\n",
      " - 7s - loss: 0.9073 - acc: 0.6992\n",
      "Epoch 34/70\n",
      " - 7s - loss: 0.9066 - acc: 0.7001\n",
      "Epoch 35/70\n",
      " - 7s - loss: 0.9035 - acc: 0.6995\n",
      "Epoch 36/70\n",
      " - 7s - loss: 0.9062 - acc: 0.6998\n",
      "Epoch 37/70\n",
      " - 7s - loss: 0.9021 - acc: 0.7026\n",
      "Epoch 38/70\n",
      " - 7s - loss: 0.8999 - acc: 0.7016\n",
      "Epoch 39/70\n",
      " - 7s - loss: 0.9001 - acc: 0.7014\n",
      "Epoch 40/70\n",
      " - 7s - loss: 0.8967 - acc: 0.7015\n",
      "Epoch 41/70\n",
      " - 7s - loss: 0.8950 - acc: 0.7011\n",
      "Epoch 42/70\n",
      " - 7s - loss: 0.8925 - acc: 0.7014\n",
      "Epoch 43/70\n",
      " - 7s - loss: 0.8936 - acc: 0.7025\n",
      "Epoch 44/70\n",
      " - 7s - loss: 0.8921 - acc: 0.7026\n",
      "Epoch 45/70\n",
      " - 7s - loss: 0.8892 - acc: 0.7040\n",
      "Epoch 46/70\n",
      " - 7s - loss: 0.8878 - acc: 0.7040\n",
      "Epoch 47/70\n",
      " - 7s - loss: 0.8854 - acc: 0.7039\n",
      "Epoch 48/70\n",
      " - 8s - loss: 0.8883 - acc: 0.7031\n",
      "Epoch 49/70\n",
      " - 8s - loss: 0.8846 - acc: 0.7046\n",
      "Epoch 50/70\n",
      " - 7s - loss: 0.8854 - acc: 0.7043\n",
      "Epoch 51/70\n",
      " - 641s - loss: 0.8788 - acc: 0.7059\n",
      "Epoch 52/70\n",
      " - 11s - loss: 0.8836 - acc: 0.7050\n",
      "Epoch 53/70\n",
      " - 9s - loss: 0.8810 - acc: 0.7049\n",
      "Epoch 54/70\n",
      " - 7s - loss: 0.8819 - acc: 0.7041\n",
      "Epoch 55/70\n",
      " - 8s - loss: 0.8775 - acc: 0.7058\n",
      "Epoch 56/70\n",
      " - 7s - loss: 0.8807 - acc: 0.7054\n",
      "Epoch 57/70\n",
      " - 9s - loss: 0.8797 - acc: 0.7061\n",
      "Epoch 58/70\n",
      " - 7s - loss: 0.8779 - acc: 0.7070\n",
      "Epoch 59/70\n",
      " - 7s - loss: 0.8757 - acc: 0.7079\n",
      "Epoch 60/70\n",
      " - 7s - loss: 0.8774 - acc: 0.7066\n",
      "Epoch 61/70\n",
      " - 8s - loss: 0.8752 - acc: 0.7070\n",
      "Epoch 62/70\n",
      " - 7s - loss: 0.8778 - acc: 0.7070\n",
      "Epoch 63/70\n",
      " - 8s - loss: 0.8723 - acc: 0.7075\n",
      "Epoch 64/70\n",
      " - 7s - loss: 0.8739 - acc: 0.7073\n",
      "Epoch 65/70\n",
      " - 7s - loss: 0.8737 - acc: 0.7077\n",
      "Epoch 66/70\n",
      " - 7s - loss: 0.8707 - acc: 0.7072\n",
      "Epoch 67/70\n",
      " - 8s - loss: 0.8718 - acc: 0.7060\n",
      "Epoch 68/70\n",
      " - 8s - loss: 0.8678 - acc: 0.7079\n",
      "Epoch 69/70\n",
      " - 8s - loss: 0.8680 - acc: 0.7069\n",
      "Epoch 70/70\n",
      " - 8s - loss: 0.8698 - acc: 0.7075\n",
      "[CV]  nodes_l3=50, nodes_l2=120, nodes_l1=170, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.4, batch_size=500, total=19.3min\n",
      "[CV] nodes_l3=50, nodes_l2=120, nodes_l1=170, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.4, batch_size=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=170)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 18s - loss: 2.1966 - acc: 0.4116\n",
      "Epoch 2/70\n",
      " - 7s - loss: 1.4345 - acc: 0.5949\n",
      "Epoch 3/70\n",
      " - 8s - loss: 1.2718 - acc: 0.6276\n",
      "Epoch 4/70\n",
      " - 8s - loss: 1.2029 - acc: 0.6401\n",
      "Epoch 5/70\n",
      " - 9s - loss: 1.1609 - acc: 0.6469\n",
      "Epoch 6/70\n",
      " - 8s - loss: 1.1270 - acc: 0.6515\n",
      "Epoch 7/70\n",
      " - 8s - loss: 1.1029 - acc: 0.6558\n",
      "Epoch 8/70\n",
      " - 8s - loss: 1.0846 - acc: 0.6614\n",
      "Epoch 9/70\n",
      " - 8s - loss: 1.0669 - acc: 0.6633\n",
      "Epoch 10/70\n",
      " - 8s - loss: 1.0518 - acc: 0.6669\n",
      "Epoch 11/70\n",
      " - 8s - loss: 1.0419 - acc: 0.6685\n",
      "Epoch 12/70\n",
      " - 8s - loss: 1.0286 - acc: 0.6718\n",
      "Epoch 13/70\n",
      " - 8s - loss: 1.0214 - acc: 0.6737\n",
      "Epoch 14/70\n",
      " - 8s - loss: 1.0090 - acc: 0.6745\n",
      "Epoch 15/70\n",
      " - 8s - loss: 1.0043 - acc: 0.6764\n",
      "Epoch 16/70\n",
      " - 8s - loss: 0.9927 - acc: 0.6789\n",
      "Epoch 17/70\n",
      " - 8s - loss: 0.9892 - acc: 0.6797\n",
      "Epoch 18/70\n",
      " - 9s - loss: 0.9818 - acc: 0.6814\n",
      "Epoch 19/70\n",
      " - 8s - loss: 0.9780 - acc: 0.6816\n",
      "Epoch 20/70\n",
      " - 7s - loss: 0.9739 - acc: 0.6838\n",
      "Epoch 21/70\n",
      " - 7s - loss: 0.9693 - acc: 0.6850\n",
      "Epoch 22/70\n",
      " - 7s - loss: 0.9635 - acc: 0.6858\n",
      "Epoch 23/70\n",
      " - 8s - loss: 0.9589 - acc: 0.6855\n",
      "Epoch 24/70\n",
      " - 7s - loss: 0.9549 - acc: 0.6866\n",
      "Epoch 25/70\n",
      " - 8s - loss: 0.9522 - acc: 0.6888\n",
      "Epoch 26/70\n",
      " - 8s - loss: 0.9459 - acc: 0.6891\n",
      "Epoch 27/70\n",
      " - 8s - loss: 0.9458 - acc: 0.6886\n",
      "Epoch 28/70\n",
      " - 10s - loss: 0.9465 - acc: 0.6897\n",
      "Epoch 29/70\n",
      " - 8s - loss: 0.9339 - acc: 0.6924\n",
      "Epoch 30/70\n",
      " - 7s - loss: 0.9371 - acc: 0.6924\n",
      "Epoch 31/70\n",
      " - 7s - loss: 0.9359 - acc: 0.6911\n",
      "Epoch 32/70\n",
      " - 7s - loss: 0.9303 - acc: 0.6930\n",
      "Epoch 33/70\n",
      " - 8s - loss: 0.9280 - acc: 0.6932\n",
      "Epoch 34/70\n",
      " - 9s - loss: 0.9278 - acc: 0.6946\n",
      "Epoch 35/70\n",
      " - 8s - loss: 0.9265 - acc: 0.6931\n",
      "Epoch 36/70\n",
      " - 7s - loss: 0.9236 - acc: 0.6950\n",
      "Epoch 37/70\n",
      " - 7s - loss: 0.9205 - acc: 0.6943\n",
      "Epoch 38/70\n",
      " - 7s - loss: 0.9205 - acc: 0.6962\n",
      "Epoch 39/70\n",
      " - 9s - loss: 0.9150 - acc: 0.6958\n",
      "Epoch 40/70\n",
      " - 9s - loss: 0.9174 - acc: 0.6957\n",
      "Epoch 41/70\n",
      " - 9s - loss: 0.9156 - acc: 0.6955\n",
      "Epoch 42/70\n",
      " - 8s - loss: 0.9105 - acc: 0.6975\n",
      "Epoch 43/70\n",
      " - 8s - loss: 0.9106 - acc: 0.6982\n",
      "Epoch 44/70\n",
      " - 9s - loss: 0.9100 - acc: 0.6974\n",
      "Epoch 45/70\n",
      " - 9s - loss: 0.9051 - acc: 0.6974\n",
      "Epoch 46/70\n",
      " - 8s - loss: 0.9062 - acc: 0.6980\n",
      "Epoch 47/70\n",
      " - 8s - loss: 0.9043 - acc: 0.6989\n",
      "Epoch 48/70\n",
      " - 8s - loss: 0.9043 - acc: 0.6991\n",
      "Epoch 49/70\n",
      " - 9s - loss: 0.9042 - acc: 0.6991\n",
      "Epoch 50/70\n",
      " - 9s - loss: 0.9040 - acc: 0.6979\n",
      "Epoch 51/70\n",
      " - 9s - loss: 0.9026 - acc: 0.6995\n",
      "Epoch 52/70\n",
      " - 8s - loss: 0.9009 - acc: 0.7023\n",
      "Epoch 53/70\n",
      " - 9s - loss: 0.8997 - acc: 0.7014\n",
      "Epoch 54/70\n",
      " - 8s - loss: 0.9002 - acc: 0.6995\n",
      "Epoch 55/70\n",
      " - 9s - loss: 0.8970 - acc: 0.7003\n",
      "Epoch 56/70\n",
      " - 9s - loss: 0.8968 - acc: 0.7019\n",
      "Epoch 57/70\n",
      " - 8s - loss: 0.8947 - acc: 0.7006\n",
      "Epoch 58/70\n",
      " - 7s - loss: 0.8932 - acc: 0.7007\n",
      "Epoch 59/70\n",
      " - 8s - loss: 0.8941 - acc: 0.6997\n",
      "Epoch 60/70\n",
      " - 7s - loss: 0.8943 - acc: 0.7009\n",
      "Epoch 61/70\n",
      " - 7s - loss: 0.8915 - acc: 0.7009\n",
      "Epoch 62/70\n",
      " - 7s - loss: 0.8925 - acc: 0.7014\n",
      "Epoch 63/70\n",
      " - 7s - loss: 0.8930 - acc: 0.7008\n",
      "Epoch 64/70\n",
      " - 7s - loss: 0.8927 - acc: 0.7014\n",
      "Epoch 65/70\n",
      " - 7s - loss: 0.8885 - acc: 0.7028\n",
      "Epoch 66/70\n",
      " - 7s - loss: 0.8914 - acc: 0.7010\n",
      "Epoch 67/70\n",
      " - 7s - loss: 0.8920 - acc: 0.7034\n",
      "Epoch 68/70\n",
      " - 7s - loss: 0.8882 - acc: 0.7023\n",
      "Epoch 69/70\n",
      " - 7s - loss: 0.8901 - acc: 0.7041\n",
      "Epoch 70/70\n",
      " - 7s - loss: 0.8874 - acc: 0.7038\n",
      "[CV]  nodes_l3=50, nodes_l2=120, nodes_l1=170, dropout_l3=0.2, dropout_l2=0.2, dropout_l1=0.4, batch_size=500, total= 9.6min\n",
      "[CV] nodes_l3=50, nodes_l2=90, nodes_l1=170, dropout_l3=0.30000000000000004, dropout_l2=0.1, dropout_l1=0.2, batch_size=2000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=170)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 13s - loss: 2.9256 - acc: 0.2558\n",
      "Epoch 2/70\n",
      " - 3s - loss: 2.0176 - acc: 0.4592\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.6346 - acc: 0.5576\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.4442 - acc: 0.6006\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.3425 - acc: 0.6199\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.2768 - acc: 0.6323\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.2266 - acc: 0.6412\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.1926 - acc: 0.6471\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.1625 - acc: 0.6509\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.1484 - acc: 0.6547\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.1225 - acc: 0.6594\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.1086 - acc: 0.6626\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.0900 - acc: 0.6643\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.0812 - acc: 0.6660\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.0722 - acc: 0.6682\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.0595 - acc: 0.6688\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.0469 - acc: 0.6734\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.0405 - acc: 0.6730\n",
      "Epoch 19/70\n",
      " - 3s - loss: 1.0352 - acc: 0.6730\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.0234 - acc: 0.6752\n",
      "Epoch 21/70\n",
      " - 3s - loss: 1.0154 - acc: 0.6789\n",
      "Epoch 22/70\n",
      " - 3s - loss: 1.0080 - acc: 0.6790\n",
      "Epoch 23/70\n",
      " - 3s - loss: 1.0034 - acc: 0.6802\n",
      "Epoch 24/70\n",
      " - 3s - loss: 0.9966 - acc: 0.6816\n",
      "Epoch 25/70\n",
      " - 3s - loss: 0.9930 - acc: 0.6819\n",
      "Epoch 26/70\n",
      " - 3s - loss: 0.9870 - acc: 0.6836\n",
      "Epoch 27/70\n",
      " - 3s - loss: 0.9864 - acc: 0.6845\n",
      "Epoch 28/70\n",
      " - 3s - loss: 0.9776 - acc: 0.6856\n",
      "Epoch 29/70\n",
      " - 3s - loss: 0.9723 - acc: 0.6855\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.9672 - acc: 0.6869\n",
      "Epoch 31/70\n",
      " - 3s - loss: 0.9612 - acc: 0.6878\n",
      "Epoch 32/70\n",
      " - 3s - loss: 0.9603 - acc: 0.6880\n",
      "Epoch 33/70\n",
      " - 3s - loss: 0.9544 - acc: 0.6883\n",
      "Epoch 34/70\n",
      " - 3s - loss: 0.9506 - acc: 0.6900\n",
      "Epoch 35/70\n",
      " - 4s - loss: 0.9502 - acc: 0.6913\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9437 - acc: 0.6918\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9389 - acc: 0.6935\n",
      "Epoch 38/70\n",
      " - 3s - loss: 0.9381 - acc: 0.6933\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.9370 - acc: 0.6932\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.9322 - acc: 0.6949\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.9305 - acc: 0.6943\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.9293 - acc: 0.6946\n",
      "Epoch 43/70\n",
      " - 4s - loss: 0.9235 - acc: 0.6949\n",
      "Epoch 44/70\n",
      " - 4s - loss: 0.9231 - acc: 0.6948\n",
      "Epoch 45/70\n",
      " - 4s - loss: 0.9230 - acc: 0.6958\n",
      "Epoch 46/70\n",
      " - 4s - loss: 0.9183 - acc: 0.6969\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.9145 - acc: 0.6977\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.9136 - acc: 0.6987\n",
      "Epoch 49/70\n",
      " - 4s - loss: 0.9105 - acc: 0.6983\n",
      "Epoch 50/70\n",
      " - 4s - loss: 0.9117 - acc: 0.6999\n",
      "Epoch 51/70\n",
      " - 4s - loss: 0.9079 - acc: 0.6986\n",
      "Epoch 52/70\n",
      " - 4s - loss: 0.9068 - acc: 0.6992\n",
      "Epoch 53/70\n",
      " - 4s - loss: 0.9042 - acc: 0.6997\n",
      "Epoch 54/70\n",
      " - 4s - loss: 0.9027 - acc: 0.7009\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.9010 - acc: 0.7002\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.8989 - acc: 0.7011\n",
      "Epoch 57/70\n",
      " - 4s - loss: 0.8983 - acc: 0.7005\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.8965 - acc: 0.7007\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.8950 - acc: 0.6996\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.8906 - acc: 0.7021\n",
      "Epoch 61/70\n",
      " - 4s - loss: 0.8911 - acc: 0.7027\n",
      "Epoch 62/70\n",
      " - 4s - loss: 0.8882 - acc: 0.7039\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.8868 - acc: 0.7036\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.8871 - acc: 0.7022\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.8856 - acc: 0.7033\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.8833 - acc: 0.7033\n",
      "Epoch 67/70\n",
      " - 4s - loss: 0.8834 - acc: 0.7033\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.8791 - acc: 0.7036\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.8774 - acc: 0.7045\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.8781 - acc: 0.7064\n",
      "[CV]  nodes_l3=50, nodes_l2=90, nodes_l1=170, dropout_l3=0.30000000000000004, dropout_l2=0.1, dropout_l1=0.2, batch_size=2000, total= 4.1min\n",
      "[CV] nodes_l3=50, nodes_l2=90, nodes_l1=170, dropout_l3=0.30000000000000004, dropout_l2=0.1, dropout_l1=0.2, batch_size=2000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=170)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 14s - loss: 2.8464 - acc: 0.2626\n",
      "Epoch 2/70\n",
      " - 4s - loss: 1.9105 - acc: 0.4950\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.5696 - acc: 0.5739\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.4103 - acc: 0.6067\n",
      "Epoch 5/70\n",
      " - 4s - loss: 1.3154 - acc: 0.6240\n",
      "Epoch 6/70\n",
      " - 4s - loss: 1.2538 - acc: 0.6350\n",
      "Epoch 7/70\n",
      " - 4s - loss: 1.2091 - acc: 0.6442\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.1753 - acc: 0.6487\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.1582 - acc: 0.6526\n",
      "Epoch 10/70\n",
      " - 4s - loss: 1.1301 - acc: 0.6589\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.1173 - acc: 0.6581\n",
      "Epoch 12/70\n",
      " - 4s - loss: 1.1012 - acc: 0.6628\n",
      "Epoch 13/70\n",
      " - 4s - loss: 1.0875 - acc: 0.6639\n",
      "Epoch 14/70\n",
      " - 4s - loss: 1.0737 - acc: 0.6679\n",
      "Epoch 15/70\n",
      " - 4s - loss: 1.0577 - acc: 0.6696\n",
      "Epoch 16/70\n",
      " - 4s - loss: 1.0552 - acc: 0.6697\n",
      "Epoch 17/70\n",
      " - 4s - loss: 1.0454 - acc: 0.6717\n",
      "Epoch 18/70\n",
      " - 4s - loss: 1.0333 - acc: 0.6752\n",
      "Epoch 19/70\n",
      " - 5s - loss: 1.0296 - acc: 0.6754\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.0209 - acc: 0.6767\n",
      "Epoch 21/70\n",
      " - 3s - loss: 1.0163 - acc: 0.6770\n",
      "Epoch 22/70\n",
      " - 3s - loss: 1.0079 - acc: 0.6786\n",
      "Epoch 23/70\n",
      " - 4s - loss: 1.0012 - acc: 0.6802\n",
      "Epoch 24/70\n",
      " - 4s - loss: 0.9939 - acc: 0.6808\n",
      "Epoch 25/70\n",
      " - 3s - loss: 0.9877 - acc: 0.6835\n",
      "Epoch 26/70\n",
      " - 3s - loss: 0.9831 - acc: 0.6857\n",
      "Epoch 27/70\n",
      " - 3s - loss: 0.9782 - acc: 0.6852\n",
      "Epoch 28/70\n",
      " - 4s - loss: 0.9749 - acc: 0.6863\n",
      "Epoch 29/70\n",
      " - 4s - loss: 0.9680 - acc: 0.6888\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.9634 - acc: 0.6886\n",
      "Epoch 31/70\n",
      " - 4s - loss: 0.9612 - acc: 0.6889\n",
      "Epoch 32/70\n",
      " - 4s - loss: 0.9572 - acc: 0.6897\n",
      "Epoch 33/70\n",
      " - 4s - loss: 0.9554 - acc: 0.6906\n",
      "Epoch 34/70\n",
      " - 4s - loss: 0.9509 - acc: 0.6912\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9464 - acc: 0.6922\n",
      "Epoch 36/70\n",
      " - 4s - loss: 0.9425 - acc: 0.6937\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9406 - acc: 0.6926\n",
      "Epoch 38/70\n",
      " - 3s - loss: 0.9353 - acc: 0.6945\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.9333 - acc: 0.6932\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.9310 - acc: 0.6943\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.9295 - acc: 0.6948\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.9273 - acc: 0.6959\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.9232 - acc: 0.6968\n",
      "Epoch 44/70\n",
      " - 4s - loss: 0.9195 - acc: 0.6974\n",
      "Epoch 45/70\n",
      " - 4s - loss: 0.9176 - acc: 0.6982\n",
      "Epoch 46/70\n",
      " - 4s - loss: 0.9146 - acc: 0.6996\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.9176 - acc: 0.6969\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.9135 - acc: 0.6990\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.9099 - acc: 0.6986\n",
      "Epoch 50/70\n",
      " - 3s - loss: 0.9046 - acc: 0.6998\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.9038 - acc: 0.7011\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.9037 - acc: 0.6985\n",
      "Epoch 53/70\n",
      " - 3s - loss: 0.9036 - acc: 0.7000\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.9002 - acc: 0.6999\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.9000 - acc: 0.7012\n",
      "Epoch 56/70\n",
      " - 4s - loss: 0.8961 - acc: 0.7008\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.8951 - acc: 0.7020\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.8925 - acc: 0.7026\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.8931 - acc: 0.7019\n",
      "Epoch 60/70\n",
      " - 4s - loss: 0.8924 - acc: 0.7021\n",
      "Epoch 61/70\n",
      " - 4s - loss: 0.8865 - acc: 0.7024\n",
      "Epoch 62/70\n",
      " - 4s - loss: 0.8890 - acc: 0.7035\n",
      "Epoch 63/70\n",
      " - 4s - loss: 0.8882 - acc: 0.7022\n",
      "Epoch 64/70\n",
      " - 4s - loss: 0.8832 - acc: 0.7036\n",
      "Epoch 65/70\n",
      " - 4s - loss: 0.8841 - acc: 0.7037\n",
      "Epoch 66/70\n",
      " - 4s - loss: 0.8809 - acc: 0.7041\n",
      "Epoch 67/70\n",
      " - 4s - loss: 0.8843 - acc: 0.7047\n",
      "Epoch 68/70\n",
      " - 5s - loss: 0.8770 - acc: 0.7051\n",
      "Epoch 69/70\n",
      " - 5s - loss: 0.8769 - acc: 0.7063\n",
      "Epoch 70/70\n",
      " - 4s - loss: 0.8770 - acc: 0.7065\n",
      "[CV]  nodes_l3=50, nodes_l2=90, nodes_l1=170, dropout_l3=0.30000000000000004, dropout_l2=0.1, dropout_l1=0.2, batch_size=2000, total= 4.6min\n",
      "[CV] nodes_l3=50, nodes_l2=90, nodes_l1=170, dropout_l3=0.30000000000000004, dropout_l2=0.1, dropout_l1=0.2, batch_size=2000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=170)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 15s - loss: 2.8444 - acc: 0.2633\n",
      "Epoch 2/70\n",
      " - 3s - loss: 1.9154 - acc: 0.4885\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.5658 - acc: 0.5752\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.4033 - acc: 0.6074\n",
      "Epoch 5/70\n",
      " - 4s - loss: 1.3079 - acc: 0.6263\n",
      "Epoch 6/70\n",
      " - 4s - loss: 1.2455 - acc: 0.6382\n",
      "Epoch 7/70\n",
      " - 3s - loss: 1.2012 - acc: 0.6468\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.1716 - acc: 0.6498\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.1414 - acc: 0.6574\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.1208 - acc: 0.6583\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.1011 - acc: 0.6630\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.0832 - acc: 0.6653\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.0696 - acc: 0.6684\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.0585 - acc: 0.6706\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.0519 - acc: 0.6704\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.0370 - acc: 0.6747\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.0251 - acc: 0.6778\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.0231 - acc: 0.6770\n",
      "Epoch 19/70\n",
      " - 3s - loss: 1.0124 - acc: 0.6798\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.0016 - acc: 0.6813\n",
      "Epoch 21/70\n",
      " - 3s - loss: 0.9942 - acc: 0.6826\n",
      "Epoch 22/70\n",
      " - 3s - loss: 0.9921 - acc: 0.6843\n",
      "Epoch 23/70\n",
      " - 3s - loss: 0.9848 - acc: 0.6849\n",
      "Epoch 24/70\n",
      " - 3s - loss: 0.9788 - acc: 0.6851\n",
      "Epoch 25/70\n",
      " - 3s - loss: 0.9724 - acc: 0.6879\n",
      "Epoch 26/70\n",
      " - 3s - loss: 0.9683 - acc: 0.6870\n",
      "Epoch 27/70\n",
      " - 3s - loss: 0.9618 - acc: 0.6883\n",
      "Epoch 28/70\n",
      " - 3s - loss: 0.9579 - acc: 0.6903\n",
      "Epoch 29/70\n",
      " - 3s - loss: 0.9519 - acc: 0.6914\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.9541 - acc: 0.6914\n",
      "Epoch 31/70\n",
      " - 3s - loss: 0.9478 - acc: 0.6925\n",
      "Epoch 32/70\n",
      " - 3s - loss: 0.9412 - acc: 0.6939\n",
      "Epoch 33/70\n",
      " - 3s - loss: 0.9345 - acc: 0.6937\n",
      "Epoch 34/70\n",
      " - 3s - loss: 0.9343 - acc: 0.6938\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9325 - acc: 0.6950\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9256 - acc: 0.6950\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9272 - acc: 0.6967\n",
      "Epoch 38/70\n",
      " - 3s - loss: 0.9208 - acc: 0.6957\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.9223 - acc: 0.6967\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.9157 - acc: 0.6965\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.9151 - acc: 0.6968\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.9156 - acc: 0.6983\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.9102 - acc: 0.6991\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.9073 - acc: 0.6999\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.9052 - acc: 0.7001\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.9001 - acc: 0.7029\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.9041 - acc: 0.7002\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.8996 - acc: 0.7011\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.8955 - acc: 0.7020\n",
      "Epoch 50/70\n",
      " - 3s - loss: 0.8947 - acc: 0.7024\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.8945 - acc: 0.7020\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.8920 - acc: 0.7015\n",
      "Epoch 53/70\n",
      " - 3s - loss: 0.8883 - acc: 0.7037\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.8892 - acc: 0.7034\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.8879 - acc: 0.7036\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.8851 - acc: 0.7034\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.8816 - acc: 0.7034\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.8824 - acc: 0.7048\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.8799 - acc: 0.7069\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.8773 - acc: 0.7052\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.8757 - acc: 0.7050\n",
      "Epoch 62/70\n",
      " - 4s - loss: 0.8770 - acc: 0.7053\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.8716 - acc: 0.7048\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.8715 - acc: 0.7075\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.8715 - acc: 0.7076\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.8704 - acc: 0.7047\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.8681 - acc: 0.7061\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.8677 - acc: 0.7073\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.8666 - acc: 0.7082\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.8648 - acc: 0.7083\n",
      "[CV]  nodes_l3=50, nodes_l2=90, nodes_l1=170, dropout_l3=0.30000000000000004, dropout_l2=0.1, dropout_l1=0.2, batch_size=2000, total= 4.0min\n",
      "[CV] nodes_l3=50, nodes_l2=90, nodes_l1=170, dropout_l3=0.30000000000000004, dropout_l2=0.1, dropout_l1=0.2, batch_size=2000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=170)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=90)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 13s - loss: 2.8999 - acc: 0.2596\n",
      "Epoch 2/70\n",
      " - 3s - loss: 1.9602 - acc: 0.4769\n",
      "Epoch 3/70\n",
      " - 3s - loss: 1.6047 - acc: 0.5637\n",
      "Epoch 4/70\n",
      " - 3s - loss: 1.4355 - acc: 0.6013\n",
      "Epoch 5/70\n",
      " - 3s - loss: 1.3336 - acc: 0.6214\n",
      "Epoch 6/70\n",
      " - 3s - loss: 1.2689 - acc: 0.6314\n",
      "Epoch 7/70\n",
      " - 4s - loss: 1.2258 - acc: 0.6385\n",
      "Epoch 8/70\n",
      " - 3s - loss: 1.1907 - acc: 0.6443\n",
      "Epoch 9/70\n",
      " - 3s - loss: 1.1585 - acc: 0.6495\n",
      "Epoch 10/70\n",
      " - 3s - loss: 1.1396 - acc: 0.6531\n",
      "Epoch 11/70\n",
      " - 3s - loss: 1.1214 - acc: 0.6565\n",
      "Epoch 12/70\n",
      " - 3s - loss: 1.1058 - acc: 0.6607\n",
      "Epoch 13/70\n",
      " - 3s - loss: 1.0916 - acc: 0.6634\n",
      "Epoch 14/70\n",
      " - 3s - loss: 1.0857 - acc: 0.6629\n",
      "Epoch 15/70\n",
      " - 3s - loss: 1.0677 - acc: 0.6662\n",
      "Epoch 16/70\n",
      " - 3s - loss: 1.0575 - acc: 0.6691\n",
      "Epoch 17/70\n",
      " - 3s - loss: 1.0514 - acc: 0.6698\n",
      "Epoch 18/70\n",
      " - 3s - loss: 1.0397 - acc: 0.6733\n",
      "Epoch 19/70\n",
      " - 3s - loss: 1.0323 - acc: 0.6738\n",
      "Epoch 20/70\n",
      " - 3s - loss: 1.0243 - acc: 0.6766\n",
      "Epoch 21/70\n",
      " - 3s - loss: 1.0161 - acc: 0.6759\n",
      "Epoch 22/70\n",
      " - 3s - loss: 1.0133 - acc: 0.6770\n",
      "Epoch 23/70\n",
      " - 3s - loss: 1.0040 - acc: 0.6783\n",
      "Epoch 24/70\n",
      " - 3s - loss: 0.9981 - acc: 0.6805\n",
      "Epoch 25/70\n",
      " - 3s - loss: 0.9914 - acc: 0.6799\n",
      "Epoch 26/70\n",
      " - 3s - loss: 0.9867 - acc: 0.6827\n",
      "Epoch 27/70\n",
      " - 3s - loss: 0.9848 - acc: 0.6827\n",
      "Epoch 28/70\n",
      " - 3s - loss: 0.9754 - acc: 0.6840\n",
      "Epoch 29/70\n",
      " - 3s - loss: 0.9729 - acc: 0.6858\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.9727 - acc: 0.6853\n",
      "Epoch 31/70\n",
      " - 3s - loss: 0.9626 - acc: 0.6876\n",
      "Epoch 32/70\n",
      " - 4s - loss: 0.9617 - acc: 0.6870\n",
      "Epoch 33/70\n",
      " - 3s - loss: 0.9595 - acc: 0.6874\n",
      "Epoch 34/70\n",
      " - 3s - loss: 0.9555 - acc: 0.6884\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.9499 - acc: 0.6891\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.9450 - acc: 0.6897\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.9461 - acc: 0.6898\n",
      "Epoch 38/70\n",
      " - 3s - loss: 0.9450 - acc: 0.6912\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.9370 - acc: 0.6921\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.9345 - acc: 0.6929\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.9301 - acc: 0.6943\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.9303 - acc: 0.6949\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.9282 - acc: 0.6944\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.9259 - acc: 0.6930\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.9214 - acc: 0.6955\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.9209 - acc: 0.6951\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.9183 - acc: 0.6947\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.9184 - acc: 0.6944\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.9124 - acc: 0.6959\n",
      "Epoch 50/70\n",
      " - 3s - loss: 0.9125 - acc: 0.6969\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.9120 - acc: 0.6975\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.9070 - acc: 0.6983\n",
      "Epoch 53/70\n",
      " - 3s - loss: 0.9037 - acc: 0.6994\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.9059 - acc: 0.6993\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.9040 - acc: 0.6990\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.9017 - acc: 0.6983\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.8994 - acc: 0.6994\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.9007 - acc: 0.6986\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.8976 - acc: 0.6996\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.8949 - acc: 0.7000\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.8936 - acc: 0.7017\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.8921 - acc: 0.7020\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.8901 - acc: 0.7022\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.8892 - acc: 0.7015\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.8860 - acc: 0.7011\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.8870 - acc: 0.7012\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.8859 - acc: 0.7020\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.8825 - acc: 0.7027\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.8813 - acc: 0.7039\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.8842 - acc: 0.7018\n",
      "[CV]  nodes_l3=50, nodes_l2=90, nodes_l1=170, dropout_l3=0.30000000000000004, dropout_l2=0.1, dropout_l1=0.2, batch_size=2000, total= 4.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed: 1214.0min finished\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=170)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
      "  import sys\n",
      "C:\\Users\\Xiuquan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=38)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 13s - loss: 2.8372 - acc: 0.2619\n",
      "Epoch 2/70\n",
      " - 4s - loss: 1.9519 - acc: 0.4744\n",
      "Epoch 3/70\n",
      " - 4s - loss: 1.6059 - acc: 0.5604\n",
      "Epoch 4/70\n",
      " - 4s - loss: 1.4463 - acc: 0.5954\n",
      "Epoch 5/70\n",
      " - 4s - loss: 1.3477 - acc: 0.6146\n",
      "Epoch 6/70\n",
      " - 4s - loss: 1.2819 - acc: 0.6290\n",
      "Epoch 7/70\n",
      " - 4s - loss: 1.2358 - acc: 0.6379\n",
      "Epoch 8/70\n",
      " - 4s - loss: 1.2022 - acc: 0.6430\n",
      "Epoch 9/70\n",
      " - 4s - loss: 1.1731 - acc: 0.6476\n",
      "Epoch 10/70\n",
      " - 4s - loss: 1.1531 - acc: 0.6520\n",
      "Epoch 11/70\n",
      " - 4s - loss: 1.1363 - acc: 0.6537\n",
      "Epoch 12/70\n",
      " - 4s - loss: 1.1224 - acc: 0.6566\n",
      "Epoch 13/70\n",
      " - 4s - loss: 1.1107 - acc: 0.6579\n",
      "Epoch 14/70\n",
      " - 4s - loss: 1.0971 - acc: 0.6605\n",
      "Epoch 15/70\n",
      " - 4s - loss: 1.0839 - acc: 0.6631\n",
      "Epoch 16/70\n",
      " - 4s - loss: 1.0721 - acc: 0.6646\n",
      "Epoch 17/70\n",
      " - 4s - loss: 1.0673 - acc: 0.6661\n",
      "Epoch 18/70\n",
      " - 4s - loss: 1.0524 - acc: 0.6701\n",
      "Epoch 19/70\n",
      " - 4s - loss: 1.0490 - acc: 0.6710\n",
      "Epoch 20/70\n",
      " - 4s - loss: 1.0406 - acc: 0.6722\n",
      "Epoch 21/70\n",
      " - 4s - loss: 1.0298 - acc: 0.6738\n",
      "Epoch 22/70\n",
      " - 5s - loss: 1.0268 - acc: 0.6745\n",
      "Epoch 23/70\n",
      " - 4s - loss: 1.0202 - acc: 0.6754\n",
      "Epoch 24/70\n",
      " - 4s - loss: 1.0148 - acc: 0.6779\n",
      "Epoch 25/70\n",
      " - 4s - loss: 1.0117 - acc: 0.6767\n",
      "Epoch 26/70\n",
      " - 4s - loss: 1.0011 - acc: 0.6799\n",
      "Epoch 27/70\n",
      " - 4s - loss: 0.9991 - acc: 0.6798\n",
      "Epoch 28/70\n",
      " - 4s - loss: 0.9930 - acc: 0.6814\n",
      "Epoch 29/70\n",
      " - 4s - loss: 0.9896 - acc: 0.6822\n",
      "Epoch 30/70\n",
      " - 4s - loss: 0.9843 - acc: 0.6827\n",
      "Epoch 31/70\n",
      " - 4s - loss: 0.9776 - acc: 0.6836\n",
      "Epoch 32/70\n",
      " - 4s - loss: 0.9763 - acc: 0.6834\n",
      "Epoch 33/70\n",
      " - 4s - loss: 0.9697 - acc: 0.6860\n",
      "Epoch 34/70\n",
      " - 4s - loss: 0.9690 - acc: 0.6855\n",
      "Epoch 35/70\n",
      " - 4s - loss: 0.9661 - acc: 0.6873\n",
      "Epoch 36/70\n",
      " - 4s - loss: 0.9601 - acc: 0.6870\n",
      "Epoch 37/70\n",
      " - 4s - loss: 0.9600 - acc: 0.6867\n",
      "Epoch 38/70\n",
      " - 4s - loss: 0.9524 - acc: 0.6888\n",
      "Epoch 39/70\n",
      " - 4s - loss: 0.9544 - acc: 0.6898\n",
      "Epoch 40/70\n",
      " - 4s - loss: 0.9493 - acc: 0.6899\n",
      "Epoch 41/70\n",
      " - 4s - loss: 0.9484 - acc: 0.6889\n",
      "Epoch 42/70\n",
      " - 4s - loss: 0.9440 - acc: 0.6909\n",
      "Epoch 43/70\n",
      " - 4s - loss: 0.9427 - acc: 0.6909\n",
      "Epoch 44/70\n",
      " - 4s - loss: 0.9426 - acc: 0.6903\n",
      "Epoch 45/70\n",
      " - 4s - loss: 0.9378 - acc: 0.6920\n",
      "Epoch 46/70\n",
      " - 4s - loss: 0.9366 - acc: 0.6915\n",
      "Epoch 47/70\n",
      " - 4s - loss: 0.9323 - acc: 0.6931\n",
      "Epoch 48/70\n",
      " - 4s - loss: 0.9331 - acc: 0.6923\n",
      "Epoch 49/70\n",
      " - 4s - loss: 0.9325 - acc: 0.6929\n",
      "Epoch 50/70\n",
      " - 4s - loss: 0.9289 - acc: 0.6936\n",
      "Epoch 51/70\n",
      " - 4s - loss: 0.9279 - acc: 0.6954\n",
      "Epoch 52/70\n",
      " - 4s - loss: 0.9293 - acc: 0.6932\n",
      "Epoch 53/70\n",
      " - 4s - loss: 0.9215 - acc: 0.6946\n",
      "Epoch 54/70\n",
      " - 4s - loss: 0.9219 - acc: 0.6948\n",
      "Epoch 55/70\n",
      " - 4s - loss: 0.9190 - acc: 0.6950\n",
      "Epoch 56/70\n",
      " - 4s - loss: 0.9172 - acc: 0.6957\n",
      "Epoch 57/70\n",
      " - 4s - loss: 0.9159 - acc: 0.6957\n",
      "Epoch 58/70\n",
      " - 4s - loss: 0.9181 - acc: 0.6961\n",
      "Epoch 59/70\n",
      " - 4s - loss: 0.9118 - acc: 0.6969\n",
      "Epoch 60/70\n",
      " - 4s - loss: 0.9139 - acc: 0.6952\n",
      "Epoch 61/70\n",
      " - 4s - loss: 0.9125 - acc: 0.6981\n",
      "Epoch 62/70\n",
      " - 4s - loss: 0.9099 - acc: 0.6972\n",
      "Epoch 63/70\n",
      " - 4s - loss: 0.9091 - acc: 0.6976\n",
      "Epoch 64/70\n",
      " - 4s - loss: 0.9065 - acc: 0.6974\n",
      "Epoch 65/70\n",
      " - 4s - loss: 0.9116 - acc: 0.6963\n",
      "Epoch 66/70\n",
      " - 6s - loss: 0.9068 - acc: 0.6977\n",
      "Epoch 67/70\n",
      " - 6s - loss: 0.9060 - acc: 0.6965\n",
      "Epoch 68/70\n",
      " - 6s - loss: 0.9035 - acc: 0.6987\n",
      "Epoch 69/70\n",
      " - 6s - loss: 0.9023 - acc: 0.6982\n",
      "Epoch 70/70\n",
      " - 6s - loss: 0.9046 - acc: 0.6987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'20:19:03.712927'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "RS3.fit(X, y)\n",
    "end = datetime.now()\n",
    "str(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
       "       'param_nodes_l3', 'param_nodes_l2', 'param_nodes_l1',\n",
       "       'param_dropout_l3', 'param_dropout_l2', 'param_dropout_l1',\n",
       "       'param_batch_size', 'params', 'split0_test_neg_log_loss',\n",
       "       'split1_test_neg_log_loss', 'split2_test_neg_log_loss',\n",
       "       'split3_test_neg_log_loss', 'mean_test_neg_log_loss',\n",
       "       'std_test_neg_log_loss', 'rank_test_neg_log_loss',\n",
       "       'split0_test_accuracy', 'split1_test_accuracy', 'split2_test_accuracy',\n",
       "       'split3_test_accuracy', 'mean_test_accuracy', 'std_test_accuracy',\n",
       "       'rank_test_accuracy'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(RS3.cv_results_).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nodes_l3': 50,\n",
       " 'nodes_l2': 120,\n",
       " 'nodes_l1': 170,\n",
       " 'dropout_l3': 0.2,\n",
       " 'dropout_l2': 0.30000000000000004,\n",
       " 'dropout_l1': 0.30000000000000004,\n",
       " 'batch_size': 3000}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RS3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.707234985471497"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RS3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['rank_test_neg_log_loss', 'mean_test_neg_log_loss', 'rank_test_accuracy', 'mean_test_accuracy', \n",
    "        'param_nodes_l1', 'param_nodes_l2', 'param_nodes_l3', 'param_dropout_l1', 'param_dropout_l2', 'param_dropout_l3', 'param_batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>param_nodes_l1</th>\n",
       "      <th>param_nodes_l2</th>\n",
       "      <th>param_nodes_l3</th>\n",
       "      <th>param_dropout_l1</th>\n",
       "      <th>param_dropout_l2</th>\n",
       "      <th>param_dropout_l3</th>\n",
       "      <th>param_batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.864630</td>\n",
       "      <td>28</td>\n",
       "      <td>0.702908</td>\n",
       "      <td>150</td>\n",
       "      <td>120</td>\n",
       "      <td>70</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>-0.872966</td>\n",
       "      <td>21</td>\n",
       "      <td>0.705228</td>\n",
       "      <td>180</td>\n",
       "      <td>90</td>\n",
       "      <td>80</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>-0.895727</td>\n",
       "      <td>30</td>\n",
       "      <td>0.701810</td>\n",
       "      <td>150</td>\n",
       "      <td>140</td>\n",
       "      <td>50</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>-0.868403</td>\n",
       "      <td>9</td>\n",
       "      <td>0.706482</td>\n",
       "      <td>190</td>\n",
       "      <td>120</td>\n",
       "      <td>70</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>-0.867779</td>\n",
       "      <td>7</td>\n",
       "      <td>0.706524</td>\n",
       "      <td>160</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.861143</td>\n",
       "      <td>4</td>\n",
       "      <td>0.706618</td>\n",
       "      <td>180</td>\n",
       "      <td>140</td>\n",
       "      <td>80</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>-0.864322</td>\n",
       "      <td>8</td>\n",
       "      <td>0.706503</td>\n",
       "      <td>180</td>\n",
       "      <td>120</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24</td>\n",
       "      <td>-0.883255</td>\n",
       "      <td>12</td>\n",
       "      <td>0.706190</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>-0.865108</td>\n",
       "      <td>3</td>\n",
       "      <td>0.706650</td>\n",
       "      <td>160</td>\n",
       "      <td>120</td>\n",
       "      <td>70</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18</td>\n",
       "      <td>-0.870023</td>\n",
       "      <td>10</td>\n",
       "      <td>0.706252</td>\n",
       "      <td>160</td>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20</td>\n",
       "      <td>-0.875789</td>\n",
       "      <td>16</td>\n",
       "      <td>0.705678</td>\n",
       "      <td>170</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>26</td>\n",
       "      <td>-0.887264</td>\n",
       "      <td>19</td>\n",
       "      <td>0.705291</td>\n",
       "      <td>160</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.861874</td>\n",
       "      <td>4</td>\n",
       "      <td>0.706618</td>\n",
       "      <td>190</td>\n",
       "      <td>110</td>\n",
       "      <td>70</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>30</td>\n",
       "      <td>-0.895741</td>\n",
       "      <td>23</td>\n",
       "      <td>0.705155</td>\n",
       "      <td>150</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.860343</td>\n",
       "      <td>15</td>\n",
       "      <td>0.705824</td>\n",
       "      <td>150</td>\n",
       "      <td>140</td>\n",
       "      <td>80</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13</td>\n",
       "      <td>-0.867015</td>\n",
       "      <td>1</td>\n",
       "      <td>0.707235</td>\n",
       "      <td>170</td>\n",
       "      <td>120</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>21</td>\n",
       "      <td>-0.875869</td>\n",
       "      <td>14</td>\n",
       "      <td>0.705887</td>\n",
       "      <td>180</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>-0.865110</td>\n",
       "      <td>2</td>\n",
       "      <td>0.707172</td>\n",
       "      <td>150</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.861552</td>\n",
       "      <td>17</td>\n",
       "      <td>0.705594</td>\n",
       "      <td>170</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.864439</td>\n",
       "      <td>24</td>\n",
       "      <td>0.704706</td>\n",
       "      <td>160</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>27</td>\n",
       "      <td>-0.890590</td>\n",
       "      <td>18</td>\n",
       "      <td>0.705479</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>28</td>\n",
       "      <td>-0.891542</td>\n",
       "      <td>29</td>\n",
       "      <td>0.701936</td>\n",
       "      <td>170</td>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.860405</td>\n",
       "      <td>27</td>\n",
       "      <td>0.703389</td>\n",
       "      <td>180</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>25</td>\n",
       "      <td>-0.884523</td>\n",
       "      <td>26</td>\n",
       "      <td>0.704214</td>\n",
       "      <td>170</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>14</td>\n",
       "      <td>-0.867340</td>\n",
       "      <td>13</td>\n",
       "      <td>0.705970</td>\n",
       "      <td>170</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>11</td>\n",
       "      <td>-0.865357</td>\n",
       "      <td>25</td>\n",
       "      <td>0.704611</td>\n",
       "      <td>160</td>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>22</td>\n",
       "      <td>-0.876415</td>\n",
       "      <td>20</td>\n",
       "      <td>0.705249</td>\n",
       "      <td>160</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>23</td>\n",
       "      <td>-0.876443</td>\n",
       "      <td>6</td>\n",
       "      <td>0.706608</td>\n",
       "      <td>150</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>12</td>\n",
       "      <td>-0.866349</td>\n",
       "      <td>10</td>\n",
       "      <td>0.706252</td>\n",
       "      <td>170</td>\n",
       "      <td>120</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>16</td>\n",
       "      <td>-0.868203</td>\n",
       "      <td>22</td>\n",
       "      <td>0.705218</td>\n",
       "      <td>170</td>\n",
       "      <td>90</td>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank_test_neg_log_loss  mean_test_neg_log_loss  rank_test_accuracy  \\\n",
       "0                        8               -0.864630                  28   \n",
       "1                       19               -0.872966                  21   \n",
       "2                       29               -0.895727                  30   \n",
       "3                       17               -0.868403                   9   \n",
       "4                       15               -0.867779                   7   \n",
       "5                        3               -0.861143                   4   \n",
       "6                        6               -0.864322                   8   \n",
       "7                       24               -0.883255                  12   \n",
       "8                        9               -0.865108                   3   \n",
       "9                       18               -0.870023                  10   \n",
       "10                      20               -0.875789                  16   \n",
       "11                      26               -0.887264                  19   \n",
       "12                       5               -0.861874                   4   \n",
       "13                      30               -0.895741                  23   \n",
       "14                       1               -0.860343                  15   \n",
       "15                      13               -0.867015                   1   \n",
       "16                      21               -0.875869                  14   \n",
       "17                      10               -0.865110                   2   \n",
       "18                       4               -0.861552                  17   \n",
       "19                       7               -0.864439                  24   \n",
       "20                      27               -0.890590                  18   \n",
       "21                      28               -0.891542                  29   \n",
       "22                       2               -0.860405                  27   \n",
       "23                      25               -0.884523                  26   \n",
       "24                      14               -0.867340                  13   \n",
       "25                      11               -0.865357                  25   \n",
       "26                      22               -0.876415                  20   \n",
       "27                      23               -0.876443                   6   \n",
       "28                      12               -0.866349                  10   \n",
       "29                      16               -0.868203                  22   \n",
       "\n",
       "    mean_test_accuracy param_nodes_l1 param_nodes_l2 param_nodes_l3  \\\n",
       "0             0.702908            150            120             70   \n",
       "1             0.705228            180             90             80   \n",
       "2             0.701810            150            140             50   \n",
       "3             0.706482            190            120             70   \n",
       "4             0.706524            160            130             70   \n",
       "5             0.706618            180            140             80   \n",
       "6             0.706503            180            120             50   \n",
       "7             0.706190            150            100             50   \n",
       "8             0.706650            160            120             70   \n",
       "9             0.706252            160             90             60   \n",
       "10            0.705678            170             90             70   \n",
       "11            0.705291            160            100             70   \n",
       "12            0.706618            190            110             70   \n",
       "13            0.705155            150             90             70   \n",
       "14            0.705824            150            140             80   \n",
       "15            0.707235            170            120             50   \n",
       "16            0.705887            180            110             80   \n",
       "17            0.707172            150            120             80   \n",
       "18            0.705594            170            120             80   \n",
       "19            0.704706            160            130             70   \n",
       "20            0.705479            150            100             60   \n",
       "21            0.701936            170             90             60   \n",
       "22            0.703389            180            120             80   \n",
       "23            0.704214            170            130             80   \n",
       "24            0.705970            170            100             60   \n",
       "25            0.704611            160            110             60   \n",
       "26            0.705249            160            100             80   \n",
       "27            0.706608            150            110             80   \n",
       "28            0.706252            170            120             50   \n",
       "29            0.705218            170             90             50   \n",
       "\n",
       "   param_dropout_l1 param_dropout_l2 param_dropout_l3 param_batch_size  \n",
       "0               0.1              0.2              0.2             3000  \n",
       "1               0.1              0.1              0.4             2000  \n",
       "2               0.1              0.2              0.4              500  \n",
       "3               0.3              0.4              0.1              500  \n",
       "4               0.4              0.3              0.1             3000  \n",
       "5               0.4              0.1              0.4             2000  \n",
       "6               0.3              0.1              0.4             1000  \n",
       "7               0.2              0.4              0.3             1000  \n",
       "8               0.4              0.3              0.1             2000  \n",
       "9               0.4              0.2              0.1              500  \n",
       "10              0.1              0.4              0.1             2000  \n",
       "11              0.4              0.3              0.2             3000  \n",
       "12              0.3              0.2              0.1              500  \n",
       "13              0.4              0.2              0.4             2000  \n",
       "14              0.4              0.3              0.1             1000  \n",
       "15              0.3              0.3              0.2             3000  \n",
       "16              0.2              0.4              0.3             1000  \n",
       "17              0.3              0.2              0.2             3000  \n",
       "18              0.1              0.2              0.2             2000  \n",
       "19              0.1              0.2              0.2             1000  \n",
       "20              0.1              0.4              0.3              500  \n",
       "21              0.1              0.2              0.3              500  \n",
       "22              0.3              0.1              0.1             3000  \n",
       "23              0.4              0.3              0.4             3000  \n",
       "24              0.1              0.1              0.3             3000  \n",
       "25              0.2              0.2              0.1              500  \n",
       "26              0.3              0.4              0.1              500  \n",
       "27              0.3              0.3              0.3              500  \n",
       "28              0.4              0.2              0.2              500  \n",
       "29              0.2              0.1              0.3             2000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(RS3.cv_results_)\n",
    "df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>param_nodes_l1</th>\n",
       "      <th>param_nodes_l2</th>\n",
       "      <th>param_nodes_l3</th>\n",
       "      <th>param_dropout_l1</th>\n",
       "      <th>param_dropout_l2</th>\n",
       "      <th>param_dropout_l3</th>\n",
       "      <th>param_batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>-0.868403</td>\n",
       "      <td>9</td>\n",
       "      <td>0.706482</td>\n",
       "      <td>190</td>\n",
       "      <td>120</td>\n",
       "      <td>70</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>-0.867779</td>\n",
       "      <td>7</td>\n",
       "      <td>0.706524</td>\n",
       "      <td>160</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.861143</td>\n",
       "      <td>4</td>\n",
       "      <td>0.706618</td>\n",
       "      <td>180</td>\n",
       "      <td>140</td>\n",
       "      <td>80</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>-0.864322</td>\n",
       "      <td>8</td>\n",
       "      <td>0.706503</td>\n",
       "      <td>180</td>\n",
       "      <td>120</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24</td>\n",
       "      <td>-0.883255</td>\n",
       "      <td>12</td>\n",
       "      <td>0.706190</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>-0.865108</td>\n",
       "      <td>3</td>\n",
       "      <td>0.706650</td>\n",
       "      <td>160</td>\n",
       "      <td>120</td>\n",
       "      <td>70</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18</td>\n",
       "      <td>-0.870023</td>\n",
       "      <td>10</td>\n",
       "      <td>0.706252</td>\n",
       "      <td>160</td>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.861874</td>\n",
       "      <td>4</td>\n",
       "      <td>0.706618</td>\n",
       "      <td>190</td>\n",
       "      <td>110</td>\n",
       "      <td>70</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.860343</td>\n",
       "      <td>15</td>\n",
       "      <td>0.705824</td>\n",
       "      <td>150</td>\n",
       "      <td>140</td>\n",
       "      <td>80</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13</td>\n",
       "      <td>-0.867015</td>\n",
       "      <td>1</td>\n",
       "      <td>0.707235</td>\n",
       "      <td>170</td>\n",
       "      <td>120</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>21</td>\n",
       "      <td>-0.875869</td>\n",
       "      <td>14</td>\n",
       "      <td>0.705887</td>\n",
       "      <td>180</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>-0.865110</td>\n",
       "      <td>2</td>\n",
       "      <td>0.707172</td>\n",
       "      <td>150</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>14</td>\n",
       "      <td>-0.867340</td>\n",
       "      <td>13</td>\n",
       "      <td>0.705970</td>\n",
       "      <td>170</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>23</td>\n",
       "      <td>-0.876443</td>\n",
       "      <td>6</td>\n",
       "      <td>0.706608</td>\n",
       "      <td>150</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>12</td>\n",
       "      <td>-0.866349</td>\n",
       "      <td>10</td>\n",
       "      <td>0.706252</td>\n",
       "      <td>170</td>\n",
       "      <td>120</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank_test_neg_log_loss  mean_test_neg_log_loss  rank_test_accuracy  \\\n",
       "3                       17               -0.868403                   9   \n",
       "4                       15               -0.867779                   7   \n",
       "5                        3               -0.861143                   4   \n",
       "6                        6               -0.864322                   8   \n",
       "7                       24               -0.883255                  12   \n",
       "8                        9               -0.865108                   3   \n",
       "9                       18               -0.870023                  10   \n",
       "12                       5               -0.861874                   4   \n",
       "14                       1               -0.860343                  15   \n",
       "15                      13               -0.867015                   1   \n",
       "16                      21               -0.875869                  14   \n",
       "17                      10               -0.865110                   2   \n",
       "24                      14               -0.867340                  13   \n",
       "27                      23               -0.876443                   6   \n",
       "28                      12               -0.866349                  10   \n",
       "\n",
       "    mean_test_accuracy param_nodes_l1 param_nodes_l2 param_nodes_l3  \\\n",
       "3             0.706482            190            120             70   \n",
       "4             0.706524            160            130             70   \n",
       "5             0.706618            180            140             80   \n",
       "6             0.706503            180            120             50   \n",
       "7             0.706190            150            100             50   \n",
       "8             0.706650            160            120             70   \n",
       "9             0.706252            160             90             60   \n",
       "12            0.706618            190            110             70   \n",
       "14            0.705824            150            140             80   \n",
       "15            0.707235            170            120             50   \n",
       "16            0.705887            180            110             80   \n",
       "17            0.707172            150            120             80   \n",
       "24            0.705970            170            100             60   \n",
       "27            0.706608            150            110             80   \n",
       "28            0.706252            170            120             50   \n",
       "\n",
       "   param_dropout_l1 param_dropout_l2 param_dropout_l3 param_batch_size  \n",
       "3               0.3              0.4              0.1              500  \n",
       "4               0.4              0.3              0.1             3000  \n",
       "5               0.4              0.1              0.4             2000  \n",
       "6               0.3              0.1              0.4             1000  \n",
       "7               0.2              0.4              0.3             1000  \n",
       "8               0.4              0.3              0.1             2000  \n",
       "9               0.4              0.2              0.1              500  \n",
       "12              0.3              0.2              0.1              500  \n",
       "14              0.4              0.3              0.1             1000  \n",
       "15              0.3              0.3              0.2             3000  \n",
       "16              0.2              0.4              0.3             1000  \n",
       "17              0.3              0.2              0.2             3000  \n",
       "24              0.1              0.1              0.3             3000  \n",
       "27              0.3              0.3              0.3              500  \n",
       "28              0.4              0.2              0.2              500  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.rank_test_accuracy<16, cols]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
